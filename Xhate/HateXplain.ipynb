{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/machlovi/Spock-paper/blob/main/X_hate_and_offensive_data_combine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdBpcROn7EF-"
   },
   "source": [
    "## This file uses HateXplain data\n",
    "We are initailizing 2 vector space for 3(after converting them into 2 class) classes in this code. Main idea is to visualize how we can separate words related to each classes in the given space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UYfxZaZz6j8",
    "outputId": "09a73fe3-70ee-4cca-c198-fafbeda639f7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! apt-get install git\n",
    "# !pip install --upgrade protobuf\n",
    "# !pip install --upgrade jupyterlab-server google-api-core cached-path alchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj4pk2f97ALa"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7fS4-4j6y_h",
    "outputId": "6b5de3d8-1951-4e39-8a5e-2a5759d5f38d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/naseem_fordham/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\",20)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# from datasets import load_dataset,Dataset\n",
    "from transformers import AutoModel, BertTokenizerFast, BertModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Importing loss file\n",
    "from custom_loss import CustomLoss, CosineSimilarityLoss, IntraClassLoss, BinaryCrossEntropyLoss, LossValues\n",
    "from BERTdata_loader import BERTDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To display full column and rows values\n",
    "# pd.set_option('display.max_column', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_seq_items', None)\n",
    "# pd.set_option('display.max_colwidth', 500)\n",
    "# pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install numba\n",
    "\n",
    "def on_gpu(f):\n",
    "    def wrapper(*args):\n",
    "        if torch.cuda.is_available():\n",
    "            return f(*args)\n",
    "        else:\n",
    "            print('cuda unavailable')\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This part of the code uses cuda for GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # ! pip install pynvml\n",
    "    from pynvml import *\n",
    "    from numba import cuda\n",
    "\n",
    "@on_gpu\n",
    "def print_gpu_utilization(dev_id):\n",
    "    try:\n",
    "        nvmlInit()\n",
    "        handle = nvmlDeviceGetHandleByIndex(dev_id)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "@on_gpu\n",
    "def free_gpu_cache(dev_id=0):\n",
    "    print(\"Initial GPU Usage\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "GPU memory occupied: 13780 MB.\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)\n",
    "\n",
    "print_gpu_utilization(device_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'distilbert-base-cased'\n",
    "# MODELS_PATH = 'models'\n",
    "# DATASET_NAME = 'imdb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwO1A2SdOWyR"
   },
   "source": [
    "### Hate and offesive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vkjUmWVzTNN_",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def text_preprocessing(text,                                                               # text is a word string ex. 'rahul in ny'\n",
    "#                       punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~='ã¶``''',\n",
    "#                       stop_words = set(stopwords.words(\"english\"))) -> list:\n",
    "\n",
    "#         '''\n",
    "#         A method to preprocess text\n",
    "\n",
    "#         '''\n",
    "\n",
    "#         for x in text.lower():\n",
    "#             if x in punctuations:\n",
    "#                 text = text.replace(x,\"\")\n",
    "\n",
    "#         # removing words that have numbers in them\n",
    "#         text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "#         # remove digits\n",
    "#         text = re.sub(r'[0-9]+', ' ', text)\n",
    "\n",
    "#         # clean the whitespaces\n",
    "\n",
    "#         text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "\n",
    "#         # convert all text to a list\n",
    "\n",
    "#         # text = text.split(' ').  # uncomment if list required\n",
    "#         emoji_pattern = re.compile(\"[\"\n",
    "#                                    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                                    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                                    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                                    u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "#                                    u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "#                                    u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "#                                    u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "#                                    u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "#                                    u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "#                                    u\"\\U00002702-\\U000027B0\"  # Dingbat symbols\n",
    "#                                    u\"\\U000024C2-\\U0001F251\" \n",
    "#                                    \"]+\", flags=re.UNICODE)\n",
    "#         text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "#         # lowercase eth\n",
    "\n",
    "#         text = text.lower()\n",
    "\n",
    "\n",
    "#         # drop the stop words\n",
    "\n",
    "\n",
    "\n",
    "#         # add the tags\n",
    "\n",
    "#         return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HateOffensive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp7FNeAE7M-s",
    "tags": []
   },
   "source": [
    "https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data#Data import\n",
    "\n",
    "Data Source \"https://github.com/t-davidson/33 ##\n",
    "hate-speech-and-offensive-language/blob/master/data/readme.md\"\n",
    "'''hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "In this case 0 non-toxic and 1 -toxic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #loading hate ofefsive data and converting it into 2 class data as toxic and non-toxic\n",
    "# df_data1=pd.read_csv(\"/home/naseem_fordham/Spock-paper/data/labeled_data.csv\")\n",
    "# dataframe=df_data1[['class','tweet']]\n",
    "# dataframe=dataframe.dropna()\n",
    "# dataframe.reset_index(drop=True)\n",
    "# dataframe['class'].unique()\n",
    "\n",
    "# # #initially we have 3 classes and now we are converting them into binary class\n",
    "\n",
    "# dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x in [0., 1.] else 0.0)\n",
    "# # HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "# dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "# dataframe = dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "# # dataframe=HateXplain\n",
    "# dataframe['class'].unique()\n",
    "# # dataframe.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgqQcCnzJ9_i",
    "tags": []
   },
   "source": [
    "### Xhate-999 data set\n",
    "Class 1 hate, Class 0 non-hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "id": "AgABCT3f-VSJ",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# # Use this part for single file\n",
    "# # Define the path to your text file\n",
    "# file_path = \"/gdrive/MyDrive/SPOCK/Dataset/xhate-main/train/XHate999-EN-Gao-train.txt\"\n",
    "\n",
    "# # Initialize empty lists to store data\n",
    "# tweets = []\n",
    "# labels = []\n",
    "\n",
    "# # Read the file line by line\n",
    "# with open(file_path, 'r') as file:\n",
    "#     for line in file:\n",
    "#         # Split the line into text and label using the last character\n",
    "#         line = line.strip()  # Remove leading/trailing whitespace\n",
    "#         text = line[:-2].strip()  # Extract text (excluding the last character)\n",
    "#         label = line[-1]  # Extract the label (as an integer)\n",
    "\n",
    "#         # Append data to lists\n",
    "#         tweets.append(text)\n",
    "#         labels.append(label)\n",
    "\n",
    "# # Create a DataFrame from the lists\n",
    "# df = pd.DataFrame({'Text': tweets, 'Label': labels})\n",
    "# df.drop(0,inplace=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Sp_S78bwGI6h",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Define the directory path where your text files are located\n",
    "# directory_path = \"/gdrive/MyDrive/SPOCK/Dataset/xhate-main/train\"\n",
    "\n",
    "# # Initialize empty lists to store data\n",
    "# tweets = []\n",
    "# labels = []\n",
    "\n",
    "# # Loop through all text files in the specified directory\n",
    "# for filename in glob.glob(os.path.join(directory_path, '*.txt')):\n",
    "#     with open(filename, 'r') as file:\n",
    "\n",
    "#       for line in file:\n",
    "#           # Split the line into text and label using the last character\n",
    "#           line = line.strip()  # Remove leading/trailing whitespace\n",
    "#           text = line[:-2].strip()  # Extract text (excluding the last character)\n",
    "#           label = line[-1]  # Extract the label (as an integer)\n",
    "\n",
    "#           # Append data to lists\n",
    "#           tweets.append(text)\n",
    "#           labels.append(label)\n",
    "\n",
    "# # Create a DataFrame from the lists\n",
    "# df = pd.DataFrame({'tweet': tweets, 'class': labels})\n",
    "# df.drop(0,inplace=True)\n",
    "\n",
    "\n",
    "# df['class']=pd.to_numeric(df['class'], errors='coerce')\n",
    "# df['class'].fillna(0, inplace=True)\n",
    "# df['class']=df['class'].astype(int)\n",
    "# df_hate2=df[df['class']==1]\n",
    "# df_nonhate2=df[df['class']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKc-jTjJSzoM"
   },
   "source": [
    "##Combing hatespeech and xhate data for hate/offensive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HateXplain Dataset\n",
    "Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this work, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales\n",
    "\n",
    "In this case we are using Toxic and Non-toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Here we have implenting attenstion score for HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path =  \"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\"  # Replace this with the actual path to your data file\n",
    "# processor = HateXplain(data_path)\n",
    "\n",
    "# # Call the preprocess_data method to preprocess the data\n",
    "# processed_data = processor.preprocess_data()\n",
    "\n",
    "# # Now you can work with the processed data as needed\n",
    "# print(processed_data.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1639900/4192771600.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['label']='non_toxic'\n",
      "/tmp/ipykernel_1639900/4192771600.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['leng']=df_n['post_tokens'].apply(lambda x: len(x))\n",
      "/tmp/ipykernel_1639900/4192771600.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['rationales'] = df_n['leng'].apply(lambda length: [1/length] *length )\n",
      "/tmp/ipykernel_1639900/4192771600.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales1']=df_ho['rationales'].apply(lambda x: x[0])\n",
      "/tmp/ipykernel_1639900/4192771600.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales2']=df_ho['rationales'].apply(lambda x: x[1])\n",
      "/tmp/ipykernel_1639900/4192771600.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales3']=df_ho['rationales'].apply(lambda x: x[2:3])\n",
      "/tmp/ipykernel_1639900/4192771600.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['sum_result'] = df_ho.apply(lambda row: [a + b + c for a, b, c in zip(row['rationales1'], row['rationales2'],row['rationales1'])], axis=1)\n",
      "/tmp/ipykernel_1639900/4192771600.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['mean']=df_ho['sum_result'].apply(lambda x: [val /3 for val in x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rationales</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>[0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>[1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>guilty until proven innocent unless you are a ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tired i can not support abortion from a moral ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>number number percent of brits think multicult...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all of my exes were cute but they were hoes i ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user condoning drug use not kike at all thanks...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  user i am bit confused coz chinese ppl can not...   \n",
       "1  this bitch in whataburger eating a burger with...   \n",
       "2  laura loomer raped me while screaming at me in...   \n",
       "3  and this is why i end up with nigger trainee d...   \n",
       "4                  nogs jews and dykes how enriching   \n",
       "5  guilty until proven innocent unless you are a ...   \n",
       "6  tired i can not support abortion from a moral ...   \n",
       "7  number number percent of brits think multicult...   \n",
       "8  all of my exes were cute but they were hoes i ...   \n",
       "9  user condoning drug use not kike at all thanks...   \n",
       "\n",
       "                                          rationales  class  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "1  [0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  toxic  \n",
       "4      [1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]  toxic  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...  toxic  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  toxic  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocess import TextPreprocessor  # Import your TextPreprocessor class\n",
    "\n",
    "\n",
    "text_processor = TextPreprocessor()\n",
    "\n",
    "# Continue with the rest of your code...\n",
    "\n",
    "df = pd.read_json(\"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\")\n",
    "df_t=df.T\n",
    "df = pd.read_json(\"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\")\n",
    "df_t=df.T\n",
    "#  extracting each label from nester list\n",
    "df_t['annotators0']=df_t['annotators'].apply(lambda x: x[0]['label'])\n",
    "df_t['annotators1']=df_t['annotators'].apply(lambda x: x[1]['label'])\n",
    "df_t['annotators2']=df_t['annotators'].apply(lambda x: x[2]['label'])\n",
    "\n",
    "# laeblling\n",
    "\n",
    "df_t['annotators0']=df_t['annotators0'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "df_t['annotators1']=df_t['annotators1'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "df_t['annotators2']=df_t['annotators2'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "\n",
    "# dropping some unnecessary columns\n",
    "df_t.drop(['post_id','annotators'],axis=1,inplace=True)\n",
    "\n",
    "# sperating non_toxic\n",
    "df_n = df_t[((df_t['annotators0'] == 2.0) & (df_t['annotators1'] == 2.0) & (df_t['annotators2'] == 2.0)) | (df_t['rationales'].apply(lambda x: len(x) == 0))]\n",
    "df_n['label']='non_toxic'\n",
    "\n",
    "#Generating rationles values for non-rationles by deving the 1 by the total length\n",
    "df_n['leng']=df_n['post_tokens'].apply(lambda x: len(x))\n",
    "df_n['rationales'] = df_n['leng'].apply(lambda length: [1/length] *length )\n",
    "\n",
    "\n",
    "#separating toxic\n",
    "df_ho = df_t[~df_t.index.isin(df_n.index)]\n",
    "\n",
    "\n",
    "# taking mean of rationales\n",
    "df_ho['rationales1']=df_ho['rationales'].apply(lambda x: x[0])\n",
    "df_ho['rationales2']=df_ho['rationales'].apply(lambda x: x[1])\n",
    "df_ho['rationales3']=df_ho['rationales'].apply(lambda x: x[2:3])\n",
    "\n",
    "df_ho['sum_result'] = df_ho.apply(lambda row: [a + b + c for a, b, c in zip(row['rationales1'], row['rationales2'],row['rationales1'])], axis=1)\n",
    "df_ho['mean']=df_ho['sum_result'].apply(lambda x: [val /3 for val in x])\n",
    "\n",
    "df_toxic=df_ho[['post_tokens','mean']].rename(columns={'mean':'rationales'})\n",
    "df_toxic['label']='toxic'\n",
    "\n",
    "df_combine = pd.concat([df_toxic,df_n[['post_tokens','label','rationales']]]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_combine[\"post_tokens\"].values\n",
    "for i in range(len(df_combine[\"post_tokens\"])):\n",
    "    df_combine[\"post_tokens\"][i] = \" \".join(df_combine[\"post_tokens\"][i])\n",
    "\n",
    "# df_combine[\"post_tokens\"] = df_combine[\"post_tokens\"].apply(lambda x : text_preprocessing(x))\n",
    "df_combine[\"post_tokens\"] = df_combine[\"post_tokens\"].apply(lambda x : text_processor.text_preprocessing(x))\n",
    "\n",
    "df_combine.rename(columns={\"post_tokens\":\"tweet\",\"label\":\"class\"},inplace=True)\n",
    "# dataframe=df_combine.sample(frac = 1).reset_index(drop = True)\n",
    "df_combine.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' We have implemented temperature function to change the rationale for sensible. \n",
    "low temperature softmax probs : [0.01,0.01,0.98]\n",
    "high temperature softmax probs : [0.2,0.2,0.6]\n",
    "since we want to differentiate using ket waord we need to use low value'''\n",
    "\n",
    "\n",
    "dataframe=df_combine.copy()\n",
    "\n",
    "dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_processor.text_preprocessing(x))\n",
    "dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x ==\"non_toxic\" else 0.0)\n",
    "\n",
    "\n",
    "Temprature=0.25\n",
    "dataframe['rationales_T']= dataframe['rationales'].apply(lambda x: [val /Temprature for val in x])\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    softmax_values= e_x / e_x.sum(axis=0)\n",
    "    return np.round(softmax_values, 3)\n",
    "\n",
    "# Apply softmax to the 'numbers' column\n",
    "dataframe['softmax_numbers'] = dataframe['rationales_T'].apply(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>softmax_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.005, 0.073, 0.005, 0.005, 0.005, 0.005, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.303, 0.303, 0.08, 0.303, 0.006, 0.006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>it a bitch to find i accidently opened it how ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>anybody notice anything strange on gab like so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.026, 0.026, 0.026, 0.026, 0.026, 0.026, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>graph straftaten gegen die sexuelle selbstbest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.037, 0.037, 0.037, 0.037, 0.037, 0.037, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>an afghani immigrant once told me that in afgh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.023, 0.023, 0.023, 0.023, 0.023, 0.023, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  class  \\\n",
       "0      user i am bit confused coz chinese ppl can not...    0.0   \n",
       "1      this bitch in whataburger eating a burger with...    0.0   \n",
       "2      laura loomer raped me while screaming at me in...    0.0   \n",
       "3      and this is why i end up with nigger trainee d...    0.0   \n",
       "4                      nogs jews and dykes how enriching    0.0   \n",
       "...                                                  ...    ...   \n",
       "20143  it a bitch to find i accidently opened it how ...    1.0   \n",
       "20144  anybody notice anything strange on gab like so...    1.0   \n",
       "20145  graph straftaten gegen die sexuelle selbstbest...    1.0   \n",
       "20146  an afghani immigrant once told me that in afgh...    1.0   \n",
       "20147  was macht der moslem wenn der zion gegen seine...    1.0   \n",
       "\n",
       "                                         softmax_numbers  \n",
       "0      [0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.0...  \n",
       "1      [0.005, 0.073, 0.005, 0.005, 0.005, 0.005, 0.0...  \n",
       "2      [0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.0...  \n",
       "3      [0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0...  \n",
       "4              [0.303, 0.303, 0.08, 0.303, 0.006, 0.006]  \n",
       "...                                                  ...  \n",
       "20143  [0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.0...  \n",
       "20144  [0.026, 0.026, 0.026, 0.026, 0.026, 0.026, 0.0...  \n",
       "20145  [0.037, 0.037, 0.037, 0.037, 0.037, 0.037, 0.0...  \n",
       "20146  [0.023, 0.023, 0.023, 0.023, 0.023, 0.023, 0.0...  \n",
       "20147  [0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...  \n",
       "\n",
       "[20148 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=dataframe[['tweet','class','softmax_numbers']]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # HateXplain Dataset converting into binary class\n",
    "# HateXplain = pd.read_csv('/home/naseem_fordham/Spock-paper/data/Hate_Xplain.csv')\n",
    "# HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "# # HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "# HateXplain[\"text\"] = HateXplain[\"text\"].apply(lambda x : text_preprocessing(x))\n",
    "# HateXplain = HateXplain.sample(frac = 1).reset_index(drop = True)\n",
    "# HateXplain.rename(columns={\"text\":\"tweet\",\"label\":\"class\"},inplace=True)\n",
    "# dataframe=HateXplain\n",
    "# dataframe['class'].unique()\n",
    "# dataframe.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nYkMXWiRRL_p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hate_combine=pd.concat([df_hate,df_hate2]).reset_index(drop=True)\n",
    "# df_nonhat_combine=pd.concat([df_peace,df_nonhate2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2O2ELyIrWKEx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hate_combine[\"tweet\"] = df_hate_combine[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "# df_nonhat_combine[\"tweet\"] = df_nonhat_combine[\"tweet\"].apply(lambda x : text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LMfpk0-oRBjF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe=pd.concat([df_hate_combine ,df_nonhat_combine]).reset_index(drop=True)\n",
    "# dataframe.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "-Y5XnqHVWi9T",
    "outputId": "868f2ad5-0f5c-41c8-b705-f1b3ad8f012f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token lengths distribution in the dataset\n",
    "token_lengths = [len(i.split()) for i in dataframe[\"tweet\"]]\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(token_lengths,bins = 30,edgecolor=\"black\")\n",
    "plt.xticks(ticks = np.linspace(10,100,11))\n",
    "plt.show()\n",
    "dataframe[\"token_length\"] = token_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQEmSl2aS7_T"
   },
   "source": [
    "# Training and validation set\n",
    "We can also consider token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6M-IQ2ZyYVwb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# token_length 128, seems a good fit for data\n",
    "\n",
    "# split training and validation data\n",
    "train_df, val_df = train_test_split(dataframe, test_size= 0.20, stratify= dataframe[\"class\"], random_state = 40)\n",
    "\n",
    "# val_df,   test_df   = train_test_split(temp_df, test_size= 0.80, stratify= temp_df[\"class\"],random_state = 47)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop  = True)\n",
    "# test_df  = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "570b9a872e614e0eab6618f306be7306",
      "34e574772e8b4f81bc7e02e8ebaeb258",
      "1cf66f2a8c5f49ce98d59dae5186298d",
      "71f100b04c964a1bbde06c537f483ed7",
      "9e1caf8b23fb4eb1976f808269d1dd3e",
      "3258d106659040dfb7ffea47c017ed38",
      "f9a2caba063b4a4f98ad258044d012fb",
      "dfd44792f624499b87bd768836016e88",
      "ae841edad05b4ef9b4308308d6683fa3",
      "34bbd1edf06c4a9194bd27eaeeee32b2",
      "ea850e74cb6a4121a456578b29ce7955",
      "d69dfd21bce04204b3220b71b4d4a968",
      "4914d10c0f354e178de66dc11449e26a",
      "f554ec9fe80a408680aa7b0a1c6837ac",
      "f4ec333b7c654876a6caad010e88c203",
      "cfe933364a3147368660f5463f1e5a29",
      "f7998e50af804d66b6af0f26b5588255",
      "4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "31914a14cfa243388f43a02da4db24b6",
      "69d90bdca5174dfb91f5cf124884095e",
      "123641d1426541fba838576dff7f6082",
      "71d0c2b02f0c4a609477bc31aa880938",
      "c12c857f159443f1b2a661fcd7afa002",
      "989933f9c84a47d4b64d5b5441a1f492",
      "2024092105904b418c984aae9f4118bf",
      "4cc5655f9bdb42bca5d80e2849e8cd2b",
      "fd56d3ae17774e5496a7fdcbcb57b874",
      "b5516712d5304670a05ec871eb5896a4",
      "9910be9c8b7b4188936721e958ca15c5",
      "50859aa086814457bcab249b35d486a8",
      "4f0a4e1b4929448a8b0a25b202271a40",
      "ac93c61a19c0474994803853194d2aa8",
      "ee12049f5a9c4505b9769a4ff9c36477",
      "18e134c7af5d45baa952ccf06f96f3d8",
      "21bf2e03eac8419fa693628ab2cef02d",
      "0f14c359d92748268810099e6cdd1fc3",
      "e99b3d05437f4cdf9e1700e3cf466b34",
      "4f1d5a79d7ec4e42add7775fa925b187",
      "e89d668a4fb541ec8d75d171bf899869",
      "430a9d1768614e0596960d2a3d15d69e",
      "909ae03e117345f7a4b53f3045e090b7",
      "06285d669e92494192637cb3ee5a40f4",
      "209ee3e0949b446b8c58c57989065c5a",
      "672e978f9b524c5784553abd8cc91507",
      "17ae300ebf634778862bc211cb432eef",
      "5a072e1f73624ea5aa35e7e18af17f50",
      "1ec35f8bfadb40968f777ab7bbb55184",
      "274875a4aa6047c9903ae3065a5d85c2",
      "a51f1ae4e3bd4563be3eb7c04dec7a60",
      "c7586ac9b41c4e75b02a6c076a458686",
      "8a0c04349bae44f4a7130463ded826d1",
      "9f11959bab964aad822250b6e6853cb8",
      "9b0c918326174bc4b80585a52ac33e32",
      "e38ea829111b4065bad8ad4a4927bc39"
     ]
    },
    "id": "qe9vOPP6TD5-",
    "outputId": "d30dde8d-148a-4d7c-d57d-05ebeb164a73",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load bertModel, bertTokenizer and freeze all layers\n",
    "bertModel = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "bertModel.trainable = False # freezing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109482240"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting model total number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(bertModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from BERTdata_loader import BERTDataset\n",
    "bert_dataset = BERTDataset(text=None, labels=None, attention_scores=None, max_length=None, tokenizer=None, projection_dim=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGGXmXltToJP"
   },
   "source": [
    "# Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "crv2VhKhUBiQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class remove_pads(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, **kwargs):\n",
    "        super(remove_pads, self).__init__(**kwargs)\n",
    "        self.mask_generator = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, inputs, input_ids):\n",
    "        masks = self.mask_generator(input_ids)\n",
    "        masks = masks.float().unsqueeze(-1)\n",
    "        temp = masks.unbind(dim=1)\n",
    "        del temp[0]\n",
    "        temp.insert(0, torch.zeros_like(temp[0]))\n",
    "        masks = torch.stack(temp, dim=1)\n",
    "        length = masks.sum(dim=1, keepdim=True)\n",
    "        masked_embeddings = inputs * masks\n",
    "        masked_embeddings = masked_embeddings.sum(dim=1, keepdim=True)\n",
    "        masked_embeddings /= length\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "class remove_padsV2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, **kwargs):\n",
    "        super(remove_padsV2, self).__init__(**kwargs)\n",
    "        self.mask_generator = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, inputs, input_ids):\n",
    "        filtered_input_ids = torch.where((input_ids == 101) | (input_ids == 102), torch.tensor(0), input_ids)\n",
    "        masks = self.mask_generator(filtered_input_ids)\n",
    "        masks = masks.float().unsqueeze(-1)\n",
    "        masked_embeddings = inputs * masks\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xVIgFoIztcq"
   },
   "source": [
    "Loading Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class SpockModel(nn.Module):\n",
    "    def __init__(self, MAX_LENGTH, PROJECTION_DIM, lambda_value):\n",
    "        super(SpockModel, self).__init__()\n",
    "        self.MAX_LENGTH = MAX_LENGTH\n",
    "        self.PROJECTION_DIM = PROJECTION_DIM\n",
    "        self.lambda_value = lambda_value\n",
    "        self.VECTOR_DIM = 768\n",
    "\n",
    "        # Layers\n",
    "        self.bert_model = bertModel  # Assuming you have defined bertModel elsewhere\n",
    "        self.offensive_embedding_layer = nn.Embedding(PROJECTION_DIM, self.VECTOR_DIM)\n",
    "        self.normal_embedding_layer = nn.Embedding(PROJECTION_DIM, self.VECTOR_DIM)\n",
    "\n",
    "        self.hidden1 = nn.Linear(2 * self.PROJECTION_DIM, 256)\n",
    "        # self.hidden2 = nn.Linear(612, 256)\n",
    "        self.hidden3 = nn.Linear(256, 64)\n",
    "        self.hidden4 = nn.Linear(64, 30)\n",
    "        self.classification_layer = nn.Linear(30, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Loss Functions\n",
    "        self.cosine_loss = CosineSimilarityLoss(name='cosine_loss')\n",
    "        self.intra_loss = IntraClassLoss(name='intra_loss')\n",
    "        self.bce_loss = BinaryCrossEntropyLoss(name='attention_loss')\n",
    "        # self.loss_values = LossValues()\n",
    "\n",
    "\n",
    "    def forward(self, ids, mks, projection_space, attention_score):\n",
    "        input_sentence = self.bert_model(ids, attention_mask=mks)[0].to(device)\n",
    "\n",
    "        offensive_embedding_np = self.offensive_embedding_layer(projection_space)\n",
    "        normal_embedding_np = self.normal_embedding_layer(projection_space)\n",
    "\n",
    "        offensive_embedding = offensive_embedding_np.permute(0, 2, 1)\n",
    "        normal_embedding = normal_embedding_np.permute(0, 2, 1)\n",
    "\n",
    "        offensive_cosine = self.cosine_similarity_projected(input_sentence, offensive_embedding)\n",
    "        normal_cosine = self.cosine_similarity_projected(input_sentence, normal_embedding)\n",
    "\n",
    "        offensive_cosine_nopads = self.remove_padsV2(offensive_cosine, ids)\n",
    "        normal_cosine_nopads = self.remove_padsV2(normal_cosine, ids)\n",
    "\n",
    "        merged = self.merge_functionV2(offensive_cosine_nopads, normal_cosine_nopads)\n",
    "        merged = merged.view(-1, 2 * self.PROJECTION_DIM)\n",
    "\n",
    "        hidden1 = F.relu(self.hidden1(merged))\n",
    "        # hidden2 = F.relu(self.hidden2(hidden1))\n",
    "        hidden3 = F.relu(self.hidden3(hidden1))\n",
    "        hidden4 = F.relu(self.hidden4(hidden3))\n",
    "\n",
    "        predictions = torch.sigmoid(self.classification_layer(hidden4))\n",
    "        # print(predictions)\n",
    "\n",
    "        # # Losses\n",
    "        offensive_normal_loss = self.cosine_loss(torch.mean(offensive_cosine, dim=1), torch.mean(normal_cosine, dim=1))\n",
    "        toxic_intra_loss = self.intra_loss(offensive_cosine)\n",
    "        non_toxic_intra_loss = self.intra_loss(normal_cosine)\n",
    "        bce_loss1 = self.bce_loss(attention_score, hidden4)\n",
    "\n",
    "        # Total Loss\n",
    "        # + self.lambda_value * bce_loss1\n",
    "        loss = offensive_normal_loss + toxic_intra_loss + non_toxic_intra_loss + self.lambda_value * bce_loss1\n",
    "        \n",
    "        # self.loss_values.update(offensive_normal_loss, toxic_intra_loss, non_toxic_intra_loss, bce_loss1)\n",
    "        \n",
    "\n",
    "\n",
    "        return predictions,loss,offensive_normal_loss, toxic_intra_loss, non_toxic_intra_loss, bce_loss1\n",
    "    \n",
    "    \n",
    "    def cosine_similarity_projected(self, x, w):\n",
    "        dp = torch.matmul(x, w)\n",
    "        x_mag = torch.norm(x, dim=2, keepdim=True)\n",
    "        w_mag = torch.norm(w, dim=1, keepdim=True)\n",
    "        cosine = dp / (x_mag * w_mag)\n",
    "        return cosine\n",
    "\n",
    "    def remove_padsV2(self, vects, ids):\n",
    "        masks = ids != 0\n",
    "        masks = masks.unsqueeze(-1).float()\n",
    "        masked_embeddings = vects * masks\n",
    "        return masked_embeddings\n",
    "\n",
    "    def merge_functionV2(self, negative, normal):\n",
    "        negative_max = torch.max(negative, dim=1, keepdim=True)[0]\n",
    "        normal_max = torch.max(normal, dim=1, keepdim=True)[0]\n",
    "        return torch.cat([negative_max, normal_max], dim=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training and Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval(f):\n",
    "    def wrapper(model, *args, **kwargs):\n",
    "        model.eval()\n",
    "        return f(model, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def train(f):\n",
    "    def wrapper(model, *args, **kwargs):\n",
    "        model.train()\n",
    "        return f(model, *args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataloader,val_dataloader=dataprep(3)\n",
    "s=1\n",
    "@train\n",
    "def train_epoch(model, train_dataloader, optimizer):\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # print(step)\n",
    "        # if step==1:\n",
    "        \n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_masks = batch['attention_masks'].to(device)\n",
    "        space = batch['space'].to(device)\n",
    "        attention_score = batch['attention_score'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids, attention_masks, space, attention_score) # (B, Seq_Len, 2)\n",
    "        preds,loss,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss, train_bce_loss1= outputs\n",
    "        loss = torch.mean(loss)  # Compute the mean loss across the batch    \n",
    "        \n",
    "        labels = labels.view(-1, 1).float()\n",
    "        \n",
    "        bce_loss = nn.BCEWithLogitsLoss()(preds.view(-1,1), labels.float())\n",
    "        loss += bce_loss\n",
    "        \n",
    "        train_preds += preds.detach().tolist()\n",
    "        train_labels += [l.item() for l in labels]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "                        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # else:\n",
    "        #     break\n",
    "    return train_loss, train_preds, train_labels,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss, train_bce_loss1\n",
    "\n",
    "@eval\n",
    "def eval_epoch(model, val_dataloader):\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for step, batch in enumerate(val_dataloader):\n",
    "            # if step==1:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_masks = batch['attention_masks'].to(device)\n",
    "            space = batch['space'].to(device)\n",
    "            attention_score = batch['attention_score'].to(device)\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(input_ids, attention_masks, space, attention_score) # (B, Seq_Len, 2)\n",
    "\n",
    "            # loss, logits = outputs.loss, outputs.logits\n",
    "            preds,loss,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss, val_bce_loss1 = outputs\n",
    "            loss=torch.mean(loss)\n",
    "            # print(preds.dtype)\n",
    "\n",
    "\n",
    "            # probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # pred = torch.argmax(probs, dim=-1) # (B)\n",
    "            val_preds += preds.detach().tolist()\n",
    "            val_labels += [l.item() for l in labels]\n",
    "            # print(val_labels,val_preds)\n",
    "            val_loss += loss.item()\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "               \n",
    "    return val_loss, val_preds, val_labels,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss, val_bce_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Metrices\n",
    "def training(model, train_data, val_data, config):\n",
    "    model = model\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    num_train_steps = int(len(train_data) / config['batch_size'] * config['epochs'])\n",
    "    num_train_steps=2\n",
    "\n",
    "    print(f'Train steps: {num_train_steps}')\n",
    "\n",
    "    # train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
    "    # val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=config['val_batch_size'])\n",
    "\n",
    "    history = {\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': [],\n",
    "        'train_f1': [],\n",
    "        'val_f1': [],\n",
    "        'train_precision': [],\n",
    "        'val_precision': [],\n",
    "        'train_recall': [],\n",
    "        'val_recall': [],\n",
    "        'train_offensive_normal_loss': [],\n",
    "        'train_toxic_intra_loss': [],\n",
    "        'train_non_toxic_intra_loss': [],\n",
    "        'train_bce_loss1': [],\n",
    "        'val_offensive_normal_loss': [],\n",
    "        'val_toxic_intra_loss': [],\n",
    "        'val_non_toxic_intra_loss': [],\n",
    "        'val_bce_loss1': []\n",
    "    }\n",
    "    # Inside the training loop\n",
    "    for epoch_num in range(config['epochs']):\n",
    "        print(f'Epoch: {epoch_num + 1}')\n",
    "\n",
    "        # Train stage\n",
    "        train_loss, train_preds, train_labels,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss, train_bce_loss1 = train_epoch(model, train_dataloader, optimizer)\n",
    "\n",
    "        # Eval stage\n",
    "        val_loss, val_preds, val_labels,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss, val_bce_loss1 = eval_epoch(model, val_dataloader)\n",
    "\n",
    "\n",
    "        train_preds_tensor = torch.tensor(train_preds)\n",
    "        val_preds_tensor = torch.tensor(val_preds)\n",
    "\n",
    "        # Get class labels using argmax\n",
    "        train_preds_labels = torch.argmax(train_preds_tensor, dim=1).cpu().numpy()\n",
    "        val_preds_labels = torch.argmax(val_preds_tensor, dim=1).cpu().numpy()\n",
    "        \n",
    "        \n",
    "                \n",
    "\n",
    "        # Metrics calculation\n",
    "        train_acc = accuracy_score(train_labels, train_preds_labels)\n",
    "        val_acc = accuracy_score(val_labels, val_preds_labels)\n",
    "        train_f1 = f1_score(train_labels, train_preds_labels, average='macro')\n",
    "        val_f1 = f1_score(val_labels, val_preds_labels, average='macro')\n",
    "        train_precision = precision_score(train_labels, train_preds_labels, average='weighted')\n",
    "        val_precision = precision_score(val_labels, val_preds_labels, average='weighted')\n",
    "        train_recall = recall_score(train_labels, train_preds_labels, average='weighted')\n",
    "        val_recall = recall_score(val_labels, val_preds_labels, average='weighted')\n",
    "\n",
    "        # Update history dictionary\n",
    "        history['train_losses'].append(train_loss / len(train_dataloader))\n",
    "        history['val_losses'].append(val_loss / len(val_dataloader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['val_recall'].append(val_recall)\n",
    "\n",
    "\n",
    "        \n",
    "        history['train_offensive_normal_loss'].append(train_offensive_normal_loss.detach().cpu().numpy())\n",
    "        history['train_toxic_intra_loss'].append(train_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['train_non_toxic_intra_loss'].append(train_non_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['train_bce_loss1'].append(train_bce_loss1.detach().cpu().numpy())\n",
    "\n",
    "        # Append validation loss values\n",
    "        history['val_offensive_normal_loss'].append(val_offensive_normal_loss.detach().cpu().numpy())\n",
    "        history['val_toxic_intra_loss'].append(val_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['val_non_toxic_intra_loss'].append(val_non_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['val_bce_loss1'].append(val_bce_loss1.detach().cpu().numpy())\n",
    "\n",
    "        print()\n",
    "        print(f'Train loss: {train_loss / len(train_dataloader)} | Val loss: {val_loss / len(val_dataloader)}')\n",
    "        print(f'Train acc: {train_acc} | Val acc: {val_acc}')\n",
    "        print(f'Train f1: {train_f1} | Val f1: {val_f1}')\n",
    "        print(f'Train precision: {train_precision} | Val precision: {val_precision}')\n",
    "        print(f'Train recall: {train_recall} | Val recall: {val_recall}')\n",
    "        \n",
    "        \n",
    "\n",
    "    # Free GPU cache if necessary\n",
    "    free_gpu_cache(device_id)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 19739 MB.\n",
      "Initial GPU Usage\n",
      "GPU memory occupied: 18573 MB.\n",
      "GPU Usage after emptying the cache\n",
      "GPU memory occupied: 18573 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization(device_id)\n",
    "torch.cuda.empty_cache()\n",
    "free_gpu_cache(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train steps: 2\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 5.5883534238452 | Val loss: 4.357758752883426\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 4.933583212277246 | Val loss: 4.043073487660242\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 4.573294027457162 | Val loss: 3.6908764763483926\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 4.216786133864569 | Val loss: 3.362045034529671\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 3.886324444933543 | Val loss: 3.040017216924637\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 3.6216006714200217 | Val loss: 2.8179283028557185\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 3.443900103133822 | Val loss: 2.6885629021932207\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 3.359435072020879 | Val loss: 2.640433635030474\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 3.33332997891638 | Val loss: 2.634206084978013\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Epoch: 10\n",
      "\n",
      "Train loss: 3.331258787995293 | Val loss: 2.6339790348022705\n",
      "Train acc: 0.5665715349298921 | Val acc: 0.5665012406947891\n",
      "Train f1: 0.3616633663366337 | Val f1: 0.3616347220022177\n",
      "Train precision: 0.3210033041928139 | Val precision: 0.3209236557087354\n",
      "Train recall: 0.5665715349298921 | Val recall: 0.5665012406947891\n",
      "Initial GPU Usage\n",
      "GPU memory occupied: 20863 MB.\n",
      "GPU Usage after emptying the cache\n",
      "GPU memory occupied: 17097 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_LEN = 30\n",
    "PROJECTION_DIM = 2\n",
    "NUM_EPOCHS=10\n",
    "BATCH_SIZE=32\n",
    "LEARNING_RATE=0.001\n",
    "w1=0.5\n",
    "w2=0.5\n",
    "\n",
    "# VECTOR_DIM = 768\n",
    "lambda_value = 0.2\n",
    "EPOCHS = 3\n",
    "\n",
    "# Initialize model\n",
    "spock_model = SpockModel(MAX_LEN, PROJECTION_DIM, lambda_value)\n",
    "# spock_model.to(device)\n",
    "\n",
    "\n",
    "# train_dataloader,val_dataloader=dataprep(PROJECTION_DIM)\n",
    "# Call the dataprep method on the object\n",
    "train_dataloader,val_dataloader = bert_dataset.dataprep(train_df, val_df, tokenizer, MAX_LEN, BATCH_SIZE, PROJECTION_DIM)\n",
    "\n",
    "config = {\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'val_batch_size': BATCH_SIZE,\n",
    "    \n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'fp16': False,\n",
    "    'lr': LEARNING_RATE,\n",
    "    # 'max_grad_norm': MAX_GRAD_NORM,\n",
    "    'weight_decay': 0.01,\n",
    "}\n",
    "history = training(spock_model.to(device), train_dataloader, val_dataloader, config)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_losses', 'val_losses', 'train_acc', 'val_acc', 'train_f1', 'val_f1', 'train_precision', 'val_precision', 'train_recall', 'val_recall', 'train_offensive_normal_loss', 'train_toxic_intra_loss', 'train_non_toxic_intra_loss', 'train_bce_loss1', 'val_offensive_normal_loss', 'val_toxic_intra_loss', 'val_non_toxic_intra_loss', 'val_bce_loss1'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_results(history, do_val=True):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 10))\n",
    "\n",
    "    # Losses\n",
    "    axs[0, 0].plot(history['train_losses'], label='Train Loss')\n",
    "    if do_val:\n",
    "        axs[0, 0].plot(history['val_losses'], label='Validation Loss')\n",
    "    axs[0, 0].set_title('Train / Validation Loss')\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Accuracy\n",
    "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy')\n",
    "    if do_val:\n",
    "        axs[0, 1].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axs[0, 1].set_title('Train / Validation Accuracy')\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('Accuracy')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # F1 Score\n",
    "    # axs[1, 0].plot(history['train_f1'], label='Train F1 Score')\n",
    "    \n",
    "    axs[1, 0].plot(history['train_offensive_normal_loss'], label='train_offensive_normal_loss')\n",
    "    if do_val:\n",
    "        axs[1, 0].plot(history['val_offensive_normal_loss'], label='val_offensive_normal_loss')\n",
    "\n",
    "    axs[1, 0].set_title('Train / Validation offensive_normal_loss')\n",
    "    axs[1, 0].set_xlabel('Epochs')\n",
    "    axs[1, 0].set_ylabel('offensive_normal_loss')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Precision\n",
    "    \n",
    "    axs[1,1].plot(history['train_toxic_intra_loss'], label='train_toxic_intra_loss')\n",
    "\n",
    "    if do_val:\n",
    "        axs[1,1].plot(history['train_non_toxic_intra_loss'], label='train_non_toxic_intra_loss')\n",
    "    # axs[1, 1].plot(history['train_precision'], label='Train Precision')\n",
    "    # if do_val:\n",
    "    #     axs[1, 1].plot(history['val_precision'], label='Validation Precision')\n",
    "    axs[1, 1].set_title('Toxic/ Non_Toxix intra_loss')\n",
    "    axs[1, 1].set_xlabel('Epochs')\n",
    "    axs[1, 1].set_ylabel('Intra_loss')\n",
    "    axs[1, 1].legend()\n",
    "    \n",
    "        # axs[1,1].plot(history['train_toxic_intra_loss'], label='train_toxic_intra_loss')\n",
    "\n",
    "    if do_val:\n",
    "        axs[2,0].plot(history['train_bce_loss1'], label='train_bce_loss1')\n",
    "        axs[2, 0].plot(history['val_bce_loss1'], label='Trainval_bce_loss1')\n",
    "    # if do_val:\n",
    "    #     axs[1, 1].plot(history['val_precision'], label='Validation Precision')\n",
    "    axs[2,0].set_title('train_bce_loss1/ val_bce_loss1')\n",
    "    axs[2,0].set_xlabel('Epochs')\n",
    "    axs[2,0].set_ylabel('BCE_loss1')\n",
    "    axs[2,0].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_results(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "OJHKxhG4Uphm",
    "outputId": "8e989294-bc36-4224-f212-269241763980",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# Set up hyperparameters\n",
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 16\n",
    "PROJECTION_DIM = 30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value = 2\n",
    "EPOCHS = 20\n",
    "PROJECTION_DIM = 10  # You redefined PROJECTION_DIM here, it might not be necessary\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "spock_model1 = SpockModel(MAX_LENGTH, PROJECTION_DIM, lambda_value)\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Define your loss function\n",
    "optimizer = optim.Adam(spock_model1.parameters(), lr=0.001)  # Define your optimizer\n",
    "train_ds,val_ds=dataprep(PROJECTION_DIM)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_ds):\n",
    "        # Get the inputs, attention masks, space, attention score, and labels from the dictionary\n",
    "        input_ids = data['input_ids']\n",
    "        attention_masks = data['attention_masks']\n",
    "        space = data['space']\n",
    "        attention_score = data['attention_score']\n",
    "        labels = data['label']\n",
    "        \n",
    "        \n",
    "        # print(input_ids.shape,attention_masks.shape,space.shape,attention_score.shape)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # print('ok')\n",
    "\n",
    "        # Forward pass\\ids, mks, projection_space, attention_score\n",
    "        outputs, loss = spock_model1(input_ids, attention_masks, space, attention_score)\n",
    "        # print('ok3')\n",
    "\n",
    "        # Calculate loss\n",
    "        \n",
    "        labels=labels.view(-1,1)\n",
    "        # print(outputs.dtype,labels.dtype)\n",
    "        # print(outputs.shape,labels.shape)\n",
    "        labels = labels.float()\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        # print('ok')\n",
    "\n",
    "        # Backward pass and optimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print('ok')\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5== 1999:  # Print every 2000 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Log loss to TensorBoard\n",
    "    writer.add_scalar(\"training_loss\", running_loss, epoch)\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiazliz the tensorboard to visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1st laod the teansorbaord before tarining\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 30\n",
    "# BATCH_SIZE = 16\n",
    "# PROJECTION_DIM =30\n",
    "# VECTOR_DIM = 768\n",
    "# \n",
    "# spock_model1= spock_model(MAX_LENGTH, PROJECTION_DIM)\n",
    "# spock_model1.summary()\\\n",
    "# tf.keras.backend.clear_session()\n",
    "# print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "# # Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ps aux | grep tensorboard\n",
    "# # !kill 146651\n",
    "# !pkill -f tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Model and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 32\n",
    "# PROJECTION_DIM =30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##incase the port is already using, we have to kill it forst\n",
    "# !lsof -i :6006\n",
    "# !kill 148692\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#laod the tensor board with passing the base path. Note incase of runing on VPN, I need to \n",
    "# http://192.168.1.206:8000/user/naseem_fordham/proxy/6006/ where 6006 is the local host port\n",
    "# %tensorboard --logdir $BASE_PATH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accuracy plots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot(history,path):\n",
    "    # Create a new figure for the combined plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot accuracy on the first subplot\n",
    "    axs[0].plot(history['accuracy'])\n",
    "    axs[0].plot(history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy', fontsize=12)\n",
    "    axs[0].set_ylim(0, 1, 0.1)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axs[0].legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    # Plot loss on the second subplot\n",
    "\n",
    "\n",
    "    axs[1].plot(history['loss'])\n",
    "    axs[1].plot(history['val_loss'])\n",
    "    axs[1].plot(history['Interspace'])\n",
    "    axs[1].plot(history['ToxicIntra_Loss'])\n",
    "    axs[1].plot(history['Non_toxicIntra_Loss'])\n",
    "    axs[1].plot(history['Attention_Loss'])\n",
    "    \n",
    " \n",
    "\n",
    "    axs[1].set_title('Model Loss', fontsize=12)\n",
    "    axs[1].set_ylim(0, 15, 1)\n",
    "    axs[1].set_ylabel('Loss', fontsize=12)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss','posStdDevLoss','norStdDevLoss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    axs[1].legend(['Train', 'Validation','Interspace','ToxicIntra_Loss','Non_toxicIntra_Loss','Attention_loss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "    # axs[1].legend(['Train', 'Validation','ToxicIntra_Loss','Non_toxicIntra_Loss','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    # Adjust spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    # Save the combined plot as a single image\n",
    "    plt.savefig(path, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model laoding from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def predictionLabels(i):\n",
    "    return np.where(i < 0.5, 0.0, 1.0)\n",
    "\n",
    "    \n",
    "    \n",
    "    # return np.argmax(i, axis=1)\n",
    "\n",
    "pattern = r\"_([0-9]+)$\"\n",
    "\n",
    "\n",
    "getLabels = np.vectorize(predictionLabels)\n",
    "# predictions = model.predict(test_ds)\n",
    "# predictedLabels = getLabels(predictions)\n",
    "\n",
    "BASE_PATH = f\"/home/naseem_fordham/Spock-paper/Spock_Hateoffensive/\"\n",
    "\n",
    "accuracy=[]\n",
    "# Iterate over subdirectories\n",
    "for folder_name in os.listdir(BASE_PATH):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(BASE_PATH, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        match = re.search(pattern, folder_name)\n",
    "        if match:\n",
    "            model_number = match.group(1)\n",
    "            print(folder_path)\n",
    "            spock_model2 = spock_model(MAX_LENGTH, int(model_number),lambda_value)\n",
    "            model_filename = os.path.join(folder_path, f\"CS_{model_number}.h5\")\n",
    "            print(model_filename)\n",
    "\n",
    "            if os.path.exists(model_filename):\n",
    "                spock_model2.load_weights(model_filename)\n",
    "                \n",
    "                history=np.load(f\"{folder_path}/training_history{model_number}.pkl\",allow_pickle=True)\n",
    "                accuracy.append(history['val_accuracy'][-1])\n",
    "                \n",
    "                # print(f\"Loaded model from {model_filename,model_number}\")\n",
    "                train_ds, val_ds = dataprep(int(model_number))\n",
    "\n",
    "                # Calculate the confusion matrix\n",
    "                predictions = spock_model2.predict(val_ds)\n",
    "                predictedLabels = predictionLabels(predictions)\n",
    "                cm = confusion_matrix(val_df['class'].values, predictedLabels)\n",
    "\n",
    "                # Calculate the confusion matrix as percentages\n",
    "                cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['Toxic', 'Non-Toxic'])\n",
    "\n",
    "                # Calculate the classification report\n",
    "                clf_report = classification_report(val_df['class'],\n",
    "                                                   predictedLabels,\n",
    "                                                   target_names=['Toxic', 'Non-Toxic'],\n",
    "                                                   output_dict=True)\n",
    "\n",
    "\n",
    "                # Create a new figure for the combined plot\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "                # Plot the confusion matrix as percentages on the left\n",
    "                disp.plot(cmap=plt.cm.Blues, values_format=\".2f\", ax=axs[0])\n",
    "                axs[0].set_title(f'Confusion Matrix of CS_{model_number}')\n",
    "\n",
    "                # Plot the classification report as a heatmap on the right\n",
    "                sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, ax=axs[1])\n",
    "                axs[1].set_title(f'Classification Report of CS_{model_number}')\n",
    "\n",
    "                # Adjust spacing between subplots\n",
    "                plt.subplots_adjust(wspace=0.5)\n",
    "                \n",
    "                \n",
    "                           # Save the combined plot as a single image\n",
    "                plt.savefig(f'{folder_path}/combined_CS_{model_number}.png')\n",
    "                plot(history,f'{folder_path}/Acc_loss{model_number}.png')\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weights and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "U7gwzlktUtH9",
    "outputId": "56a7955b-b7bf-49f7-c6b5-135b4bcb0926"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS CELL AFTER MODEL TRAINING\n",
    "\n",
    "# save model history\n",
    "\n",
    "with open(f\"{BASE_PATH}/training_historyV4.pkl\",\"wb\") as hist:\n",
    "  pickle.dump(history.history,hist)\n",
    "\n",
    "# history=np.save(f\"/home/naseem_fordham/Hate_Xplain/history/C_loss_history_{PROJECTION_DIM}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/naseem_fordham/Spock-paper/Spock_HateXplain\"\n",
    "model.load_weights(f\"{BASE_PATH}/test3.h5\")\n",
    "history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23gCGD8ZeJfE",
    "outputId": "43e84bd0-3285-47e0-9b26-f5ed8ba6102f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BASE_PATH='/home/naseem_fordham/Spock-paper/'\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)\n",
    "# history\n",
    "# import pickle\n",
    "\n",
    "# with open('/home/naseem_fordham/Spock-paper/Random_w/Model/training_historyV4.pkl', 'rb') as f:\n",
    "#     loaded_data = np.load(f,allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3kEUFa9eRfk"
   },
   "outputs": [],
   "source": [
    "# prepare test data for evaluation:\n",
    "test_gen   = dataset(test_df[\"tweet\"].values,test_df[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer, projection_dim=PROJECTION_DIM, val = True)\n",
    "test_ds = tf.data.Dataset.from_generator(test_gen,\n",
    "                                            output_signature = \n",
    "                                           ({\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VcYiveLe-Ki"
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "def predictionLabels(i):\n",
    "     return np.argmax(i, axis=1)\n",
    "\n",
    "  # if i < 0.5:\n",
    "  #   return 0.0\n",
    "  # else:\n",
    "  #   return 1.0\n",
    "\n",
    "# getLabels = np.vectorize(predictionLabels)\n",
    "predictions = model.predict(test_ds)\n",
    "predictedLabels = predictionLabels(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-Cv6nLJsSsL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "predictedLabels = predictionLabels(predictions)\n",
    "\n",
    "confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "ConfusionMatrixDisplay.from_predictions(test_df['class'].values, predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "\n",
    "# Calculate the confusion matrix as percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['0','1','2'])  # You should define class_labels\n",
    "\n",
    "# Plot the confusion matrix as percentages\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nIV_XQ00gUYz",
    "outputId": "a28ee2c7-3d22-4fa8-a4fc-16b73454c70b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# print(classification_report(y_test, predictedLabels))\n",
    "clf_report = classification_report(test_df['class'],\n",
    "                                   predictedLabels,\n",
    "                                   \n",
    "                                   target_names=[0,1,2],\n",
    "                                   output_dict=True)\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-1xVwjAJgVrt",
    "outputId": "2b7f24a8-291e-4f8b-a5a3-cf9d89f07aaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.ylim(0,1,0.1)\n",
    "\n",
    "plt.ylabel('accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',{'fontsize' : 12})\n",
    "# plt.ylim(0, ,0.05)\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation accuracy')\n",
    "# display(plt.show())\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain//acc.png\",dpi=300)\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain/Plots/plots{PROJECTION_DIM}/accu_{PROJECTION_DIM}.png\",dpi=300)\n",
    "\n",
    "#skip: plt.savefig(\"/gdrive/Shareddrives/Thesis/Results_for_thesis/spock_xhate_acc.png\",dpi=300)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# plt.yticks(np.arange(0,1,step=.1))\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.ylim(0,3,0.1)\n",
    "\n",
    "# plt.title('Training loss vs Validation Loss',fontdict = {'fontsize' : 12})\n",
    "plt.ylabel('loss',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',fontdict = {'fontsize' : 12})\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime Explainibity\n",
    "In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification## In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in train_ds.take(1):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0][\"input_ids\"]\n",
    "# # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# laoding data set and performning cleaning to ready for feed funtion,\n",
    "# here we have assigned a tem class to our data set\n",
    "df_test=pd.read_csv('/home/naseem_fordham/Spock-paper/test.txt',sep='/n', header=None,engine='python')\n",
    "df_test = df_test.rename(columns={0: 'tweet'})\n",
    "df_test\n",
    "\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "df_test['class']=1\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create generators for train and validation\n",
    "BATCH_SIZE = 32\n",
    "# make sure batch size complies with total data set\n",
    "lime_gen = dataset(df_test[\"tweet\"].values,df_test[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer,projection_dim=PROJECTION_DIM)\n",
    "\n",
    "# create tensorflow dataloaders from generators\n",
    "lime_ds = tf.data.Dataset.from_generator(lime_gen,\n",
    "                                            output_signature =\n",
    "                                           ( {\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict function which will be use later for each text in sentence\n",
    "def predict_fun(x):\n",
    "    return model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(1):\n",
    "#     t=ele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['non_hate','hate'])\n",
    "# exp=explainer.explain_instance(x, predict_fun, num_features=90, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_test['tweet'].iloc[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementing LIME on each sentence\n",
    "\"\"\"Interpretability: If you want highly interpretable explanations that focus on the most salient \n",
    "words or terms, you may choose a lower num_features value.\n",
    "\n",
    "Comprehensiveness: If you want a more comprehensive understanding of why the model made a particular\n",
    "prediction and are willing to explore a larger number of words or terms, you may choose a higher num_features value.\"\"\"\n",
    "\n",
    "\n",
    "''' 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "for i in range(1,10):\n",
    "\n",
    "    x=df_test['tweet'].iloc[i]\n",
    "    # num=len(df_test['tweet'].iloc[i].split())\n",
    "    \n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=['hate','offensive','normal'])\n",
    "    exp=explainer.explain_instance(x, predict_fun, num_features=6, labels=(0,1), num_samples=10, distance_metric='cosine')\n",
    "    exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime EXplaniation Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(0):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0]\n",
    "# # # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_res= list()\n",
    "# for tweet in df_test['tweet']:\n",
    "#   tweet = text_preprocessing(tweet)\n",
    "#   test_res.append(tweet)\n",
    "#     # print(tweet)\n",
    "\n",
    "# df_test['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96kydpg1iWwm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Input_ids=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1]))\n",
    "# # bertModel = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "# # tokenizer \n",
    "# '''In this part we are creating the bert inputs for our model and pass it to the model to predicts the class. \n",
    "# Later on we pass this predict model to LIME to underrstand which part of text is more relavent as per our model prediction'''\n",
    "\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# bmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# import torch\n",
    "# def predict(x):\n",
    "#     encoded = tokenizer(\n",
    "#     text=df_test['tweet'].tolist(),  # the sentence to be encoded\n",
    "#     add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "#     max_length = 45,  # maximum length of a sentence\n",
    "#     padding='max_length',  # Add [PAD]s\n",
    "#     return_attention_mask = True,  # Generate the attention mask\n",
    "#     return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "\n",
    "#   )\n",
    "#   # print(encoded)\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         outputs = bmodel(**encoded)\n",
    "\n",
    "#         # Evaluating the model will return a different number of objects based on \n",
    "#         # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "#         # becase we set `output_hidden_states = True`, the third item will be the \n",
    "#         # hidden states from all layers. See the documentation for more details:\n",
    "#         # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "#         # hidden_states = outputs[2]\n",
    "#         # violent_hidden_states = violent_outputs[2]\n",
    "\n",
    "#         last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "#     # print(last_hidden_states)\n",
    "\n",
    "#     x_test=last_hidden_states.numpy()\n",
    "#     # print(x_test.shape)\n",
    "#     Inputs_test=encoded['input_ids']\n",
    "#     # print(Inputs_test.shape)\n",
    "#     Inputs_test=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1])).numpy()\n",
    "#     print(Inputs_test.shape)\n",
    "\n",
    "\n",
    "#     # print(x_test.shape,Inputs_test.shape)\n",
    "#     embedding_test=embedding_index[0].reshape(embedding_index[0].shape[0],1)\n",
    "#     # embedding_test=embedding_index[:30]\n",
    "#   # embedding_test=embedding_index[:30].reshape(30,embedding_index[:30].shape[1],1)\n",
    "#   # embedding_test=embedding_index[:10].reshape(10,embedding_index.shape[1])\n",
    "#   # return model.predict([x_test,Inputs_test,embedding_test])\n",
    "  \n",
    "#     # print(embedding_test.shape)\n",
    "#     print(x_test.shape,Inputs_test.shape,embedding_test.shape)\n",
    "#     return np.array([[float(1-x), float (x)] for x in model.predict(lime_ds)])\n",
    "#     # return last_hidden_states\n",
    "# # model.predict([x_train,Input_ids,embedding_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def return_embedding_index(count):\n",
    "  \n",
    "#   embedding_index=np.array([i for i in range(count)])\n",
    "#   # embeding_index=np.array([[0,1,2]])\n",
    "#   embeding_index=np.ravel(embedding_index)\n",
    "\n",
    "#   embedding_index=np.tile(embedding_index,(len(df_test),1,))\n",
    "#   # print(embedding_index.shape, type(embeding_index))\n",
    "#   return embedding_index\n",
    "\n",
    "# embedding_index = return_embedding_index(PROJECTION_DIM)\n",
    "# embedding_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "# exp=explainer.explain_instance(x, predict, num_features=60, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# #num of sample must be same as length of the data set \n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "# for i in range(10):\n",
    "\n",
    "#     x=df_test['tweet'].iloc[i]\n",
    "\n",
    "#     explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "#     exp=explainer.explain_instance(x, predict, num_features=30, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "#     #num of sample must be same as length of the data set \n",
    "#     exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Concept Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "\n",
    "\n",
    "hate_layer = model.get_layer('hate_embedding')\n",
    "hate_embedding = hate_layer.get_weights()\n",
    "# positive_weights=positive_weights[0].T\n",
    "\n",
    "\n",
    "offensive_layer = model.get_layer('offensive_embedding')\n",
    "offensive_embedding = offensive_layer.get_weights()\n",
    "\n",
    "\n",
    "normal_layer = model.get_layer('normal_embedding')\n",
    "normal_embedding = normal_layer.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# positive_embedding = model.get_layer('positive_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# positive_embedding = specific_layer.get_weights()\n",
    "# positive_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# negative_embedding = model.get_layer('negative_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# negative_embedding = specific_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you have two weight vectors of shape (10, 768)\n",
    "\n",
    "\n",
    "\n",
    "# # Combine the two weight vectors into one array\n",
    "# combined_weight_vectors = np.vstack([offensive_embedding[0], hate_embedding[0],normal_embedding[0]])\n",
    "# tsne = TSNE(n_components=2, perplexity=2, early_exaggeration=12.0, learning_rate=20.0, n_iter=1000)\n",
    "# # Compute t-SNE embeddings\n",
    "# # tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# # Separate the t-SNE embeddings for the two weight vectors\n",
    "# tsne_embeddings1 = tsne_embeddings[:25]  # First weight vector\n",
    "# tsne_embeddings2 = tsne_embeddings[25:50]  # Second weight vector\n",
    "# tsne_embeddings3 = tsne_embeddings[50:] \n",
    "\n",
    "# # Create a scatter plot for the t-SNE embeddings\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], label='hate_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='offensive_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], label='offensive_embedding', s=5)\n",
    "# # plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='normal_embedding', s=5)\n",
    "\n",
    "# plt.xlabel('t-SNE Dimension 1')\n",
    "# plt.ylabel('t-SNE Dimension 2')\n",
    "# plt.legend()\n",
    "# plt.title('t-SNE Visualization of Weight Vectors')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import the 3D plotting module\n",
    "\n",
    "# Assuming you have three weight vectors of shape (10, 768)\n",
    "\n",
    "# Combine the three weight vectors into one array\n",
    "combined_weight_vectors = np.vstack([hate_embedding[0], offensive_embedding[0], normal_embedding[0]])\n",
    "tsne = TSNE(n_components=3, perplexity=50, early_exaggeration=12.0, learning_rate=50.0, n_iter=10000)\n",
    "\n",
    "# Compute t-SNE embeddings\n",
    "tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# Separate the t-SNE embeddings for the three weight vectors\n",
    "tsne_embeddings1 = tsne_embeddings[:25]        # First weight vector (hate)\n",
    "tsne_embeddings2 = tsne_embeddings[25:50]      # Second weight vector (offensive)\n",
    "tsne_embeddings3 = tsne_embeddings[50:]        # Third weight vector (normal)\n",
    "\n",
    "# Create a 3D scatter plot for the t-SNE embeddings\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Create a 3D axis\n",
    "\n",
    "ax.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], tsne_embeddings1[:, 2], label='hate_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], tsne_embeddings2[:, 2], label='offensive_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], tsne_embeddings3[:, 2], label='normal_embedding', s=5)\n",
    "\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "ax.set_zlabel('t-SNE Dimension 3')\n",
    "plt.legend()\n",
    "plt.title('3D t-SNE Visualization of Weight Vectors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMciCgoRuYPP4D87bGoAjIQ",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06285d669e92494192637cb3ee5a40f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f14c359d92748268810099e6cdd1fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06285d669e92494192637cb3ee5a40f4",
      "placeholder": "​",
      "style": "IPY_MODEL_209ee3e0949b446b8c58c57989065c5a",
      "value": " 232k/232k [00:00&lt;00:00, 2.84MB/s]"
     }
    },
    "123641d1426541fba838576dff7f6082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17ae300ebf634778862bc211cb432eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51f1ae4e3bd4563be3eb7c04dec7a60",
      "placeholder": "​",
      "style": "IPY_MODEL_c7586ac9b41c4e75b02a6c076a458686",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "18e134c7af5d45baa952ccf06f96f3d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f1d5a79d7ec4e42add7775fa925b187",
      "placeholder": "​",
      "style": "IPY_MODEL_e89d668a4fb541ec8d75d171bf899869",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "1cf66f2a8c5f49ce98d59dae5186298d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd44792f624499b87bd768836016e88",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae841edad05b4ef9b4308308d6683fa3",
      "value": 570
     }
    },
    "1ec35f8bfadb40968f777ab7bbb55184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b0c918326174bc4b80585a52ac33e32",
      "placeholder": "​",
      "style": "IPY_MODEL_e38ea829111b4065bad8ad4a4927bc39",
      "value": " 466k/466k [00:00&lt;00:00, 8.67MB/s]"
     }
    },
    "2024092105904b418c984aae9f4118bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f0a4e1b4929448a8b0a25b202271a40",
      "placeholder": "​",
      "style": "IPY_MODEL_ac93c61a19c0474994803853194d2aa8",
      "value": " 28.0/28.0 [00:00&lt;00:00, 584B/s]"
     }
    },
    "209ee3e0949b446b8c58c57989065c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21bf2e03eac8419fa693628ab2cef02d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430a9d1768614e0596960d2a3d15d69e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_909ae03e117345f7a4b53f3045e090b7",
      "value": 231508
     }
    },
    "274875a4aa6047c9903ae3065a5d85c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31914a14cfa243388f43a02da4db24b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3258d106659040dfb7ffea47c017ed38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34bbd1edf06c4a9194bd27eaeeee32b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e574772e8b4f81bc7e02e8ebaeb258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3258d106659040dfb7ffea47c017ed38",
      "placeholder": "​",
      "style": "IPY_MODEL_f9a2caba063b4a4f98ad258044d012fb",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "3c294ab0d9a648f39ea3f3fb7dd08c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430a9d1768614e0596960d2a3d15d69e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4914d10c0f354e178de66dc11449e26a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7998e50af804d66b6af0f26b5588255",
      "placeholder": "​",
      "style": "IPY_MODEL_4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "4cc5655f9bdb42bca5d80e2849e8cd2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f0a4e1b4929448a8b0a25b202271a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1d5a79d7ec4e42add7775fa925b187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa52eecbe8a4ba38ef969fd1cf48cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50859aa086814457bcab249b35d486a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "570b9a872e614e0eab6618f306be7306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34e574772e8b4f81bc7e02e8ebaeb258",
       "IPY_MODEL_1cf66f2a8c5f49ce98d59dae5186298d",
       "IPY_MODEL_71f100b04c964a1bbde06c537f483ed7"
      ],
      "layout": "IPY_MODEL_9e1caf8b23fb4eb1976f808269d1dd3e"
     }
    },
    "5a072e1f73624ea5aa35e7e18af17f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a0c04349bae44f4a7130463ded826d1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f11959bab964aad822250b6e6853cb8",
      "value": 466062
     }
    },
    "672e978f9b524c5784553abd8cc91507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17ae300ebf634778862bc211cb432eef",
       "IPY_MODEL_5a072e1f73624ea5aa35e7e18af17f50",
       "IPY_MODEL_1ec35f8bfadb40968f777ab7bbb55184"
      ],
      "layout": "IPY_MODEL_274875a4aa6047c9903ae3065a5d85c2"
     }
    },
    "69d90bdca5174dfb91f5cf124884095e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71d0c2b02f0c4a609477bc31aa880938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c12c857f159443f1b2a661fcd7afa002",
       "IPY_MODEL_989933f9c84a47d4b64d5b5441a1f492",
       "IPY_MODEL_2024092105904b418c984aae9f4118bf"
      ],
      "layout": "IPY_MODEL_4cc5655f9bdb42bca5d80e2849e8cd2b"
     }
    },
    "71f100b04c964a1bbde06c537f483ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34bbd1edf06c4a9194bd27eaeeee32b2",
      "placeholder": "​",
      "style": "IPY_MODEL_ea850e74cb6a4121a456578b29ce7955",
      "value": " 570/570 [00:00&lt;00:00, 5.04kB/s]"
     }
    },
    "8a0c04349bae44f4a7130463ded826d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "909ae03e117345f7a4b53f3045e090b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "989933f9c84a47d4b64d5b5441a1f492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9910be9c8b7b4188936721e958ca15c5",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50859aa086814457bcab249b35d486a8",
      "value": 28
     }
    },
    "9910be9c8b7b4188936721e958ca15c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0c918326174bc4b80585a52ac33e32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1caf8b23fb4eb1976f808269d1dd3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f11959bab964aad822250b6e6853cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a51f1ae4e3bd4563be3eb7c04dec7a60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac93c61a19c0474994803853194d2aa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae841edad05b4ef9b4308308d6683fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5516712d5304670a05ec871eb5896a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c12c857f159443f1b2a661fcd7afa002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd56d3ae17774e5496a7fdcbcb57b874",
      "placeholder": "​",
      "style": "IPY_MODEL_b5516712d5304670a05ec871eb5896a4",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "c7586ac9b41c4e75b02a6c076a458686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfe933364a3147368660f5463f1e5a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69dfd21bce04204b3220b71b4d4a968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4914d10c0f354e178de66dc11449e26a",
       "IPY_MODEL_f554ec9fe80a408680aa7b0a1c6837ac",
       "IPY_MODEL_f4ec333b7c654876a6caad010e88c203"
      ],
      "layout": "IPY_MODEL_cfe933364a3147368660f5463f1e5a29"
     }
    },
    "dfd44792f624499b87bd768836016e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e38ea829111b4065bad8ad4a4927bc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e89d668a4fb541ec8d75d171bf899869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e99b3d05437f4cdf9e1700e3cf466b34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea850e74cb6a4121a456578b29ce7955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee12049f5a9c4505b9769a4ff9c36477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18e134c7af5d45baa952ccf06f96f3d8",
       "IPY_MODEL_21bf2e03eac8419fa693628ab2cef02d",
       "IPY_MODEL_0f14c359d92748268810099e6cdd1fc3"
      ],
      "layout": "IPY_MODEL_e99b3d05437f4cdf9e1700e3cf466b34"
     }
    },
    "f4ec333b7c654876a6caad010e88c203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d90bdca5174dfb91f5cf124884095e",
      "placeholder": "​",
      "style": "IPY_MODEL_123641d1426541fba838576dff7f6082",
      "value": " 440M/440M [00:06&lt;00:00, 121MB/s]"
     }
    },
    "f554ec9fe80a408680aa7b0a1c6837ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31914a14cfa243388f43a02da4db24b6",
      "value": 440449768
     }
    },
    "f7998e50af804d66b6af0f26b5588255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a2caba063b4a4f98ad258044d012fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd56d3ae17774e5496a7fdcbcb57b874": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
