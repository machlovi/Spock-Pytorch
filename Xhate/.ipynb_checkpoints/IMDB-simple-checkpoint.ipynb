{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/machlovi/Spock-paper/blob/main/X_hate_and_offensive_data_combine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdBpcROn7EF-"
   },
   "source": [
    "## This file uses HateXplain data\n",
    "We are initailizing 2 vector space for 3(after converting them into 2 class) classes in this code. Main idea is to visualize how we can separate words related to each classes in the given space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UYfxZaZz6j8",
    "outputId": "09a73fe3-70ee-4cca-c198-fafbeda639f7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! apt-get install git\n",
    "# !pip install --upgrade protobuf\n",
    "# !pip install --upgrade jupyterlab-server google-api-core cached-path alchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj4pk2f97ALa"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7fS4-4j6y_h",
    "outputId": "6b5de3d8-1951-4e39-8a5e-2a5759d5f38d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/naseem_fordham/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\",20)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# from datasets import load_dataset,Dataset\n",
    "from transformers import AutoModel, BertTokenizerFast, BertModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Importing loss file\n",
    "from custom_loss import CustomLoss, CosineSimilarityLoss, IntraClassLoss, BinaryCrossEntropyLoss, LossValues\n",
    "from BERTdata_loader import BERTDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocess import TextPreprocessor  # Import your TextPreprocessor class\n",
    "text_processor = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To display full column and rows values\n",
    "# pd.set_option('display.max_column', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_seq_items', None)\n",
    "# pd.set_option('display.max_colwidth', 500)\n",
    "# pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install numba\n",
    "\n",
    "def on_gpu(f):\n",
    "    def wrapper(*args):\n",
    "        if torch.cuda.is_available():\n",
    "            return f(*args)\n",
    "        else:\n",
    "            print('cuda unavailable')\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This part of the code uses cuda for GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # ! pip install pynvml\n",
    "    from pynvml import *\n",
    "    from numba import cuda\n",
    "\n",
    "@on_gpu\n",
    "def print_gpu_utilization(dev_id):\n",
    "    try:\n",
    "        nvmlInit()\n",
    "        handle = nvmlDeviceGetHandleByIndex(dev_id)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "@on_gpu\n",
    "def free_gpu_cache(dev_id=0):\n",
    "    print(\"Initial GPU Usage\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "GPU memory occupied: 10911 MB.\n"
     ]
    }
   ],
   "source": [
    "device_id = 1\n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)\n",
    "\n",
    "print_gpu_utilization(device_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HateOffensive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp7FNeAE7M-s",
    "tags": []
   },
   "source": [
    "https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data#Data import\n",
    "\n",
    "Data Source \"https://github.com/t-davidson/33 ##\n",
    "hate-speech-and-offensive-language/blob/master/data/readme.md\"\n",
    "'''hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "In this case 0 non-toxic and 1 -toxic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading hate ofefsive data and converting it into 2 class data as toxic and non-toxic\n",
    "df_data1=pd.read_csv(\"/home/naseem_fordham/Spock-paper/data/labeled_data.csv\")\n",
    "dataframe=df_data1[['class','tweet']]\n",
    "dataframe=dataframe.dropna()\n",
    "dataframe.reset_index(drop=True)\n",
    "dataframe['class'].unique()\n",
    "\n",
    "# #initially we have 3 classes and now we are converting them into binary class\n",
    "\n",
    "dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x in [0., 1.] else 0.0)\n",
    "# HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_processor.text_preprocessing(x))\n",
    "dataframe = dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "# dataframe=HateXplain\n",
    "dataframe['class'].unique()\n",
    "# dataframe.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>now i am seeing chatter among jihadi fans taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>you think she classy niggah but she really rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>rt nikowavy some hoes look better without they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>rt if your boy breaks up with you and has a ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>baaaabyshaaaay spitted sprite on you niggah wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lmaooooooo rt dontcallmekyrie record scratches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38891</th>\n",
       "      <td>1.0</td>\n",
       "      <td>im out vandalsavage slipping mollies in the je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38892</th>\n",
       "      <td>1.0</td>\n",
       "      <td>these judges gon try amp hoe floyd if he dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38893</th>\n",
       "      <td>0.0</td>\n",
       "      <td>i used to get grs a lot tho maybe thats why my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>rt cinco de mind yo own damn business bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38895 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "0        0.0  now i am seeing chatter among jihadi fans taki...\n",
       "1        1.0  you think she classy niggah but she really rat...\n",
       "2        1.0  rt nikowavy some hoes look better without they...\n",
       "3        0.0  rt if your boy breaks up with you and has a ne...\n",
       "4        1.0  baaaabyshaaaay spitted sprite on you niggah wi...\n",
       "...      ...                                                ...\n",
       "38890    1.0  lmaooooooo rt dontcallmekyrie record scratches...\n",
       "38891    1.0  im out vandalsavage slipping mollies in the je...\n",
       "38892    1.0  these judges gon try amp hoe floyd if he dont ...\n",
       "38893    0.0  i used to get grs a lot tho maybe thats why my...\n",
       "38894    1.0        rt cinco de mind yo own damn business bitch\n",
       "\n",
       "[38895 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'dataframe' is your DataFrame\n",
    "class_1_data = dataframe[dataframe['class'] == 1.0].sample(n=100, random_state=1)\n",
    "class_0_data = dataframe[dataframe['class'] == 0.0].sample(n=100, random_state=1)\n",
    "\n",
    "# Concatenate both class samples\n",
    "selected_data = pd.concat([class_0_data, class_1_data])\n",
    "\n",
    "# Shuffle the selected data\n",
    "selected_data = selected_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "dataframe=selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "-Y5XnqHVWi9T",
    "outputId": "868f2ad5-0f5c-41c8-b705-f1b3ad8f012f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAHSCAYAAADhZ+amAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbuUlEQVR4nO3df7Dld13f8dfbvQETpIAG6MJlE4bSIIOAcCdFqagEMeAOUYstTKGgaFrL7zIloK2onc6wYlX6S2cLAVpjGOWH0hUpGcRiZyB2E4IEwi+RZbNkyXWoomUoIXz6xzmrN8ve/XHP2Xved8/jMXNm7/l+z7nnfb/33B/P+/1+z9YYIwAAALBo37DoAQAAACARqAAAADQhUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALK9v5YBdeeOG4+OKLt/MhAQAA2CY33HDDn40x7rvV+29roF588cU5ePDgdj4kAAAA26SqDs1yf4f4AgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0cMpAraqrq+r2qrr5BOteVlWjqi48O+MBAACwLE5nD+obk1x+/MKqelCSJyf57JxnAgAAYAmdMlDHGO9L8oUTrPrlJC9PMuY9FAAAAMtnS+egVtUVSY6MMT4053kAAABYUmccqFV1QZKfSvIzp3n7K6vqYFUdXF9fP9OHY2r36p5U1aaXlbuff9L1u1f3LPpDAAAAOKmVLdznIUkenORDVZUkq0lurKpLxxhHj7/xGGN/kv1Jsra25nDgLTp65HAuuurApusP7dt7yvUAAACdnXGgjjE+nOR+x65X1WeSrI0x/myOcwEAALBkTue/mbk2yfuTXFJVt1bV887+WAAAACybU+5BHWM88xTrL57bNAAAACytLb2KLwAAAMybQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoPLXdq/uSVVtetm9umfRIwIAAOewlUUPQB9HjxzORVcd2HT9oX17t3EaAABg2diDCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoIVTBmpVXV1Vt1fVzRuWvaaqPlZVf1xVb6+qe5/VKQEAADjnnc4e1Dcmufy4ZdclecQY45FJPpHklXOeCwAAgCVzykAdY7wvyReOW/buMcZXp1c/kGT1LMwGAADAEpnHOag/luT35vB+AAAAWGIzBWpV/XSSrya55iS3ubKqDlbVwfX19VkeDrJ7dU+qatPL7tU9ix4RAADYopWt3rGqnptkb5LLxhhjs9uNMfYn2Z8ka2trm94OTsfRI4dz0VUHNl1/aN/ebZwGAACYpy0FalVdnuTlSb57jPGl+Y4EAADAMjqd/2bm2iTvT3JJVd1aVc9L8h+T3DPJdVV1U1X92lmeEwAAgHPcKfegjjGeeYLFrz8LswAAALDE5vEqvgAAADAzgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALpwzUqrq6qm6vqps3LPvmqrquqj45/fc+Z3dMAAAAznWnswf1jUkuP27ZK5K8Z4zx0CTvmV4HAACALTtloI4x3pfkC8ctviLJm6ZvvynJD853LAAAAJbNVs9Bvf8Y47bp20eT3H9O8wAAALCkZn6RpDHGSDI2W19VV1bVwao6uL6+PuvDtbR7dU+qatPL7tU9ix5xPnadd9KPc+Xu5590/Tm1LQAAgLlb2eL9Pl9Vu8cYt1XV7iS3b3bDMcb+JPuTZG1tbdOQ3cmOHjmci646sOn6Q/v2buM0Z9Gdd5zy4zzZ+mO3AQAAOJGt7kF9R5LnTN9+TpLfmc84AAAALKvT+W9mrk3y/iSXVNWtVfW8JK9O8n1V9ckkT5peBwAAgC075SG+Y4xnbrLqsjnPAgAAwBKb+UWSAAAAYB4EKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC3MFKhV9dKq+khV3VxV11bVN85rMAAAAJbLlgO1qh6Y5EVJ1sYYj0iyK8kz5jUYAAAAy2XWQ3xXkpxfVStJLkjyudlHAgAAYBltOVDHGEeS/GKSzya5LclfjDHePa/BAAAAWC6zHOJ7nyRXJHlwkgckuUdVPesEt7uyqg5W1cH19fWtT7qT7TovVbXpZffqnkVPuFR2r+6Z6fNxqvtXVVbufv5M6z0nAABYRisz3PdJSf50jLGeJFX1tiTfmeTXN95ojLE/yf4kWVtbGzM83s515x256KoDm64+tG/vNg7D0SOHZ/p8nOr+x97HqR7DcwIAAO5qlnNQP5vkcVV1QVVVksuS3DKfsQAAAFg2s5yDen2StyS5McmHp+9r/5zmAgAAYMnMcohvxhivSvKqOc0CAADAEpv1v5kBAACAuRCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCop2H36p5U1aYXGtl13kk/Vzvm83UaH8fK3c8/6frdq3sW/VEAAMAZWVn0ADvB0SOHc9FVBzZdf2jf3m2chpO6846Tfq6SHfL5Os2Pw/MSAIBziT2oAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWpgpUKvq3lX1lqr6WFXdUlXfMa/BAAAAWC4rM97/tUneNcZ4elXdLckFc5gJAACAJbTlQK2qeyV5QpLnJskY4ytJvjKfsQAAAFg2sxzi++Ak60neUFUfrKrXVdU9jr9RVV1ZVQer6uD6+voMD3d27F7dk6o66YXtc6rPx7bYdd7iZwAAgCU0yyG+K0kek+SFY4zrq+q1SV6R5F9vvNEYY3+S/UmytrY2Zni8s+LokcO56KoDJ73NoX17t2kaTvX52JbPxZ13LH4GAABYQrPsQb01ya1jjOun19+SSbACAADAGdtyoI4xjiY5XFWXTBddluSjc5kKAACApTPrq/i+MMk101fw/XSSH519JAAAAJbRTIE6xrgpydp8RgEAAGCZzXIOKgAAAMyNQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoHaw67xU1UkvO+Ix2FF2r+456fNh9+qeRY8IAMCSWVn0ACS5845cdNWBk97k0L69/R+DHeXokcMnfU54PgAAsN3sQQUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANDCzIFaVbuq6oNVdWAeAwEAALCc5rEH9cVJbpnD+wEAAGCJzRSoVbWa5AeSvG4+4wAAALCsZt2D+itJXp7ka5vdoKqurKqDVXVwfX19xof7ertX96SqNr3sXt0z98cEJnz9AQAwTytbvWNV7U1y+xjjhqr6ns1uN8bYn2R/kqytrY2tPt5mjh45nIuu2vz010P79s77IYEpX38AAMzTLHtQH5/kaVX1mSRvTvLEqvr1uUwFAADA0tlyoI4xXjnGWB1jXJzkGUl+f4zxrLlNBgAAwFLx/6ACAADQwpbPQd1ojPEHSf5gHu8LAACA5WQPKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBZWFj0AcJbsOi9VtegpAADgtAlUOFfdeUcuuurApqsP7du7jcMAAMCpOcQXAACAFgQqAAAALQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABAC1sO1Kp6UFW9t6o+WlUfqaoXz3MwAAAAlsvKDPf9apKXjTFurKp7Jrmhqq4bY3x0TrMBAACwRLa8B3WMcdsY48bp23+Z5JYkD5zXYAAAACyXuZyDWlUXJ/n2JNfP4/0BAACwfGYO1Kr6piRvTfKSMcYXT7D+yqo6WFUH19fXZ324M7frvFTVphcAAAB6mOUc1FTVeZnE6TVjjLed6DZjjP1J9ifJ2tramOXxtuTOO3LRVQc2XX1o395tHAYAAIDNzPIqvpXk9UluGWP80vxGAgAAYBnNcojv45M8O8kTq+qm6eWpc5oLAACAJbPlQ3zHGP8riZM4AQAAmIu5vIovAAAAzEqgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFgQqAAAALQhUAAAAWhCoAAAAtNA6UHev7klVnfQCnCW7zpv96+8U72P36p6z/3EAALBjrCx6gJM5euRwLrrqwElvc2jf3m2aBpbMnXfM/vV3ivfh6xcAgI1a70EFAABgeQhUAAAAWhCoAAAAtCBQAQAAaEGgAgAA0IJABQAAoAWBCgAAQAsCFQAAgBYEKgAAAC0IVAAAAFoQqAAAALQgUAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC0IFABAABoQaACAADQgkAFAACgBYEKAABACwIVAACAFmYK1Kq6vKo+XlWfqqpXzGsoAAAAls+WA7WqdiX5T0mekuThSZ5ZVQ+f12AAAAAsl1n2oF6a5FNjjE+PMb6S5M1JrpjPWAAAACybWQL1gUkOb7h+63QZAAAAnLEaY2ztjlVPT3L5GOPHp9efneTvjTFecNztrkxy5fTqJUk+vvVxOUMXJvmzRQ+xg9l+s7H9Zmcbzsb2m43tNxvbbza232xsv9nYfrO5ZIxxz63eeWWGBz6S5EEbrq9Ol93FGGN/kv0zPA5bVFUHxxhri55jp7L9ZmP7zc42nI3tNxvbbza232xsv9nYfrOx/WZTVQdnuf8sh/j+7yQPraoHV9XdkjwjyTtmGQYAAIDlteU9qGOMr1bVC5L8jyS7klw9xvjI3CYDAABgqcxyiG/GGO9M8s45zcL8ObR6NrbfbGy/2dmGs7H9ZmP7zcb2m43tNxvbbza232xm2n5bfpEkAAAAmKdZzkEFAACAuRGo54iqurqqbq+qmzcs++aquq6qPjn99z6LnLGzTbbfo6rq/VX14ar671X1txY5Y2dV9aCqem9VfbSqPlJVL54uf3RVfaCqbqqqg1V16aJn7aiqvrGq/qiqPjTdfj83Xf6H0213U1V9rqp+e8GjtlZVu6rqg1V1YHq9qurfVtUnquqWqnrRomfsqqo+M/1ed9OxV1+sqp+tqiMbnoNPXfScXVXVvavqLVX1selz7Ts2rHtZVY2qunCRM3ZVVZdseI7dVFVfrKqXVNW/qao/ni57d1U9YNGzdlVVL53+7Li5qq6d/ky5pqo+Pl12dVWdt+g5u6qqF0+300eq6iXTZT8yvf61qvJqvhucSXNMfw7/+6r61PTr+TGn8xgC9dzxxiSXH7fsFUneM8Z4aJL3TK9zYm/M12+/1yV5xRjj25K8Pcm/3O6hdpCvJnnZGOPhSR6X5PlV9fAkv5Dk58YYj07yM9PrfL3/l+SJY4xHJXl0ksur6nFjjO8aYzx6uv3en+RtC5xxJ3hxkls2XH9uJv8d2sPGGN+a5M2LGGoH+d7p823jL2O/fOw5OH3dCU7stUneNcZ4WJJHZfo8rKoHJXlyks8ucLbWxhgf3/B97rFJvpTJz9zXjDEeOV1+IJOfIRynqh6Y5EVJ1sYYj8jkhUufkeSaJA9L8m1Jzk/y4wsbsrGqekSSn0hyaSZfu3ur6u8kuTnJDyd53wLH6+qNOf3meEqSh04vVyb51dN5AIF6jhhjvC/JF45bfEWSN03fflOSH9zOmXaSTbbf383ffGO6Lsk/2NahdpAxxm1jjBunb/9lJr+cPTDJSHJsz/O9knxuMRP2Nib+anr1vOnlr18gYLr3/olJfnv7p9sZqmo1yQ9k8oelY34yyc+PMb6WJGOM2xcxG+e2qrpXkickeX2SjDG+Msb48+nqX07y8mz4euakLkvyJ2OMQ2OML25Yfo/YhiezkuT8qlpJckGSz40x3jn92TKS/FGS1YVO2Ne3Jrl+jPGlMcZXk/zPJD88xrhljPHxBc/W0hk2xxVJ/uv0qfiBJPeuqt2negyBem67/xjjtunbR5Pcf5HD7EAfyeQLK0l+JJM9MZxCVV2c5NuTXJ/kJUleU1WHk/xiklcubrLepoen3pTk9iTXjTGu37D6BzP5y+QXT3RfkiS/kkkIfG3Dsock+UfTw8t/r6oeupDJdoaR5N1VdUNVXblh+Qumh2Vd7TSRTT04yXqSN0wPMX9dVd2jqq5IcmSM8aEFz7eTPCPJtceuTA/RP5zkH8ce1BMaYxzJ5OfrZ5PcluQvxhjvPrZ+emjvs5O8azETtndzku+qqm+pqguSPDV+39uKzZrjgUkOb7jdrdNlJyVQl8T0L2j++nhmfizJP6+qG5LcM8lXFjxPe1X1TUnemuQl05j6ySQvHWM8KMlLM93DwNcbY9w5PZRtNcml08OOjnlmNvzSxl1V1d4kt48xbjhu1d2TfHl6yOp/SXL1tg+3c/z9McZjMjkc6/lV9YRMDsV6SCaHnd+W5N8tbrzWVpI8JsmvjjG+Pcn/TfKzSX4qouq0VdXdkjwtyW8dWzbG+Onpz49rkrxgUbN1Nv3D0RWZ/KHkAUnuUVXP2nCT/5zkfWOMP1zEfN2NMW5Jsi/JuzOJ+JuS3LnImXa6eTSHQD23ff7YbvTpvw5vOwNjjI+NMZ48xnhsJnHwJ4ueqbPpX2nfmuSaMcaxcyWfk785b/K3MjnHg5OYHhr43kzP75i+sMqlSX53gWN19/gkT6uqz2RynukTq+rXM/lL7bHn39uTPHIx4/U33Qtz7DDotye5dIzx+ekfTr6WSeD7+j2xW5PcuuGoh7dkEqwPTvKh6fNyNcmNVfW3FzPijvCUJDeOMT5/gnXXxGk2m3lSkj8dY6yPMe7I5HvedyZJVb0qyX2T/IsFztfeGOP1Y4zHjjGekOT/JPnEomfagTZrjiO56x7p1emykxKo57Z3ZBIImf77OwucZcepqvtN//2GJP8qya8tdqK+qqoy2Tt6yxjjlzas+lyS756+/cQkn9zu2XaCqrpvVd17+vb5Sb4vycemq5+e5MAY48sLGq+9McYrxxirY4yLMzlE8PfHGM/K5Jzd753e7Lvjl44Tmh6Oes9jb2fyoj43H3ee0A9lcigcxxljHE1yuKoumS66LJPQut8Y4+Lp8/LWJI+Z3pYTu8uRIscdkn9F/uZ7Inf12SSPq6oLpj+LL0tyS1X9eJLvT/LMY+fhc2Ibft/bk8kLI/3GYifakTZrjnck+SfTV/N9XCaHoN92onew0crZmZHtVlXXJvmeJBdW1a1JXpXk1Ul+s6qel+RQkn+4uAl722T7fVNVPX96k7clecOCxtsJHp/JOS4fnp5HmUwOb/uJJK+dvnDDlzN5BTe+3u4kb6qqXZn84fA3xxgHpuuekcnXMmfu1UmuqaqXJvmreBXLzdw/ydsnv9tmJclvjDHeVVX/raoencmhWp9J8k8XNmF/L8zkuXa3JJ9O8qMLnmdHmf5h5Pty1+fYq6fR/7VMfof5Z4uYrbsxxvVV9ZYkN2byivofTLI/k0PNDyV5//Rr+21jjJ9f2KC9vbWqviXJHUmeP8b486r6oST/IZM90L9bVTeNMb5/oVM2cYbN8c5Mzuv9VCav0H1a3xtrcpgwAAAALJZDfAEAAGhBoAIAANCCQAUAAKAFgQoAAEALAhUAAIAWBCoAAAAtCFQAAABaEKgAAAC08P8BLPUzsIbqwVoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token lengths distribution in the dataset\n",
    "token_lengths = [len(i.split()) for i in dataframe[\"tweet\"]]\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(token_lengths,bins = 30,edgecolor=\"black\")\n",
    "plt.xticks(ticks = np.linspace(10,100,11))\n",
    "plt.show()\n",
    "dataframe[\"token_length\"] = token_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQEmSl2aS7_T"
   },
   "source": [
    "# Training and validation set\n",
    "We can also consider token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6M-IQ2ZyYVwb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# token_length 128, seems a good fit for data\n",
    "\n",
    "# split training and validation data\n",
    "train_df, val_df = train_test_split(dataframe, test_size= 0.20, stratify= dataframe[\"class\"], random_state = 40)\n",
    "\n",
    "# val_df,   test_df   = train_test_split(temp_df, test_size= 0.80, stratify= temp_df[\"class\"],random_state = 47)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop  = True)\n",
    "# test_df  = test_df.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "570b9a872e614e0eab6618f306be7306",
      "34e574772e8b4f81bc7e02e8ebaeb258",
      "1cf66f2a8c5f49ce98d59dae5186298d",
      "71f100b04c964a1bbde06c537f483ed7",
      "9e1caf8b23fb4eb1976f808269d1dd3e",
      "3258d106659040dfb7ffea47c017ed38",
      "f9a2caba063b4a4f98ad258044d012fb",
      "dfd44792f624499b87bd768836016e88",
      "ae841edad05b4ef9b4308308d6683fa3",
      "34bbd1edf06c4a9194bd27eaeeee32b2",
      "ea850e74cb6a4121a456578b29ce7955",
      "d69dfd21bce04204b3220b71b4d4a968",
      "4914d10c0f354e178de66dc11449e26a",
      "f554ec9fe80a408680aa7b0a1c6837ac",
      "f4ec333b7c654876a6caad010e88c203",
      "cfe933364a3147368660f5463f1e5a29",
      "f7998e50af804d66b6af0f26b5588255",
      "4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "31914a14cfa243388f43a02da4db24b6",
      "69d90bdca5174dfb91f5cf124884095e",
      "123641d1426541fba838576dff7f6082",
      "71d0c2b02f0c4a609477bc31aa880938",
      "c12c857f159443f1b2a661fcd7afa002",
      "989933f9c84a47d4b64d5b5441a1f492",
      "2024092105904b418c984aae9f4118bf",
      "4cc5655f9bdb42bca5d80e2849e8cd2b",
      "fd56d3ae17774e5496a7fdcbcb57b874",
      "b5516712d5304670a05ec871eb5896a4",
      "9910be9c8b7b4188936721e958ca15c5",
      "50859aa086814457bcab249b35d486a8",
      "4f0a4e1b4929448a8b0a25b202271a40",
      "ac93c61a19c0474994803853194d2aa8",
      "ee12049f5a9c4505b9769a4ff9c36477",
      "18e134c7af5d45baa952ccf06f96f3d8",
      "21bf2e03eac8419fa693628ab2cef02d",
      "0f14c359d92748268810099e6cdd1fc3",
      "e99b3d05437f4cdf9e1700e3cf466b34",
      "4f1d5a79d7ec4e42add7775fa925b187",
      "e89d668a4fb541ec8d75d171bf899869",
      "430a9d1768614e0596960d2a3d15d69e",
      "909ae03e117345f7a4b53f3045e090b7",
      "06285d669e92494192637cb3ee5a40f4",
      "209ee3e0949b446b8c58c57989065c5a",
      "672e978f9b524c5784553abd8cc91507",
      "17ae300ebf634778862bc211cb432eef",
      "5a072e1f73624ea5aa35e7e18af17f50",
      "1ec35f8bfadb40968f777ab7bbb55184",
      "274875a4aa6047c9903ae3065a5d85c2",
      "a51f1ae4e3bd4563be3eb7c04dec7a60",
      "c7586ac9b41c4e75b02a6c076a458686",
      "8a0c04349bae44f4a7130463ded826d1",
      "9f11959bab964aad822250b6e6853cb8",
      "9b0c918326174bc4b80585a52ac33e32",
      "e38ea829111b4065bad8ad4a4927bc39"
     ]
    },
    "id": "qe9vOPP6TD5-",
    "outputId": "d30dde8d-148a-4d7c-d57d-05ebeb164a73",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f640e59b-1730-4598-9f93-9a8bca070525)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b1efc17c-0955-4e5c-9174-f38602b55b06)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# load bertModel, bertTokenizer and freeze all layers\n",
    "bertModel = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "bertModel.trainable = False # freezing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109482240"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting model total number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(bertModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from BERTdata_loader_noattention import BERTDataset\n",
    "bert_dataset = BERTDataset(text=None, labels=None,  max_length=None, tokenizer=None, projection_dim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGGXmXltToJP"
   },
   "source": [
    "# Paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xVIgFoIztcq"
   },
   "source": [
    "Loading Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class SpockModel(nn.Module):\n",
    "    def __init__(self, MAX_LENGTH, PROJECTION_DIM, lambda_value):\n",
    "        super(SpockModel, self).__init__()\n",
    "        self.MAX_LENGTH = MAX_LENGTH\n",
    "        self.PROJECTION_DIM = PROJECTION_DIM\n",
    "        self.lambda_value = lambda_value\n",
    "        self.VECTOR_DIM = 768\n",
    "\n",
    "        # Layers\n",
    "        self.bert_model = bertModel  # Assuming you have defined bertModel elsewhere\n",
    "        self.offensive_embedding_layer = nn.Embedding(PROJECTION_DIM, self.VECTOR_DIM) # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "        self.normal_embedding_layer = nn.Embedding(PROJECTION_DIM, self.VECTOR_DIM)   # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "\n",
    "        self.hidden1 = nn.Linear(2 * self.PROJECTION_DIM, 612)\n",
    "        self.hidden2 = nn.Linear(612, 256)\n",
    "        # self.hidden3 = nn.Linear(256, 64)\n",
    "        # self.hidden4 = nn.Linear(64, 30)\n",
    "        self.hidden5 = nn.Linear(256, 60)\n",
    "        self.classification_layer = nn.Linear(60, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Loss Functions\n",
    "        self.cosine_loss = CosineSimilarityLoss(name='cosine_loss')\n",
    "        self.intra_loss = IntraClassLoss(name='intra_loss')\n",
    "        self.bce_loss = BinaryCrossEntropyLoss(name='attention_loss')\n",
    "        # self.loss_values = LossValues()\n",
    "\n",
    "\n",
    "    def forward(self, ids, mks, projection_space):\n",
    "        input_sentence = self.bert_model(ids, attention_mask=mks)[0].to(device)   #(None, Max_Len,VECTOR_DIM)\n",
    "        # print(input_sentence.shape)\n",
    "        offensive_embedding_np = self.offensive_embedding_layer(projection_space)  # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "        normal_embedding_np = self.normal_embedding_layer(projection_space)        # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "        # print(normal_embedding_np.shape)\n",
    "        offensive_embedding = offensive_embedding_np.permute(0, 2, 1)              #(None,PROJECTION_DIM, VECTOR_DIM) --> (None,VECTOR_DIM,PROJECTION_DIM)\n",
    "        normal_embedding = normal_embedding_np.permute(0, 2, 1)\n",
    "        # print(normal_embedding.shape)\n",
    "\n",
    "        offensive_cosine = self.cosine_similarity_projected(input_sentence, offensive_embedding) #  (None, Max_Len,VECTOR_DIM). (None,VECTOR_DIM,PROJECTION_DIM) -->((None, Max_Len, Projection)\n",
    "        normal_cosine = self.cosine_similarity_projected(input_sentence, normal_embedding)\n",
    "        # print(normal_cosine.shape)\n",
    "\n",
    "        \n",
    "        offensive_cosine_nopads = self.remove_padsV2(offensive_cosine, ids)\n",
    "        normal_cosine_nopads = self.remove_padsV2(normal_cosine, ids)\n",
    "\n",
    "        \n",
    "        \n",
    "        merged = self.merge_functionV2(offensive_cosine_nopads, normal_cosine_nopads)\n",
    "        merged = merged.view(-1, 2 * self.PROJECTION_DIM)\n",
    "\n",
    "        hidden1 = torch.tanh(self.hidden1(merged))\n",
    "        hidden2 = torch.tanh(self.hidden2(hidden1))\n",
    "        # hidden3 = F.relu(self.hidden3(hidden2))\n",
    "        # hidden4 = F.relu(self.hidden4(hidden3))\n",
    "        hidden5 = torch.tanh(self.hidden5(hidden2))\n",
    "\n",
    "        predictions = torch.sigmoid(self.classification_layer(hidden5))\n",
    "        # print(predictions)\n",
    "\n",
    "        # # Losses\n",
    "        offensive_normal_loss = self.cosine_loss(torch.mean(offensive_cosine, dim=1), torch.mean(normal_cosine, dim=1))\n",
    "        toxic_intra_loss = self.intra_loss(offensive_cosine)\n",
    "        non_toxic_intra_loss = self.intra_loss(normal_cosine)\n",
    "\n",
    "        # Total Loss\n",
    "        # + self.lambda_value * bce_loss1\n",
    "        loss = offensive_normal_loss + toxic_intra_loss + non_toxic_intra_loss \n",
    "        print(predictions)\n",
    "        \n",
    "        \n",
    "        return predictions,loss,offensive_normal_loss, toxic_intra_loss, non_toxic_intra_loss\n",
    "    \n",
    "    \n",
    "    def cosine_similarity_projected(self, x, w):\n",
    "        dp = torch.matmul(x, w)\n",
    "        x_mag = torch.norm(x, dim=2, keepdim=True)\n",
    "        w_mag = torch.norm(w, dim=1, keepdim=True)\n",
    "        cosine = dp / (x_mag * w_mag)\n",
    "        return cosine\n",
    "    \n",
    "\n",
    "\n",
    "    def merge_functionV2(self, negative, normal):\n",
    "        negative_max = torch.max(negative, dim=1, keepdim=True)[0]\n",
    "        normal_max = torch.max(normal, dim=1, keepdim=True)[0]\n",
    "        return torch.cat([negative_max, normal_max], dim=-1)\n",
    "    \n",
    "    def remove_padsV2(self, vects, ids):\n",
    "        # masks = ids != 0\n",
    "        masks = (ids != 101) & (ids != 102)\n",
    "        masks = masks.unsqueeze(-1).float()\n",
    "        masked_embeddings = vects * masks\n",
    "\n",
    "        # print(masked_embeddings.shape)\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training and Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def eval(f):\n",
    "#     def wrapper(model, *args, **kwargs):\n",
    "#         model.eval()\n",
    "#         return f(model, *args, **kwargs)\n",
    "#     return wrapper\n",
    "\n",
    "# def train(f):\n",
    "#     def wrapper(model, *args, **kwargs):\n",
    "#         model.train()\n",
    "#         return f(model, *args, **kwargs)\n",
    "#     return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_offensive_normal_loss = 0.0\n",
    "    train_toxic_intra_loss = 0.0\n",
    "    train_non_toxic_intra_loss = 0.0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        # loss=0\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mks = batch['attention_masks'].to(device)\n",
    "        space = batch['space'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions, loss, off_normal_loss, toxic_intra_loss, non_toxic_intra_loss = model(ids, mks, space)\n",
    "        \n",
    "        # Compute Binary Cross-Entropy Loss\n",
    "        # bce_loss = torch.nn.BCELoss()(predictions, labels.float())\n",
    "        bce_loss = torch.nn.BCELoss()(predictions.view(-1,1), labels.float().view(-1,1))\n",
    "\n",
    "        # Total Loss\n",
    "        loss += bce_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_offensive_normal_loss += off_normal_loss.item()\n",
    "        train_toxic_intra_loss += toxic_intra_loss.item()\n",
    "        train_non_toxic_intra_loss += non_toxic_intra_loss.item()\n",
    "\n",
    "    return train_loss, predictions, labels, train_offensive_normal_loss, train_toxic_intra_loss, train_non_toxic_intra_loss\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_offensive_normal_loss = 0.0\n",
    "    val_toxic_intra_loss = 0.0\n",
    "    val_non_toxic_intra_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            ids = batch['input_ids'].to(device)\n",
    "            mks = batch['attention_masks'].to(device)\n",
    "            space = batch['space'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            predictions, loss, off_normal_loss, toxic_intra_loss, non_toxic_intra_loss = model(ids, mks, space)\n",
    "\n",
    "            # Compute Binary Cross-Entropy Loss\n",
    "            # bce_loss = torch.nn.BCELoss()(predictions, labels.float())\n",
    "            \n",
    "            bce_loss = torch.nn.BCELoss()(predictions.view(-1,1), labels.float().view(-1,1))\n",
    "\n",
    "\n",
    "            # Total Loss\n",
    "            loss += bce_loss\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_offensive_normal_loss += off_normal_loss.item()\n",
    "            val_toxic_intra_loss += toxic_intra_loss.item()\n",
    "            val_non_toxic_intra_loss += non_toxic_intra_loss.item()\n",
    "            \n",
    "     \n",
    "\n",
    "    return val_loss, predictions, labels, val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # train_dataloader,val_dataloader=dataprep(3)\n",
    "# @train\n",
    "# def train_epoch(model, train_dataloader, optimizer):\n",
    "#     train_loss = 0.0\n",
    "#     train_preds = []\n",
    "#     train_labels = []\n",
    "\n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         # print(step)\n",
    "#         # if step==1:\n",
    "#         # loss=0\n",
    "        \n",
    "        \n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_masks = batch['attention_masks'].to(device)\n",
    "#         space = batch['space'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "#         outputs = model(input_ids, attention_masks, space) # (B, Seq_Len, 2)\n",
    "#         preds,loss,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss= outputs\n",
    "#         loss = torch.mean(loss)  # Compute the mean loss across the batch    \n",
    "        \n",
    "#         labels = labels.view(-1, 1).float()\n",
    "        \n",
    "#         bce_loss = nn.BCEWithLogitsLoss()(preds.view(-1,1), labels.float())\n",
    "#         loss += bce_loss\n",
    "        \n",
    "#         train_preds += preds.detach().tolist()\n",
    "#         # print(preds)\n",
    "#         train_labels += [l.item() for l in labels]\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         loss.backward()\n",
    "                        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "#         # else:\n",
    "#         #     break\n",
    "#     return train_loss, train_preds, train_labels,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss\n",
    "\n",
    "# @eval\n",
    "# # '''PLOT HISTIOGRAM TO SEE THE SCORE DISTRIBUTION'''\n",
    "\n",
    "# def eval_epoch(model, val_dataloader):\n",
    "#     val_loss = 0.0\n",
    "#     val_preds = []\n",
    "#     val_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for step, batch in enumerate(val_dataloader):\n",
    "#             # if step==1:\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_masks = batch['attention_masks'].to(device)\n",
    "#             space = batch['space'].to(device)\n",
    "#             labels = batch['label']\n",
    "\n",
    "#             outputs = model(input_ids, attention_masks, space) # (B, Seq_Len, 2)\n",
    "\n",
    "#             # loss, logits = outputs.loss, outputs.logits\n",
    "#             preds,loss,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss = outputs\n",
    "#             loss=torch.mean(loss)\n",
    "#             # print(preds.dtype)\n",
    "\n",
    "\n",
    "#             # probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "#             # pred = torch.argmax(probs, dim=-1) # (B)\n",
    "#             val_preds += preds.detach().tolist()\n",
    "#             val_labels += [l.item() for l in labels]\n",
    "#             # print(val_labels,val_preds)\n",
    "#             val_loss += loss.item()\n",
    "#         # else:\n",
    "#         #     continue\n",
    "\n",
    "               \n",
    "#     return val_loss, val_preds, val_labels,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Metrices\n",
    "#assert take afucntion to take a conditon \n",
    "\n",
    "\n",
    "def training(model, train_data, val_data, config):\n",
    "    model = model\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=0.9)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(\n",
    "    #     params=model.parameters(),\n",
    "    #     lr=config['lr'],\n",
    "        # weight_decay=config['weight_decay']\n",
    "    # )\n",
    "\n",
    "    num_train_steps = int(len(train_data) / config['batch_size'] * config['epochs'])\n",
    "    # num_train_steps=2\n",
    "\n",
    "    print(f'Train steps: {num_train_steps}')\n",
    "\n",
    "\n",
    "    history = {\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': [],\n",
    "        'train_f1': [],\n",
    "        'val_f1': [],\n",
    "        'train_precision': [],\n",
    "        'val_precision': [],\n",
    "        'train_recall': [],\n",
    "        'val_recall': [],\n",
    "        'train_offensive_normal_loss': [],\n",
    "        'train_toxic_intra_loss': [],\n",
    "        'train_non_toxic_intra_loss': [],\n",
    "        'val_offensive_normal_loss': [],\n",
    "        'val_toxic_intra_loss': [],\n",
    "        'val_non_toxic_intra_loss': [],\n",
    "    }\n",
    "    # Inside the training loop\n",
    "    for epoch_num in range(config['epochs']):\n",
    "        print(f'Epoch: {epoch_num + 1}')\n",
    "\n",
    "        # Train stage\n",
    "        train_loss, train_preds, train_labels,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss = train_epoch(model, train_dataloader, optimizer)\n",
    "\n",
    "        # Eval stage\n",
    "        val_loss, val_preds, val_labels,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss= evaluate(model, val_dataloader)\n",
    "\n",
    "\n",
    "        train_preds_tensor = torch.tensor(train_preds).detach()\n",
    "        val_preds_tensor = torch.tensor(val_preds).detach()\n",
    "        \n",
    "        \n",
    "        train_preds_tensor = train_preds_tensor.cpu().numpy()\n",
    "        val_preds_tensor = val_preds_tensor.cpu().numpy()\n",
    "        \n",
    "        val_labels=val_labels.cpu().numpy()\n",
    "        train_labels=train_labels.cpu().numpy()\n",
    "        \n",
    "\n",
    "        train_preds_labels = (train_preds_tensor >= 0.5).astype(int)\n",
    "        val_preds_labels = (val_preds_tensor >= 0.5).astype(int)\n",
    "    \n",
    "     \n",
    "        # print(train_preds_tensor,train_labels)\n",
    "    \n",
    "    \n",
    "        # Metrics calculation\n",
    "        train_acc = accuracy_score(train_labels, train_preds_labels)\n",
    "        val_acc = accuracy_score(val_labels, val_preds_labels)\n",
    "        train_f1 = f1_score(train_labels, train_preds_labels, average='macro')\n",
    "        val_f1 = f1_score(val_labels, val_preds_labels, average='macro')\n",
    "        train_precision = precision_score(train_labels, train_preds_labels, average='weighted')\n",
    "        val_precision = precision_score(val_labels, val_preds_labels, average='weighted')\n",
    "        train_recall = recall_score(train_labels, train_preds_labels, average='weighted')\n",
    "        val_recall = recall_score(val_labels, val_preds_labels, average='weighted')\n",
    "\n",
    "        # Update history dictionary\n",
    "        history['train_losses'].append(train_loss / len(train_dataloader))\n",
    "        history['val_losses'].append(val_loss / len(val_dataloader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        \n",
    "        history['train_offensive_normal_loss'].append(train_offensive_normal_loss)\n",
    "        history['train_toxic_intra_loss'].append(train_toxic_intra_loss)\n",
    "        history['train_non_toxic_intra_loss'].append(train_non_toxic_intra_loss)\n",
    "\n",
    "        # Append validation loss values\n",
    "        history['val_offensive_normal_loss'].append(val_offensive_normal_loss)\n",
    "        history['val_toxic_intra_loss'].append(val_toxic_intra_loss)\n",
    "        history['val_non_toxic_intra_loss'].append(val_non_toxic_intra_loss)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#         history['train_offensive_normal_loss'].append(train_offensive_normal_loss.detach().cpu().numpy())\n",
    "#         history['train_toxic_intra_loss'].append(train_toxic_intra_loss.detach().cpu().numpy())\n",
    "#         history['train_non_toxic_intra_loss'].append(train_non_toxic_intra_loss.detach().cpu().numpy())\n",
    "\n",
    "#         # Append validation loss values\n",
    "#         history['val_offensive_normal_loss'].append(val_offensive_normal_loss.detach().cpu().numpy())\n",
    "#         history['val_toxic_intra_loss'].append(val_toxic_intra_loss.detach().cpu().numpy())\n",
    "#         history['val_non_toxic_intra_loss'].append(val_non_toxic_intra_loss.detach().cpu().numpy())\n",
    "\n",
    "        print()\n",
    "        print(f'Train loss: {train_loss / len(train_dataloader)} | Val loss: {val_loss / len(val_dataloader)}')\n",
    "        print(f'Train acc: {train_acc} | Val acc: {val_acc}')\n",
    "        # print(f'Train f1: {train_f1} | Val f1: {val_f1}')\n",
    "        # print(f'Train precision: {train_precision} | Val precision: {val_precision}')\n",
    "        # print(f'Train recall: {train_recall} | Val recall: {val_recall}')\n",
    "        \n",
    "        \n",
    "\n",
    "    # Free GPU cache if necessary\n",
    "    free_gpu_cache(device_id)\n",
    "\n",
    "    return history,val_preds, val_labels,train_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 12392 MB.\n",
      "Initial GPU Usage\n",
      "GPU memory occupied: 12392 MB.\n",
      "GPU Usage after emptying the cache\n",
      "GPU memory occupied: 12392 MB.\n"
     ]
    }
   ],
   "source": [
    "# history['train_toxic_intra_loss']\n",
    "torch.cuda.empty_cache()\n",
    "print_gpu_utilization(device_id)\n",
    "torch.cuda.empty_cache()\n",
    "free_gpu_cache(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 12392 MB.\n",
      "Initial GPU Usage\n",
      "GPU memory occupied: 12392 MB.\n",
      "GPU Usage after emptying the cache\n",
      "GPU memory occupied: 12392 MB.\n",
      "Train steps: 15\n",
      "Epoch: 1\n",
      "tensor([[0.5234],\n",
      "        [0.5234],\n",
      "        [0.5234],\n",
      "        [0.5232],\n",
      "        [0.5233],\n",
      "        [0.5231],\n",
      "        [0.5233],\n",
      "        [0.5232],\n",
      "        [0.5232],\n",
      "        [0.5234],\n",
      "        [0.5232],\n",
      "        [0.5233],\n",
      "        [0.5234],\n",
      "        [0.5232],\n",
      "        [0.5232],\n",
      "        [0.5233]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5229],\n",
      "        [0.5230],\n",
      "        [0.5231],\n",
      "        [0.5230],\n",
      "        [0.5229],\n",
      "        [0.5233],\n",
      "        [0.5230],\n",
      "        [0.5226],\n",
      "        [0.5230],\n",
      "        [0.5231],\n",
      "        [0.5229],\n",
      "        [0.5229],\n",
      "        [0.5230],\n",
      "        [0.5228],\n",
      "        [0.5229],\n",
      "        [0.5228]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5228],\n",
      "        [0.5226],\n",
      "        [0.5227],\n",
      "        [0.5226],\n",
      "        [0.5227],\n",
      "        [0.5227],\n",
      "        [0.5228],\n",
      "        [0.5227],\n",
      "        [0.5229],\n",
      "        [0.5229],\n",
      "        [0.5225],\n",
      "        [0.5225],\n",
      "        [0.5227],\n",
      "        [0.5224],\n",
      "        [0.5226],\n",
      "        [0.5227]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5224],\n",
      "        [0.5222],\n",
      "        [0.5223],\n",
      "        [0.5222],\n",
      "        [0.5224],\n",
      "        [0.5224],\n",
      "        [0.5222],\n",
      "        [0.5222],\n",
      "        [0.5223],\n",
      "        [0.5222],\n",
      "        [0.5222],\n",
      "        [0.5224],\n",
      "        [0.5221],\n",
      "        [0.5222],\n",
      "        [0.5222],\n",
      "        [0.5221]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5217],\n",
      "        [0.5219],\n",
      "        [0.5219],\n",
      "        [0.5218],\n",
      "        [0.5217],\n",
      "        [0.5217],\n",
      "        [0.5216],\n",
      "        [0.5218],\n",
      "        [0.5218],\n",
      "        [0.5216],\n",
      "        [0.5215],\n",
      "        [0.5218],\n",
      "        [0.5218],\n",
      "        [0.5219],\n",
      "        [0.5217],\n",
      "        [0.5219]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5213],\n",
      "        [0.5215],\n",
      "        [0.5215],\n",
      "        [0.5213],\n",
      "        [0.5217],\n",
      "        [0.5216],\n",
      "        [0.5212],\n",
      "        [0.5216],\n",
      "        [0.5214],\n",
      "        [0.5214],\n",
      "        [0.5215],\n",
      "        [0.5215],\n",
      "        [0.5215],\n",
      "        [0.5215],\n",
      "        [0.5219],\n",
      "        [0.5215]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5208],\n",
      "        [0.5210],\n",
      "        [0.5211],\n",
      "        [0.5211],\n",
      "        [0.5211],\n",
      "        [0.5209],\n",
      "        [0.5213],\n",
      "        [0.5211],\n",
      "        [0.5212],\n",
      "        [0.5210],\n",
      "        [0.5211],\n",
      "        [0.5212],\n",
      "        [0.5212],\n",
      "        [0.5212],\n",
      "        [0.5210],\n",
      "        [0.5213]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5208],\n",
      "        [0.5205],\n",
      "        [0.5208],\n",
      "        [0.5207],\n",
      "        [0.5208],\n",
      "        [0.5211],\n",
      "        [0.5210],\n",
      "        [0.5209],\n",
      "        [0.5206],\n",
      "        [0.5209],\n",
      "        [0.5207],\n",
      "        [0.5206],\n",
      "        [0.5209],\n",
      "        [0.5206],\n",
      "        [0.5206],\n",
      "        [0.5207]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5205],\n",
      "        [0.5205],\n",
      "        [0.5206],\n",
      "        [0.5204],\n",
      "        [0.5204],\n",
      "        [0.5205],\n",
      "        [0.5203],\n",
      "        [0.5205],\n",
      "        [0.5204],\n",
      "        [0.5206],\n",
      "        [0.5202],\n",
      "        [0.5209],\n",
      "        [0.5208],\n",
      "        [0.5206],\n",
      "        [0.5206],\n",
      "        [0.5205]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5202],\n",
      "        [0.5202],\n",
      "        [0.5203],\n",
      "        [0.5201],\n",
      "        [0.5202],\n",
      "        [0.5199],\n",
      "        [0.5200],\n",
      "        [0.5201],\n",
      "        [0.5204],\n",
      "        [0.5202],\n",
      "        [0.5200],\n",
      "        [0.5201],\n",
      "        [0.5202],\n",
      "        [0.5203],\n",
      "        [0.5202],\n",
      "        [0.5200]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194]], device='cuda:1')\n",
      "tensor([[0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194]], device='cuda:1')\n",
      "tensor([[0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5194]], device='cuda:1')\n",
      "\n",
      "Train loss: 28.050479125976562 | Val loss: 13.319644292195639\n",
      "Train acc: 0.4375 | Val acc: 0.25\n",
      "Epoch: 2\n",
      "tensor([[0.5198],\n",
      "        [0.5197],\n",
      "        [0.5197],\n",
      "        [0.5198],\n",
      "        [0.5197],\n",
      "        [0.5199],\n",
      "        [0.5199],\n",
      "        [0.5200],\n",
      "        [0.5198],\n",
      "        [0.5200],\n",
      "        [0.5198],\n",
      "        [0.5197],\n",
      "        [0.5197],\n",
      "        [0.5196],\n",
      "        [0.5197],\n",
      "        [0.5198]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5191],\n",
      "        [0.5193],\n",
      "        [0.5193],\n",
      "        [0.5194],\n",
      "        [0.5195],\n",
      "        [0.5194],\n",
      "        [0.5193],\n",
      "        [0.5194],\n",
      "        [0.5195],\n",
      "        [0.5192],\n",
      "        [0.5195],\n",
      "        [0.5193],\n",
      "        [0.5194],\n",
      "        [0.5194],\n",
      "        [0.5193],\n",
      "        [0.5194]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5192],\n",
      "        [0.5194],\n",
      "        [0.5192],\n",
      "        [0.5190],\n",
      "        [0.5192],\n",
      "        [0.5191],\n",
      "        [0.5192],\n",
      "        [0.5193],\n",
      "        [0.5193],\n",
      "        [0.5189],\n",
      "        [0.5193],\n",
      "        [0.5190],\n",
      "        [0.5192],\n",
      "        [0.5193],\n",
      "        [0.5190],\n",
      "        [0.5192]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5192],\n",
      "        [0.5192],\n",
      "        [0.5190],\n",
      "        [0.5190],\n",
      "        [0.5191],\n",
      "        [0.5189],\n",
      "        [0.5191],\n",
      "        [0.5191],\n",
      "        [0.5189],\n",
      "        [0.5189],\n",
      "        [0.5191],\n",
      "        [0.5190],\n",
      "        [0.5190],\n",
      "        [0.5189],\n",
      "        [0.5189],\n",
      "        [0.5190]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5189],\n",
      "        [0.5189],\n",
      "        [0.5188],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5188],\n",
      "        [0.5187],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5185],\n",
      "        [0.5188],\n",
      "        [0.5187],\n",
      "        [0.5188],\n",
      "        [0.5188],\n",
      "        [0.5188],\n",
      "        [0.5188]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5185],\n",
      "        [0.5184],\n",
      "        [0.5183],\n",
      "        [0.5184],\n",
      "        [0.5185],\n",
      "        [0.5183],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5184],\n",
      "        [0.5183],\n",
      "        [0.5183],\n",
      "        [0.5183],\n",
      "        [0.5184],\n",
      "        [0.5183],\n",
      "        [0.5185],\n",
      "        [0.5183]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5181],\n",
      "        [0.5181],\n",
      "        [0.5177],\n",
      "        [0.5177],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5181],\n",
      "        [0.5183],\n",
      "        [0.5179],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5179],\n",
      "        [0.5178],\n",
      "        [0.5178],\n",
      "        [0.5178],\n",
      "        [0.5181]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5175],\n",
      "        [0.5176],\n",
      "        [0.5175],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5176],\n",
      "        [0.5173],\n",
      "        [0.5172],\n",
      "        [0.5180],\n",
      "        [0.5174],\n",
      "        [0.5174],\n",
      "        [0.5174],\n",
      "        [0.5178],\n",
      "        [0.5174],\n",
      "        [0.5173],\n",
      "        [0.5173]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5171],\n",
      "        [0.5171],\n",
      "        [0.5174],\n",
      "        [0.5174],\n",
      "        [0.5175],\n",
      "        [0.5174],\n",
      "        [0.5172],\n",
      "        [0.5173],\n",
      "        [0.5173],\n",
      "        [0.5173],\n",
      "        [0.5172],\n",
      "        [0.5173],\n",
      "        [0.5173],\n",
      "        [0.5174],\n",
      "        [0.5173],\n",
      "        [0.5172]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5171],\n",
      "        [0.5170],\n",
      "        [0.5172],\n",
      "        [0.5172],\n",
      "        [0.5172],\n",
      "        [0.5172],\n",
      "        [0.5171],\n",
      "        [0.5172],\n",
      "        [0.5173],\n",
      "        [0.5171],\n",
      "        [0.5172],\n",
      "        [0.5171],\n",
      "        [0.5170],\n",
      "        [0.5172],\n",
      "        [0.5171],\n",
      "        [0.5172]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164]], device='cuda:1')\n",
      "tensor([[0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164]], device='cuda:1')\n",
      "tensor([[0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5164]], device='cuda:1')\n",
      "\n",
      "Train loss: 12.455495262145996 | Val loss: 11.231329600016275\n",
      "Train acc: 0.375 | Val acc: 0.625\n",
      "Epoch: 3\n",
      "tensor([[0.5168],\n",
      "        [0.5170],\n",
      "        [0.5168],\n",
      "        [0.5170],\n",
      "        [0.5168],\n",
      "        [0.5168],\n",
      "        [0.5170],\n",
      "        [0.5170],\n",
      "        [0.5168],\n",
      "        [0.5169],\n",
      "        [0.5167],\n",
      "        [0.5169],\n",
      "        [0.5169],\n",
      "        [0.5169],\n",
      "        [0.5171],\n",
      "        [0.5169]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5162],\n",
      "        [0.5166],\n",
      "        [0.5164],\n",
      "        [0.5165],\n",
      "        [0.5168],\n",
      "        [0.5169],\n",
      "        [0.5164],\n",
      "        [0.5165],\n",
      "        [0.5166],\n",
      "        [0.5164],\n",
      "        [0.5168],\n",
      "        [0.5166],\n",
      "        [0.5165],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5166]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5163],\n",
      "        [0.5166],\n",
      "        [0.5163],\n",
      "        [0.5162],\n",
      "        [0.5167],\n",
      "        [0.5163],\n",
      "        [0.5165],\n",
      "        [0.5165],\n",
      "        [0.5164],\n",
      "        [0.5163],\n",
      "        [0.5163],\n",
      "        [0.5164],\n",
      "        [0.5164],\n",
      "        [0.5163],\n",
      "        [0.5163],\n",
      "        [0.5164]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5159],\n",
      "        [0.5161],\n",
      "        [0.5160],\n",
      "        [0.5160],\n",
      "        [0.5159],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5158],\n",
      "        [0.5158],\n",
      "        [0.5162],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5158],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5159]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5155],\n",
      "        [0.5157],\n",
      "        [0.5155],\n",
      "        [0.5154],\n",
      "        [0.5155],\n",
      "        [0.5157],\n",
      "        [0.5154],\n",
      "        [0.5154],\n",
      "        [0.5153],\n",
      "        [0.5155],\n",
      "        [0.5156],\n",
      "        [0.5156],\n",
      "        [0.5155],\n",
      "        [0.5158],\n",
      "        [0.5157],\n",
      "        [0.5157]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5154],\n",
      "        [0.5150],\n",
      "        [0.5152],\n",
      "        [0.5152],\n",
      "        [0.5149],\n",
      "        [0.5154],\n",
      "        [0.5153],\n",
      "        [0.5153],\n",
      "        [0.5152],\n",
      "        [0.5153],\n",
      "        [0.5152],\n",
      "        [0.5153],\n",
      "        [0.5151],\n",
      "        [0.5152],\n",
      "        [0.5151],\n",
      "        [0.5152]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5151],\n",
      "        [0.5148],\n",
      "        [0.5150],\n",
      "        [0.5150],\n",
      "        [0.5149],\n",
      "        [0.5149],\n",
      "        [0.5150],\n",
      "        [0.5146],\n",
      "        [0.5149],\n",
      "        [0.5147],\n",
      "        [0.5148],\n",
      "        [0.5151],\n",
      "        [0.5151],\n",
      "        [0.5147],\n",
      "        [0.5148],\n",
      "        [0.5150]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5149],\n",
      "        [0.5149],\n",
      "        [0.5148],\n",
      "        [0.5148],\n",
      "        [0.5145],\n",
      "        [0.5150],\n",
      "        [0.5147],\n",
      "        [0.5146],\n",
      "        [0.5145],\n",
      "        [0.5146],\n",
      "        [0.5146],\n",
      "        [0.5148],\n",
      "        [0.5147],\n",
      "        [0.5148],\n",
      "        [0.5148],\n",
      "        [0.5148]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5147],\n",
      "        [0.5146],\n",
      "        [0.5144],\n",
      "        [0.5143],\n",
      "        [0.5144],\n",
      "        [0.5144],\n",
      "        [0.5146],\n",
      "        [0.5143],\n",
      "        [0.5146],\n",
      "        [0.5145],\n",
      "        [0.5144],\n",
      "        [0.5146],\n",
      "        [0.5146],\n",
      "        [0.5142],\n",
      "        [0.5147],\n",
      "        [0.5144]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5143],\n",
      "        [0.5145],\n",
      "        [0.5144],\n",
      "        [0.5144],\n",
      "        [0.5144],\n",
      "        [0.5146],\n",
      "        [0.5145],\n",
      "        [0.5145],\n",
      "        [0.5142],\n",
      "        [0.5146],\n",
      "        [0.5144],\n",
      "        [0.5141],\n",
      "        [0.5143],\n",
      "        [0.5146],\n",
      "        [0.5146],\n",
      "        [0.5145]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138]], device='cuda:1')\n",
      "tensor([[0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138]], device='cuda:1')\n",
      "tensor([[0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138]], device='cuda:1')\n",
      "\n",
      "Train loss: 11.315967750549316 | Val loss: 10.640619595845541\n",
      "Train acc: 0.4375 | Val acc: 0.625\n",
      "Epoch: 4\n",
      "tensor([[0.5144],\n",
      "        [0.5141],\n",
      "        [0.5143],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5141],\n",
      "        [0.5140],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5141],\n",
      "        [0.5141],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5142],\n",
      "        [0.5145],\n",
      "        [0.5142]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5142],\n",
      "        [0.5143],\n",
      "        [0.5143],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5144],\n",
      "        [0.5140],\n",
      "        [0.5139],\n",
      "        [0.5142],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5144],\n",
      "        [0.5142],\n",
      "        [0.5140],\n",
      "        [0.5140],\n",
      "        [0.5140]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5142],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5142],\n",
      "        [0.5140],\n",
      "        [0.5146],\n",
      "        [0.5142],\n",
      "        [0.5143],\n",
      "        [0.5146],\n",
      "        [0.5142],\n",
      "        [0.5140],\n",
      "        [0.5142],\n",
      "        [0.5139],\n",
      "        [0.5140],\n",
      "        [0.5141],\n",
      "        [0.5140]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5140],\n",
      "        [0.5140],\n",
      "        [0.5137],\n",
      "        [0.5138],\n",
      "        [0.5142],\n",
      "        [0.5140],\n",
      "        [0.5142],\n",
      "        [0.5139],\n",
      "        [0.5139],\n",
      "        [0.5139],\n",
      "        [0.5141],\n",
      "        [0.5138],\n",
      "        [0.5136],\n",
      "        [0.5141],\n",
      "        [0.5141],\n",
      "        [0.5139]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5137],\n",
      "        [0.5140],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5139],\n",
      "        [0.5137],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5139],\n",
      "        [0.5136],\n",
      "        [0.5141],\n",
      "        [0.5138],\n",
      "        [0.5139],\n",
      "        [0.5137],\n",
      "        [0.5140],\n",
      "        [0.5141]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5141],\n",
      "        [0.5138],\n",
      "        [0.5140],\n",
      "        [0.5141],\n",
      "        [0.5137],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5139],\n",
      "        [0.5138],\n",
      "        [0.5139],\n",
      "        [0.5138],\n",
      "        [0.5139],\n",
      "        [0.5136],\n",
      "        [0.5139],\n",
      "        [0.5138]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5137],\n",
      "        [0.5139],\n",
      "        [0.5140],\n",
      "        [0.5140],\n",
      "        [0.5138],\n",
      "        [0.5141],\n",
      "        [0.5137],\n",
      "        [0.5139],\n",
      "        [0.5137],\n",
      "        [0.5140],\n",
      "        [0.5140],\n",
      "        [0.5140],\n",
      "        [0.5138],\n",
      "        [0.5141],\n",
      "        [0.5140],\n",
      "        [0.5140]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5138],\n",
      "        [0.5139],\n",
      "        [0.5137],\n",
      "        [0.5136],\n",
      "        [0.5135],\n",
      "        [0.5140],\n",
      "        [0.5136],\n",
      "        [0.5137],\n",
      "        [0.5138],\n",
      "        [0.5138],\n",
      "        [0.5136],\n",
      "        [0.5136],\n",
      "        [0.5136],\n",
      "        [0.5137],\n",
      "        [0.5136],\n",
      "        [0.5136]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5136],\n",
      "        [0.5134],\n",
      "        [0.5134],\n",
      "        [0.5137],\n",
      "        [0.5137],\n",
      "        [0.5135],\n",
      "        [0.5135],\n",
      "        [0.5134],\n",
      "        [0.5135],\n",
      "        [0.5135],\n",
      "        [0.5136],\n",
      "        [0.5137],\n",
      "        [0.5136],\n",
      "        [0.5135],\n",
      "        [0.5137],\n",
      "        [0.5137]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5134],\n",
      "        [0.5131],\n",
      "        [0.5132],\n",
      "        [0.5132],\n",
      "        [0.5131],\n",
      "        [0.5131],\n",
      "        [0.5131],\n",
      "        [0.5130],\n",
      "        [0.5130],\n",
      "        [0.5132],\n",
      "        [0.5131],\n",
      "        [0.5133],\n",
      "        [0.5132],\n",
      "        [0.5131],\n",
      "        [0.5132],\n",
      "        [0.5132]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126]], device='cuda:1')\n",
      "tensor([[0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126]], device='cuda:1')\n",
      "tensor([[0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.904380130767823 | Val loss: 10.411080678304037\n",
      "Train acc: 0.625 | Val acc: 0.375\n",
      "Epoch: 5\n",
      "tensor([[0.5130],\n",
      "        [0.5128],\n",
      "        [0.5130],\n",
      "        [0.5130],\n",
      "        [0.5130],\n",
      "        [0.5132],\n",
      "        [0.5130],\n",
      "        [0.5131],\n",
      "        [0.5132],\n",
      "        [0.5131],\n",
      "        [0.5130],\n",
      "        [0.5131],\n",
      "        [0.5131],\n",
      "        [0.5131],\n",
      "        [0.5131],\n",
      "        [0.5131]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5130],\n",
      "        [0.5130],\n",
      "        [0.5131],\n",
      "        [0.5132],\n",
      "        [0.5130],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5130],\n",
      "        [0.5132],\n",
      "        [0.5129],\n",
      "        [0.5131],\n",
      "        [0.5130],\n",
      "        [0.5129],\n",
      "        [0.5129],\n",
      "        [0.5130],\n",
      "        [0.5131]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5129],\n",
      "        [0.5127],\n",
      "        [0.5127],\n",
      "        [0.5127],\n",
      "        [0.5128],\n",
      "        [0.5126],\n",
      "        [0.5130],\n",
      "        [0.5129],\n",
      "        [0.5129],\n",
      "        [0.5130],\n",
      "        [0.5130],\n",
      "        [0.5130],\n",
      "        [0.5129],\n",
      "        [0.5128],\n",
      "        [0.5126],\n",
      "        [0.5127]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5127],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5127],\n",
      "        [0.5125],\n",
      "        [0.5128],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5125]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5126],\n",
      "        [0.5129],\n",
      "        [0.5126],\n",
      "        [0.5125],\n",
      "        [0.5126],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5129],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5127],\n",
      "        [0.5127],\n",
      "        [0.5128]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5127],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5129],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5129],\n",
      "        [0.5126],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5127],\n",
      "        [0.5129],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5127]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5130],\n",
      "        [0.5129],\n",
      "        [0.5130],\n",
      "        [0.5129],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5129],\n",
      "        [0.5129],\n",
      "        [0.5129],\n",
      "        [0.5129],\n",
      "        [0.5128],\n",
      "        [0.5127],\n",
      "        [0.5128],\n",
      "        [0.5129],\n",
      "        [0.5130],\n",
      "        [0.5132]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5130],\n",
      "        [0.5128],\n",
      "        [0.5127],\n",
      "        [0.5128],\n",
      "        [0.5129],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5129],\n",
      "        [0.5126],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5129],\n",
      "        [0.5128],\n",
      "        [0.5128],\n",
      "        [0.5127],\n",
      "        [0.5127]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5127],\n",
      "        [0.5124],\n",
      "        [0.5127],\n",
      "        [0.5127],\n",
      "        [0.5126],\n",
      "        [0.5126],\n",
      "        [0.5125],\n",
      "        [0.5126],\n",
      "        [0.5127],\n",
      "        [0.5125],\n",
      "        [0.5126],\n",
      "        [0.5125],\n",
      "        [0.5126],\n",
      "        [0.5125],\n",
      "        [0.5125],\n",
      "        [0.5128]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5124],\n",
      "        [0.5122],\n",
      "        [0.5124],\n",
      "        [0.5125],\n",
      "        [0.5124],\n",
      "        [0.5124],\n",
      "        [0.5123],\n",
      "        [0.5125],\n",
      "        [0.5124],\n",
      "        [0.5124],\n",
      "        [0.5125],\n",
      "        [0.5123],\n",
      "        [0.5126],\n",
      "        [0.5124],\n",
      "        [0.5123],\n",
      "        [0.5122]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117]], device='cuda:1')\n",
      "tensor([[0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117]], device='cuda:1')\n",
      "tensor([[0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117],\n",
      "        [0.5117]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.714370250701904 | Val loss: 10.28677749633789\n",
      "Train acc: 0.4375 | Val acc: 0.125\n",
      "Epoch: 6\n",
      "tensor([[0.5122],\n",
      "        [0.5122],\n",
      "        [0.5121],\n",
      "        [0.5124],\n",
      "        [0.5121],\n",
      "        [0.5124],\n",
      "        [0.5122],\n",
      "        [0.5120],\n",
      "        [0.5121],\n",
      "        [0.5122],\n",
      "        [0.5122],\n",
      "        [0.5122],\n",
      "        [0.5122],\n",
      "        [0.5121],\n",
      "        [0.5120],\n",
      "        [0.5122]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5119],\n",
      "        [0.5118],\n",
      "        [0.5117],\n",
      "        [0.5119],\n",
      "        [0.5118],\n",
      "        [0.5116],\n",
      "        [0.5118],\n",
      "        [0.5116],\n",
      "        [0.5120],\n",
      "        [0.5119],\n",
      "        [0.5118],\n",
      "        [0.5120],\n",
      "        [0.5119],\n",
      "        [0.5120],\n",
      "        [0.5121],\n",
      "        [0.5119]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5115],\n",
      "        [0.5113],\n",
      "        [0.5114],\n",
      "        [0.5115],\n",
      "        [0.5115],\n",
      "        [0.5115],\n",
      "        [0.5113],\n",
      "        [0.5115],\n",
      "        [0.5115],\n",
      "        [0.5116],\n",
      "        [0.5112],\n",
      "        [0.5114],\n",
      "        [0.5115],\n",
      "        [0.5115],\n",
      "        [0.5114],\n",
      "        [0.5113]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5110],\n",
      "        [0.5108],\n",
      "        [0.5109],\n",
      "        [0.5109],\n",
      "        [0.5111],\n",
      "        [0.5111],\n",
      "        [0.5114],\n",
      "        [0.5109],\n",
      "        [0.5110],\n",
      "        [0.5110],\n",
      "        [0.5108],\n",
      "        [0.5110],\n",
      "        [0.5110],\n",
      "        [0.5110],\n",
      "        [0.5111],\n",
      "        [0.5107]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5105],\n",
      "        [0.5107],\n",
      "        [0.5106],\n",
      "        [0.5106],\n",
      "        [0.5108],\n",
      "        [0.5106],\n",
      "        [0.5105],\n",
      "        [0.5106],\n",
      "        [0.5105],\n",
      "        [0.5109],\n",
      "        [0.5108],\n",
      "        [0.5108],\n",
      "        [0.5109],\n",
      "        [0.5108],\n",
      "        [0.5107],\n",
      "        [0.5107]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5104],\n",
      "        [0.5104],\n",
      "        [0.5107],\n",
      "        [0.5103],\n",
      "        [0.5106],\n",
      "        [0.5105],\n",
      "        [0.5106],\n",
      "        [0.5103],\n",
      "        [0.5106],\n",
      "        [0.5107],\n",
      "        [0.5106],\n",
      "        [0.5101],\n",
      "        [0.5105],\n",
      "        [0.5106],\n",
      "        [0.5105],\n",
      "        [0.5105]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5102],\n",
      "        [0.5103],\n",
      "        [0.5103],\n",
      "        [0.5104],\n",
      "        [0.5104],\n",
      "        [0.5104],\n",
      "        [0.5104],\n",
      "        [0.5103],\n",
      "        [0.5106],\n",
      "        [0.5106],\n",
      "        [0.5107],\n",
      "        [0.5104],\n",
      "        [0.5103],\n",
      "        [0.5106],\n",
      "        [0.5104],\n",
      "        [0.5104]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5098],\n",
      "        [0.5101],\n",
      "        [0.5100],\n",
      "        [0.5102],\n",
      "        [0.5102],\n",
      "        [0.5102],\n",
      "        [0.5100],\n",
      "        [0.5101],\n",
      "        [0.5100],\n",
      "        [0.5101],\n",
      "        [0.5101],\n",
      "        [0.5102],\n",
      "        [0.5102],\n",
      "        [0.5101],\n",
      "        [0.5101],\n",
      "        [0.5099]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5099],\n",
      "        [0.5097],\n",
      "        [0.5097],\n",
      "        [0.5100],\n",
      "        [0.5098],\n",
      "        [0.5098],\n",
      "        [0.5098],\n",
      "        [0.5100],\n",
      "        [0.5098],\n",
      "        [0.5099],\n",
      "        [0.5099],\n",
      "        [0.5098],\n",
      "        [0.5098],\n",
      "        [0.5097],\n",
      "        [0.5099],\n",
      "        [0.5100]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5095],\n",
      "        [0.5097],\n",
      "        [0.5097],\n",
      "        [0.5094],\n",
      "        [0.5097],\n",
      "        [0.5097],\n",
      "        [0.5096],\n",
      "        [0.5096],\n",
      "        [0.5095],\n",
      "        [0.5096],\n",
      "        [0.5096],\n",
      "        [0.5096],\n",
      "        [0.5096],\n",
      "        [0.5095],\n",
      "        [0.5094],\n",
      "        [0.5096]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091]], device='cuda:1')\n",
      "tensor([[0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091]], device='cuda:1')\n",
      "tensor([[0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5091]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.602074337005615 | Val loss: 10.190788586934408\n",
      "Train acc: 0.625 | Val acc: 0.375\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5097],\n",
      "        [0.5095],\n",
      "        [0.5095],\n",
      "        [0.5093],\n",
      "        [0.5099],\n",
      "        [0.5094],\n",
      "        [0.5098],\n",
      "        [0.5096],\n",
      "        [0.5097],\n",
      "        [0.5096],\n",
      "        [0.5095],\n",
      "        [0.5095],\n",
      "        [0.5095],\n",
      "        [0.5098],\n",
      "        [0.5096],\n",
      "        [0.5095]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5096],\n",
      "        [0.5096],\n",
      "        [0.5096],\n",
      "        [0.5095],\n",
      "        [0.5093],\n",
      "        [0.5097],\n",
      "        [0.5098],\n",
      "        [0.5097],\n",
      "        [0.5097],\n",
      "        [0.5095],\n",
      "        [0.5096],\n",
      "        [0.5095],\n",
      "        [0.5093],\n",
      "        [0.5096],\n",
      "        [0.5097],\n",
      "        [0.5095]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5092],\n",
      "        [0.5093],\n",
      "        [0.5095],\n",
      "        [0.5093],\n",
      "        [0.5092],\n",
      "        [0.5093],\n",
      "        [0.5093],\n",
      "        [0.5095],\n",
      "        [0.5094],\n",
      "        [0.5093],\n",
      "        [0.5093],\n",
      "        [0.5093],\n",
      "        [0.5094],\n",
      "        [0.5094],\n",
      "        [0.5093],\n",
      "        [0.5094]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5090],\n",
      "        [0.5090],\n",
      "        [0.5090],\n",
      "        [0.5088],\n",
      "        [0.5090],\n",
      "        [0.5090],\n",
      "        [0.5090],\n",
      "        [0.5088],\n",
      "        [0.5090],\n",
      "        [0.5091],\n",
      "        [0.5090],\n",
      "        [0.5091],\n",
      "        [0.5091],\n",
      "        [0.5092],\n",
      "        [0.5089],\n",
      "        [0.5090]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5086],\n",
      "        [0.5084],\n",
      "        [0.5086],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5087],\n",
      "        [0.5084],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5087],\n",
      "        [0.5088],\n",
      "        [0.5083],\n",
      "        [0.5085]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5086],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5086],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5084],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5086],\n",
      "        [0.5083],\n",
      "        [0.5087],\n",
      "        [0.5084],\n",
      "        [0.5085],\n",
      "        [0.5086],\n",
      "        [0.5084]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5084],\n",
      "        [0.5086],\n",
      "        [0.5087],\n",
      "        [0.5085],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5083],\n",
      "        [0.5087],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5084],\n",
      "        [0.5082],\n",
      "        [0.5086],\n",
      "        [0.5083],\n",
      "        [0.5085]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5087],\n",
      "        [0.5084],\n",
      "        [0.5084],\n",
      "        [0.5080],\n",
      "        [0.5083],\n",
      "        [0.5081],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5081],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5083],\n",
      "        [0.5084],\n",
      "        [0.5083]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5082],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5079]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5078],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5082],\n",
      "        [0.5075],\n",
      "        [0.5077],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5080]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075]], device='cuda:1')\n",
      "tensor([[0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075]], device='cuda:1')\n",
      "tensor([[0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.51880922317505 | Val loss: 10.11450990041097\n",
      "Train acc: 0.6875 | Val acc: 0.625\n",
      "Epoch: 8\n",
      "tensor([[0.5078],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5076],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5081]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5080],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5077],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5080]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5078],\n",
      "        [0.5077],\n",
      "        [0.5081],\n",
      "        [0.5081]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5080],\n",
      "        [0.5083],\n",
      "        [0.5082],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5081],\n",
      "        [0.5083],\n",
      "        [0.5083],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5078]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5079],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5083],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5080]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5080],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5082],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5080]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5080],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5082],\n",
      "        [0.5080]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5078],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5076],\n",
      "        [0.5075],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5077]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5078],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5077],\n",
      "        [0.5083],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5076],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5079]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5078],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5076],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5077],\n",
      "        [0.5074],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5076],\n",
      "        [0.5078],\n",
      "        [0.5076]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073]], device='cuda:1')\n",
      "tensor([[0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073]], device='cuda:1')\n",
      "tensor([[0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.450435543060303 | Val loss: 10.055492719014486\n",
      "Train acc: 0.5625 | Val acc: 0.375\n",
      "Epoch: 9\n",
      "tensor([[0.5079],\n",
      "        [0.5077],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5078],\n",
      "        [0.5073],\n",
      "        [0.5077],\n",
      "        [0.5076],\n",
      "        [0.5077],\n",
      "        [0.5076],\n",
      "        [0.5075],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5077],\n",
      "        [0.5079]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5076],\n",
      "        [0.5077],\n",
      "        [0.5077],\n",
      "        [0.5078],\n",
      "        [0.5080],\n",
      "        [0.5075],\n",
      "        [0.5076],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5076],\n",
      "        [0.5077],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5077],\n",
      "        [0.5076],\n",
      "        [0.5076]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5076],\n",
      "        [0.5081],\n",
      "        [0.5076],\n",
      "        [0.5077],\n",
      "        [0.5077],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5076],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5076],\n",
      "        [0.5081],\n",
      "        [0.5078],\n",
      "        [0.5077]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5079]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5081],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5081],\n",
      "        [0.5084],\n",
      "        [0.5084],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5083],\n",
      "        [0.5082]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5080],\n",
      "        [0.5083],\n",
      "        [0.5083],\n",
      "        [0.5082],\n",
      "        [0.5084],\n",
      "        [0.5082],\n",
      "        [0.5083],\n",
      "        [0.5083],\n",
      "        [0.5082],\n",
      "        [0.5082],\n",
      "        [0.5083],\n",
      "        [0.5081],\n",
      "        [0.5080],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5083]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5083],\n",
      "        [0.5084],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5083],\n",
      "        [0.5083],\n",
      "        [0.5082],\n",
      "        [0.5082],\n",
      "        [0.5084],\n",
      "        [0.5084],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5083],\n",
      "        [0.5086],\n",
      "        [0.5082],\n",
      "        [0.5084]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5085],\n",
      "        [0.5085],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5086],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5088],\n",
      "        [0.5085],\n",
      "        [0.5088],\n",
      "        [0.5085],\n",
      "        [0.5088],\n",
      "        [0.5088],\n",
      "        [0.5085],\n",
      "        [0.5084],\n",
      "        [0.5084]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5084],\n",
      "        [0.5088],\n",
      "        [0.5087],\n",
      "        [0.5088],\n",
      "        [0.5085],\n",
      "        [0.5084],\n",
      "        [0.5090],\n",
      "        [0.5087],\n",
      "        [0.5088],\n",
      "        [0.5085],\n",
      "        [0.5084],\n",
      "        [0.5088],\n",
      "        [0.5087],\n",
      "        [0.5087],\n",
      "        [0.5089],\n",
      "        [0.5087]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5088],\n",
      "        [0.5087],\n",
      "        [0.5087],\n",
      "        [0.5089],\n",
      "        [0.5086],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5087],\n",
      "        [0.5088],\n",
      "        [0.5090],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5088],\n",
      "        [0.5087],\n",
      "        [0.5088],\n",
      "        [0.5088]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081]], device='cuda:1')\n",
      "tensor([[0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081]], device='cuda:1')\n",
      "tensor([[0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5081]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.39674425125122 | Val loss: 10.005603154500326\n",
      "Train acc: 0.25 | Val acc: 0.5\n",
      "Epoch: 10\n",
      "tensor([[0.5087],\n",
      "        [0.5083],\n",
      "        [0.5084],\n",
      "        [0.5086],\n",
      "        [0.5084],\n",
      "        [0.5083],\n",
      "        [0.5089],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5086],\n",
      "        [0.5082],\n",
      "        [0.5086],\n",
      "        [0.5084]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5086],\n",
      "        [0.5084],\n",
      "        [0.5084],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5084],\n",
      "        [0.5086],\n",
      "        [0.5081],\n",
      "        [0.5083],\n",
      "        [0.5085],\n",
      "        [0.5088],\n",
      "        [0.5084],\n",
      "        [0.5083],\n",
      "        [0.5084]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5083],\n",
      "        [0.5083],\n",
      "        [0.5084],\n",
      "        [0.5084],\n",
      "        [0.5087],\n",
      "        [0.5082],\n",
      "        [0.5086],\n",
      "        [0.5084],\n",
      "        [0.5084],\n",
      "        [0.5086],\n",
      "        [0.5084],\n",
      "        [0.5086],\n",
      "        [0.5083],\n",
      "        [0.5083],\n",
      "        [0.5081],\n",
      "        [0.5088]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5084],\n",
      "        [0.5087],\n",
      "        [0.5086],\n",
      "        [0.5082],\n",
      "        [0.5085],\n",
      "        [0.5088],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5086],\n",
      "        [0.5085],\n",
      "        [0.5088],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5083],\n",
      "        [0.5082]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5084],\n",
      "        [0.5085],\n",
      "        [0.5082],\n",
      "        [0.5084],\n",
      "        [0.5081],\n",
      "        [0.5084],\n",
      "        [0.5082],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5086],\n",
      "        [0.5083],\n",
      "        [0.5087],\n",
      "        [0.5085],\n",
      "        [0.5085],\n",
      "        [0.5082],\n",
      "        [0.5084]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5080],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5080],\n",
      "        [0.5083],\n",
      "        [0.5079],\n",
      "        [0.5079],\n",
      "        [0.5083],\n",
      "        [0.5081],\n",
      "        [0.5080],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5082],\n",
      "        [0.5081]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5078],\n",
      "        [0.5079],\n",
      "        [0.5081],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5083],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5081],\n",
      "        [0.5082],\n",
      "        [0.5080],\n",
      "        [0.5083],\n",
      "        [0.5082],\n",
      "        [0.5082],\n",
      "        [0.5083],\n",
      "        [0.5080]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5081],\n",
      "        [0.5075],\n",
      "        [0.5078],\n",
      "        [0.5077],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5079],\n",
      "        [0.5078],\n",
      "        [0.5079],\n",
      "        [0.5080],\n",
      "        [0.5080],\n",
      "        [0.5079],\n",
      "        [0.5077],\n",
      "        [0.5077],\n",
      "        [0.5080],\n",
      "        [0.5077]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5075],\n",
      "        [0.5075],\n",
      "        [0.5075],\n",
      "        [0.5074],\n",
      "        [0.5077],\n",
      "        [0.5076],\n",
      "        [0.5075],\n",
      "        [0.5076],\n",
      "        [0.5076],\n",
      "        [0.5077],\n",
      "        [0.5075],\n",
      "        [0.5077],\n",
      "        [0.5077],\n",
      "        [0.5076],\n",
      "        [0.5076],\n",
      "        [0.5075]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5075],\n",
      "        [0.5075],\n",
      "        [0.5073],\n",
      "        [0.5074],\n",
      "        [0.5075],\n",
      "        [0.5074],\n",
      "        [0.5074],\n",
      "        [0.5072],\n",
      "        [0.5073],\n",
      "        [0.5074],\n",
      "        [0.5076],\n",
      "        [0.5074],\n",
      "        [0.5074],\n",
      "        [0.5073],\n",
      "        [0.5072],\n",
      "        [0.5074]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068]], device='cuda:1')\n",
      "tensor([[0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068]], device='cuda:1')\n",
      "tensor([[0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5068]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.350829315185546 | Val loss: 9.963562965393066\n",
      "Train acc: 0.5625 | Val acc: 0.5\n",
      "Epoch: 11\n",
      "tensor([[0.5070],\n",
      "        [0.5072],\n",
      "        [0.5073],\n",
      "        [0.5074],\n",
      "        [0.5072],\n",
      "        [0.5073],\n",
      "        [0.5072],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5073],\n",
      "        [0.5071],\n",
      "        [0.5070],\n",
      "        [0.5072],\n",
      "        [0.5074],\n",
      "        [0.5074],\n",
      "        [0.5074]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5069],\n",
      "        [0.5066],\n",
      "        [0.5069],\n",
      "        [0.5066],\n",
      "        [0.5069],\n",
      "        [0.5069],\n",
      "        [0.5066],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5072],\n",
      "        [0.5070],\n",
      "        [0.5070],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5069]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5068],\n",
      "        [0.5064],\n",
      "        [0.5066],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5066],\n",
      "        [0.5067],\n",
      "        [0.5069],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5068],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5070]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5067],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5069],\n",
      "        [0.5067],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5065],\n",
      "        [0.5069],\n",
      "        [0.5066],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5067]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5068],\n",
      "        [0.5065],\n",
      "        [0.5067],\n",
      "        [0.5066],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5067],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5067],\n",
      "        [0.5065],\n",
      "        [0.5067],\n",
      "        [0.5067]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5065],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5066],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5066],\n",
      "        [0.5068],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5064],\n",
      "        [0.5066]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5067],\n",
      "        [0.5068],\n",
      "        [0.5067],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5068],\n",
      "        [0.5067],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5070],\n",
      "        [0.5067],\n",
      "        [0.5066],\n",
      "        [0.5068],\n",
      "        [0.5067],\n",
      "        [0.5069],\n",
      "        [0.5065]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5069],\n",
      "        [0.5071],\n",
      "        [0.5068],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5072],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5072],\n",
      "        [0.5072],\n",
      "        [0.5068],\n",
      "        [0.5073],\n",
      "        [0.5070],\n",
      "        [0.5069]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5070],\n",
      "        [0.5072],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5071],\n",
      "        [0.5068],\n",
      "        [0.5068],\n",
      "        [0.5071],\n",
      "        [0.5071],\n",
      "        [0.5067],\n",
      "        [0.5071],\n",
      "        [0.5068],\n",
      "        [0.5071],\n",
      "        [0.5069],\n",
      "        [0.5070]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5070],\n",
      "        [0.5067],\n",
      "        [0.5067],\n",
      "        [0.5068],\n",
      "        [0.5066],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5067],\n",
      "        [0.5069],\n",
      "        [0.5069],\n",
      "        [0.5068],\n",
      "        [0.5069],\n",
      "        [0.5067],\n",
      "        [0.5070],\n",
      "        [0.5068],\n",
      "        [0.5068]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062]], device='cuda:1')\n",
      "tensor([[0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062]], device='cuda:1')\n",
      "tensor([[0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5062]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.311158275604248 | Val loss: 9.92700163523356\n",
      "Train acc: 0.4375 | Val acc: 0.375\n",
      "Epoch: 12\n",
      "tensor([[0.5063],\n",
      "        [0.5066],\n",
      "        [0.5066],\n",
      "        [0.5063],\n",
      "        [0.5066],\n",
      "        [0.5065],\n",
      "        [0.5069],\n",
      "        [0.5066],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5067],\n",
      "        [0.5066]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5066],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5063],\n",
      "        [0.5065],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5066]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5064],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5064],\n",
      "        [0.5063]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5062],\n",
      "        [0.5065],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5062],\n",
      "        [0.5064],\n",
      "        [0.5062],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5065],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5064]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5064],\n",
      "        [0.5063],\n",
      "        [0.5062],\n",
      "        [0.5061],\n",
      "        [0.5063],\n",
      "        [0.5061],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5061],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5061],\n",
      "        [0.5062],\n",
      "        [0.5062]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5063],\n",
      "        [0.5063],\n",
      "        [0.5061],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5062],\n",
      "        [0.5059],\n",
      "        [0.5064],\n",
      "        [0.5061],\n",
      "        [0.5062],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5061],\n",
      "        [0.5063]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5066],\n",
      "        [0.5063],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5061],\n",
      "        [0.5063],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5066],\n",
      "        [0.5064],\n",
      "        [0.5062],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5066]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5066],\n",
      "        [0.5064],\n",
      "        [0.5066],\n",
      "        [0.5067],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5064],\n",
      "        [0.5065],\n",
      "        [0.5063],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5069],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5066],\n",
      "        [0.5068]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5065],\n",
      "        [0.5065],\n",
      "        [0.5065],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5067],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5062],\n",
      "        [0.5064],\n",
      "        [0.5066],\n",
      "        [0.5063],\n",
      "        [0.5063]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5064],\n",
      "        [0.5063],\n",
      "        [0.5060],\n",
      "        [0.5059],\n",
      "        [0.5062],\n",
      "        [0.5063],\n",
      "        [0.5061],\n",
      "        [0.5063],\n",
      "        [0.5064],\n",
      "        [0.5064],\n",
      "        [0.5063],\n",
      "        [0.5063],\n",
      "        [0.5060],\n",
      "        [0.5061],\n",
      "        [0.5061],\n",
      "        [0.5064]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056]], device='cuda:1')\n",
      "tensor([[0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056]], device='cuda:1')\n",
      "tensor([[0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5056]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.273584651947022 | Val loss: 9.894219398498535\n",
      "Train acc: 0.5 | Val acc: 0.25\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5058],\n",
      "        [0.5058],\n",
      "        [0.5066],\n",
      "        [0.5065],\n",
      "        [0.5062],\n",
      "        [0.5061],\n",
      "        [0.5057],\n",
      "        [0.5063],\n",
      "        [0.5059],\n",
      "        [0.5061],\n",
      "        [0.5059],\n",
      "        [0.5058],\n",
      "        [0.5059],\n",
      "        [0.5063],\n",
      "        [0.5060],\n",
      "        [0.5060]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5061],\n",
      "        [0.5060],\n",
      "        [0.5059],\n",
      "        [0.5060],\n",
      "        [0.5058],\n",
      "        [0.5059],\n",
      "        [0.5060],\n",
      "        [0.5061],\n",
      "        [0.5059],\n",
      "        [0.5060],\n",
      "        [0.5059],\n",
      "        [0.5058],\n",
      "        [0.5062],\n",
      "        [0.5060],\n",
      "        [0.5059],\n",
      "        [0.5058]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5059],\n",
      "        [0.5061],\n",
      "        [0.5058],\n",
      "        [0.5060],\n",
      "        [0.5060],\n",
      "        [0.5056],\n",
      "        [0.5060],\n",
      "        [0.5058],\n",
      "        [0.5060],\n",
      "        [0.5060],\n",
      "        [0.5057],\n",
      "        [0.5058],\n",
      "        [0.5058],\n",
      "        [0.5060],\n",
      "        [0.5058],\n",
      "        [0.5058]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5059],\n",
      "        [0.5056],\n",
      "        [0.5059],\n",
      "        [0.5058],\n",
      "        [0.5056],\n",
      "        [0.5056],\n",
      "        [0.5058],\n",
      "        [0.5056],\n",
      "        [0.5057],\n",
      "        [0.5057],\n",
      "        [0.5059],\n",
      "        [0.5058],\n",
      "        [0.5058],\n",
      "        [0.5057],\n",
      "        [0.5056],\n",
      "        [0.5056]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5057],\n",
      "        [0.5053],\n",
      "        [0.5057],\n",
      "        [0.5055],\n",
      "        [0.5056],\n",
      "        [0.5055],\n",
      "        [0.5055],\n",
      "        [0.5053],\n",
      "        [0.5055],\n",
      "        [0.5053],\n",
      "        [0.5056],\n",
      "        [0.5054],\n",
      "        [0.5056],\n",
      "        [0.5054],\n",
      "        [0.5054],\n",
      "        [0.5057]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5052],\n",
      "        [0.5052],\n",
      "        [0.5052],\n",
      "        [0.5053],\n",
      "        [0.5053],\n",
      "        [0.5049],\n",
      "        [0.5053],\n",
      "        [0.5050],\n",
      "        [0.5053],\n",
      "        [0.5052],\n",
      "        [0.5051],\n",
      "        [0.5051],\n",
      "        [0.5049],\n",
      "        [0.5054],\n",
      "        [0.5052],\n",
      "        [0.5050]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5051],\n",
      "        [0.5051],\n",
      "        [0.5052],\n",
      "        [0.5051],\n",
      "        [0.5051],\n",
      "        [0.5052],\n",
      "        [0.5051],\n",
      "        [0.5050],\n",
      "        [0.5052],\n",
      "        [0.5051],\n",
      "        [0.5051],\n",
      "        [0.5049],\n",
      "        [0.5051],\n",
      "        [0.5048],\n",
      "        [0.5053],\n",
      "        [0.5048]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5050],\n",
      "        [0.5049],\n",
      "        [0.5050],\n",
      "        [0.5048],\n",
      "        [0.5048],\n",
      "        [0.5050],\n",
      "        [0.5050],\n",
      "        [0.5047],\n",
      "        [0.5047],\n",
      "        [0.5049],\n",
      "        [0.5048],\n",
      "        [0.5050],\n",
      "        [0.5050],\n",
      "        [0.5049],\n",
      "        [0.5051],\n",
      "        [0.5050]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5049],\n",
      "        [0.5047],\n",
      "        [0.5049],\n",
      "        [0.5049],\n",
      "        [0.5048],\n",
      "        [0.5048],\n",
      "        [0.5049],\n",
      "        [0.5050],\n",
      "        [0.5050],\n",
      "        [0.5049],\n",
      "        [0.5050],\n",
      "        [0.5051],\n",
      "        [0.5048],\n",
      "        [0.5050],\n",
      "        [0.5048],\n",
      "        [0.5047]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5052],\n",
      "        [0.5050],\n",
      "        [0.5049],\n",
      "        [0.5048],\n",
      "        [0.5046],\n",
      "        [0.5049],\n",
      "        [0.5046],\n",
      "        [0.5046],\n",
      "        [0.5048],\n",
      "        [0.5048],\n",
      "        [0.5046],\n",
      "        [0.5046],\n",
      "        [0.5048],\n",
      "        [0.5046],\n",
      "        [0.5046],\n",
      "        [0.5047]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043]], device='cuda:1')\n",
      "tensor([[0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043]], device='cuda:1')\n",
      "tensor([[0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5043]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.241966152191162 | Val loss: 9.863531430562338\n",
      "Train acc: 0.5625 | Val acc: 0.5\n",
      "Epoch: 14\n",
      "tensor([[0.5046],\n",
      "        [0.5042],\n",
      "        [0.5047],\n",
      "        [0.5046],\n",
      "        [0.5047],\n",
      "        [0.5047],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5047],\n",
      "        [0.5049],\n",
      "        [0.5046],\n",
      "        [0.5045],\n",
      "        [0.5048],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5048]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5047],\n",
      "        [0.5047],\n",
      "        [0.5048],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5046],\n",
      "        [0.5046],\n",
      "        [0.5045],\n",
      "        [0.5047],\n",
      "        [0.5048],\n",
      "        [0.5045],\n",
      "        [0.5049],\n",
      "        [0.5047],\n",
      "        [0.5049],\n",
      "        [0.5043],\n",
      "        [0.5045]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5044],\n",
      "        [0.5047],\n",
      "        [0.5047],\n",
      "        [0.5044],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5047],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5047],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5046]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5042],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5041],\n",
      "        [0.5044],\n",
      "        [0.5044]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5041],\n",
      "        [0.5042],\n",
      "        [0.5040],\n",
      "        [0.5040],\n",
      "        [0.5043],\n",
      "        [0.5040],\n",
      "        [0.5044],\n",
      "        [0.5041],\n",
      "        [0.5042],\n",
      "        [0.5039],\n",
      "        [0.5042],\n",
      "        [0.5041],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5040],\n",
      "        [0.5040]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5044],\n",
      "        [0.5042],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5046],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5043],\n",
      "        [0.5041],\n",
      "        [0.5045],\n",
      "        [0.5042]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5044],\n",
      "        [0.5043],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5043]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5045],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5043],\n",
      "        [0.5047],\n",
      "        [0.5044],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5043]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5042],\n",
      "        [0.5044],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5046],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5046],\n",
      "        [0.5042],\n",
      "        [0.5040],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5046],\n",
      "        [0.5043],\n",
      "        [0.5043]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5045],\n",
      "        [0.5046],\n",
      "        [0.5046],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5046],\n",
      "        [0.5046],\n",
      "        [0.5042],\n",
      "        [0.5046],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5045]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039]], device='cuda:1')\n",
      "tensor([[0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039]], device='cuda:1')\n",
      "tensor([[0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5039]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.214535808563232 | Val loss: 9.83670425415039\n",
      "Train acc: 0.4375 | Val acc: 0.5\n",
      "Epoch: 15\n",
      "tensor([[0.5044],\n",
      "        [0.5044],\n",
      "        [0.5046],\n",
      "        [0.5044],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5041],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5043],\n",
      "        [0.5042]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5043],\n",
      "        [0.5047],\n",
      "        [0.5041],\n",
      "        [0.5044],\n",
      "        [0.5043],\n",
      "        [0.5041],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5042],\n",
      "        [0.5042]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5043],\n",
      "        [0.5044],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5041],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5041],\n",
      "        [0.5044],\n",
      "        [0.5041],\n",
      "        [0.5042],\n",
      "        [0.5043],\n",
      "        [0.5041],\n",
      "        [0.5040]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5040],\n",
      "        [0.5042],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5040],\n",
      "        [0.5044],\n",
      "        [0.5040],\n",
      "        [0.5038],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5043]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5040],\n",
      "        [0.5040],\n",
      "        [0.5040],\n",
      "        [0.5040],\n",
      "        [0.5039],\n",
      "        [0.5040],\n",
      "        [0.5039],\n",
      "        [0.5042],\n",
      "        [0.5040],\n",
      "        [0.5038],\n",
      "        [0.5041],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5039]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5036],\n",
      "        [0.5042],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5040],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5040],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5037],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5037]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5036],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5037]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5038],\n",
      "        [0.5033],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5038]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5035],\n",
      "        [0.5035],\n",
      "        [0.5032],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5036]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5035],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5038],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5036]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031]], device='cuda:1')\n",
      "tensor([[0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031]], device='cuda:1')\n",
      "tensor([[0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.186439514160156 | Val loss: 9.812570254007975\n",
      "Train acc: 0.5 | Val acc: 0.375\n",
      "Epoch: 16\n",
      "tensor([[0.5034],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5031],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5038],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5038]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5035],\n",
      "        [0.5035],\n",
      "        [0.5031],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5036],\n",
      "        [0.5032],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5031],\n",
      "        [0.5034],\n",
      "        [0.5034]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5031],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5031],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5034],\n",
      "        [0.5034]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5031],\n",
      "        [0.5031],\n",
      "        [0.5033],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5035],\n",
      "        [0.5031],\n",
      "        [0.5033],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5031],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5033],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5032],\n",
      "        [0.5028],\n",
      "        [0.5033],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5033],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5034],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5031]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5027],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5028]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5027],\n",
      "        [0.5029],\n",
      "        [0.5033],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5030]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1')\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1')\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.161804676055908 | Val loss: 9.789777437845865\n",
      "Train acc: 0.4375 | Val acc: 0.5\n",
      "Epoch: 17\n",
      "tensor([[0.5027],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5032],\n",
      "        [0.5035],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5034]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5034]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5035],\n",
      "        [0.5033],\n",
      "        [0.5031],\n",
      "        [0.5034],\n",
      "        [0.5030],\n",
      "        [0.5033],\n",
      "        [0.5035],\n",
      "        [0.5030],\n",
      "        [0.5033],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5035],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5033],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5037],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5035]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5035],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5033]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5028],\n",
      "        [0.5034],\n",
      "        [0.5029],\n",
      "        [0.5034]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5030]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5032],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5024],\n",
      "        [0.5026],\n",
      "        [0.5030],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5027]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5025],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5029],\n",
      "        [0.5026],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024]], device='cuda:1')\n",
      "tensor([[0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024]], device='cuda:1')\n",
      "tensor([[0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.142663097381591 | Val loss: 9.768361727396647\n",
      "Train acc: 0.4375 | Val acc: 0.5\n",
      "Epoch: 18\n",
      "tensor([[0.5028],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5030],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5026],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5028]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5031],\n",
      "        [0.5030],\n",
      "        [0.5027],\n",
      "        [0.5032],\n",
      "        [0.5030],\n",
      "        [0.5033],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5033],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5034],\n",
      "        [0.5033],\n",
      "        [0.5033],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5038],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5035]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5038],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5034],\n",
      "        [0.5037],\n",
      "        [0.5041],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5038]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5038],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5035],\n",
      "        [0.5038],\n",
      "        [0.5040],\n",
      "        [0.5039],\n",
      "        [0.5040]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5038],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5040],\n",
      "        [0.5039]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5040],\n",
      "        [0.5039],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5036],\n",
      "        [0.5040],\n",
      "        [0.5038],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5040],\n",
      "        [0.5037]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5036],\n",
      "        [0.5040],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5041],\n",
      "        [0.5038],\n",
      "        [0.5040],\n",
      "        [0.5036],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5039]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5036],\n",
      "        [0.5037],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5034],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5033],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5036]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032]], device='cuda:1')\n",
      "tensor([[0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032]], device='cuda:1')\n",
      "tensor([[0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5032]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.11944513320923 | Val loss: 9.748478253682455\n",
      "Train acc: 0.5 | Val acc: 0.375\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5037],\n",
      "        [0.5036],\n",
      "        [0.5036],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5038],\n",
      "        [0.5034],\n",
      "        [0.5038],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5035]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5035],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5032],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5032],\n",
      "        [0.5034]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5035],\n",
      "        [0.5034],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5032],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5036],\n",
      "        [0.5035],\n",
      "        [0.5038],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5033],\n",
      "        [0.5034],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5032],\n",
      "        [0.5036]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5040],\n",
      "        [0.5039],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5039],\n",
      "        [0.5040],\n",
      "        [0.5040],\n",
      "        [0.5040],\n",
      "        [0.5039],\n",
      "        [0.5041],\n",
      "        [0.5039],\n",
      "        [0.5040]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5044],\n",
      "        [0.5045],\n",
      "        [0.5046],\n",
      "        [0.5042],\n",
      "        [0.5044],\n",
      "        [0.5046],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5042],\n",
      "        [0.5046],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5046],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5043]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5046],\n",
      "        [0.5047],\n",
      "        [0.5046],\n",
      "        [0.5048],\n",
      "        [0.5045],\n",
      "        [0.5046],\n",
      "        [0.5051],\n",
      "        [0.5049],\n",
      "        [0.5049],\n",
      "        [0.5046],\n",
      "        [0.5048],\n",
      "        [0.5046],\n",
      "        [0.5049],\n",
      "        [0.5045],\n",
      "        [0.5047],\n",
      "        [0.5048]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5048],\n",
      "        [0.5048],\n",
      "        [0.5046],\n",
      "        [0.5047],\n",
      "        [0.5048],\n",
      "        [0.5048],\n",
      "        [0.5048],\n",
      "        [0.5048],\n",
      "        [0.5047],\n",
      "        [0.5047],\n",
      "        [0.5047],\n",
      "        [0.5050],\n",
      "        [0.5047],\n",
      "        [0.5047],\n",
      "        [0.5048],\n",
      "        [0.5047]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5044],\n",
      "        [0.5044],\n",
      "        [0.5046],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5046],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5046],\n",
      "        [0.5045]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5042],\n",
      "        [0.5045],\n",
      "        [0.5045],\n",
      "        [0.5043],\n",
      "        [0.5042],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5045],\n",
      "        [0.5046],\n",
      "        [0.5047],\n",
      "        [0.5043],\n",
      "        [0.5045],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5044],\n",
      "        [0.5044]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037]], device='cuda:1')\n",
      "tensor([[0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037]], device='cuda:1')\n",
      "tensor([[0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037],\n",
      "        [0.5037]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.09991159439087 | Val loss: 9.729800542195639\n",
      "Train acc: 0.375 | Val acc: 0.5\n",
      "Epoch: 20\n",
      "tensor([[0.5041],\n",
      "        [0.5040],\n",
      "        [0.5042],\n",
      "        [0.5042],\n",
      "        [0.5041],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5040],\n",
      "        [0.5041],\n",
      "        [0.5042],\n",
      "        [0.5041],\n",
      "        [0.5043],\n",
      "        [0.5041],\n",
      "        [0.5041],\n",
      "        [0.5044],\n",
      "        [0.5041]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5039],\n",
      "        [0.5038],\n",
      "        [0.5038],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5038],\n",
      "        [0.5036],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5039],\n",
      "        [0.5038]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5038],\n",
      "        [0.5034],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5036],\n",
      "        [0.5037],\n",
      "        [0.5038],\n",
      "        [0.5033],\n",
      "        [0.5036],\n",
      "        [0.5036],\n",
      "        [0.5038],\n",
      "        [0.5039],\n",
      "        [0.5035],\n",
      "        [0.5036]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5032],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5032],\n",
      "        [0.5033],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5035],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5033],\n",
      "        [0.5029],\n",
      "        [0.5032],\n",
      "        [0.5030],\n",
      "        [0.5033],\n",
      "        [0.5032],\n",
      "        [0.5033]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5029],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5024],\n",
      "        [0.5027],\n",
      "        [0.5024],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5023],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5026],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5023],\n",
      "        [0.5023],\n",
      "        [0.5025],\n",
      "        [0.5023],\n",
      "        [0.5023],\n",
      "        [0.5022],\n",
      "        [0.5022],\n",
      "        [0.5026],\n",
      "        [0.5022],\n",
      "        [0.5024],\n",
      "        [0.5023]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5021],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5022],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5023],\n",
      "        [0.5022],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5025],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5023]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5019],\n",
      "        [0.5024],\n",
      "        [0.5022],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5023],\n",
      "        [0.5022],\n",
      "        [0.5018],\n",
      "        [0.5021],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5018],\n",
      "        [0.5020],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5020]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5018],\n",
      "        [0.5017],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5019],\n",
      "        [0.5020],\n",
      "        [0.5020],\n",
      "        [0.5016],\n",
      "        [0.5019],\n",
      "        [0.5017],\n",
      "        [0.5019],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5019]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016]], device='cuda:1')\n",
      "tensor([[0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016]], device='cuda:1')\n",
      "tensor([[0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5016]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.082130908966064 | Val loss: 9.712523778279623\n",
      "Train acc: 0.625 | Val acc: 0.625\n",
      "Epoch: 21\n",
      "tensor([[0.5021],\n",
      "        [0.5022],\n",
      "        [0.5020],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5019],\n",
      "        [0.5018],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5018],\n",
      "        [0.5017],\n",
      "        [0.5021],\n",
      "        [0.5018]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5020],\n",
      "        [0.5022],\n",
      "        [0.5022],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5022],\n",
      "        [0.5022],\n",
      "        [0.5023],\n",
      "        [0.5021],\n",
      "        [0.5020],\n",
      "        [0.5020],\n",
      "        [0.5024],\n",
      "        [0.5022],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5024]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5024],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5025],\n",
      "        [0.5024],\n",
      "        [0.5025],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5025],\n",
      "        [0.5024],\n",
      "        [0.5023],\n",
      "        [0.5023]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5025],\n",
      "        [0.5024],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5022],\n",
      "        [0.5027],\n",
      "        [0.5022],\n",
      "        [0.5026],\n",
      "        [0.5024],\n",
      "        [0.5023],\n",
      "        [0.5026]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5024],\n",
      "        [0.5025],\n",
      "        [0.5023],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5024],\n",
      "        [0.5022],\n",
      "        [0.5026],\n",
      "        [0.5025]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5027],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5025]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5028],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5022],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5024],\n",
      "        [0.5027],\n",
      "        [0.5025]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5030],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5028]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5030],\n",
      "        [0.5027],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5033],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5026]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5030],\n",
      "        [0.5026],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5032]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024]], device='cuda:1')\n",
      "tensor([[0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024]], device='cuda:1')\n",
      "tensor([[0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024],\n",
      "        [0.5024]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.065051651000976 | Val loss: 9.696090698242188\n",
      "Train acc: 0.5 | Val acc: 0.625\n",
      "Epoch: 22\n",
      "tensor([[0.5027],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5025],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5027]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5024],\n",
      "        [0.5025],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5024],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5022],\n",
      "        [0.5026],\n",
      "        [0.5022],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5023],\n",
      "        [0.5025],\n",
      "        [0.5024],\n",
      "        [0.5025],\n",
      "        [0.5024],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5023],\n",
      "        [0.5023],\n",
      "        [0.5024]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5025],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5023],\n",
      "        [0.5026],\n",
      "        [0.5023],\n",
      "        [0.5028],\n",
      "        [0.5025],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5024],\n",
      "        [0.5026]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5032],\n",
      "        [0.5026],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5027],\n",
      "        [0.5027],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5031]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5030],\n",
      "        [0.5028],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5029],\n",
      "        [0.5027],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5031]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5030],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5032],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5030]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5029],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5027],\n",
      "        [0.5031],\n",
      "        [0.5034],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5030],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5034],\n",
      "        [0.5033],\n",
      "        [0.5031],\n",
      "        [0.5034],\n",
      "        [0.5030],\n",
      "        [0.5032],\n",
      "        [0.5034],\n",
      "        [0.5034],\n",
      "        [0.5033],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5032],\n",
      "        [0.5030]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5031],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5031],\n",
      "        [0.5032],\n",
      "        [0.5033],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5032],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5030],\n",
      "        [0.5033],\n",
      "        [0.5031],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1')\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1')\n",
      "tensor([[0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.046102333068848 | Val loss: 9.680230140686035\n",
      "Train acc: 0.375 | Val acc: 0.75\n",
      "Epoch: 23\n",
      "tensor([[0.5027],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5030],\n",
      "        [0.5026],\n",
      "        [0.5028],\n",
      "        [0.5031],\n",
      "        [0.5033],\n",
      "        [0.5029],\n",
      "        [0.5029],\n",
      "        [0.5030],\n",
      "        [0.5028],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5031],\n",
      "        [0.5029]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5028],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5029],\n",
      "        [0.5028],\n",
      "        [0.5025],\n",
      "        [0.5028],\n",
      "        [0.5026],\n",
      "        [0.5026],\n",
      "        [0.5025],\n",
      "        [0.5027],\n",
      "        [0.5029],\n",
      "        [0.5024],\n",
      "        [0.5028]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5023],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5023],\n",
      "        [0.5023],\n",
      "        [0.5021],\n",
      "        [0.5022],\n",
      "        [0.5024],\n",
      "        [0.5025],\n",
      "        [0.5023],\n",
      "        [0.5024],\n",
      "        [0.5021],\n",
      "        [0.5022],\n",
      "        [0.5025],\n",
      "        [0.5024],\n",
      "        [0.5025]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5025],\n",
      "        [0.5019],\n",
      "        [0.5022],\n",
      "        [0.5019],\n",
      "        [0.5021],\n",
      "        [0.5024],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5020],\n",
      "        [0.5023],\n",
      "        [0.5024],\n",
      "        [0.5020],\n",
      "        [0.5020],\n",
      "        [0.5023],\n",
      "        [0.5021],\n",
      "        [0.5022]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5020],\n",
      "        [0.5022],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5023],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5020],\n",
      "        [0.5021],\n",
      "        [0.5021],\n",
      "        [0.5020],\n",
      "        [0.5022],\n",
      "        [0.5020],\n",
      "        [0.5023],\n",
      "        [0.5020]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5019],\n",
      "        [0.5020],\n",
      "        [0.5020],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5016],\n",
      "        [0.5022],\n",
      "        [0.5018],\n",
      "        [0.5020],\n",
      "        [0.5019],\n",
      "        [0.5020],\n",
      "        [0.5017],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5015],\n",
      "        [0.5017]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5020],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5018],\n",
      "        [0.5017],\n",
      "        [0.5016],\n",
      "        [0.5016],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5019],\n",
      "        [0.5018],\n",
      "        [0.5019],\n",
      "        [0.5017],\n",
      "        [0.5017]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5016],\n",
      "        [0.5017],\n",
      "        [0.5015],\n",
      "        [0.5018],\n",
      "        [0.5017],\n",
      "        [0.5015],\n",
      "        [0.5017],\n",
      "        [0.5016],\n",
      "        [0.5018],\n",
      "        [0.5017],\n",
      "        [0.5018],\n",
      "        [0.5017],\n",
      "        [0.5017],\n",
      "        [0.5014],\n",
      "        [0.5017],\n",
      "        [0.5015]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5016],\n",
      "        [0.5016],\n",
      "        [0.5014],\n",
      "        [0.5016],\n",
      "        [0.5014],\n",
      "        [0.5015],\n",
      "        [0.5015],\n",
      "        [0.5013],\n",
      "        [0.5013],\n",
      "        [0.5015],\n",
      "        [0.5016],\n",
      "        [0.5012],\n",
      "        [0.5015],\n",
      "        [0.5014],\n",
      "        [0.5015],\n",
      "        [0.5012]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5013],\n",
      "        [0.5013],\n",
      "        [0.5012],\n",
      "        [0.5014],\n",
      "        [0.5011],\n",
      "        [0.5013],\n",
      "        [0.5014],\n",
      "        [0.5016],\n",
      "        [0.5014],\n",
      "        [0.5012],\n",
      "        [0.5015],\n",
      "        [0.5015],\n",
      "        [0.5013],\n",
      "        [0.5015],\n",
      "        [0.5011],\n",
      "        [0.5015]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010]], device='cuda:1')\n",
      "tensor([[0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010]], device='cuda:1')\n",
      "tensor([[0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010],\n",
      "        [0.5010]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.030559158325195 | Val loss: 9.665795962015787\n",
      "Train acc: 0.5625 | Val acc: 0.5\n",
      "Epoch: 24\n",
      "tensor([[0.5012],\n",
      "        [0.5015],\n",
      "        [0.5015],\n",
      "        [0.5014],\n",
      "        [0.5013],\n",
      "        [0.5012],\n",
      "        [0.5012],\n",
      "        [0.5013],\n",
      "        [0.5014],\n",
      "        [0.5013],\n",
      "        [0.5014],\n",
      "        [0.5011],\n",
      "        [0.5014],\n",
      "        [0.5013],\n",
      "        [0.5014],\n",
      "        [0.5016]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5010],\n",
      "        [0.5012],\n",
      "        [0.5010],\n",
      "        [0.5013],\n",
      "        [0.5012],\n",
      "        [0.5011],\n",
      "        [0.5012],\n",
      "        [0.5010],\n",
      "        [0.5011],\n",
      "        [0.5013],\n",
      "        [0.5012],\n",
      "        [0.5012],\n",
      "        [0.5012],\n",
      "        [0.5012],\n",
      "        [0.5012],\n",
      "        [0.5012]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5007],\n",
      "        [0.5010],\n",
      "        [0.5011],\n",
      "        [0.5008],\n",
      "        [0.5010],\n",
      "        [0.5009],\n",
      "        [0.5010],\n",
      "        [0.5006],\n",
      "        [0.5009],\n",
      "        [0.5010],\n",
      "        [0.5007],\n",
      "        [0.5010],\n",
      "        [0.5008],\n",
      "        [0.5010],\n",
      "        [0.5009],\n",
      "        [0.5008]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5005],\n",
      "        [0.5003],\n",
      "        [0.5002],\n",
      "        [0.5004],\n",
      "        [0.5003],\n",
      "        [0.5004],\n",
      "        [0.5006],\n",
      "        [0.5006],\n",
      "        [0.5006],\n",
      "        [0.5005],\n",
      "        [0.5007],\n",
      "        [0.5002],\n",
      "        [0.5004],\n",
      "        [0.5006],\n",
      "        [0.5001],\n",
      "        [0.5003]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5003],\n",
      "        [0.5004],\n",
      "        [0.5002],\n",
      "        [0.5003],\n",
      "        [0.5002],\n",
      "        [0.5004],\n",
      "        [0.5004],\n",
      "        [0.5001],\n",
      "        [0.5004],\n",
      "        [0.5004],\n",
      "        [0.5004],\n",
      "        [0.5001],\n",
      "        [0.5004],\n",
      "        [0.5004],\n",
      "        [0.5003],\n",
      "        [0.5002]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5001],\n",
      "        [0.5001],\n",
      "        [0.4998],\n",
      "        [0.5002],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5001],\n",
      "        [0.5001],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5003],\n",
      "        [0.4999],\n",
      "        [0.5000],\n",
      "        [0.4998],\n",
      "        [0.4999],\n",
      "        [0.5001]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997],\n",
      "        [0.4995],\n",
      "        [0.4996],\n",
      "        [0.4998],\n",
      "        [0.4997],\n",
      "        [0.4994],\n",
      "        [0.4995],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4995],\n",
      "        [0.4997],\n",
      "        [0.4993],\n",
      "        [0.4994],\n",
      "        [0.4997],\n",
      "        [0.4995],\n",
      "        [0.4996]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997],\n",
      "        [0.4996],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4992],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4994],\n",
      "        [0.4996],\n",
      "        [0.4995],\n",
      "        [0.4995],\n",
      "        [0.4996],\n",
      "        [0.4991],\n",
      "        [0.4994],\n",
      "        [0.4998],\n",
      "        [0.4995]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4992],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4994],\n",
      "        [0.4992],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4992],\n",
      "        [0.4991],\n",
      "        [0.4993],\n",
      "        [0.4991],\n",
      "        [0.4992],\n",
      "        [0.4995]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4996],\n",
      "        [0.4997],\n",
      "        [0.4996],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4996],\n",
      "        [0.4994],\n",
      "        [0.4996],\n",
      "        [0.4993],\n",
      "        [0.4996],\n",
      "        [0.4997],\n",
      "        [0.4995],\n",
      "        [0.4994],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4995]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993]], device='cuda:1')\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993]], device='cuda:1')\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993]], device='cuda:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 10.01666316986084 | Val loss: 9.65142790476481\n",
      "Train acc: 0.5 | Val acc: 0.375\n",
      "Epoch: 25\n",
      "tensor([[0.4997],\n",
      "        [0.4998],\n",
      "        [0.4996],\n",
      "        [0.4996],\n",
      "        [0.4994],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4998],\n",
      "        [0.4996],\n",
      "        [0.4994],\n",
      "        [0.4997],\n",
      "        [0.4995],\n",
      "        [0.4999],\n",
      "        [0.4994],\n",
      "        [0.4995],\n",
      "        [0.4997]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997],\n",
      "        [0.4996],\n",
      "        [0.4999],\n",
      "        [0.4997],\n",
      "        [0.4998],\n",
      "        [0.4996],\n",
      "        [0.4998],\n",
      "        [0.4998],\n",
      "        [0.4995],\n",
      "        [0.4996],\n",
      "        [0.4996],\n",
      "        [0.4994],\n",
      "        [0.4998],\n",
      "        [0.4993],\n",
      "        [0.4997],\n",
      "        [0.5000]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4995],\n",
      "        [0.4999],\n",
      "        [0.4998],\n",
      "        [0.4995],\n",
      "        [0.4997],\n",
      "        [0.4998],\n",
      "        [0.4997],\n",
      "        [0.4997],\n",
      "        [0.4998],\n",
      "        [0.4996],\n",
      "        [0.4997],\n",
      "        [0.4998],\n",
      "        [0.4995],\n",
      "        [0.4996],\n",
      "        [0.4994],\n",
      "        [0.4999]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4997],\n",
      "        [0.4997],\n",
      "        [0.4996],\n",
      "        [0.4996],\n",
      "        [0.4999],\n",
      "        [0.4997],\n",
      "        [0.4997],\n",
      "        [0.4997],\n",
      "        [0.4996],\n",
      "        [0.4995],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4996],\n",
      "        [0.4992],\n",
      "        [0.4995],\n",
      "        [0.4996]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4991],\n",
      "        [0.4993],\n",
      "        [0.4995],\n",
      "        [0.4995],\n",
      "        [0.4994],\n",
      "        [0.4994],\n",
      "        [0.4992],\n",
      "        [0.4991],\n",
      "        [0.4994],\n",
      "        [0.4994],\n",
      "        [0.4996],\n",
      "        [0.4993]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4993],\n",
      "        [0.4997],\n",
      "        [0.4996],\n",
      "        [0.4996],\n",
      "        [0.4993],\n",
      "        [0.4992],\n",
      "        [0.4996],\n",
      "        [0.4992],\n",
      "        [0.4996],\n",
      "        [0.4995],\n",
      "        [0.4997],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4996],\n",
      "        [0.4996],\n",
      "        [0.4996]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4993],\n",
      "        [0.4995],\n",
      "        [0.4990],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4995],\n",
      "        [0.4991],\n",
      "        [0.4994],\n",
      "        [0.4996],\n",
      "        [0.4992],\n",
      "        [0.4991],\n",
      "        [0.4991],\n",
      "        [0.4993],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4992]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4993],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4992],\n",
      "        [0.4992],\n",
      "        [0.4997],\n",
      "        [0.4993],\n",
      "        [0.4991],\n",
      "        [0.4996],\n",
      "        [0.4993],\n",
      "        [0.4992],\n",
      "        [0.4992],\n",
      "        [0.4994],\n",
      "        [0.4992]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4994],\n",
      "        [0.4991],\n",
      "        [0.4994],\n",
      "        [0.4995],\n",
      "        [0.4993],\n",
      "        [0.4998],\n",
      "        [0.4991],\n",
      "        [0.4994],\n",
      "        [0.4992],\n",
      "        [0.4995],\n",
      "        [0.4994],\n",
      "        [0.4994],\n",
      "        [0.4995],\n",
      "        [0.4992],\n",
      "        [0.4993],\n",
      "        [0.4992]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4995],\n",
      "        [0.4994],\n",
      "        [0.4996],\n",
      "        [0.4994],\n",
      "        [0.4993],\n",
      "        [0.4994],\n",
      "        [0.4992],\n",
      "        [0.4991],\n",
      "        [0.4992],\n",
      "        [0.4994],\n",
      "        [0.4994],\n",
      "        [0.4996],\n",
      "        [0.4996],\n",
      "        [0.4995],\n",
      "        [0.4995],\n",
      "        [0.4994]], device='cuda:1', grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993]], device='cuda:1')\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993]], device='cuda:1')\n",
      "tensor([[0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993],\n",
      "        [0.4993]], device='cuda:1')\n",
      "\n",
      "Train loss: 10.001374530792237 | Val loss: 9.637876828511557\n",
      "Train acc: 0.375 | Val acc: 0.375\n",
      "Initial GPU Usage\n",
      "GPU memory occupied: 12832 MB.\n",
      "GPU Usage after emptying the cache\n",
      "GPU memory occupied: 12802 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816603/2392238126.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_preds_tensor = torch.tensor(train_preds).detach()\n",
      "/tmp/ipykernel_1816603/2392238126.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_preds_tensor = torch.tensor(val_preds).detach()\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization(device_id)\n",
    "torch.cuda.empty_cache()\n",
    "free_gpu_cache(device_id)\n",
    "MAX_LEN = 25\n",
    "PROJECTION_DIM = 10\n",
    "BATCH_SIZE=16\n",
    "w1=0.5\n",
    "w2=0.5\n",
    "# VECTOR_DIM = 768\n",
    "lambda_value = 0.2\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE=0.001\n",
    "MAX_GRAD_NORM=1000\n",
    "# Initialize model\n",
    "\n",
    "spock_model = SpockModel(MAX_LEN, PROJECTION_DIM, lambda_value)\n",
    "# spock_model.to(device)\n",
    "\n",
    "\n",
    "# train_dataloader,val_dataloader=dataprep(PROJECTION_DIM)\n",
    "# Call the dataprep method on the object\n",
    "train_dataloader,val_dataloader = bert_dataset.dataprep(train_df, val_df, tokenizer, MAX_LEN, BATCH_SIZE, PROJECTION_DIM)\n",
    "\n",
    "config = {\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'val_batch_size': BATCH_SIZE,\n",
    "    \n",
    "    'fp16': False,\n",
    "    'lr': LEARNING_RATE,\n",
    "}\n",
    "history,val_preds, val_labels,train_preds = training(spock_model.to(device), train_dataloader, val_dataloader, config)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAX_LEN = 30\n",
    "# PROJECTION_DIM = 30\n",
    "# BATCH_SIZE=20\n",
    "# LEARNING_RATE=0.01\n",
    "# w1=0.5\n",
    "# w2=0.5\n",
    "# MAX_GRAD_NORM=1000\n",
    "# VECTOR_DIM = 768\n",
    "# lambda_value = 0.2\n",
    "# NUM_EPOCHS = 20\n",
    "\n",
    "# # Initialize model\n",
    "# spock_model2 = SpockModel(MAX_LEN, PROJECTION_DIM, lambda_value)\n",
    "# # spock_model.to(device)\n",
    "\n",
    "\n",
    "# # train_dataloader,val_dataloader=dataprep(PROJECTION_DIM)\n",
    "# # Call the dataprep method on the object\n",
    "# train_dataloader,val_dataloader = bert_dataset.dataprep(train_df, val_df, tokenizer, MAX_LEN, BATCH_SIZE, PROJECTION_DIM)\n",
    "\n",
    "# config = {\n",
    "#     'epochs': NUM_EPOCHS,\n",
    "#     'batch_size': BATCH_SIZE,\n",
    "#     'val_batch_size': BATCH_SIZE,\n",
    "    \n",
    "#     # 'gradient_accumulation_steps': 5, \n",
    "    \n",
    "#     # ''''gradient_accumulation_steps': 1: Gradient accumulation is a technique used for training \n",
    "#     # when the effective batch size is larger than the available memory. It accumulates gradients over multiple batches before\n",
    "#     # updating the model parameters.'''\n",
    "    \n",
    "#     'fp16': False,\n",
    "#     'lr': LEARNING_RATE,\n",
    "#     # 'max_grad_norm': MAX_GRAD_NORM,\n",
    "#     # 'weight_decay': 0,\n",
    "# }\n",
    "# history,val_preds, val_labels,train_preds = training(spock_model2.to(device), train_dataloader, val_dataloader, config)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_results(history, do_val=True):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    # Losses\n",
    "    axs[0, 0].plot(history['train_losses'], label='Train Loss')\n",
    "    if do_val:\n",
    "        axs[0, 0].plot(history['val_losses'], label='Validation Loss')\n",
    "    axs[0, 0].set_title('Train / Validation Loss')\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Accuracy\n",
    "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy')\n",
    "    if do_val:\n",
    "        axs[0, 1].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axs[0, 1].set_title('Train / Validation Accuracy')\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('Accuracy')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # F1 Score\n",
    "    # axs[1, 0].plot(history['train_f1'], label='Train F1 Score')\n",
    "    \n",
    "    axs[1, 0].plot(history['train_offensive_normal_loss'], label='train_offensive_normal_loss')\n",
    "    if do_val:\n",
    "        axs[1, 0].plot(history['val_offensive_normal_loss'], label='val_offensive_normal_loss')\n",
    "\n",
    "    axs[1, 0].set_title('Train / Validation offensive_normal_loss')\n",
    "    axs[1, 0].set_xlabel('Epochs')\n",
    "    axs[1, 0].set_ylabel('offensive_normal_loss')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Precision\n",
    "    \n",
    "    axs[1,1].plot(history['train_toxic_intra_loss'], label='train_toxic_intra_loss')\n",
    "\n",
    "    if do_val:\n",
    "        axs[1,1].plot(history['train_non_toxic_intra_loss'], label='train_non_toxic_intra_loss')\n",
    "    # axs[1, 1].plot(history['train_precision'], label='Train Precision')\n",
    "    # if do_val:\n",
    "    #     axs[1, 1].plot(history['val_precision'], label='Validation Precision')\n",
    "    axs[1, 1].set_title('Toxic/ Non_Toxix intra_loss')\n",
    "    axs[1, 1].set_xlabel('Epochs')\n",
    "    axs[1, 1].set_ylabel('Intra_loss')\n",
    "    axs[1, 1].legend()\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(wspace=5, hspace=0.5)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_results(history)\n",
    "\n",
    "# learn oythin debggung\n",
    "#ASSERT FUNCTION\n",
    "#USE ATMOST 100 LABELS\n",
    "#PLOT MIRE SENSISBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "OJHKxhG4Uphm",
    "outputId": "8e989294-bc36-4224-f212-269241763980",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# Set up hyperparameters\n",
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 16\n",
    "PROJECTION_DIM = 30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value = 2\n",
    "EPOCHS = 20\n",
    "PROJECTION_DIM = 10  # You redefined PROJECTION_DIM here, it might not be necessary\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "spock_model1 = SpockModel(MAX_LENGTH, PROJECTION_DIM, lambda_value)\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Define your loss function\n",
    "optimizer = optim.Adam(spock_model1.parameters(), lr=0.001)  # Define your optimizer\n",
    "train_ds,val_ds=dataprep(PROJECTION_DIM)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_ds):\n",
    "        # Get the inputs, attention masks, space, attention score, and labels from the dictionary\n",
    "        input_ids = data['input_ids']\n",
    "        attention_masks = data['attention_masks']\n",
    "        space = data['space']\n",
    "        labels = data['label']\n",
    "        \n",
    "        \n",
    "        # print(input_ids.shape,attention_masks.shape,space.shape,attention_score.shape)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # print('ok')\n",
    "\n",
    "        # Forward pass\\ids, mks, projection_space, attention_score\n",
    "        outputs, loss = spock_model1(input_ids, attention_masks, space)\n",
    "        # print('ok3')\n",
    "\n",
    "        # Calculate loss\n",
    "        \n",
    "        labels=labels.view(-1,1)\n",
    "        # print(outputs.dtype,labels.dtype)\n",
    "        # print(outputs.shape,labels.shape)\n",
    "        labels = labels.float()\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        # print('ok')\n",
    "\n",
    "        # Backward pass and optimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print('ok')\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5== 1999:  # Print every 2000 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Log loss to TensorBoard\n",
    "    writer.add_scalar(\"training_loss\", running_loss, epoch)\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiazliz the tensorboard to visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1st laod the teansorbaord before tarining\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 30\n",
    "# BATCH_SIZE = 16\n",
    "# PROJECTION_DIM =30\n",
    "# VECTOR_DIM = 768\n",
    "# \n",
    "# spock_model1= spock_model(MAX_LENGTH, PROJECTION_DIM)\n",
    "# spock_model1.summary()\\\n",
    "# tf.keras.backend.clear_session()\n",
    "# print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "# # Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ps aux | grep tensorboard\n",
    "# # !kill 146651\n",
    "# !pkill -f tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Model and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 32\n",
    "# PROJECTION_DIM =30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##incase the port is already using, we have to kill it forst\n",
    "# !lsof -i :6006\n",
    "# !kill 148692\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#laod the tensor board with passing the base path. Note incase of runing on VPN, I need to \n",
    "# http://192.168.1.206:8000/user/naseem_fordham/proxy/6006/ where 6006 is the local host port\n",
    "# %tensorboard --logdir $BASE_PATH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accuracy plots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot(history,path):\n",
    "    # Create a new figure for the combined plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot accuracy on the first subplot\n",
    "    axs[0].plot(history['accuracy'])\n",
    "    axs[0].plot(history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy', fontsize=12)\n",
    "    axs[0].set_ylim(0, 1, 0.1)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axs[0].legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    # Plot loss on the second subplot\n",
    "\n",
    "\n",
    "    axs[1].plot(history['loss'])\n",
    "    axs[1].plot(history['val_loss'])\n",
    "    axs[1].plot(history['Interspace'])\n",
    "    axs[1].plot(history['ToxicIntra_Loss'])\n",
    "    axs[1].plot(history['Non_toxicIntra_Loss'])\n",
    "    axs[1].plot(history['Attention_Loss'])\n",
    "    \n",
    " \n",
    "\n",
    "    axs[1].set_title('Model Loss', fontsize=12)\n",
    "    axs[1].set_ylim(0, 15, 1)\n",
    "    axs[1].set_ylabel('Loss', fontsize=12)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss','posStdDevLoss','norStdDevLoss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    axs[1].legend(['Train', 'Validation','Interspace','ToxicIntra_Loss','Non_toxicIntra_Loss','Attention_loss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "    # axs[1].legend(['Train', 'Validation','ToxicIntra_Loss','Non_toxicIntra_Loss','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    # Adjust spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    # Save the combined plot as a single image\n",
    "    plt.savefig(path, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model laoding from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def predictionLabels(i):\n",
    "    return np.where(i < 0.5, 0.0, 1.0)\n",
    "\n",
    "    \n",
    "    \n",
    "    # return np.argmax(i, axis=1)\n",
    "\n",
    "pattern = r\"_([0-9]+)$\"\n",
    "\n",
    "\n",
    "getLabels = np.vectorize(predictionLabels)\n",
    "# predictions = model.predict(test_ds)\n",
    "# predictedLabels = getLabels(predictions)\n",
    "\n",
    "BASE_PATH = f\"/home/naseem_fordham/Spock-paper/Spock_Hateoffensive/\"\n",
    "\n",
    "accuracy=[]\n",
    "# Iterate over subdirectories\n",
    "for folder_name in os.listdir(BASE_PATH):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(BASE_PATH, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        match = re.search(pattern, folder_name)\n",
    "        if match:\n",
    "            model_number = match.group(1)\n",
    "            print(folder_path)\n",
    "            spock_model2 = spock_model(MAX_LENGTH, int(model_number),lambda_value)\n",
    "            model_filename = os.path.join(folder_path, f\"CS_{model_number}.h5\")\n",
    "            print(model_filename)\n",
    "\n",
    "            if os.path.exists(model_filename):\n",
    "                spock_model2.load_weights(model_filename)\n",
    "                \n",
    "                history=np.load(f\"{folder_path}/training_history{model_number}.pkl\",allow_pickle=True)\n",
    "                accuracy.append(history['val_accuracy'][-1])\n",
    "                \n",
    "                # print(f\"Loaded model from {model_filename,model_number}\")\n",
    "                train_ds, val_ds = dataprep(int(model_number))\n",
    "\n",
    "                # Calculate the confusion matrix\n",
    "                predictions = spock_model2.predict(val_ds)\n",
    "                predictedLabels = predictionLabels(predictions)\n",
    "                cm = confusion_matrix(val_df['class'].values, predictedLabels)\n",
    "\n",
    "                # Calculate the confusion matrix as percentages\n",
    "                cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['Toxic', 'Non-Toxic'])\n",
    "\n",
    "                # Calculate the classification report\n",
    "                clf_report = classification_report(val_df['class'],\n",
    "                                                   predictedLabels,\n",
    "                                                   target_names=['Toxic', 'Non-Toxic'],\n",
    "                                                   output_dict=True)\n",
    "\n",
    "\n",
    "                # Create a new figure for the combined plot\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "                # Plot the confusion matrix as percentages on the left\n",
    "                disp.plot(cmap=plt.cm.Blues, values_format=\".2f\", ax=axs[0])\n",
    "                axs[0].set_title(f'Confusion Matrix of CS_{model_number}')\n",
    "\n",
    "                # Plot the classification report as a heatmap on the right\n",
    "                sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, ax=axs[1])\n",
    "                axs[1].set_title(f'Classification Report of CS_{model_number}')\n",
    "\n",
    "                # Adjust spacing between subplots\n",
    "                plt.subplots_adjust(wspace=0.5)\n",
    "                \n",
    "                \n",
    "                           # Save the combined plot as a single image\n",
    "                plt.savefig(f'{folder_path}/combined_CS_{model_number}.png')\n",
    "                plot(history,f'{folder_path}/Acc_loss{model_number}.png')\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weights and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "U7gwzlktUtH9",
    "outputId": "56a7955b-b7bf-49f7-c6b5-135b4bcb0926"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS CELL AFTER MODEL TRAINING\n",
    "\n",
    "# save model history\n",
    "\n",
    "with open(f\"{BASE_PATH}/training_historyV4.pkl\",\"wb\") as hist:\n",
    "  pickle.dump(history.history,hist)\n",
    "\n",
    "# history=np.save(f\"/home/naseem_fordham/Hate_Xplain/history/C_loss_history_{PROJECTION_DIM}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/naseem_fordham/Spock-paper/Spock_HateXplain\"\n",
    "model.load_weights(f\"{BASE_PATH}/test3.h5\")\n",
    "history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23gCGD8ZeJfE",
    "outputId": "43e84bd0-3285-47e0-9b26-f5ed8ba6102f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BASE_PATH='/home/naseem_fordham/Spock-paper/'\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)\n",
    "# history\n",
    "# import pickle\n",
    "\n",
    "# with open('/home/naseem_fordham/Spock-paper/Random_w/Model/training_historyV4.pkl', 'rb') as f:\n",
    "#     loaded_data = np.load(f,allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3kEUFa9eRfk"
   },
   "outputs": [],
   "source": [
    "# prepare test data for evaluation:\n",
    "test_gen   = dataset(test_df[\"tweet\"].values,test_df[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer, projection_dim=PROJECTION_DIM, val = True)\n",
    "test_ds = tf.data.Dataset.from_generator(test_gen,\n",
    "                                            output_signature = \n",
    "                                           ({\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VcYiveLe-Ki"
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "def predictionLabels(i):\n",
    "     return np.argmax(i, axis=1)\n",
    "\n",
    "  # if i < 0.5:\n",
    "  #   return 0.0\n",
    "  # else:\n",
    "  #   return 1.0\n",
    "\n",
    "# getLabels = np.vectorize(predictionLabels)\n",
    "predictions = model.predict(test_ds)\n",
    "predictedLabels = predictionLabels(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-Cv6nLJsSsL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "predictedLabels = predictionLabels(predictions)\n",
    "\n",
    "confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "ConfusionMatrixDisplay.from_predictions(test_df['class'].values, predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "\n",
    "# Calculate the confusion matrix as percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['0','1','2'])  # You should define class_labels\n",
    "\n",
    "# Plot the confusion matrix as percentages\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nIV_XQ00gUYz",
    "outputId": "a28ee2c7-3d22-4fa8-a4fc-16b73454c70b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# print(classification_report(y_test, predictedLabels))\n",
    "clf_report = classification_report(test_df['class'],\n",
    "                                   predictedLabels,\n",
    "                                   \n",
    "                                   target_names=[0,1,2],\n",
    "                                   output_dict=True)\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-1xVwjAJgVrt",
    "outputId": "2b7f24a8-291e-4f8b-a5a3-cf9d89f07aaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.ylim(0,1,0.1)\n",
    "\n",
    "plt.ylabel('accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',{'fontsize' : 12})\n",
    "# plt.ylim(0, ,0.05)\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation accuracy')\n",
    "# display(plt.show())\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain//acc.png\",dpi=300)\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain/Plots/plots{PROJECTION_DIM}/accu_{PROJECTION_DIM}.png\",dpi=300)\n",
    "\n",
    "#skip: plt.savefig(\"/gdrive/Shareddrives/Thesis/Results_for_thesis/spock_xhate_acc.png\",dpi=300)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# plt.yticks(np.arange(0,1,step=.1))\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.ylim(0,3,0.1)\n",
    "\n",
    "# plt.title('Training loss vs Validation Loss',fontdict = {'fontsize' : 12})\n",
    "plt.ylabel('loss',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',fontdict = {'fontsize' : 12})\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime Explainibity\n",
    "In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification## In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in train_ds.take(1):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0][\"input_ids\"]\n",
    "# # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# laoding data set and performning cleaning to ready for feed funtion,\n",
    "# here we have assigned a tem class to our data set\n",
    "df_test=pd.read_csv('/home/naseem_fordham/Spock-paper/test.txt',sep='/n', header=None,engine='python')\n",
    "df_test = df_test.rename(columns={0: 'tweet'})\n",
    "df_test\n",
    "\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "df_test['class']=1\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create generators for train and validation\n",
    "BATCH_SIZE = 32\n",
    "# make sure batch size complies with total data set\n",
    "lime_gen = dataset(df_test[\"tweet\"].values,df_test[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer,projection_dim=PROJECTION_DIM)\n",
    "\n",
    "# create tensorflow dataloaders from generators\n",
    "lime_ds = tf.data.Dataset.from_generator(lime_gen,\n",
    "                                            output_signature =\n",
    "                                           ( {\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict function which will be use later for each text in sentence\n",
    "def predict_fun(x):\n",
    "    return model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(1):\n",
    "#     t=ele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['non_hate','hate'])\n",
    "# exp=explainer.explain_instance(x, predict_fun, num_features=90, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_test['tweet'].iloc[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementing LIME on each sentence\n",
    "\"\"\"Interpretability: If you want highly interpretable explanations that focus on the most salient \n",
    "words or terms, you may choose a lower num_features value.\n",
    "\n",
    "Comprehensiveness: If you want a more comprehensive understanding of why the model made a particular\n",
    "prediction and are willing to explore a larger number of words or terms, you may choose a higher num_features value.\"\"\"\n",
    "\n",
    "\n",
    "''' 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "for i in range(1,10):\n",
    "\n",
    "    x=df_test['tweet'].iloc[i]\n",
    "    # num=len(df_test['tweet'].iloc[i].split())\n",
    "    \n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=['hate','offensive','normal'])\n",
    "    exp=explainer.explain_instance(x, predict_fun, num_features=6, labels=(0,1), num_samples=10, distance_metric='cosine')\n",
    "    exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime EXplaniation Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(0):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0]\n",
    "# # # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_res= list()\n",
    "# for tweet in df_test['tweet']:\n",
    "#   tweet = text_preprocessing(tweet)\n",
    "#   test_res.append(tweet)\n",
    "#     # print(tweet)\n",
    "\n",
    "# df_test['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96kydpg1iWwm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Input_ids=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1]))\n",
    "# # bertModel = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "# # tokenizer \n",
    "# '''In this part we are creating the bert inputs for our model and pass it to the model to predicts the class. \n",
    "# Later on we pass this predict model to LIME to underrstand which part of text is more relavent as per our model prediction'''\n",
    "\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# bmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# import torch\n",
    "# def predict(x):\n",
    "#     encoded = tokenizer(\n",
    "#     text=df_test['tweet'].tolist(),  # the sentence to be encoded\n",
    "#     add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "#     max_length = 45,  # maximum length of a sentence\n",
    "#     padding='max_length',  # Add [PAD]s\n",
    "#     return_attention_mask = True,  # Generate the attention mask\n",
    "#     return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "\n",
    "#   )\n",
    "#   # print(encoded)\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         outputs = bmodel(**encoded)\n",
    "\n",
    "#         # Evaluating the model will return a different number of objects based on \n",
    "#         # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "#         # becase we set `output_hidden_states = True`, the third item will be the \n",
    "#         # hidden states from all layers. See the documentation for more details:\n",
    "#         # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "#         # hidden_states = outputs[2]\n",
    "#         # violent_hidden_states = violent_outputs[2]\n",
    "\n",
    "#         last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "#     # print(last_hidden_states)\n",
    "\n",
    "#     x_test=last_hidden_states.numpy()\n",
    "#     # print(x_test.shape)\n",
    "#     Inputs_test=encoded['input_ids']\n",
    "#     # print(Inputs_test.shape)\n",
    "#     Inputs_test=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1])).numpy()\n",
    "#     print(Inputs_test.shape)\n",
    "\n",
    "\n",
    "#     # print(x_test.shape,Inputs_test.shape)\n",
    "#     embedding_test=embedding_index[0].reshape(embedding_index[0].shape[0],1)\n",
    "#     # embedding_test=embedding_index[:30]\n",
    "#   # embedding_test=embedding_index[:30].reshape(30,embedding_index[:30].shape[1],1)\n",
    "#   # embedding_test=embedding_index[:10].reshape(10,embedding_index.shape[1])\n",
    "#   # return model.predict([x_test,Inputs_test,embedding_test])\n",
    "  \n",
    "#     # print(embedding_test.shape)\n",
    "#     print(x_test.shape,Inputs_test.shape,embedding_test.shape)\n",
    "#     return np.array([[float(1-x), float (x)] for x in model.predict(lime_ds)])\n",
    "#     # return last_hidden_states\n",
    "# # model.predict([x_train,Input_ids,embedding_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def return_embedding_index(count):\n",
    "  \n",
    "#   embedding_index=np.array([i for i in range(count)])\n",
    "#   # embeding_index=np.array([[0,1,2]])\n",
    "#   embeding_index=np.ravel(embedding_index)\n",
    "\n",
    "#   embedding_index=np.tile(embedding_index,(len(df_test),1,))\n",
    "#   # print(embedding_index.shape, type(embeding_index))\n",
    "#   return embedding_index\n",
    "\n",
    "# embedding_index = return_embedding_index(PROJECTION_DIM)\n",
    "# embedding_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "# exp=explainer.explain_instance(x, predict, num_features=60, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# #num of sample must be same as length of the data set \n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "# for i in range(10):\n",
    "\n",
    "#     x=df_test['tweet'].iloc[i]\n",
    "\n",
    "#     explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "#     exp=explainer.explain_instance(x, predict, num_features=30, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "#     #num of sample must be same as length of the data set \n",
    "#     exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Concept Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "\n",
    "\n",
    "hate_layer = model.get_layer('hate_embedding')\n",
    "hate_embedding = hate_layer.get_weights()\n",
    "# positive_weights=positive_weights[0].T\n",
    "\n",
    "\n",
    "offensive_layer = model.get_layer('offensive_embedding')\n",
    "offensive_embedding = offensive_layer.get_weights()\n",
    "\n",
    "\n",
    "normal_layer = model.get_layer('normal_embedding')\n",
    "normal_embedding = normal_layer.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# positive_embedding = model.get_layer('positive_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# positive_embedding = specific_layer.get_weights()\n",
    "# positive_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# negative_embedding = model.get_layer('negative_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# negative_embedding = specific_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you have two weight vectors of shape (10, 768)\n",
    "\n",
    "\n",
    "\n",
    "# # Combine the two weight vectors into one array\n",
    "# combined_weight_vectors = np.vstack([offensive_embedding[0], hate_embedding[0],normal_embedding[0]])\n",
    "# tsne = TSNE(n_components=2, perplexity=2, early_exaggeration=12.0, learning_rate=20.0, n_iter=1000)\n",
    "# # Compute t-SNE embeddings\n",
    "# # tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# # Separate the t-SNE embeddings for the two weight vectors\n",
    "# tsne_embeddings1 = tsne_embeddings[:25]  # First weight vector\n",
    "# tsne_embeddings2 = tsne_embeddings[25:50]  # Second weight vector\n",
    "# tsne_embeddings3 = tsne_embeddings[50:] \n",
    "\n",
    "# # Create a scatter plot for the t-SNE embeddings\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], label='hate_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='offensive_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], label='offensive_embedding', s=5)\n",
    "# # plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='normal_embedding', s=5)\n",
    "\n",
    "# plt.xlabel('t-SNE Dimension 1')\n",
    "# plt.ylabel('t-SNE Dimension 2')\n",
    "# plt.legend()\n",
    "# plt.title('t-SNE Visualization of Weight Vectors')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import the 3D plotting module\n",
    "\n",
    "# Assuming you have three weight vectors of shape (10, 768)\n",
    "\n",
    "# Combine the three weight vectors into one array\n",
    "combined_weight_vectors = np.vstack([hate_embedding[0], offensive_embedding[0], normal_embedding[0]])\n",
    "tsne = TSNE(n_components=3, perplexity=50, early_exaggeration=12.0, learning_rate=50.0, n_iter=10000)\n",
    "\n",
    "# Compute t-SNE embeddings\n",
    "tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# Separate the t-SNE embeddings for the three weight vectors\n",
    "tsne_embeddings1 = tsne_embeddings[:25]        # First weight vector (hate)\n",
    "tsne_embeddings2 = tsne_embeddings[25:50]      # Second weight vector (offensive)\n",
    "tsne_embeddings3 = tsne_embeddings[50:]        # Third weight vector (normal)\n",
    "\n",
    "# Create a 3D scatter plot for the t-SNE embeddings\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Create a 3D axis\n",
    "\n",
    "ax.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], tsne_embeddings1[:, 2], label='hate_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], tsne_embeddings2[:, 2], label='offensive_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], tsne_embeddings3[:, 2], label='normal_embedding', s=5)\n",
    "\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "ax.set_zlabel('t-SNE Dimension 3')\n",
    "plt.legend()\n",
    "plt.title('3D t-SNE Visualization of Weight Vectors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMciCgoRuYPP4D87bGoAjIQ",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06285d669e92494192637cb3ee5a40f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f14c359d92748268810099e6cdd1fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06285d669e92494192637cb3ee5a40f4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_209ee3e0949b446b8c58c57989065c5a",
      "value": " 232k/232k [00:00&lt;00:00, 2.84MB/s]"
     }
    },
    "123641d1426541fba838576dff7f6082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17ae300ebf634778862bc211cb432eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51f1ae4e3bd4563be3eb7c04dec7a60",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c7586ac9b41c4e75b02a6c076a458686",
      "value": "Downloading (â€¦)/main/tokenizer.json: 100%"
     }
    },
    "18e134c7af5d45baa952ccf06f96f3d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f1d5a79d7ec4e42add7775fa925b187",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e89d668a4fb541ec8d75d171bf899869",
      "value": "Downloading (â€¦)solve/main/vocab.txt: 100%"
     }
    },
    "1cf66f2a8c5f49ce98d59dae5186298d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd44792f624499b87bd768836016e88",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae841edad05b4ef9b4308308d6683fa3",
      "value": 570
     }
    },
    "1ec35f8bfadb40968f777ab7bbb55184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b0c918326174bc4b80585a52ac33e32",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e38ea829111b4065bad8ad4a4927bc39",
      "value": " 466k/466k [00:00&lt;00:00, 8.67MB/s]"
     }
    },
    "2024092105904b418c984aae9f4118bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f0a4e1b4929448a8b0a25b202271a40",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ac93c61a19c0474994803853194d2aa8",
      "value": " 28.0/28.0 [00:00&lt;00:00, 584B/s]"
     }
    },
    "209ee3e0949b446b8c58c57989065c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21bf2e03eac8419fa693628ab2cef02d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430a9d1768614e0596960d2a3d15d69e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_909ae03e117345f7a4b53f3045e090b7",
      "value": 231508
     }
    },
    "274875a4aa6047c9903ae3065a5d85c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31914a14cfa243388f43a02da4db24b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3258d106659040dfb7ffea47c017ed38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34bbd1edf06c4a9194bd27eaeeee32b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e574772e8b4f81bc7e02e8ebaeb258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3258d106659040dfb7ffea47c017ed38",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f9a2caba063b4a4f98ad258044d012fb",
      "value": "Downloading (â€¦)lve/main/config.json: 100%"
     }
    },
    "3c294ab0d9a648f39ea3f3fb7dd08c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430a9d1768614e0596960d2a3d15d69e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4914d10c0f354e178de66dc11449e26a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7998e50af804d66b6af0f26b5588255",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "4cc5655f9bdb42bca5d80e2849e8cd2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f0a4e1b4929448a8b0a25b202271a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1d5a79d7ec4e42add7775fa925b187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa52eecbe8a4ba38ef969fd1cf48cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50859aa086814457bcab249b35d486a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "570b9a872e614e0eab6618f306be7306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34e574772e8b4f81bc7e02e8ebaeb258",
       "IPY_MODEL_1cf66f2a8c5f49ce98d59dae5186298d",
       "IPY_MODEL_71f100b04c964a1bbde06c537f483ed7"
      ],
      "layout": "IPY_MODEL_9e1caf8b23fb4eb1976f808269d1dd3e"
     }
    },
    "5a072e1f73624ea5aa35e7e18af17f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a0c04349bae44f4a7130463ded826d1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f11959bab964aad822250b6e6853cb8",
      "value": 466062
     }
    },
    "672e978f9b524c5784553abd8cc91507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17ae300ebf634778862bc211cb432eef",
       "IPY_MODEL_5a072e1f73624ea5aa35e7e18af17f50",
       "IPY_MODEL_1ec35f8bfadb40968f777ab7bbb55184"
      ],
      "layout": "IPY_MODEL_274875a4aa6047c9903ae3065a5d85c2"
     }
    },
    "69d90bdca5174dfb91f5cf124884095e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71d0c2b02f0c4a609477bc31aa880938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c12c857f159443f1b2a661fcd7afa002",
       "IPY_MODEL_989933f9c84a47d4b64d5b5441a1f492",
       "IPY_MODEL_2024092105904b418c984aae9f4118bf"
      ],
      "layout": "IPY_MODEL_4cc5655f9bdb42bca5d80e2849e8cd2b"
     }
    },
    "71f100b04c964a1bbde06c537f483ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34bbd1edf06c4a9194bd27eaeeee32b2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ea850e74cb6a4121a456578b29ce7955",
      "value": " 570/570 [00:00&lt;00:00, 5.04kB/s]"
     }
    },
    "8a0c04349bae44f4a7130463ded826d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "909ae03e117345f7a4b53f3045e090b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "989933f9c84a47d4b64d5b5441a1f492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9910be9c8b7b4188936721e958ca15c5",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50859aa086814457bcab249b35d486a8",
      "value": 28
     }
    },
    "9910be9c8b7b4188936721e958ca15c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0c918326174bc4b80585a52ac33e32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1caf8b23fb4eb1976f808269d1dd3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f11959bab964aad822250b6e6853cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a51f1ae4e3bd4563be3eb7c04dec7a60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac93c61a19c0474994803853194d2aa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae841edad05b4ef9b4308308d6683fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5516712d5304670a05ec871eb5896a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c12c857f159443f1b2a661fcd7afa002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd56d3ae17774e5496a7fdcbcb57b874",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b5516712d5304670a05ec871eb5896a4",
      "value": "Downloading (â€¦)okenizer_config.json: 100%"
     }
    },
    "c7586ac9b41c4e75b02a6c076a458686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfe933364a3147368660f5463f1e5a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69dfd21bce04204b3220b71b4d4a968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4914d10c0f354e178de66dc11449e26a",
       "IPY_MODEL_f554ec9fe80a408680aa7b0a1c6837ac",
       "IPY_MODEL_f4ec333b7c654876a6caad010e88c203"
      ],
      "layout": "IPY_MODEL_cfe933364a3147368660f5463f1e5a29"
     }
    },
    "dfd44792f624499b87bd768836016e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e38ea829111b4065bad8ad4a4927bc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e89d668a4fb541ec8d75d171bf899869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e99b3d05437f4cdf9e1700e3cf466b34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea850e74cb6a4121a456578b29ce7955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee12049f5a9c4505b9769a4ff9c36477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18e134c7af5d45baa952ccf06f96f3d8",
       "IPY_MODEL_21bf2e03eac8419fa693628ab2cef02d",
       "IPY_MODEL_0f14c359d92748268810099e6cdd1fc3"
      ],
      "layout": "IPY_MODEL_e99b3d05437f4cdf9e1700e3cf466b34"
     }
    },
    "f4ec333b7c654876a6caad010e88c203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d90bdca5174dfb91f5cf124884095e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_123641d1426541fba838576dff7f6082",
      "value": " 440M/440M [00:06&lt;00:00, 121MB/s]"
     }
    },
    "f554ec9fe80a408680aa7b0a1c6837ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31914a14cfa243388f43a02da4db24b6",
      "value": 440449768
     }
    },
    "f7998e50af804d66b6af0f26b5588255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a2caba063b4a4f98ad258044d012fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd56d3ae17774e5496a7fdcbcb57b874": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
