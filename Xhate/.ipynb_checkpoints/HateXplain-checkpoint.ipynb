{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/machlovi/Spock-paper/blob/main/X_hate_and_offensive_data_combine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdBpcROn7EF-"
   },
   "source": [
    "## This file uses HateXplain data\n",
    "We are initailizing 2 vector space for 3(after converting them into 2 class) classes in this code. Main idea is to visualize how we can separate words related to each classes in the given space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UYfxZaZz6j8",
    "outputId": "09a73fe3-70ee-4cca-c198-fafbeda639f7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! apt-get install git\n",
    "# !pip install --upgrade protobuf\n",
    "# !pip install --upgrade jupyterlab-server google-api-core cached-path alchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj4pk2f97ALa"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7fS4-4j6y_h",
    "outputId": "6b5de3d8-1951-4e39-8a5e-2a5759d5f38d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\",20)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# from datasets import load_dataset,Dataset\n",
    "from transformers import AutoModel, BertTokenizerFast, BertModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naseem_fordham/Pytorch/Xhate\n",
      "custom_loss.py\t    HateXplain_spock-2_PS-Copy1.ipynb  preprocess.py\n",
      "HateXplain_data.py  HateXplain_spock-2_PS.ipynb        __pycache__\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing loss file\n",
    "from custom_loss import CustomLoss, CosineSimilarityLoss, IntraClassLoss, BinaryCrossEntropyLoss, LossValues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To display full column and rows values\n",
    "# pd.set_option('display.max_column', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_seq_items', None)\n",
    "# pd.set_option('display.max_colwidth', 500)\n",
    "# pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install numba\n",
    "\n",
    "def on_gpu(f):\n",
    "    def wrapper(*args):\n",
    "        if torch.cuda.is_available():\n",
    "            return f(*args)\n",
    "        else:\n",
    "            print('cuda unavailable')\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This part of the code uses cuda for GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # ! pip install pynvml\n",
    "    from pynvml import *\n",
    "    from numba import cuda\n",
    "\n",
    "@on_gpu\n",
    "def print_gpu_utilization(dev_id):\n",
    "    try:\n",
    "        nvmlInit()\n",
    "        handle = nvmlDeviceGetHandleByIndex(dev_id)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "@on_gpu\n",
    "def free_gpu_cache(dev_id=0):\n",
    "    print(\"Initial GPU Usage\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    print_gpu_utilization(dev_id)\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "GPU memory occupied: 11074 MB.\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)\n",
    "\n",
    "print_gpu_utilization(device_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'distilbert-base-cased'\n",
    "# MODELS_PATH = 'models'\n",
    "# DATASET_NAME = 'imdb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwO1A2SdOWyR"
   },
   "source": [
    "### Hate and offesive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vkjUmWVzTNN_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def text_preprocessing(text,                                                               # text is a word string ex. 'rahul in ny'\n",
    "#                       punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~='ã¶``''',\n",
    "#                       stop_words = set(stopwords.words(\"english\"))) -> list:\n",
    "\n",
    "#         '''\n",
    "#         A method to preprocess text\n",
    "\n",
    "#         '''\n",
    "\n",
    "#         for x in text.lower():\n",
    "#             if x in punctuations:\n",
    "#                 text = text.replace(x,\"\")\n",
    "\n",
    "#         # removing words that have numbers in them\n",
    "#         text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "#         # remove digits\n",
    "#         text = re.sub(r'[0-9]+', ' ', text)\n",
    "\n",
    "#         # clean the whitespaces\n",
    "\n",
    "#         text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "\n",
    "#         # convert all text to a list\n",
    "\n",
    "#         # text = text.split(' ').  # uncomment if list required\n",
    "#         emoji_pattern = re.compile(\"[\"\n",
    "#                                    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                                    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                                    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                                    u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "#                                    u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "#                                    u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "#                                    u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "#                                    u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "#                                    u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "#                                    u\"\\U00002702-\\U000027B0\"  # Dingbat symbols\n",
    "#                                    u\"\\U000024C2-\\U0001F251\" \n",
    "#                                    \"]+\", flags=re.UNICODE)\n",
    "#         text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "#         # lowercase eth\n",
    "\n",
    "#         text = text.lower()\n",
    "\n",
    "\n",
    "#         # drop the stop words\n",
    "\n",
    "\n",
    "\n",
    "#         # add the tags\n",
    "\n",
    "#         return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HateOffensive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp7FNeAE7M-s"
   },
   "source": [
    "https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data#Data import\n",
    "\n",
    "Data Source \"https://github.com/t-davidson/33 ##\n",
    "hate-speech-and-offensive-language/blob/master/data/readme.md\"\n",
    "'''hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "In this case 0 non-toxic and 1 -toxic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #loading hate ofefsive data and converting it into 2 class data as toxic and non-toxic\n",
    "# df_data1=pd.read_csv(\"/home/naseem_fordham/Spock-paper/data/labeled_data.csv\")\n",
    "# dataframe=df_data1[['class','tweet']]\n",
    "# dataframe=dataframe.dropna()\n",
    "# dataframe.reset_index(drop=True)\n",
    "# dataframe['class'].unique()\n",
    "\n",
    "# # #initially we have 3 classes and now we are converting them into binary class\n",
    "\n",
    "# dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x in [0., 1.] else 0.0)\n",
    "# # HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "# dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "# dataframe = dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "# # dataframe=HateXplain\n",
    "# dataframe['class'].unique()\n",
    "# # dataframe.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgqQcCnzJ9_i",
    "tags": []
   },
   "source": [
    "### Xhate-999 data set\n",
    "Class 1 hate, Class 0 non-hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellView": "form",
    "id": "AgABCT3f-VSJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# # Use this part for single file\n",
    "# # Define the path to your text file\n",
    "# file_path = \"/gdrive/MyDrive/SPOCK/Dataset/xhate-main/train/XHate999-EN-Gao-train.txt\"\n",
    "\n",
    "# # Initialize empty lists to store data\n",
    "# tweets = []\n",
    "# labels = []\n",
    "\n",
    "# # Read the file line by line\n",
    "# with open(file_path, 'r') as file:\n",
    "#     for line in file:\n",
    "#         # Split the line into text and label using the last character\n",
    "#         line = line.strip()  # Remove leading/trailing whitespace\n",
    "#         text = line[:-2].strip()  # Extract text (excluding the last character)\n",
    "#         label = line[-1]  # Extract the label (as an integer)\n",
    "\n",
    "#         # Append data to lists\n",
    "#         tweets.append(text)\n",
    "#         labels.append(label)\n",
    "\n",
    "# # Create a DataFrame from the lists\n",
    "# df = pd.DataFrame({'Text': tweets, 'Label': labels})\n",
    "# df.drop(0,inplace=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Sp_S78bwGI6h",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Define the directory path where your text files are located\n",
    "# directory_path = \"/gdrive/MyDrive/SPOCK/Dataset/xhate-main/train\"\n",
    "\n",
    "# # Initialize empty lists to store data\n",
    "# tweets = []\n",
    "# labels = []\n",
    "\n",
    "# # Loop through all text files in the specified directory\n",
    "# for filename in glob.glob(os.path.join(directory_path, '*.txt')):\n",
    "#     with open(filename, 'r') as file:\n",
    "\n",
    "#       for line in file:\n",
    "#           # Split the line into text and label using the last character\n",
    "#           line = line.strip()  # Remove leading/trailing whitespace\n",
    "#           text = line[:-2].strip()  # Extract text (excluding the last character)\n",
    "#           label = line[-1]  # Extract the label (as an integer)\n",
    "\n",
    "#           # Append data to lists\n",
    "#           tweets.append(text)\n",
    "#           labels.append(label)\n",
    "\n",
    "# # Create a DataFrame from the lists\n",
    "# df = pd.DataFrame({'tweet': tweets, 'class': labels})\n",
    "# df.drop(0,inplace=True)\n",
    "\n",
    "\n",
    "# df['class']=pd.to_numeric(df['class'], errors='coerce')\n",
    "# df['class'].fillna(0, inplace=True)\n",
    "# df['class']=df['class'].astype(int)\n",
    "# df_hate2=df[df['class']==1]\n",
    "# df_nonhate2=df[df['class']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKc-jTjJSzoM"
   },
   "source": [
    "##Combing hatespeech and xhate data for hate/offensive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HateXplain Dataset\n",
    "Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this work, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales\n",
    "\n",
    "In this case we are using Toxic and Non-toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Here we have implenting attenstion score for HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path =  \"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\"  # Replace this with the actual path to your data file\n",
    "# processor = HateXplain(data_path)\n",
    "\n",
    "# # Call the preprocess_data method to preprocess the data\n",
    "# processed_data = processor.preprocess_data()\n",
    "\n",
    "# # Now you can work with the processed data as needed\n",
    "# print(processed_data.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1597782/4192771600.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['label']='non_toxic'\n",
      "/tmp/ipykernel_1597782/4192771600.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['leng']=df_n['post_tokens'].apply(lambda x: len(x))\n",
      "/tmp/ipykernel_1597782/4192771600.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['rationales'] = df_n['leng'].apply(lambda length: [1/length] *length )\n",
      "/tmp/ipykernel_1597782/4192771600.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales1']=df_ho['rationales'].apply(lambda x: x[0])\n",
      "/tmp/ipykernel_1597782/4192771600.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales2']=df_ho['rationales'].apply(lambda x: x[1])\n",
      "/tmp/ipykernel_1597782/4192771600.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales3']=df_ho['rationales'].apply(lambda x: x[2:3])\n",
      "/tmp/ipykernel_1597782/4192771600.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['sum_result'] = df_ho.apply(lambda row: [a + b + c for a, b, c in zip(row['rationales1'], row['rationales2'],row['rationales1'])], axis=1)\n",
      "/tmp/ipykernel_1597782/4192771600.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['mean']=df_ho['sum_result'].apply(lambda x: [val /3 for val in x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rationales</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>[0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>[1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>guilty until proven innocent unless you are a ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tired i can not support abortion from a moral ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>number number percent of brits think multicult...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all of my exes were cute but they were hoes i ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user condoning drug use not kike at all thanks...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  user i am bit confused coz chinese ppl can not...   \n",
       "1  this bitch in whataburger eating a burger with...   \n",
       "2  laura loomer raped me while screaming at me in...   \n",
       "3  and this is why i end up with nigger trainee d...   \n",
       "4                  nogs jews and dykes how enriching   \n",
       "5  guilty until proven innocent unless you are a ...   \n",
       "6  tired i can not support abortion from a moral ...   \n",
       "7  number number percent of brits think multicult...   \n",
       "8  all of my exes were cute but they were hoes i ...   \n",
       "9  user condoning drug use not kike at all thanks...   \n",
       "\n",
       "                                          rationales  class  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "1  [0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  toxic  \n",
       "4      [1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]  toxic  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...  toxic  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  toxic  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocess import TextPreprocessor  # Import your TextPreprocessor class\n",
    "\n",
    "\n",
    "text_processor = TextPreprocessor()\n",
    "\n",
    "# Continue with the rest of your code...\n",
    "\n",
    "df = pd.read_json(\"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\")\n",
    "df_t=df.T\n",
    "df = pd.read_json(\"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\")\n",
    "df_t=df.T\n",
    "#  extracting each label from nester list\n",
    "df_t['annotators0']=df_t['annotators'].apply(lambda x: x[0]['label'])\n",
    "df_t['annotators1']=df_t['annotators'].apply(lambda x: x[1]['label'])\n",
    "df_t['annotators2']=df_t['annotators'].apply(lambda x: x[2]['label'])\n",
    "\n",
    "# laeblling\n",
    "\n",
    "df_t['annotators0']=df_t['annotators0'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "df_t['annotators1']=df_t['annotators1'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "df_t['annotators2']=df_t['annotators2'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "\n",
    "# dropping some unnecessary columns\n",
    "df_t.drop(['post_id','annotators'],axis=1,inplace=True)\n",
    "\n",
    "# sperating non_toxic\n",
    "df_n = df_t[((df_t['annotators0'] == 2.0) & (df_t['annotators1'] == 2.0) & (df_t['annotators2'] == 2.0)) | (df_t['rationales'].apply(lambda x: len(x) == 0))]\n",
    "df_n['label']='non_toxic'\n",
    "\n",
    "#Generating rationles values for non-rationles by deving the 1 by the total length\n",
    "df_n['leng']=df_n['post_tokens'].apply(lambda x: len(x))\n",
    "df_n['rationales'] = df_n['leng'].apply(lambda length: [1/length] *length )\n",
    "\n",
    "\n",
    "#separating toxic\n",
    "df_ho = df_t[~df_t.index.isin(df_n.index)]\n",
    "\n",
    "\n",
    "# taking mean of rationales\n",
    "df_ho['rationales1']=df_ho['rationales'].apply(lambda x: x[0])\n",
    "df_ho['rationales2']=df_ho['rationales'].apply(lambda x: x[1])\n",
    "df_ho['rationales3']=df_ho['rationales'].apply(lambda x: x[2:3])\n",
    "\n",
    "df_ho['sum_result'] = df_ho.apply(lambda row: [a + b + c for a, b, c in zip(row['rationales1'], row['rationales2'],row['rationales1'])], axis=1)\n",
    "df_ho['mean']=df_ho['sum_result'].apply(lambda x: [val /3 for val in x])\n",
    "\n",
    "df_toxic=df_ho[['post_tokens','mean']].rename(columns={'mean':'rationales'})\n",
    "df_toxic['label']='toxic'\n",
    "\n",
    "df_combine = pd.concat([df_toxic,df_n[['post_tokens','label','rationales']]]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_combine[\"post_tokens\"].values\n",
    "for i in range(len(df_combine[\"post_tokens\"])):\n",
    "    df_combine[\"post_tokens\"][i] = \" \".join(df_combine[\"post_tokens\"][i])\n",
    "\n",
    "# df_combine[\"post_tokens\"] = df_combine[\"post_tokens\"].apply(lambda x : text_preprocessing(x))\n",
    "df_combine[\"post_tokens\"] = df_combine[\"post_tokens\"].apply(lambda x : text_processor.text_preprocessing(x))\n",
    "\n",
    "df_combine.rename(columns={\"post_tokens\":\"tweet\",\"label\":\"class\"},inplace=True)\n",
    "# dataframe=df_combine.sample(frac = 1).reset_index(drop = True)\n",
    "df_combine.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' We have implemented temperature function to change the rationale for sensible. \n",
    "low temperature softmax probs : [0.01,0.01,0.98]\n",
    "high temperature softmax probs : [0.2,0.2,0.6]\n",
    "since we want to differentiate using ket waord we need to use low value'''\n",
    "\n",
    "\n",
    "dataframe=df_combine.copy()\n",
    "\n",
    "dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x ==\"non_toxic\" else 0.0)\n",
    "\n",
    "\n",
    "Temprature=0.25\n",
    "dataframe['rationales_T']= dataframe['rationales'].apply(lambda x: [val /Temprature for val in x])\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    softmax_values= e_x / e_x.sum(axis=0)\n",
    "    return np.round(softmax_values, 3)\n",
    "\n",
    "# Apply softmax to the 'numbers' column\n",
    "dataframe['softmax_numbers'] = dataframe['rationales_T'].apply(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>softmax_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.005, 0.073, 0.005, 0.005, 0.005, 0.005, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.303, 0.303, 0.08, 0.303, 0.006, 0.006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>it a bitch to find i accidently opened it how ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>anybody notice anything strange on gab like so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.026, 0.026, 0.026, 0.026, 0.026, 0.026, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>graph straftaten gegen die sexuelle selbstbest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.037, 0.037, 0.037, 0.037, 0.037, 0.037, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>an afghani immigrant once told me that in afgh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.023, 0.023, 0.023, 0.023, 0.023, 0.023, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  class  \\\n",
       "0      user i am bit confused coz chinese ppl can not...    0.0   \n",
       "1      this bitch in whataburger eating a burger with...    0.0   \n",
       "2      laura loomer raped me while screaming at me in...    0.0   \n",
       "3      and this is why i end up with nigger trainee d...    0.0   \n",
       "4                      nogs jews and dykes how enriching    0.0   \n",
       "...                                                  ...    ...   \n",
       "20143  it a bitch to find i accidently opened it how ...    1.0   \n",
       "20144  anybody notice anything strange on gab like so...    1.0   \n",
       "20145  graph straftaten gegen die sexuelle selbstbest...    1.0   \n",
       "20146  an afghani immigrant once told me that in afgh...    1.0   \n",
       "20147  was macht der moslem wenn der zion gegen seine...    1.0   \n",
       "\n",
       "                                         softmax_numbers  \n",
       "0      [0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.0...  \n",
       "1      [0.005, 0.073, 0.005, 0.005, 0.005, 0.005, 0.0...  \n",
       "2      [0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.0...  \n",
       "3      [0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0...  \n",
       "4              [0.303, 0.303, 0.08, 0.303, 0.006, 0.006]  \n",
       "...                                                  ...  \n",
       "20143  [0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.0...  \n",
       "20144  [0.026, 0.026, 0.026, 0.026, 0.026, 0.026, 0.0...  \n",
       "20145  [0.037, 0.037, 0.037, 0.037, 0.037, 0.037, 0.0...  \n",
       "20146  [0.023, 0.023, 0.023, 0.023, 0.023, 0.023, 0.0...  \n",
       "20147  [0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...  \n",
       "\n",
       "[20148 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=dataframe[['tweet','class','softmax_numbers']]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # HateXplain Dataset converting into binary class\n",
    "# HateXplain = pd.read_csv('/home/naseem_fordham/Spock-paper/data/Hate_Xplain.csv')\n",
    "# HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "# # HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "# HateXplain[\"text\"] = HateXplain[\"text\"].apply(lambda x : text_preprocessing(x))\n",
    "# HateXplain = HateXplain.sample(frac = 1).reset_index(drop = True)\n",
    "# HateXplain.rename(columns={\"text\":\"tweet\",\"label\":\"class\"},inplace=True)\n",
    "# dataframe=HateXplain\n",
    "# dataframe['class'].unique()\n",
    "# dataframe.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nYkMXWiRRL_p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hate_combine=pd.concat([df_hate,df_hate2]).reset_index(drop=True)\n",
    "# df_nonhat_combine=pd.concat([df_peace,df_nonhate2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2O2ELyIrWKEx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hate_combine[\"tweet\"] = df_hate_combine[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "# df_nonhat_combine[\"tweet\"] = df_nonhat_combine[\"tweet\"].apply(lambda x : text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LMfpk0-oRBjF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe=pd.concat([df_hate_combine ,df_nonhat_combine]).reset_index(drop=True)\n",
    "# dataframe.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine HateXplain, Xhate and offensive speech data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataframe=pd.read_csv(\"combine_data.csv\")\n",
    "# dataframe=pd.concat([dataframe ,HateXplain]).reset_index(drop=True)\n",
    "\n",
    "# dataframe.dropna(inplace=True)\n",
    "# dataframe.to_csv(\"3dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe=pd.read_csv(\"3dataset.csv\")\n",
    "\n",
    "# dataframe.dropna(inplace=True)\n",
    "# dataframe\n",
    "\n",
    "# NUM_EPOCHS = 3\n",
    "# BATCH_SIZE = 256\n",
    "# MAX_SEQ_LEN = 256\n",
    "# LEARNING_RATE = 2e-4\n",
    "# MAX_GRAD_NORM = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "-Y5XnqHVWi9T",
    "outputId": "868f2ad5-0f5c-41c8-b705-f1b3ad8f012f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token lengths distribution in the dataset\n",
    "token_lengths = [len(i.split()) for i in dataframe[\"tweet\"]]\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(token_lengths,bins = 30,edgecolor=\"black\")\n",
    "plt.xticks(ticks = np.linspace(10,100,11))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0AxSspAzSE6A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe[dataframe['class']==1].shape,dataframe[dataframe['class']==0].shape,dataframe[dataframe['class']==2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQEmSl2aS7_T"
   },
   "source": [
    "# Training and validation set\n",
    "We can also consider token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xA2mJ75ARWBv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe[\"token_length\"] = token_lengths\n",
    "# dataframe = dataframe.loc[dataframe[\"token_length\"] <= 25, :].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "6M-IQ2ZyYVwb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# token_length 128, seems a good fit for data\n",
    "\n",
    "# split training and validation data\n",
    "train_df, val_df = train_test_split(dataframe, test_size= 0.20, stratify= dataframe[\"class\"], random_state = 40)\n",
    "\n",
    "# val_df,   test_df   = train_test_split(temp_df, test_size= 0.80, stratify= temp_df[\"class\"],random_state = 47)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop  = True)\n",
    "# test_df  = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9qCr_5aTbOn"
   },
   "source": [
    "#Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "570b9a872e614e0eab6618f306be7306",
      "34e574772e8b4f81bc7e02e8ebaeb258",
      "1cf66f2a8c5f49ce98d59dae5186298d",
      "71f100b04c964a1bbde06c537f483ed7",
      "9e1caf8b23fb4eb1976f808269d1dd3e",
      "3258d106659040dfb7ffea47c017ed38",
      "f9a2caba063b4a4f98ad258044d012fb",
      "dfd44792f624499b87bd768836016e88",
      "ae841edad05b4ef9b4308308d6683fa3",
      "34bbd1edf06c4a9194bd27eaeeee32b2",
      "ea850e74cb6a4121a456578b29ce7955",
      "d69dfd21bce04204b3220b71b4d4a968",
      "4914d10c0f354e178de66dc11449e26a",
      "f554ec9fe80a408680aa7b0a1c6837ac",
      "f4ec333b7c654876a6caad010e88c203",
      "cfe933364a3147368660f5463f1e5a29",
      "f7998e50af804d66b6af0f26b5588255",
      "4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "31914a14cfa243388f43a02da4db24b6",
      "69d90bdca5174dfb91f5cf124884095e",
      "123641d1426541fba838576dff7f6082",
      "71d0c2b02f0c4a609477bc31aa880938",
      "c12c857f159443f1b2a661fcd7afa002",
      "989933f9c84a47d4b64d5b5441a1f492",
      "2024092105904b418c984aae9f4118bf",
      "4cc5655f9bdb42bca5d80e2849e8cd2b",
      "fd56d3ae17774e5496a7fdcbcb57b874",
      "b5516712d5304670a05ec871eb5896a4",
      "9910be9c8b7b4188936721e958ca15c5",
      "50859aa086814457bcab249b35d486a8",
      "4f0a4e1b4929448a8b0a25b202271a40",
      "ac93c61a19c0474994803853194d2aa8",
      "ee12049f5a9c4505b9769a4ff9c36477",
      "18e134c7af5d45baa952ccf06f96f3d8",
      "21bf2e03eac8419fa693628ab2cef02d",
      "0f14c359d92748268810099e6cdd1fc3",
      "e99b3d05437f4cdf9e1700e3cf466b34",
      "4f1d5a79d7ec4e42add7775fa925b187",
      "e89d668a4fb541ec8d75d171bf899869",
      "430a9d1768614e0596960d2a3d15d69e",
      "909ae03e117345f7a4b53f3045e090b7",
      "06285d669e92494192637cb3ee5a40f4",
      "209ee3e0949b446b8c58c57989065c5a",
      "672e978f9b524c5784553abd8cc91507",
      "17ae300ebf634778862bc211cb432eef",
      "5a072e1f73624ea5aa35e7e18af17f50",
      "1ec35f8bfadb40968f777ab7bbb55184",
      "274875a4aa6047c9903ae3065a5d85c2",
      "a51f1ae4e3bd4563be3eb7c04dec7a60",
      "c7586ac9b41c4e75b02a6c076a458686",
      "8a0c04349bae44f4a7130463ded826d1",
      "9f11959bab964aad822250b6e6853cb8",
      "9b0c918326174bc4b80585a52ac33e32",
      "e38ea829111b4065bad8ad4a4927bc39"
     ]
    },
    "id": "qe9vOPP6TD5-",
    "outputId": "d30dde8d-148a-4d7c-d57d-05ebeb164a73",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load bertModel, bertTokenizer and freeze all layers\n",
    "bertModel = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "bertModel.trainable = False # freezing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109482240"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting model total number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(bertModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bert_dataset import BERTDataset\n",
    "\n",
    "# Define constants\n",
    "MAX_LEN = 30\n",
    "BATCH_SIZE = 16\n",
    "PROJECTION_DIM = 2\n",
    "\n",
    "# Instantiate a BERT tokenizer\n",
    "\n",
    "# Instantiate an object of the BERTDataset class\n",
    "bert_dataset = BERTDataset(text=None, labels=None, attention_scores=None, max_length=None, tokenizer=None, projection_dim=None)\n",
    "\n",
    "# Call the dataprep method on the object\n",
    "train_loader, val_loader = bert_dataset.dataprep(train_df, val_df, tokenizer, MAX_LEN, BATCH_SIZE, PROJECTION_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  4597,  4939,  7743,  2007,  1037,  2601,  2217,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2515,  2008, 16114, 24992,  2094,  7928,  2030,\n",
      "          4424, 16011,  2006,  1996,  2395,  2323,  2308,  1999,  2256,  2219,\n",
      "          2455,  2006,  2256,  2219,  5800,  2256,  2219,  2308,  2025,   102],\n",
      "        [  101,  8239,  5223, 18411,  2015,  5236,  2316, 20014,  6132, 14144,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3059,  9152, 23033,  2015,  2655,  2027,  5980,  1996, 13433,\n",
      "         18153,  2075,  2072,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7929,  2061,  1045,  2031,  2042,  2125,  1056, 24281,  3334,\n",
      "          2005,  2070,  2051,  2085,  2061,  1045,  2089,  2074,  2022, 13174,\n",
      "          2021,  2038, 24247, 11382,  3489, 18792,  2075,  2941,  5407,   102],\n",
      "        [  101, 11891,  2026,  5980,  1998,  2655,  2033,  1037,  6904, 13871,\n",
      "          4140,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3097,  2106,  2017,  3602,  1996,  4485, 29334,  2015,  2007,\n",
      "          2147, 24487,  8292, 29577,  2075,  2317,  4841, 10643,  2008,  2074,\n",
      "          1996,  4485,  3667, 14997, 13162,  1998,  1996,  2224,  1997,   102],\n",
      "        [  101,  5310,  5310,  2024,  2027,  2641,  8711,  2065,  2027,  3631,\n",
      "          1996,  2375,  2077,  1996,  4040,  2025, 18792,  2075, 15958,  8025,\n",
      "          2055,  2043,  1996, 13141,  3570,  2003,  4162,   102,     0,     0],\n",
      "        [  101,  2012,  2026,  2152,  2082,  2074,  2000,  8741,  2585, 27589,\n",
      "          2290,  2010,  2128,  7559,  5732,  2522, 27794,  2015,  1045,  2097,\n",
      "          2022,  9936,  1037,  2120,  5843,  1999,  2006,  3058,  2193,   102],\n",
      "        [  101,  2288,  1037,  3232,  2062,  3316,  2017,  2064, 17757,  2023,\n",
      "          4234,  2161,  2034,  2028,  2003,  4811,  2027,  2031,  2288,  2195,\n",
      "          2193, 14997,  2041,  3794,  1038, 15000,  3091,  7171,  1997,   102],\n",
      "        [  101,  2748,  1996,  2067, 23835,  2112,  1997,  2023,  2162,  2097,\n",
      "          2022, 28144,  5714,  4328, 21633,  2040,  2097,  2467, 29543,  1998,\n",
      "          2886,  1996,  1996, 11579,  1998,  2217,  2007,  7025,  2096,   102],\n",
      "        [  101,  1037, 28616, 15707, 26942,  2003,  1037,  2158,  2040, 18959,\n",
      "          2015,  2308,  2004,  2172,  2004,  2027,  4078, 18136,  2063,  2169,\n",
      "          2060,  1044,  2140,  2273, 19766, 28616, 15707,  4890,   102,     0],\n",
      "        [  101,  2144, 18301,  2038,  2062, 21553,  2084,  1996,  8495,  1998,\n",
      "          2027,  3555,  2023,  9288,  2193,  2335,  1045,  7166,  2000,  2903,\n",
      "          2009,  2001,  2178, 14163,  2480,  8609,  9452,  2886,   102,     0],\n",
      "        [  101,  2643,  1045,  2293,  2009,  2043,  3864,  2079,  2025,  2175,\n",
      "          2037,  2126,  1998,  2059,  2027,  7743,  2055,  2009,  2006, 10474,\n",
      "          2009, 17704,  6517,  6553,  2021,  2009,  2074,  2205,  2172,   102],\n",
      "        [  101,  3599,  1045, 15375,  2043,  2308,  2360,  2016,  2081,  2009,\n",
      "          2006,  2014,  2219,  2053,  2016,  2106,  2025,  2016,  2001,  1996,\n",
      "          2034,  3203,  1998,  2150,  1037,  5205,  2074,  2022, 15671,   102],\n",
      "        [  101,  1045,  2572,  2145,  3046,  2532,  2156,  2054,  7415,  1037,\n",
      "          9152, 23033,  6270,  4366,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.4710, 0.4710, 0.0090, 0.0330, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0130, 0.0130, 0.1920, 0.0130, 0.0130, 0.0130, 0.0130, 0.7280, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6300, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0700, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0700],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.6490, 0.0450, 0.0450, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5960, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  6583,  2860,  2009,  2763,  9152, 13327,  8112,  6346,  5670,\n",
      "          1996,  7499,  7929,  1045,  7499,  1996,  5181,  3649,  3531,  8046,\n",
      "          1996,  7743,  4906,  2007, 17207,  2480,  2009, 18856,  8649,   102],\n",
      "        [  101,  2009,  4600,  8832,  2008,  3144,  2111,  2007,  1037,  3020,\n",
      "          2779, 26264,  2024, 27188,  2011,  2216,  2008,  2079,  2025,  2000,\n",
      "          1996,  2391,  2008, 16491,  9714,  8106,  2024,  9530,  3597,   102],\n",
      "        [  101,  2017,  2196,  2113,  2045,  2001,  2008,  2028,  2611,  2040,\n",
      "          2081,  2841,  6397,  1998,  1037,  9129,  1997,  2060,  4315, 22043,\n",
      "          2094, 13350,  2008,  7386,  3209,  2000, 11870,  4742,  2045,   102],\n",
      "        [  101,  2995,  9353,  2638, 29364,  2483,  1999,  4639,  2308,  2089,\n",
      "          2022,  2349, 10032,  2030, 10840,  2107,  2004, 26572,  5666, 10074,\n",
      "          1051, 21639,  8715,  7632,  2869, 21823,  6491,  2030, 12731,   102],\n",
      "        [  101,  9587, 25016,  5244,  2024,  2025,  3039,  2000,  3642,  2213,\n",
      "          2078,  1996, 15554,  2035,  9587, 25016,  5244,  2024,  2000, 10797,\n",
      "          6355,  2162, 24815,  1996,  2364, 24815, 18411,  2860,  1998,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2106,  3361,  9211,  3828,  5181,\n",
      "          2013, 11513,  2079,  2017,  2031,  2151,  2801,  2129,  2172,  5181,\n",
      "          2076,  2718,  8017, 27788,  2001,  4138,  1998, 18241,   102,     0],\n",
      "        [  101,  1045,  6655,  2002,  2001,  2759,  1999,  1996, 17276,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2044,  9268,  7025,  3308,  7699,  5123,  3570,  2011,  1996,\n",
      "          4071,  1997, 11822,  5657,  1996,  2976,  2231,  2153,  3228,  2769,\n",
      "          2000,  8711,  2003,  7861,  4783, 17644,  3672,  1998, 13675,   102],\n",
      "        [  101,  2821,  2428,  8945,  2021,  2017,  1037, 14071,  5484,  5292,\n",
      "          2595,  2033, 11082,  2377,  3608,  2502,  9152, 13327, 20325,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2182,  2028,  1997,  2115,  2062,  9716,  7928,  2013,\n",
      "          2193,  2070,  2024,  2145, 12097,  2066,  1996,  3522, 14163,  2232,\n",
      "          4487,  6834,  2015,  2024,  3563,  2000,  1996,  5472, 25518,   102],\n",
      "        [  101,  1048,  2863,  2080,  1996,  5637, 16522,  6732,  2010,  2217,\n",
      "          2253,  2000,  2521,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5292,  4067,  2017,  2005,  2025,  2108,  1037,  6933,  1059,\n",
      "         10606,  2100,  7743,  2066,  1996,  2308,  1999,  2008,  2678,  1040,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1048,  2213,  7011,  2080,  2611,  2049,  2074,\n",
      "         17276,  1998,  2049,  2467,  2632,  4140,  2183,  2006,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 29500,  7955,  3342,  2008,  1999,  5152,  3032,  2027,  2079,\n",
      "          2025,  3499,  2308, 19045,  3198,  2068,  2000,  3524,  1999,  1996,\n",
      "          2482,  1998,  4604,  1037,  2158,   102,     0,     0,     0,     0],\n",
      "        [  101,  2051, 11928,  2638,  6171,  6517, 24589,  2011,  1996,  3168,\n",
      "          3238,  2552,  1997,  3282,  4808,  2012,  4058,  2110,  2023,  2851,\n",
      "         14488,  2005,  1996,  5229,  1998,  1996,  2972, 10131, 17683,   102],\n",
      "        [  101,  2023,  5777,  2894,  4485,  2003, 17276,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.3040, 0.0800, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0800, 0.0800, 0.0800, 0.0800, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0800, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4150,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0080, 0.0080,\n",
      "         0.0080, 0.0290, 0.0290],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1570, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0410, 0.0110,\n",
      "         0.1570, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0110,\n",
      "         0.0030, 0.0110, 0.0110],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0540, 0.0540, 0.0540, 0.7800, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0570, 0.0570, 0.0570,\n",
      "         0.0570, 0.0570, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0570, 0.0570, 0.0570],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0510, 0.7360, 0.0510, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0140, 0.0550, 0.7890, 0.0550, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0360, 0.0360, 0.0360, 0.1370, 0.1370, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0190, 0.0190,\n",
      "         0.2780, 0.2780, 0.2780],\n",
      "        [0.0450, 0.0450, 0.0450, 0.6490, 0.0450, 0.1710, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  1045,  2079,  2025,  3305,  2129,  2061,  2312,  1037,\n",
      "          2112,  1997,  1996,  2529,  2679,  2288,  2061,  2128,  7559,  5732,\n",
      "          2061,  3435,  2009,  5621, 22132, 17125,  1996,  2568,   102,     0],\n",
      "        [  101,  1045,  8239,  5223,  2023,  2208,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  1996,  2329,  2231,  2106,  2025,  2215,  2017,  2000,\n",
      "          2963,  1037,  4613,  2008, 13275,  7073,  2000,  1996,  2755,  2008,\n",
      "          1996,  6284,  2313,  2003,  2108,  2999,  2011,  5152,  7489,   102],\n",
      "        [  101,  2079, 12244, 11047, 11475,  4502,  6045,  2050, 27829,  2050,\n",
      "         11333,  9759,  3070,  2226, 14071, 10830,  7847,  5289,  3148,  5796,\n",
      "         15000,  2063,  2017,  2024,  3060,  2017, 25276,  2000,  3060,   102],\n",
      "        [  101,  2008,  7570,  2063,  2069,  2288,  2051,  2005,  2010,  2814,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045, 10416,  5669,  2009,  2013,  2023,  2028,  2138,  2009,\n",
      "          2074,  4906,  1996,  2466,  2240,  1997,  2115, 11382,  3489,  2771,\n",
      "          2072,  2447,  2061,  2092,  2021,  2182,  1996,  2440,  5053,   102],\n",
      "        [  101,  5310, 15244,  2094,  2003,  4629,  1998,  2038,  2019,  4540,\n",
      "          2005,  1996,  2653,  1045,  2562,  2667,  2000,  4139,  2870,  2013,\n",
      "         21935,  2007,  2146,  2908,  6555,  2015,  1999,  1996,  1042,   102],\n",
      "        [  101,  2057,  2031,  1996,  2087, 12382,  7521,  3343,  2021,  2054,\n",
      "          2003,  1037,  5142,  2003,  2043,  6206,  7489,  2272,  1998, 25174,\n",
      "          1037,  3528,  1997,  1996,  3001,  2008,  2147,  1999,  2344,   102],\n",
      "        [  101,  2193,  6616,  2015,  1045,  2079,  2025,  2507, 14163,  4246,\n",
      "         14163, 12680,  2075,  4954,  5963,  4012,  9856,  7743,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  8040,  4140,  2271,  7743, 11159, 16215, 16215, 13782,\n",
      "          2130,  1996, 22212,  3530,  2193,  2193,  2065,  2023,  3247,  2515,\n",
      "          2025, 19141,  1996, 10528,  2839,  1997, 24247,  6794,  1999,   102],\n",
      "        [  101,  3524,  1045,  2572,  6069,  2022,  1999,  3000,  2012,  1996,\n",
      "          2203,  1997,  2255,  3531,  2425,  2033,  2045, 29500,  1999,  3000,\n",
      "          1998,  1045,  2064,  2031,  8827,  2140,  2066,  1996,  2317,   102],\n",
      "        [  101,  2339,  2323,  1045,  2215,  2026, 12608,  2925,  5079,  2000,\n",
      "         16831,  7489,  2030,  2037,  2336,  2129,  2003,  2008,  1999,  2037,\n",
      "          2190,  3037,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2551,  2193,  2420,  1037,  2733,  2003, 17276,  2021,  1045,\n",
      "          1521,  1049,  2145,  2183,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20976, 18520,  7459, 14163, 13793,  2229,  1996,  2168,  2126,\n",
      "          2016,  7459,  9680,  5130,  2216,  2024,  2014, 21392,  4523,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1056, 24281,  3334,  2515,  2025,  2066, 14163,  2480,  8609,\n",
      "          2593,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  8398,  9767,  1996,  2542,  4485,  2041,  1997,  7795,\n",
      "          7543,  1037,  2454,  1997,  2062,  8711,  2024,  2183,  2000, 10574,\n",
      "          2000,  2885,  1998,  6974,  5181,  2031,  7167,  1997,  3218,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0640, 0.0640,\n",
      "         0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.2430, 0.0640,\n",
      "         0.0640, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0240, 0.0240, 0.3500,\n",
      "         0.3500, 0.0060, 0.0060],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.6950, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0380, 0.0380,\n",
      "         0.5450, 0.0100, 0.0100],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0280, 0.0280, 0.3980,\n",
      "         0.1050, 0.3980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.3630, 0.3630, 0.0250, 0.0250, 0.0250, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0420, 0.0420, 0.6070, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.2190, 0.2190, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150]]), 'label': tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3958, 24876,  2319,  2057,  2215, 12882,  2015,  2000,  2272,\n",
      "          2091,  2005,  2690,  2465,  1998,  2551,  2465,  2945,  2033,  2205,\n",
      "          1998,  6206,  2015,  2041,  7574, 26352,  2015,  2131,  2125,   102],\n",
      "        [  101,  2006,  2651,  3959,  2129,  2000,  4019,  1037,  4750,  4329,\n",
      "          2007,  2053,  2126,  1997, 15242,  2005, 13141,  2000,  1996,  7327,\n",
      "          2030,  2149,  2175,  2148,  3060,  3032,  2021,  2191,  2469,   102],\n",
      "        [  101,  2798,  2003,  4854,  2008,  2028,  1997,  2010,  9152, 13327,\n",
      "         10243,  2288,  3236,  9680,  2075,  2153,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2489,  2308,  3627,  2907,  2115,  2132,  2039,  2152,  4147,\n",
      "          4071,  5061, 16717,  1998, 12436, 20876, 12703,  2024,  2005,  5410,\n",
      "         11227,  2040,  2490,  3173,  2308,  2091,  2005,  4424, 19591,   102],\n",
      "        [  101,  5735,  2036,  7009,  2055,  2129,  3644,  1998,  3059, 11240,\n",
      "         15608,  2631,  5869,  7136,  3644,  9385, 15862,  2631,  5365,  1998,\n",
      "          5637,  5003,  8873, 19137,  2015,  3271, 12125,  1996,  5637,   102],\n",
      "        [  101,  2026,  2643,  2021,  1045,  2572,  2019,  5448,  4383,  7743,\n",
      "          2651,  2021,  2074,  2360,  2378,  9295,  2038,  2738,  2417, 21564,\n",
      "          2098,  2841,  9906, 16717,  2125,  2000,  2014,  2245,  2016,   102],\n",
      "        [  101,  2017,  2323,  2175,  3102,  4426,  2005,  2108,  1037, 11690,\n",
      "          1041,  2860,  2123,  1521,  1056,  2228,  1997,  2033,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2023,  2733,  1999,  4485,  8059,  3274, 11553, 18404,\n",
      "          6887,  7389,  6779,  2007,  5410, 16902,  2292,  2149,  2156,  2129,\n",
      "          2023,  2097,  1998,  2763,  2525,  2038,  2042, 28616, 13901,   102],\n",
      "        [  101,  2821, 10245,  2079,  2025,  2027,  2036,  2031,  1037,  2312,\n",
      "         14163, 13793,  2063,  2313,  2045,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  4314,  2308,  2024,  6719,  7079,  1037, 24963,  2158,\n",
      "          4147,  1037, 15913,  2000,  4344,  2068,  2005,  2193,  3371,  7242,\n",
      "          6521,  2008,  2025,  7242,  2008,  1037,  4424,  2326,  1998,   102],\n",
      "        [  101,  5310,  5310,  2012,  2560,  2027,  2069,  2081,  2017,  4364,\n",
      "          2041,  2000,  2022,  2066,  2474, 18733, 13157,  1998,  4785,  2689,\n",
      "          7939, 10136,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821,  2298,  6655,  2074,  2587,  1044, 13512,  2615,  1996,\n",
      "          2047,  4714, 17276,  2160,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3427,  5310,  1998,  2054,  2079,  1057,  2113,  2027,\n",
      "          2018,  1037,  2553,  2055,  2108, 15504,  1998, 17536,  2012,  1996,\n",
      "          3115,  3309,  2011,  1037, 11417, 15493,  2828, 10334,  2842,   102],\n",
      "        [  101, 26264,  5609,  2017, 11870, 21919,  1056, 24281,  2096,  2017,\n",
      "          2024,  3393, 19159,  2006,  1996, 10480,  6210,  1997, 14398,  9152,\n",
      "         13327,  2015,  4954, 12221,  1998, 14163, 13793,  2229,  2024,   102],\n",
      "        [  101,  5310,  5310,  3426,  1045,  2572,  2304,  1045,  2614,  2066,\n",
      "         12873,  1998, 17276,  2065,  2008,  7110,  1056,  1996,  7078, 12873,\n",
      "          4355,  4485,  1045,  2031,  3191,  2651, 16780,  2017,  2614,   102],\n",
      "        [  101,  2193,  1997,  2193,  6645,  2024,  2108, 23516,  8050,  2529,\n",
      "          4781,  2024,  2108, 27251,  1996, 13141, 29375,  1998,  1996,  4424,\n",
      "          2566, 27774,  2024,  3755,  2011,  1996,  3451, 15511,  2015,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0030, 0.0030, 0.0110, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600, 0.1600,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.8320, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0050, 0.0050, 0.0010, 0.0010, 0.0010, 0.0180, 0.0180, 0.0670, 0.0670,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0970, 0.3670, 0.3670, 0.0070, 0.0250,\n",
      "         0.0250, 0.0250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2850, 0.2850,\n",
      "         0.0050, 0.2850, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1010, 0.1010, 0.1010, 0.1010,\n",
      "         0.1010, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1010, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070]]), 'label': tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  4931,  5310,  2073,  2026, 11804,  5233,  2678,  2055, 22212,\n",
      "          2015,  9343,  3765,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  4138,  1037,  4534, 16584,  3334,  2040,  2496,\n",
      "          2000,  1037, 11382,  3489,  2008,  2573,  2005,  1037, 13067,  2029,\n",
      "          6753,  5611,  4454, 20378,  2070,  6986,  3981,  1997, 25937,   102],\n",
      "        [  101,  2821, 11631,  2080,  2339,  2035,  1996, 17276,  2831,  2043,\n",
      "          2017,  2131,  1037,  6297,  4638,  2394,  2003,  2026,  2117,  2653,\n",
      "          1998,  1045,  3713,  2193,  2193,  1999,  2035,   102,     0,     0],\n",
      "        [  101,  2089, 28949,  5222, 11721,  2497,  4455,  2032,  1037,  9152,\n",
      "         13327,  2089, 28949, 12386, 11721,  2497,  4455,  2032,  1037,  9152,\n",
      "         13327,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2193, 10958,  5403,  6519,  3280,  9152, 14728, 12190,  4270,\n",
      "          4078,  2061, 12871, 28235,  2271, 12324, 27665,  2099, 27713,  2078,\n",
      "         12098, 19205,  3334, 26086, 11393, 11417,  2140,  3280, 20377,   102],\n",
      "        [  101,  5310,  2010, 11213,  2008,  2308,  2735, 22212,  2138,  2027,\n",
      "          5458,  1997, 15589, 12043,  2003,  2074,  2066,  1059, 24475,  2672,\n",
      "          2016,  2015,  2074, 18307,  1998,  2036, 19483,  2339,  2064,   102],\n",
      "        [  101,  5310,  2017,  4364,  2024,  2061, 17203,  2057,  2131,  2009,\n",
      "         24471,  7591,  2021,  2644, 27853,  2035,  1996,  2204, 16215, 22895,\n",
      "          5620,  2005,  2149,  3442,  2317,  8135,  2175,  2022,  3407,   102],\n",
      "        [  101,  5310, 17022,  2053,  1045,  2001,  2894,  1045,  2572,  2025,\n",
      "          1037,  6394,  2317, 10514, 28139, 22911,  2923,  2030,  2151,  2060,\n",
      "          2828,  1997,  2711,  1045,  2572,  2193,  2670,  1045,  2490,   102],\n",
      "        [  101,  1996, 17203,  2112,  2003,  2008,  2750,  2035,  1996,  3350,\n",
      "         13946,  1996,  7570, 24729, 10441,  2595,  2003, 14636,  2045,  2145,\n",
      "          6904, 13871, 12868,  2066,  2017,  2040,  2145,  4965,  2009,   102],\n",
      "        [  101, 22212,  2015,  1998,  6904, 13871, 12868,  2024, 10597,  5665,\n",
      "          2566, 16874,  2015,  2903,  2009,  2028, 22212,  2003,  2788,  1996,\n",
      "         14818,  3287, 22212,  1998,  1996,  2060,  2003,  2049,  2564,   102],\n",
      "        [  101,  6781,  2685,  2065,  2016,  2758,  2111,  2024,  5637, 17813,\n",
      "          1998,  2016, 14054,  2007,  3407,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  6517,  2112,  2003,  2035,  2008,  2017,  2360,  2003,\n",
      "          2995,  1996,  5181,  3288,  2216,  4942, 28600,  2319,  4485, 29334,\n",
      "          7228,  8040, 18163,  2000,  1999, 10085, 19879,  2618,  2256,   102],\n",
      "        [  101,  5310,  3531,  2079,  2025,  3102,  4426,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2052,  3087,  2941,  5987,  1037,  9152, 13327,  2000,  3828,\n",
      "          1037,  2317,  2158,  2166,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6320,  1040, 21058, 19699,  3695,  2003,  1037,  8239,\n",
      "          3364,  8840,  2140,  2054,  2002,  2288,  2183,  2006,  2008,  2003,\n",
      "          2128, 20051,  3085,  2000,  2149,  1999,  2151,  2126,  2002,   102],\n",
      "        [  101,  1999,  1996,  8952,  7004,  2170, 20228,  5657,  3145,  2317,\n",
      "         28844,  2100,  2612,  1997, 23205,  6525,  1996,  2064,  2483,  3576,\n",
      "         26136, 28516,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.8320, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0050, 0.0050, 0.0200, 0.0200, 0.2920, 0.2920, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.1790, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.3230, 0.0850, 0.0850, 0.0060, 0.0060, 0.3230, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.1950, 0.1950, 0.1950, 0.0510, 0.0510, 0.0510, 0.1950, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0140, 0.2070, 0.2070, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0510, 0.7380, 0.0510, 0.0510, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2043,  6221,  8398,  7949,  2010,  9587, 25016,  2213,  7221,\n",
      "          2000,  2421,  1996,  2878,  1997,  4774,  3011,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2502, 23592,  4000,  5291,  2091,  2115,  5413,  2026,  2129,\n",
      "          1996,  3974,  1055,  3501,  2860,  2855,  2735,  2000,  5223,  4613,\n",
      "          1998,  4808,  2043,  2477,  2123,  2102,  2175,  2037,  2126,   102],\n",
      "        [  101,  5310,  5310,  3530, 28831,  2027,  2024,  2025,  8711, 17522,\n",
      "         23035, 23996,  2012,  2190, 27256,  2015,  1998,  3348, 17857,  2012,\n",
      "          5409,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002, 19424, 12731,  3600,  2008, 17210,  2000,  2022,  7271,\n",
      "         17818,  2002,  1037, 17328,  2008,  2339,  2010,  2406,  2003,  2108,\n",
      "         15504,  1998, 17357, 18655,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 14560,  2318,  4214,  3209, 21524,  1999,  1996,  2397,\n",
      "          2009,  2053,  2062,  2084,  1037, 28520,  1045,  2228,  2017,  2024,\n",
      "         28616,  2378, 29021,  2593,  2115, 21379,  2277,  2030,  2060,   102],\n",
      "        [  101,  5310,  2122,  3032,  2097,  2025,  7487,  2037,  4725,  1998,\n",
      "          9859,  2005,  8398,  2348,  2053,  4797,  1996,  2827,  7610,  2052,\n",
      "          2022, 16312,  2027,  8840,  8988,  2063,  2010, 12538,  2317,   102],\n",
      "        [  101,  5310,  5310,  6616,  2017,  3280,  2525,  2017,  4485, 11867,\n",
      "          7974,  2075, 22418,  6723,  5677,  1045,  8239,  5223,  2017,  3246,\n",
      "          2017, 16769,  2006,  2019,  8288, 11338, 12274, 15379,   102,     0],\n",
      "        [  101,  2067,  2000,  2073,  2027,  2234,  2013,  2030,  2317, 13481,\n",
      "          2342,  2000,  3857,  2037,  2219,  3842,  2013, 11969, 13343,  2500,\n",
      "          1996,  2168,  2126,  1996,  5181,  2106,  2007,  3956,   102,     0],\n",
      "        [  101,  2070,  2111,  2074,  6069,  2022, 17276,  6229,  2027,  3280,\n",
      "          8840,  2140,  7570,  9856,  2467,  4122,  2317, 15618,  2040,  1996,\n",
      "          6616,  5176,  2005,  2317,  3317,  1999,  2193,   102,     0,     0],\n",
      "        [  101,  5310,  5310,  2092,  2005,  2028,  2027,  3582, 24184,  2025,\n",
      "          1037,  2643,  7025,  2003,  1996,  3291,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22889, 11431,  3057,  3153,  2007,  3151, 12320,  4519,  2137,\n",
      "          3057,  3153,  2007, 18835, 11265, 17603,  4757,  8111,  1056, 29548,\n",
      "          2075, 10007, 25384,  2066, 13114, 15928,  2063,  2016,  8670,   102],\n",
      "        [  101,  3282,  2491,  1996,  3399,  2008,  1037,  2450,  2179,  2757,\n",
      "          1999,  2019,  8975, 15504,  1998, 21384,  2007,  2014,  6090,  3723,\n",
      "         21290,  2003,  5064, 28980,  6020,  2000,  1037,  2450,  9990,   102],\n",
      "        [  101,  2026,  2905,  2003,  2383,  2019,  2035, 11690,  2769, 25518,\n",
      "          4590,  9902,  6826,  8004,  4590,  2954,  3666,  2283,  2003,  8362,\n",
      "          1037,  2518,  2426,  2611,  7011,  5620,  2030,  2242,   102,     0],\n",
      "        [  101,  2129,  2017,  2031,  2589,  2673,  2000,  2330,  2115,  2677,\n",
      "          6904, 13871,  4140, 11496,  2003,  1037,  8991,  6313,  2035,  2017,\n",
      "          2031,  2589,  2122,  2086,  2003,  2886,  2886,  1998,  6343,   102],\n",
      "        [  101,  2087,  2187,  3358,  5181,  5223,  3956,  2029,  2017,  2092,\n",
      "          2113,  2087,  2187,  3358,  5181,  2024,  4750,  2025, 21379,  2017,\n",
      "          2024,  2019, 10041,  1037, 29591,  2000,  1996,  2317,  2679,   102],\n",
      "        [  101,  2009,  1996,  2783,  2095,  1998, 10823,  1999,  3088,  2024,\n",
      "          2145,  5983,  2632, 21891,  2015,  2138,  2027,  2228,  2009,  3957,\n",
      "          2068,  8687,  4204, 12456, 15950,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1850,\n",
      "         0.1850, 0.0030, 0.0030, 0.1850, 0.0130, 0.1850, 0.1850, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.2750, 0.0190, 0.0190, 0.0190, 0.0190, 0.2750, 0.2750,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0010, 0.0140, 0.0140, 0.0140, 0.0140, 0.0520, 0.0520, 0.0520,\n",
      "         0.0520, 0.0520, 0.0520],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0020, 0.0020, 0.1260, 0.1260, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.1260, 0.1260, 0.0090, 0.1260, 0.1260, 0.1260, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1910, 0.1910, 0.1910, 0.1910,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.2380, 0.2380, 0.2380, 0.2380, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0290, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4140, 0.4140, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0200, 0.2890, 0.2890, 0.2890,\n",
      "         0.0200, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0200,\n",
      "         0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0400, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1380, 0.1380, 0.1380, 0.1380,\n",
      "         0.1380, 0.1380, 0.1380, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  8840,  2140,  2054,  1037,  5236, 27571,  2243,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  2146,  2004,  2017,  2131,  7629,  2769, 10930,  7743,\n",
      "          2123,  1521,  1056,  2729,  2065,  2017,  2123,  1521,  1056,  2175,\n",
      "          2041,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19992, 24008, 17620, 14753,  2290,  1045,  2572,  2822,  2040,\n",
      "          2344, 13017,  5785,  8840, 24182,  3103,  1056,  9759,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2129,  2079,  2017,  3292,  4426,  2013, 13157,  2213,\n",
      "          2021,  2012,  1996,  2168,  2051,  2017,  3713,  2012,  2037,  2233,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3867,  1997,  9152, 13327,  2015,  2040,  2131,  2915,  2011,\n",
      "          2610,  1999,  2637, 10107,  2009,  1998,  2323,  2196,  2022,  9530,\n",
      "         10258,  4383,  2007, 12461,  2040,  2131,  2915,  2011,  4297,   102],\n",
      "        [  101,  5310,  1045,  2572,  2025,  1037,  5470,  1997,  4808,  2383,\n",
      "          2056,  2008,  1045,  2031,  2196,  2464,  1037,  2062,  8595,  3085,\n",
      "          2227,  2008,  1996,  1056,  9148,  2102,  8334,   102,     0,     0],\n",
      "        [  101,  5310,  5310,  2027,  2024,  2035,  2317,  2205,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2317,  4632,  2474,  2515,  2025,  5271, 15270,  2850,\n",
      "          1996,  5744,  2666,  3203,  2106,  2025,  2130,  2113,  1059, 24475,\n",
      "          1045,  2001,  3331,  2055,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2664,  2178,  2166,  7494,  2458,  2746,  2041,  1997,  2054,\n",
      "          5152, 15554,  1998,  5424,  2455, 15862,  4366,  2003,  3644,  4548,\n",
      "          8976,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2270,  5193,  2069,  2573,  1999,  2035,  2317,  3032,  4728,\n",
      "          2009,  4150, 17276,  5193,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6343,  2749, 10823,  2000,  2202,  7574,  6343,  2749,  2317,\n",
      "          2308,  2000,  2022,  6530, 17219,  2015,  2298,  2012,  1996, 14163,\n",
      "         14540, 18163, 27455,  2037, 16561,  1999,  1996,  2225,  2027,   102],\n",
      "        [  101,  5310,  3398,  2096,  1045,  2079,  2025,  5993,  2007,  9202,\n",
      "          4490,  1997,  4808, 10413,  2003,  2635,  7195,  2004,  1037, 19483,\n",
      "          2711,  2006,  2122,  9202,  7087,  3111,  2926,  1996, 21877,   102],\n",
      "        [  101,  5310, 12043,  1059, 24475,  2017,  2404, 10257,  2132,  2058,\n",
      "          2033,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24664, 21756,  2210,  2611,  2317,  5232,  5016, 24664, 21756,\n",
      "          2402,  2450,  1996,  2305,  2332, 16371,  4246,  2056,  2288,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2021,  2008,  2003,  2025,  2008, 12731,  2480,  2916,  2008,\n",
      "          2031,  2053,  4646,  2000,  2070,  2111, 12825,  2089,  2022,  4072,\n",
      "          1999,  1996,  2925, 15080, 28548,  1997,  2916,  2008,  2079,   102],\n",
      "        [  101,  1045,  2572,  3666, 19483,  3239,  1998,  2027,  2024,  2035,\n",
      "          2074, 13071,  2105,  1996,  2160,  1999,  6007,  6517,  2006, 10135,\n",
      "          6517,  1045,  5223,  2023,  6517,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0160, 0.0160, 0.0160, 0.0160, 0.0610, 0.8750, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0970, 0.0970, 0.0970, 0.0970, 0.0970, 0.0970, 0.3670, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.3980, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3980,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.1170, 0.1170,\n",
      "         0.1170, 0.1170, 0.1170, 0.1170, 0.1170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0230,\n",
      "         0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880,\n",
      "         0.0880, 0.0880, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.1220, 0.1220, 0.0020, 0.0020, 0.0020, 0.0320,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0080, 0.0080, 0.1220],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.4700, 0.4700, 0.0090, 0.0090,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2061,  2017,  2024, 10468, 24791,  1998, 14863, 13027,\n",
      "          2019,  6206,  7344,  2040,  2003,  2747,  4911,  1996,  4277,  1997,\n",
      "          2023,  2406,  2003,  2008,  2129,  2009,  2573,   102,     0,     0],\n",
      "        [  101, 14071,  2098,  1045,  2079,  2025,  2113,  2339,  2017,  2052,\n",
      "          2215,  2000,  3422,  2008,  9152, 13327, 14636,  1999,  1996,  2034,\n",
      "          2173,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  2035,  1997,  2149,  2113, 19483,  2015,  2066,  2000,\n",
      "         15429,  3126, 20179,  1999,  1996, 20014,  4355, 10586,  1997,  2619,\n",
      "          2842,  5525,  2023,  2515,  2025,  2812,  2027,  1040,  2066,   102],\n",
      "        [  101,  7574,  2003,  1037, 11382,  3489,  8040,  3286,  2000,  9585,\n",
      "          9152, 13327,  2015,  2066,  2017,  2000, 25742,  2125,  1997,  1996,\n",
      "          2291,  2009,  2001,  3724,  2588,  1996,  2406, 15175,  2135,   102],\n",
      "        [  101,  5310,  4487,  9284,  1045,  2079,  2025,  2113,  2129,  2317,\n",
      "          9416, 16629,  2097,  2994,  1999,  2449,  2320, 12461, 10214,  2000,\n",
      "          2175,  2041,  1997,  3571,  1045,  2572,  2025,  1999,  1996,   102],\n",
      "        [  101,  2053,  2023,  2003,  2025,  1996,  2813,  2012,  3796,  2193,\n",
      "          1999, 17151,  2232, 15362,  2042,  2045,  2870,  1998,  2017,  2024,\n",
      "          6149,  2053,  8198,  2023,  6302,  3497,  2013,  1996,  8199,   102],\n",
      "        [  101, 26988,  2008,  4485,  2125,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 21379,  5181,  2024,  2457,  2075,  2037,  2219,\n",
      "          6215,  2011,  3017, 21379,  2015,  2008,  2003,  1037, 14888, 19728,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3383,  1996,  2273,  1999,  3160,  9544,  2308,  2040,  2079,\n",
      "          2025,  4377,  2066,  2395, 26965,  2015,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2317,  7743,  2007,  2019,  8016,  1997, 17546,  2606,\n",
      "          2074,  2056,  2431,  1996,  3057,  1045,  3113,  2007,  2026, 14902,\n",
      "          1997,  2606,  2024,  2304,  2821,  2026,  2643,  1045,  2572,   102],\n",
      "        [  101,  7694,  4808,  2030, 11973,  1999,  2576,  4808,  2003,  2025,\n",
      "         14044,  2057,  2079,  2025,  2031,  1996,  3616,  2030,  1996,  2490,\n",
      "          2000,  8526,  1999,  6206,  3450,  2107,  4490,  1997,  4808,   102],\n",
      "        [  101, 15624,  1998,  2002,  6010,  2008, 16795,  2594,  5909,  2296,\n",
      "          2733,  2129,  2128,  7559,  5732,  1998,  9535,  3238,  2003,  2023,\n",
      "          2158,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2115,  3566, 20482,  7564,  1997, 10338,  1998,  2017,  2020,\n",
      "          2141,  2079,  2017,  2130,  2113,  2029,  1997,  2035,  2216, 17276,\n",
      "         24106,  2115,  3611,  2003,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2025,  1996,  2028, 11113, 11589,  2075, 10834,\n",
      "          2182,  2115,  4314,  2317,  2308,  2024,  2725,  2008,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2204,  2028, 11184,  3524,  6229,  2216,  7937, 22212,\n",
      "          2015,  2131,  2907,  1997,  2014,  2461,  2210,  4632,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  2059,  2292,  2025,  2074,  7221, 25283, 15580,  2292,\n",
      "          7221,  5637,  2015,  2308,  2013,  4337, 10636,  1998,  7486,  2138,\n",
      "          2027,  2031,  7645,  2037, 14588,  2003,  2000,  2037, 13555,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.7340, 0.0510, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2500, 0.0660, 0.0660, 0.0660,\n",
      "         0.0660, 0.0660, 0.0660, 0.0660, 0.0660, 0.0660, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0060, 0.0060, 0.0060, 0.3220, 0.0060, 0.0060, 0.0060, 0.3220, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1410, 0.1410, 0.1410,\n",
      "         0.1410, 0.1410, 0.1410, 0.1410, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1850, 0.1850, 0.0030, 0.0030,\n",
      "         0.0130, 0.1850, 0.1850, 0.1850, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.1110, 0.1110, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1180, 0.1180, 0.0080, 0.0080,\n",
      "         0.1180, 0.1180, 0.1180, 0.1180, 0.1180, 0.1180, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4430, 0.4430,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0070, 0.1010, 0.0020, 0.1010,\n",
      "         0.1010, 0.1010, 0.1010, 0.1010, 0.0070, 0.0070, 0.0070, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1010, 0.1010,\n",
      "         0.1010, 0.0270, 0.0020]]), 'label': tensor([1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 14163, 22592,  2015,  4652,  2017,  2013,  2893,  1037,  2417,\n",
      "         18278,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2064,  2025,  2903,  2522, 14478, 15504,  1996,  2128,\n",
      "          2080,  3177,  4213,  7446,  3124,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19483,  3239,  2003,  6719, 14412, 27892,  6904, 13871,  4140,\n",
      "          2854,  2005,  3442,  2111,  2123,  2102,  2033,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  9152, 13327,  2112,  2001,  6057,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2108,  6439,  2011,  1037,  2317,  2158,  2003, 10468,  2032,\n",
      "          4214,  2017,  1037,  9152, 13327,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 27669,  2721,  2058,  1996,  7489,  2108, 14620,  2012,\n",
      "         13586,  2069,  2038,  2000,  2079,  2007,  2216,  2007, 24487,  2025,\n",
      "          8711,  1996,  8711,  2024,  2025,  2893,  1999,  1996,  5796,   102],\n",
      "        [  101, 10047, 15807,  2012,  2035,  1996, 14068,  2545,  5413,  5705,\n",
      "          9152, 13327,  2015,  1998,  5472, 25518, 15776,  2008,  3298,  1998,\n",
      "          2224,  3765, 19207,  2027,  7141,  2000,  2026,  3226,  1996,   102],\n",
      "        [  101,  5310, 24471,  6077, 16584,  6904, 13871,  4140,  2029,  7607,\n",
      "          2339,  1057,  1054,  2058,  2193,  1998,  2196,  2064,  2191, 18856,\n",
      "          2358, 11263,  6904, 13871,  4140,   102,     0,     0,     0,     0],\n",
      "        [  101,  2672,  2021,  2017,  2131,  2068,  1999,  2035,  3837,  2256,\n",
      "          5221,  3291,  2003,  2317,  2104, 26266,  2066,  2023,  2017,  2342,\n",
      "          2000, 16957,  3088,  2000,  2256,  4781,  2302,  2037,  1059,   102],\n",
      "        [  101,  7564,  1997,  6904, 13871, 12868,  2000,  2831,  2000,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7743,  2229,  5492,  2070,  2310, 13871,  3111,  1998,  8415,\n",
      "          2027,  2890,  9246,  5954,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7929,  2292,  2360, 24471,  2035, 16939,  1998,  4485,  1998,\n",
      "          1057,  2074,  4468,  2304,  4903,  2140,  2066,  2070, 16939,  6616,\n",
      "          2378,  6394,  2469,  1057, 12099,  2896, 24471, 10238,  1997,   102],\n",
      "        [  101,  5310,  5310,  5310,  2079,  2025,  2292,  2032,  2125, 10497,\n",
      "          2017,  2482, 12032,  2008,  9117, 11669,  7110,  1056,  4276,  2009,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  2317,  3328,  2046,  1037,  4825,  1998,  2009,\n",
      "          2038,  9152, 13327,  5126,  2054,  2079,  2017,  2079,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2231,  1997,  3577,  2038,  4217,  2000,  2224,  2610,\n",
      "          4808,  2114,  2049,  9379,  4480,  2138,  1997,  1996,  2126,  2027,\n",
      "          5444,  1999,  1037,  2270,  2602,  1996,  3795,  5130,  2933,   102],\n",
      "        [  101,  5310,  2027, 10657,  2228, 10094,  1996,  9152, 13327,  2015,\n",
      "          1045,  1040,  2022,  3228,  2041,  5610,  2066,  1037,  9464, 21431,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0150, 0.0150, 0.0150, 0.0150, 0.8100, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2170, 0.2170, 0.2170, 0.0150,\n",
      "         0.2170, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0040, 0.0040, 0.2350, 0.2350, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2350, 0.2350,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.2640, 0.2640, 0.2640, 0.0700, 0.0700, 0.0700, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.8720, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0690, 0.0690, 0.0690, 0.0690,\n",
      "         0.0690, 0.0690, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.7840, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 11184,  1045,  2200,  2172,  4299,  2023,  2071,  2022,  1037,\n",
      "          6061,  1999,  1996,  2149,  2174,  1996,  2951,  2144,  1996,  2193,\n",
      "          2127,  2651, 16481,  2008, 10823,  5181,  2033, 16643, 28370,   102],\n",
      "        [  101,  2009,  2200,  4129,  2008,  2010,  9704,  2024,  2440,  1997,\n",
      "          2317,  1998,  3262,  2690,  4793,  2111,  4129,  2032,  2129,  2157,\n",
      "          2002,  2003,  1998,  2129,  2172,  2027,  2064, 14396,  1996,   102],\n",
      "        [  101,  5310,  5310,  5310,  8529,  8840,  2140,  2644,  2108,  6918,\n",
      "          1045,  2001, 16644,  2008,  1996,  4469,  1060, 16706,  2003,  2054,\n",
      "          3084,  2149,  2215,  2000,  2663,  9918,  1045,  2196,  2056,   102],\n",
      "        [  101,  5310,  5310,  2027,  2079,  2025,  2215,  2000,  6314,  1996,\n",
      "         17276, 28857,  2011,  9391,  2205,  9414,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2339,  2079,  2025,  2017,  2831,  2055,  9212,  8540,\n",
      "          3017,  1998,  5696,  2739,  8462,  2317,  4268,  2482, 17364,  2098,\n",
      "         15504, 12364,  2059,  7129,  2011,  2193, 10823,  1999,  2702,   102],\n",
      "        [  101,  5310,  5310,  1045,  5223,  9413, 16168,  2319,  2021,  2017,\n",
      "          2024, 16939,  6394, 26476,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2228,  3484,  1997,  1996,  2193,  1997,  4004,  2015,\n",
      "          2024,  6206,  1045,  2215,  2000,  2156,  1996,  2951,  2369,  2023,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2023,  2003,  2025,  1037,  2844,  2553,  2005,  5412,\n",
      "          3510,  2005,  5622, 19279,  4232,  2317,  2308,  2059,  1045,  2079,\n",
      "          2025,  2113,  2054,  2003,  3484,  1997,  2187,  4232,  2317,   102],\n",
      "        [  101,  2106,  2017,  2113,  1996,  2069,  2051,  9587, 25016,  2213,\n",
      "          2308,  2064,  3328,  2077,  2273,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  1045,  2572,  2019,\n",
      "          3080,  2317,  1998,  1045,  2079,  2205,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2637,  2003,  2061, 16939,  2008,  2027,  2228,  4004,  2015,\n",
      "          2024, 25670,  2084, 10823,  1998,  6696,  2015,  2027,  2036,  3477,\n",
      "          4004,  2015,  2062,  2205,  1998,  4004,  2015,  2024,  2062,   102],\n",
      "        [  101,  2108,  1037,  2711,  2003,  1037,  8239, 10103,  1045,  2106,\n",
      "          2025,  3198,  2005,  2023,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2001,  1996,  5506, 14163, 13793,  2063,  2007,  1037,  4690,\n",
      "          2648, 17836,  4186,  1037, 19169,  4062,  2057,  2342,  2000,  2113,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2000,  2191,  1037,  5622, 19279,  4232,  2079,  2350,\n",
      "          2128,  5243,  3351,  1045,  2074,  4149,  1037,  9152, 13327,  2005,\n",
      "          2769,  8740, 16774,  2594,  8040,  9910,  8450,  1045,  2572,   102],\n",
      "        [  101,  1996,  2069,  2204, 14163, 13793,  2063,  2003,  1037,  2757,\n",
      "         14163, 13793,  2063,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7681,  5181,  2005,  7486,  1998,  1045,  1040,  5993,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0930, 0.0930, 0.3520, 0.0930,\n",
      "         0.0930, 0.0060, 0.0060],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.4030, 0.1060, 0.1060, 0.1060, 0.1060, 0.1060, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.6950, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.1410, 0.1410, 0.1410, 0.1410, 0.1410, 0.1410, 0.1410, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310, 18168,  2290,  2040,  2064,  1045,  2113,  5292,  3270,\n",
      "          2748,  2017,  2024,  2157,  1998, 18168,  2290, 10166,  3915,  2008,\n",
      "          2015,  2061,  4658,  2025,  2116,  4004,  2015,  2024,  2045,   102],\n",
      "        [  101,  5310,  5310,  4151,  4485,  2428,  2008,  8239,  9577,  2061,\n",
      "          2057,  2024,  5599,  1996,  7968,  3124,  1999,  1996,  2317,  2160,\n",
      "          5646,  2040,  2064,  2031,  3229,  2000,  2637,  2087,  7070,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  4865,  3655,  3432,  2024,  2058,\n",
      "          8569, 18246,  2098,  2119,  1996,  8711,  9015,  2637, 18411,  2860,\n",
      "          2106,  2017,  2113,  1037, 13141,  2064,  4374,  2035,  5450,   102],\n",
      "        [  101,  2053,  8037,  2079,  2025,  2215,  2068,  2000,  4632, 27605,\n",
      "         13806,  2004, 10003,  2011,  2037,  4506,  2044,  1996,  2942,  2162,\n",
      "          2157,  2039,  2000,  2651,  2073,  2027,  2191,  2469, 10823,   102],\n",
      "        [  101,  3524,  2027,  7917, 27233,  2063,  2033,  7834,  2013,  1996,\n",
      "          2139, 24759,  6525,  7384,  2008,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 18210,  1041, 24411,  2232,  2003,  1996,  2388,  1997,  2035,\n",
      "         14777,  5637,  4268,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122, 14331,  7923,  2342,  2000,  2644,  1996,  3800,  1997,\n",
      "          2166,  2003,  2000,  2566, 22327, 20598,  1996,  2427,  2048,  3057,\n",
      "          3685, 21376,  2048,  3057,  2052,  2025,  2191,  2204,  3008,   102],\n",
      "        [  101,  6317, 11999,  2071,  2310,  2288,  2216, 23368,  6029, 18310,\n",
      "          2000,  6497,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  5226, 27275,  2389,  2428,  2003,  1996,  4958,  9956,\n",
      "          4168,  1997,  8909,  3695, 26775, 15719,  2009,  2004,  2065,  2116,\n",
      "          4841,  2024,  2205,  5236,  2000,  2131,  2137,  2381,  4983,   102],\n",
      "        [  101,  4315,  2361,  2139,  4315,  2361,  2292,  2033,  2074,  3913,\n",
      "          2041,  2026,  9518,  2061,  2023, 11382,  3489, 17219,  2064,  2886,\n",
      "          2026,  2476,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2085,  2005,  1996,  2717,  1997,  2068,  1999,  5365,\n",
      "          2040,  2031, 15504,  1998, 16999,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2111,  2323,  2025, 12134,  4735, 18079,  2442,  1999,  2023,\n",
      "          2553,  2023,  6432, 12316,  2094, 17219,  2040,  3658,  2016,  2003,\n",
      "          1037,  3035,  2096,  2515,  2025,  2031,  2130,  1037,  4530,   102],\n",
      "        [  101,  3027, 14045, 20744, 16054,  2015,  2293,  4206,  2308, 27793,\n",
      "          1999,  4183,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2023,  2003,  2339,  2358, 29147,  2072,  3464,\n",
      "          1996,  6020,  2317,  2611,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8711,  2097,  2467,  2514,  5561,  2182,  1999,  1996,  2149,\n",
      "          2127,  2027, 15454, 15554,  2735,  1999,  1996,  9219,  1999,  2037,\n",
      "          4279, 11092,  1998,  2490,  2137,  4277,  1998,  2256,  4552,   102],\n",
      "        [  101,  5310,  5310,  2017,  2018,  2053,  3601, 22800,  3336,  2017,\n",
      "          2734,  2032,  2062,  2084,  2002,  2734,  2017,  1996,  2069,  2518,\n",
      "          2940, 24457,  2100,  3021,  2734,  1037,  2450,  2005,  2001,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1890, 0.1890,\n",
      "         0.1890, 0.1890, 0.0500],\n",
      "        [0.0050, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.2910, 0.2910,\n",
      "         0.2910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0150, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0150, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2170,\n",
      "         0.2170, 0.2170, 0.2170],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.4360, 0.4360, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.1440, 0.5470, 0.0380, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0020, 0.0020, 0.1070, 0.1070, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0210, 0.0210,\n",
      "         0.0210, 0.3060, 0.3060, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210]]), 'label': tensor([1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2074,  2191,  2469,  2017,  2079,  2025, 26202,  2115,  3239,\n",
      "          2041,  2021,  2065,  2017,  2079,  1045,  2097,  2131,  2017,  1037,\n",
      "          2317, 11942,  2005,  2115,  5798,   102,     0,     0,     0,     0],\n",
      "        [  101,  3685,  2735,  1037,  7570,  2063,  2046,  1037,  2160,  2564,\n",
      "          2065,  8038,  3363,  2074,  8239,  2061,  2022,  2009,  2079,  2025,\n",
      "          3046,  2000,  2689,  2014,  3971,  2017,  2064,  2025,  2016,   102],\n",
      "        [  101,  2022,  4273,  1998,  4468,  3604,  1999,  3655,  2057,  2064,\n",
      "          2196,  2202,  1996,  9152, 13327,  2041,  1997,  1996,  9152, 13327,\n",
      "          3190,  6222,  5626,  2323,  2022,  2053,  2175, 10019,  1998,   102],\n",
      "        [  101,  2054,  1996,  6616, 16787, 15270,  2025,  1037,  8257, 27135,\n",
      "          3293,  3794,  2299,  2637,  2074,  2018,  5152, 10047,  2863,  5244,\n",
      "          1998,  2132,  8641,  1998, 13677,  2643,  8328,  2010,  4519,   102],\n",
      "        [  101,  5310,  2065,  2023,  2406,  2001,  2631,  2026,  7486,  2009,\n",
      "          2052,  2022,  2019, 28558,  3412,  2135,  2046,  3917,  4630,  6939,\n",
      "          2009,  2052,  2022,  4238,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  1045,  5299,  2026,  6309,  1999,  2026,  2482,  1998,\n",
      "         10047,  2085, 14684, 12588, 14722, 10869,  1999,  1996,  9047,  3669,\n",
      "          2595,  5581,  2843,  2023,  2003,  2009,  2023,  2003,  2129,   102],\n",
      "        [  101,  2016,  2109,  2000,  2360,  2070,  3492,  8271,  4485,  2145,\n",
      "          1037,  8797,  2121, 22212, 10469,  2295,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15624,  1998,  2008,  8494,  7377,  8024,  2003,  6069,  2022,\n",
      "         14248,  2005,  2679,  6809,  3904,  1997,  2037, 12583,  2097,  2644,\n",
      "          2008,  2643, 16424,  2679, 23228,  2015,  1998,  2008,  6548,   102],\n",
      "        [  101,  2000,  1996,  2091, 22994,  2121,  2079,  2017,  9772,  2023,\n",
      "          2202,  1037, 25957,  4063,  2012,  5310,  8466,  4953,  2715,  8135,\n",
      "          1037,  1047,  1037, 12731, 10603, 10772,  2015,  8275,  8135,   102],\n",
      "        [  101,  3190,  8493,  2103,  5292,  3270,  3270,  1037,  3232,  2706,\n",
      "          1999,  2008,  2162,  4224, 11276,  2000,  2022,  2438,  2000,  3499,\n",
      "          6206,  2015,  2000,  7515,  2004,  8711,  2067,  1999,  2037,   102],\n",
      "        [  101,  1996,  5796,  2213, 18444,  2253,  2013,  6206, 12114,  2000,\n",
      "         25672, 24894, 14088,  7489,  2000,  2074,  7489,  2058,  1996,  2197,\n",
      "          3232,  1997,  2086,  1045,  2113,  2116,  3423,  7489,  2008,   102],\n",
      "        [  101,  2005,  3071,  2008,  2038,  4895,  7913,  4383,  5587,  5310,\n",
      "          2003,  6719,  1037, 27571,  2243,  2185,  2013, 26768,  2017,  2064,\n",
      "          2025,  2130,  3305,  2664,  2009,  2035, 21882,  7088,  5289,   102],\n",
      "        [  101,  3374,  1045,  2074,  2228,  2009, 12726,  2065,  1045,  2572,\n",
      "          2012,  1037,  2283,  1998,  2019,  5025,  2128,  7559,  2094,  2003,\n",
      "          2045,  1998,  1045,  2572,  2025,  4766,  2098,  6932,  2033,   102],\n",
      "        [  101,  7743,  2229,  1998,  7570,  2229,  2027,  2079,  2025,  4839,\n",
      "          2339,  1996,  7570,  2229,  2113,  8945,  1037, 10469,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20839, 15857,  4561,  2061,  1037, 14163, 13793,  2063,  3138,\n",
      "          2019,  5424,  2000,  2457,  2025,  1037,  8595,  4179,  2079, 16485,\n",
      "          2428,  6160,  2035,  8578,  2025,  4902,  2025, 18196,  2015,   102],\n",
      "        [  101,  5310,  5310,  6569,  2022,  8167,  2017,  2113,  5181,  2031,\n",
      "         10424,  2891,  2205,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.1280, 0.1280, 0.0340, 0.0340, 0.0340, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.1320, 0.1320, 0.1320, 0.1320, 0.1320, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0350, 0.0350],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0570, 0.0570, 0.0570,\n",
      "         0.0570, 0.0570, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1590, 0.1590, 0.1590, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0110, 0.1590, 0.1590, 0.1590, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0520, 0.7460, 0.0520, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.1690, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0120, 0.0120, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1690, 0.1690, 0.1690, 0.1690, 0.0030, 0.0030, 0.0030, 0.0030, 0.0120,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0340, 0.1280, 0.1280, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1320, 0.1320,\n",
      "         0.1320, 0.1320, 0.1320, 0.1320, 0.1320, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1910, 0.1910, 0.0130, 0.0500,\n",
      "         0.0500, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.6050, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0420, 0.0420, 0.0110],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3980, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3980, 0.0070],\n",
      "        [0.1060, 0.1060, 0.1060, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.4020, 0.0280, 0.0280, 0.0280, 0.0280, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0490, 0.0490, 0.7040, 0.0490, 0.0490,\n",
      "         0.0490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2040,  3957,  1037,  6616,  2055,  1996,  5472,  9152, 13327,\n",
      "         21524,  2065,  2027,  2359,  3521,  2045,  2052,  2022,  3521,  2065,\n",
      "          2003, 22852,  2359,  2162,  1996, 21524,  2052,  2022,  2757,   102],\n",
      "        [  101,  2023,  2003,  2074,  2128,  7559,  5732,  3798,  1997,  6685,\n",
      "          2023,  2003,  1037,  3043,  1997,  2489,  4613,  2111,  2079,  2025,\n",
      "          2031,  2000,  4952,  2000,  2009,  2111,  2031,  2000,  2404,   102],\n",
      "        [  101,  3673, 11560,  2313,  1999,  2647,  3032,  3058,  2605,  2038,\n",
      "          2152,  6165,  1997,  7489,  3097,  2141,  2021,  2036,  2152,  6165,\n",
      "          1997,  7489,  1999,  1050,  2094,  4245,  2025,  8897,  2004,   102],\n",
      "        [  101,  1045,  2109,  2000,  2292,  2061,  2172,  4485,  6911,  2033,\n",
      "          2041,  2129, 17276,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2036, 28844,  2891,  2024,  2069,  2126,  2000,  2562,\n",
      "          1997,  2317,  7570,  2229,  2013,  2383, 10834,  1045,  1041, 28616,\n",
      "          4305,  2890, 10985,  2388,  9021,  3531,  2562, 28844,  2891,   102],\n",
      "        [  101,  5310,  8135,  8246,  2000,  4863,  2129,  2023,  7386,  2015,\n",
      "          2068,  2295,  2009,  7386,  2015,  2149,  2043,  2017,  6904, 13871,\n",
      "         12868, 16582,  2066,  1996,  4295,  9207, 21877,  3527, 21850,   102],\n",
      "        [  101,  2022,  8797,  2121,  4982,  2039,  2043,  3229,  2000,  2592,\n",
      "          2003,  4600,  4758,  2247,  3310,  4274,  2287,  2031,  1996,  2088,\n",
      "          2012,  2115,  4344, 10247,  2903,  2477,  2130,  2062,  2128,   102],\n",
      "        [  101,  2182,  3310,  3165,  8602,  2000,  2317,  5000,  2005,  6904,\n",
      "         13871,  4140,  2854,  2096,  2635, 18911, 12326,  2015,  2012,  5310,\n",
      "          2017,  2024,  1037, 17203,  6904, 13871,  4140,  5136,  2019,   102],\n",
      "        [  101,  4916,  2015,  2064,  2022,  2004,  2128,  7559,  5732,  2030,\n",
      "         12138,  2004,  2027,  2215,  1999,  3290,  2073,  2009,  2025,  2026,\n",
      "          3291,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  3726,  2042,  7917,  2013, 10474,  2009,  2965,\n",
      "          5181,  2031,  2741,  2017,  1037, 26828,  2008,  2017,  2053,  2936,\n",
      "          2031,  2916,  1999,  1996,  2047,  2088,  2344,  1998,  2017,   102],\n",
      "        [  101,  5310,  1048,  2863,  2080,  2365,  2017,  2113,  2026,  2568,\n",
      "          2908,  3458,  1996,  3180,  4689,  4485,  1045,  1521,  1049,  2128,\n",
      "          7559,  5732,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2070, 10469,  2015,  2360,  2008,  2308,  2147,  6211,  2084,\n",
      "          2273,  2005,  2625,  3477, 10377,  2061,  2612,  1997,  2635,  1996,\n",
      "          2154,  2125,  2052,  2025,  2009,  2191,  2062,  3168,  2000,   102],\n",
      "        [  101,  1045,  2655,  2308,  2293,  2040,  1045,  2079,  2025,  2113,\n",
      "          2035,  1996,  2051,  2004,  2017,  2089,  2031,  3264,  2498,  4424,\n",
      "          2030, 17183, 11219,  2075,  3214,  2074,  2108,  5379,  2009,   102],\n",
      "        [  101,  5310,  2021,  1045,  2031,  6343,  2000,  2022,  5637,  2005,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2064,  2025,  1998,  2097,  2025,  3844,  2039,  2027,\n",
      "          2024,  2025, 18207, 23972,  2295,  2009,  3504,  2008,  2126,  2027,\n",
      "          2024,  2206,  2019,  5110,  3298,  2009,  1996,  2168,  3114,   102],\n",
      "        [  101,  4365,  1045,  2031,  2025,  2464,  1037,  9152, 13327,  2131,\n",
      "         12428,  2008,  6649,  2144, 28919,  2696, 12631,  2618,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.1040, 0.1040, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.3330, 0.3330, 0.0230, 0.0230, 0.0230, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0440, 0.0030, 0.0030,\n",
      "         0.0030, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440,\n",
      "         0.0440, 0.0440, 0.0440],\n",
      "        [0.0100, 0.5520, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1450,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0190, 0.0190, 0.0190, 0.2670, 0.0050,\n",
      "         0.0050, 0.0700, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2670,\n",
      "         0.2670, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2970, 0.0780, 0.0780, 0.0780, 0.2970, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0980,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0120, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.6650, 0.0460,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0250, 0.0250,\n",
      "         0.0250, 0.0940, 0.0940],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2193, 12668,  1998,  6386,  2089,  3338,  2026,  5944,  2021,\n",
      "          3415,  2097,  2196,  3480,  2033,  2193, 22894,  2025,  2026,  2343,\n",
      "          1045,  2572, 13330,  2017,  2024,  1037,  4097, 22987,  2015,   102],\n",
      "        [  101,  2304,  2111,  2145,  2031,  2025,  5228,  2037,  4963,  2058,\n",
      "          2783,  9587, 25016,  2213,  6658,  5608,  1999,  1996,  2690,  2264,\n",
      "          1998,  2167,  3088,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 22708,  2417, 18278,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2025,  5637,  2021,  1045,  2097,  6616,  2115,\n",
      "          4632,  2066,  1037,  6904, 13871,  4140,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2002,  2003,  2025,  4637,  1037, 11513,  7939,  3771,\n",
      "         21461,  2015,  2002,  2003,  4637,  2489,  4613,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2041,  2098,  4426,  2004,  1037, 11382,  3489,  2008,\n",
      "          2001,  2026,  3125,  2030,  2106,  2017,  2215,  2000,  4830, 17644,\n",
      "          2149,  2582,  2007,  2115, 16522,  7221,  5753,  2175,  2005,   102],\n",
      "        [  101,  2034,  2518,  2317,  4903,  2140,  7166,  2000,  2360,  2000,\n",
      "          2033,  2044,  2027,  2106,  2070,  5156,  2969,  4709, 18667,  2003,\n",
      "          1045,  3246,  2017,  2079,  2025,  2568,  2021,  1045,  2253,   102],\n",
      "        [  101,  5310,  9826,  2004,  1037,  4012,  5244,  2711,  3102,  2035,\n",
      "          4012,  5244,  2111,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2106,  2025,  8112,  4654, 11880,  2845, 23473,  2004,  2092,\n",
      "          1996,  2149,  2003,  2193, 23458,  6363,  1999,  7016,  2009,  3685,\n",
      "          8984,  2178,  2162,  1996,  5181,  2024,  7143,  2037,  2051,   102],\n",
      "        [  101,  7743,  2229,  3714,  8072,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2066,  2129,  1996, 16522,  2003,  3974,  2061,  2049,\n",
      "          2478,  1037,  6638,  9152, 13327,  2000,  2831,  4485,  2467,  3342,\n",
      "          9152, 13327,  1996, 16522,  6658,  2094,  2017,  2025,  1996,   102],\n",
      "        [  101,  2053,  4314, 26478,  8609,  8898,  7560,  8711,  2695,  9298,\n",
      "          2138,  2027,  5223, 18221,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2339,  2024,  2017, 15192,  4426,  2024,  2017,\n",
      "          1037,  2210,  2128,  7559,  5732,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2304,  2111,  2024,  6728, 19811,  2011,  2037,  2219,  3226,\n",
      "          1998,  2451, 10823,  2342,  2000,  5256,  1998,  5382,  1996,  8037,\n",
      "          2283,  2003,  1996, 16939,  2283,  2008,  3594,  2068,  2005,   102],\n",
      "        [  101,  7025,  2003,  2631,  2006,  1996,  6958,  1997, 25505,  2204,\n",
      "          1998, 10723,  7386,  2035,  1997,  2049,  4277,  7065,  4747,  3726,\n",
      "          2105,  2023,  4145,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 21746,  1037,  2317,  7743,  1999,  1996,  4632,  2016,  4485,\n",
      "          3064,  2655,  2009,  1037, 11338, 10258,  3126,  2854,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.1540, 0.1540, 0.5850, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2190, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0580, 0.0580, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7590, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0220, 0.3230, 0.0850, 0.3230, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0230, 0.0230, 0.3340, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3340, 0.0060, 0.0230, 0.0230, 0.0230, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0880, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4620, 0.4620, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.8320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0310, 0.4440, 0.4440, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2323,  2025,  2009,  2022,  2308,  2040,  2228,  2273,  2024,\n",
      "          6020,  2000,  2308,  2655,  3209, 10469,  2015,  2053,  2028, 16424,\n",
      "         10768, 25300, 22758,  1998,  2931,  4395,  2062,  2084, 10469,   102],\n",
      "        [  101,  2686,  2003,  5637,  1998,  2061,  2024,  2017,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9303,  2050,  3796,  2023,  9152, 23033,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2196, 19337,  7416,  3726,  1037, 24815,  2072,\n",
      "          2027, 11721, 15185,  2004, 10644,  2008,  2015,  1037,  3114,  4903,\n",
      "          2140,  1999,  2236,  2123,  2102,  3404,  2068,   102,     0,     0],\n",
      "        [  101, 24004, 20200,  2965,  2619,  2008,  2003,  4452,  1997, 15949,\n",
      "          2040,  2064,  2022,  4452,  1997,  1037, 11690,  8840,  2140,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4248,  3160,  1045,  2572,  2274,  2086,  2182,  1999,  1996,\n",
      "          3072,  2066,  2572,  1045,  2025,  2664,  2204,  2438,  2000,  2074,\n",
      "          2022,  1037, 12731, 29358,  2666,  2469,  2417, 18278,  5683,   102],\n",
      "        [  101, 10166,  2023,  1040,  4524,  2065,  2002,  2025,  1037, 11382,\n",
      "          3489,  2002,  2453,  2004,  2092,  2022,  2028, 20277,  9759,  2015,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2502,  6616,  2378,  3066,  2119, 13008, 11545,  1998,  1996,\n",
      "          5088,  2024,  7619,  4485,  2005, 11829,  3549,  2131,  1037,  2613,\n",
      "         10424,  8004, 11528, 10733,  1998,  2644,  3666,  9152, 13327,   102],\n",
      "        [  101, 14477, 18155, 23884, 25084,  2137,  1045,  2066,  3423,  7489,\n",
      "          2040,  2272,  2182,  2000,  2022,  2137,  1998,  2191,  1037,  2488,\n",
      "          2166,  2005,  3209,  1998,  2037,  2336,  1996,  6206,  2015,   102],\n",
      "        [  101,  2061,  4841,  1998, 28101,  5644,  2024,  1996,  2087,  2128,\n",
      "          7559,  5732,  2111,  1999,  1996,  2088,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2001, 25540,  9050,  1037, 11382,  3489,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2695,  1037,  2678,  4760,  1996, 16880,  4712,  1997,\n",
      "          4808,  2011,  1996,  2148,  3060,  1041,  4246,  3209,  1998, 16522,\n",
      "         28251,  2063,  2145,  2360,  1045,  2572,  7694,  4808,   102,     0],\n",
      "        [  101,  1037,  5152,  1999,  4701,  2356,  2005, 18301, 11440,  2005,\n",
      "          2193,  2086,  2006,  9130,  1998,  2010,  4070,  2001,  2025, 17159,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2741,  4903, 27263,  2015,  2008,  4424,  6905,  2085,\n",
      "          1042, 21693,  1998,  2383, 13141,  2684,  3348,  7179,  2025,  2061,\n",
      "          2172,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2021,  2054,  1996,  1042,  3047,  2000,  2068,  2632,\n",
      "          2226, 19782,  3347,  2030,  2070, 14652,  2066,  2008,  2057,  2064,\n",
      "          2069,  5987,  1996,  1996, 14163, 18719,  2063,  2655,  2000,   102],\n",
      "        [  101,  1996, 15124, 15315,  7974,  1516,  1996,  6698,  2000,  2029,\n",
      "          1037,  2309,  3287,  6431,  2116,  3767, 15785,  2015, 13195,  1516,\n",
      "          2003,  2172,  3020,  2426, 23648, 15853,  2084,  2009,  2003,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0090, 0.0090, 0.4780, 0.1260, 0.1260, 0.1260, 0.1260, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4330, 0.1140, 0.1140, 0.1140,\n",
      "         0.1140, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7840,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1790, 0.1790, 0.1790, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.1790, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1790, 0.1790, 0.1790, 0.1790,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.4610,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.1220, 0.1220, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.1030, 0.0070, 0.0070, 0.0070, 0.0070, 0.3910, 0.3910, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0670, 0.0050, 0.0050, 0.0050, 0.2530,\n",
      "         0.2530, 0.2530, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0670, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190]]), 'label': tensor([1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  9200,  4012,  9856,  7087, 22212, 12731,  3372,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1996,  3124,  2323,  2022, 14159, 10468,  4214,  7987,\n",
      "         10288,  4183,  7206,  6394,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2115,  2317,  3586,  1998,  1037,  9118,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10768,  5244,  2017,  2035,  2041,  7474,  2063,  8239, 22212,\n",
      "          2015,  2008,  2342,  2431,  2006,  1996,  9278,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3565,  4138,  9152, 13327,  3565,  4138, 16522,  9794,  2749,\n",
      "          2000,  2425,  2149,  2129,  9202,  1996,  2317,  2158,  2003,  2317,\n",
      "          2111,  2644,  3228,  2115,  2769,  2000,  2111,  2008,  5223,   102],\n",
      "        [  101,  7513,  2128,  7559,  5732,  1996,  2972,  2149,  2592,  2974,\n",
      "          3068,  2005,  2193,  2086,  2138,  1996,  2562,  2098, 28636,  1998,\n",
      "         14163, 29336,  2075,  2037,  4646,  2565, 19706,  2061,  2008,   102],\n",
      "        [  101,  2003,  2008,  2708,  4862, 25655,  4221,  9610,  4665, 24916,\n",
      "          4665, 14479, 23644, 15441,  5092,  2072, 10958, 14227, 14459,  3504,\n",
      "          4165,  2066,  2008, 11382,  3489,   102,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2763,  2323,  2031,  2404, 24978,  2546,  2860,  2006,\n",
      "          2008,  2036,  2025,  3647,  2005,  2188,  2941,  2025,  3647,  2005,\n",
      "          3671,  2317,  2111,  2129,  1037,  2016,  5092,  2239,  9020,   102],\n",
      "        [  101,  5310,  2047,  2298, 19992, 24008,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2020,  1996, 10556, 13639, 17043,  2015, 15419, 16912,  2992,\n",
      "          2000,  2022,  5317,  6402,  2545,  2030,  2054,  1045,  2812,  1996,\n",
      "          3566,  2496,  1037,  4689,  2317,  2158,  2008,  6732,  2002,   102],\n",
      "        [  101,  9680,  2075,  2304,  2308,  2003,  2066, 18138,  2075,  1999,\n",
      "          1996,  4542,  3038,  4931, 12461,  2292,  7195,  9040,  1996,  2304,\n",
      "          2308,  2003,  2066,  3038,  4931,  2292, 11669,  1996, 17276,   102],\n",
      "        [  101,  1045,  2572,  1037,  7098, 24978,  2850,  2361,  2266,  6394,\n",
      "          2001,  1037, 11382,  3489, 22889,  3126,  1045,  2097,  2025,  4929,\n",
      "          2009, 24978,  2094,  9706,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2453,  2444,  1999,  1037,  9117,  2380,  2021,  2012,\n",
      "          2560,  2002,  2025,  1037,  9152, 13327,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2033,  2108,  2066, 18168,  2290,  1045,  2079,  2025,  2031,\n",
      "          2151, 11895, 15088,  2187,  2129,  2572,  1045,  4011,  2000,  3102,\n",
      "          2035,  2122, 11562,  2545,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2292,  2033, 12134,  2000,  2216,  2986, 12455,  2040,  2628,\n",
      "          2033,  1045,  2074,  2288,  5697,  2007,  2147,  2031,  2025,  2018,\n",
      "          2051,  2000,  3579,  2006, 11721,  2497,  1045,  2572,  1037,   102],\n",
      "        [  101,  5310,  5310,  9040,  3226,  2003,  2043,  9040,  2003, 15157,\n",
      "          4424,  4808,  2003,  3671,  3550, 28512,  2011,  2759,  3226,  2193,\n",
      "          1999,  2193,  2308,  2131, 15504,  2802,  2037,  2166,  2062,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0940, 0.0940, 0.0940, 0.3580, 0.3580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.2390, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0630,\n",
      "         0.0630, 0.0630, 0.0630, 0.0630, 0.0630, 0.0630, 0.0630, 0.0630, 0.0630,\n",
      "         0.0630, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.8320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.5480, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0090, 0.0090, 0.0090, 0.4870, 0.4870, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.1810, 0.1810, 0.1810, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0470, 0.0470, 0.0470, 0.0130, 0.0130, 0.0130,\n",
      "         0.6830, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230]]), 'label': tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2009,  2061,  9152, 13327,  2925,  1038, 13728,  2266,  2003,\n",
      "          2054,  2017,  2614,  2066,  2024,  2017,  2013,  5395,  2023,  4165,\n",
      "          2066,  2008,  9152, 13327, 13044,  2013,  2008,  4485, 11484,   102],\n",
      "        [  101,  5310,  5310,  1996,  2208,  2003,  1037,  8239, 17743,  6616,\n",
      "          2035,  1996,  5223,  2869,  4521,  4485,  1049, 10343,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 14163, 13793,  2229,  1998,  2304,  5231,  2031,  2467,\n",
      "          2042,  2445,  1037,  3413,  2023,  3952,  7126,  4603,  5231,  2008,\n",
      "          2031,  2042,  4333,  2006,  2576,  3314,  2041,  1997,  3571,   102],\n",
      "        [  101,  2008, 21360,  3070, 11721,  4213,  7507,  2299,  2003,  2061,\n",
      "          2919,  9444,  3248,  2009,  2038,  1037,  4013,  2721, 29251, 28667,\n",
      "         11667,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2785,  1997,  7987, 10431,  5292, 21112,  2015,  6904,\n",
      "         13871,  4140,  3594,  2019,  3670,  2066,  2045,  2053,  2502,  2045,\n",
      "          2045,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2061, 17276,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2024,  1037,  2317,  3232,  1999,  2115,  2193,\n",
      "          1998,  2193,  1998,  2017,  2071, 11092,  2317,  6469,  2336,  1998,\n",
      "          2507,  2068,  1037,  2204,  2188,  1045,  2360,  2339,  2025,   102],\n",
      "        [  101,  2017,  2024,  3331,  2055,  2659, 26264, 10597,  2128,  7559,\n",
      "          5732, 12593,  2015,  1998, 12461,  2008,  2031,  3737,  2608,  1998,\n",
      "          2064,  5607,  2012,  2846,  2026,  2769,  2003,  2006,  2068,   102],\n",
      "        [  101,  1996,  2613,  5694,  2182,  2024,  1996, 27754,  2074,  3564,\n",
      "          2105,  2568,  2075,  2037,  2219,  2449,  1998,  4060,  1050,  4521,\n",
      "          1050, 26735,  2015,  1998,  2059,  2027,  2131,  4102,  2000,   102],\n",
      "        [  101,  2196,  1999,  2026,  2166,  2097,  2017,  2156,  2033,  3058,\n",
      "          1037,  2317, 17520, 11690,  1045,  2097,  2196,  2079,  2008,  2000,\n",
      "          2870,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017, 14161,  2080,  1045,  2293,  1037, 22889,  4904,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13451,  3336,  2228,  1045,  2572,  2108,  6802,  2514,  2066,\n",
      "          2002,  2467,  6069,  8011,  2009, 24955,  2033,  2000,  2360,  2129,\n",
      "          1045,  2514,  2055,  2032,  9152, 23033, 10047,  5697,  2108,   102],\n",
      "        [  101, 11324,  6206, 12114,  2330,  6645,  2833, 12133,  5637,  3510,\n",
      "          4385,  4385,  2035,  2179,  1999,  1996,  4552,  1996,  2157,  2000,\n",
      "          4562,  2608,  2025,  2061,  2172,  2035,  5622, 19279, 18117,   102],\n",
      "        [  101,  1996,  2047, 15950,  2003, 25240,  2105,  1996,  8398, 14268,\n",
      "          2860, 16584,  2229,  6279, 28578,  6305,  2923,  6415,  2667,  2000,\n",
      "          6011,  2000, 16939,  2015,  2008,  8398,  2003,  2025,  2028,   102],\n",
      "        [  101,  2613,  2376,  7486,  2088,  2044,  1038,  6979,  9284,  2003,\n",
      "          7610,  5480, 10047,  5521,  4967,  2376,  1997, 13329,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2439,  1037,  2402,  2317,  3287,  2000,  5920,  2197,\n",
      "          2305,  2065,  2017,  2024, 11878,  2831,  2000,  2619,  2130,  1037,\n",
      "          7985,  2026, 10243,  3362,  2041,  2000,  2256,  3360,  2292,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.3030, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.3030, 0.0800, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2030,\n",
      "         0.2030, 0.2030, 0.2030, 0.0530, 0.0530, 0.0530, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.4270, 0.1130, 0.1130, 0.1130, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.7960, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.1520, 0.1520, 0.1520, 0.1520, 0.1520,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0450, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0450, 0.0450, 0.0450],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940,\n",
      "         0.0940, 0.0940, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2150, 0.2150,\n",
      "         0.2150, 0.2150, 0.0040],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230]]), 'label': tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2045,  1037, 11382,  3489,  2105,  2296,  3420,  1037,  6270,\n",
      "          2767,  2105,  2296,  8815,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12873, 12873,  1996, 23961, 12045,  4136,  2149,  2008,  3644,\n",
      "          2668,  2515,  2025,  2507,  2068,  2151,  2569,  5684,  2007,  2643,\n",
      "          2044,  4828,  1998,  2008,  5181,  2040, 10214,  2000,  3582,   102],\n",
      "        [  101,  1045,  2572,  3407,  2320,  1996,  2197, 11382,  3489, 17991,\n",
      "          2013,  1037,  3392,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2279,  3134, 15963,  9587,  9644, 20860,  3065,  2097,  2022,\n",
      "          4159,  2522,  5644,  2024,  2027,  2130,  1996,  2168,  2427,  1998,\n",
      "          1996,  3606,  2055, 14759, 27263,  7088, 15580,  1999,  1037,   102],\n",
      "        [  101,  2017,  2024,  2112,  1997,  1037,  3652,  6903,  1999,  2554,\n",
      "          1997,  2308,  2383,  2008,  2168,  5998,  1045,  2903,  5207, 12001,\n",
      "          7607,  1996,  8790,  3243,  2092,  1045,  2424,  2651,  5306,   102],\n",
      "        [  101, 11382,  3489, 11867,  2594,  9152, 13327,  6904, 13871,  4140,\n",
      "         16455, 19237,  4845,  5980,  2015,  5181,  2106,  2193,  2193,  2317,\n",
      "          2373, 16215, 14365,  8042,  2106,  2498,  3308,   102,     0,     0],\n",
      "        [  101,  9152, 23033,  2017,  7110,  1056, 11265,  3567,  2718,  2053,\n",
      "          3097, 15966,  2053,  2317,  7743,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2026, 12191, 13184,  2044, 13184,  1996, 17276,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  5310,\n",
      "          5310,  2471,  2001,  4457,  2011,  1037,  2312,  2158,  2012,  2305,\n",
      "          1999,  1037,  2380,  1998,  2004,  1037,  2450,  1045,  2342,   102],\n",
      "        [  101, 15657,  2003,  4808,  3568,  4808,  2114,  2216,  2040,  2215,\n",
      "          2000,  8292, 29577,  2003, 10943,  2098,  1998, 12962,  2004,  2969,\n",
      "          3639,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2035,  1996, 11382,  3489,  2739,  6125,  2031,  3492,\n",
      "          5344,  2007,  4064,  4641,  3752,  2037, 10093, 13699, 21716, 13876,\n",
      "          2545,  2339,  2064,  2025,  2057,  2031, 22302, 25670,  3924,   102],\n",
      "        [  101,  5310,  5310,  2021,  2008,  1056, 28394,  2102,  2003,  2517,\n",
      "          2011,  2619,  2040,  2626,  1037,  2265,  1059,  1037,  2304,  2450,\n",
      "          2108, 15504,  2011,  1037,  2317,  2158,  1998,  2101,  2758,   102],\n",
      "        [  101,  1045,  2079,  2025,  2066,  1996, 10823,  1998,  2030,  4004,\n",
      "          2015,  6616,  2859,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2106,  2017,  2113,  2008,  2317,  6914, 10085,  5178,  5942,\n",
      "          5094,  5181,  2404,  9259,  1999,  1996,  2117,  2572,  3549, 22117,\n",
      "          4765,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2288, 22399,  1999,  3653,  7363,  2078,  1997,  7842,\n",
      "         19699,  5555,  6213, 16216, 14232, 19190,  2571, 14270,  2050, 16950,\n",
      "          2863, 10016,  2035,  2317,  6617,   102,     0,     0,     0,     0],\n",
      "        [  101,  5181,  2024,  2317,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0150, 0.0150, 0.8320, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1890, 0.1890, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0500,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1090, 0.4150, 0.1090, 0.1090,\n",
      "         0.1090, 0.1090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2170,\n",
      "         0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0040, 0.0040, 0.0570,\n",
      "         0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.2620, 0.0050, 0.2620, 0.2620, 0.0690, 0.0690, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.4480, 0.4480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.7130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0330, 0.1240, 0.1240, 0.1240, 0.0330, 0.1240, 0.0330, 0.0330, 0.1240,\n",
      "         0.1240, 0.1240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410,\n",
      "         0.1560, 0.1560, 0.1560, 0.1560, 0.1560, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2821,  2074,  1037, 16522,  9152, 13327,  2007,  1037,  3042,\n",
      "          2008,  2515,  2025,  2113,  3788,  2096,  7467,  2003,  2128,  7559,\n",
      "          5732,  3046,  3173,  2145, 16522,  9152, 13327,   102,     0,     0],\n",
      "        [  101,  5310,  2044,  2431,  2037,  3057,  2131, 15504,  9467,  3238,\n",
      "         12455,  2151,  2969, 27818,  2554,  2052,  2031, 14831,  2062, 12411,\n",
      "          5332,  6321,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2048,  2086,  3283,  2651,  2193,  2111,  2020, 20547, 25202,\n",
      "          2011,  1037, 17026,  6080,  1997,  9587, 25016,  2213,  8906,  1999,\n",
      "          7151,  6305,  5802,  3000,  2045,  2097,  2022,  2116,  2062,   102],\n",
      "        [  101,  2070, 14556,  2170,  2033, 17276,  2197,  2305,  1045,  4191,\n",
      "          2138,  1045,  2572, 23042,  2000, 22794, 20934, 15449,  2659,  2166,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2008,  2129, 12148, 14398,  2007,  2393,  2013,\n",
      "          2610,  2110,  1998,  2317, 22006,  2291,  2003,  4082,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2204,  2000,  2156,  2111,  2013,  2563,  3885,  1998,  5772,\n",
      "          5463,  1996,  8090,  2114,  6643, 26010, 24862,  2015,  1999, 10330,\n",
      "          2651,  9826,  2064,  2025,  2156, 11059,  2030,  1996,  2148,   102],\n",
      "        [  101,  2025,  3406,  2695,  2019, 19657,  5448,  2021,  6121,  7305,\n",
      "          2003,  2145,  2028,  1997,  1996,  2087,  3376, 12155,  3549,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2317,  2111, 17612,  2055, 24004, 24920,  1999,  1996,  2690,\n",
      "          2264,  2074,  2000,  4762,  2037,  7025,  7361,  6806, 11607,  2027,\n",
      "          6719,  2123,  1521,  1056,  2507,  1037,  4485,  2055,  5637,   102],\n",
      "        [  101,  7025,  1998,  1996,  6394,  2190,  2767,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3062, 24955,  2293,  1998,  2179,  1037,  5795,  7743,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821, 20261, 19387,  5310,  8058,  1999,  1040,  5244,  1999,\n",
      "          2023,  4610,  1059,  5369,  2860,  2775,  1996, 17276,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3305,  2009,  2165, 16543,  1037,  2146,  2051,  2000,\n",
      "          3280,  1037, 11414,  4566,  2005,  1037,  5472,  9152, 13327,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2097,  2562,  2026,  2502,  4140,  2854,  2157,  2182,\n",
      "          4283,  2017,  2111,  9152, 13327,  2015,  1998,  5181,  1998,  1045,\n",
      "          2064,  2025,  2228,  1997,  2505,  4788,  2084,  9152, 13327,   102],\n",
      "        [  101,  2112,  1997,  2026,  3105,  2003,  7149,  2007, 18614,  2087,\n",
      "          2128,  7559,  5732,  2111,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  7025,  2003,  2498, 17490,  2019,  4763,  2668, 15222,\n",
      "         12096,  2100,  8754,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  1999,  2066,  1996, 12043,  2015,  2073,  2315,  5980,\n",
      "          1998, 22212,  1998, 13988,  2030,  3649,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.3500, 0.3500, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0920, 0.0920, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0260, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.3790],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0350, 0.0350, 0.1320, 0.0350, 0.0350, 0.0350, 0.0350,\n",
      "         0.0350, 0.0350, 0.0350, 0.1320, 0.1320, 0.1320, 0.1320, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4400, 0.4400, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0580, 0.0580, 0.0040, 0.0580, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0150, 0.0150, 0.2200, 0.2200, 0.2200, 0.0040, 0.0040,\n",
      "         0.0580, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.8450, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2061,  1037,  2317,  2711,  2019,  2272,  2046,\n",
      "          2115,  2188,  1998,  3102,  1057,  1998,  2498,  2097,  4148,  2023,\n",
      "          2003,  3458, 23179,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13475,  2035,  1996,  5796,  2213,  5980, 15501, 15478,  9152,\n",
      "         13327,  2679, 17328,  2425,  7861,  2129,  2017,  2024,  2428,  2019,\n",
      "          1055,  3501,  2860,  2040,  3903,  2007,  6517, 18515,  4967,   102],\n",
      "        [  101,  5310,  6616,  2017,  2205,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6289, 19585,  1056,  3351, 10424,  6799,  2039,  2210,\n",
      "         24665,  4014,  2017,  1998, 24471,  1047, 24667,  2361,  2061,  5637,\n",
      "         19739, 19629,  5302,  2571,  1998,  4590,  2099, 17076,  2099,   102],\n",
      "        [  101,  9092,  2696,  8991,  2618, 10861,  3653, 22987,  2050,  2139,\n",
      "         19128, 14066, 16137, 10861,  2213, 25957,  3270,  1041,  1051,  5637,\n",
      "         10861,  3653, 22987,  2050,  2139, 19817,  6790, 23065,  4487,   102],\n",
      "        [  101,  2204,  7615,  2006,  7987, 20175,  8237,  2102,  2012, 26065,\n",
      "         10760, 14289,  2078,  1528,  2193,  2781,  3283, 13599,  6206,  7489,\n",
      "          2000,  3423,  7489,  2003,  2066,  1037,  3573,  3208,  3038,   102],\n",
      "        [  101,  5310,  2054,  1999,  2940, 24457,  2100,  3109,  2003,  2023,\n",
      "          2047, 14636,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3147,  5967, 23399,  2015,  1997,  1996,  2642, 14130,\n",
      "          2097,  2191,  2126,  2005,  1996, 24004,  6020,  2004,  1996,  4857,\n",
      "          2317,  3804,  2052,  2404,  2009,   102,     0,     0,     0,     0],\n",
      "        [  101,  4895,  3313,  3115,  2057,  2106,  2025,  2156,  4000,  2043,\n",
      "          2062,  2084,  1047,  4268,  1999,  2225, 22973,  2020, 23044,  1999,\n",
      "          3147,  2668,  2011, 24815,  2072,  8431,  1998,  3950,  2302,   102],\n",
      "        [  101,  1996, 16011,  1997,  3725,  2034,  4247,  2027, 10107,  2115,\n",
      "          2490,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2145,  2228,  1045,  2097,  9927,  1998,  7858,  2104,\n",
      "          2026, 16021, 23091, 14593,  2009,  4569,  2652,  1037,  3407,  2839,\n",
      "          1045,  2572,  4600, 16312,  2000,  2707,  1037,  9927,  1998,   102],\n",
      "        [  101,  5365, 21877, 20338,  2015,  4808,  1998,  4028,  2059,  4122,\n",
      "          2000,  2202,  2256,  4409,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2001,  2009,  2074,  2019,  4926,  2008,  2317,  6914, 10085,\n",
      "          5178,  5470, 12070,  8112,  2318,  1996,  5233,  1999, 12917,  7795,\n",
      "          2008,  3303,  1996,  5152, 13141,  5274,  1997,  2885,  1998,   102],\n",
      "        [  101,  2013,  2051,  2017,  2156,  1037, 17276,  9805,  2618,  1999,\n",
      "          5337,  4929,  2074,  2113,  2027, 10094,  2050,  2175,  2000,  2457,\n",
      "          2030,  6715,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008, 26316,  2129,  2116,  2128,  7559,  5732,  2111,  2017,\n",
      "          2113,  2008,  2064,  3642,  1999,  2012,  2560,  2193,  3698,  4155,\n",
      "         11067,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  2304,  2111,  2017,  2425,  1037,  9152, 13327,\n",
      "          2025,  2000,  2079,  2242,  1998,  2027,  2175,  2006,  1998,  2079,\n",
      "          2009,  9152, 13327,  4630,  6558,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0020, 0.0350, 0.1330, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0960, 0.0960, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.3660, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0960, 0.0960, 0.0070],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.4190, 0.4190, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0690],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0180, 0.0180, 0.0680,\n",
      "         0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0050, 0.0010, 0.0010, 0.0010,\n",
      "         0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0010,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6350, 0.1670, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.2890, 0.2890, 0.0050, 0.0050, 0.0050, 0.0200, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2890, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  4847,  9945,  2061,  2172,  1045,  3786,  2308,  2061,\n",
      "          2027,  2064,  2031,  1996,  2168,  7750,  2273,  2131,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2331,  2000,  9152, 13327,  2015,  2331,  2000, 10608, 23957,\n",
      "         11382,  3489,  4485, 15385,  2545,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2042,  6616,  7743,  2229,  1045,  2042,  2006,  2026, 23088,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1037,  3145,  3171,  4145,  2170, 10417,  3465,  2008,\n",
      "          3849, 12711,  2182,  2273,  2323,  2467,  6611,  2009,  2000,  2308,\n",
      "          2040, 26292,  4487,  3736,  9397, 25785, 10311,  3425,  2003,   102],\n",
      "        [  101,  2151,  2739,  2006,  2008,  9152, 23033, 12484,  2043,  2002,\n",
      "          7294,  2866,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2831,  2055,  2128,  7559,  5732,  2054,  1037,\n",
      "          5236, 21025,  2546,  2017,  3711,  2000,  2022,  1996, 13082,  2879,\n",
      "          2005,  2009,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2012,  2560,  1045,  2572,  2583,  2000,  3713,  5372,  2394,\n",
      "          2085,  2024,  2017,  2183,  2000,  9377,  6394,  2193,  2335,  8074,\n",
      "          1037,  6394,  2000,  2131, 15807,  2058,  2108,  2170,  1037,   102],\n",
      "        [  101,  5310,  2025,  2035, 14560,  2065,  2017,  2024,  2205,  5236,\n",
      "          2000,  5382,  2008,  7025,  1998,  2049, 25712,  2024,  2054,  2017,\n",
      "          2024,  7851,  1045,  2064,  2025,  2393,  8038,   102,     0,     0],\n",
      "        [  101,  2205,  2116,  1997,  2149,  5996,  2005,  2053,  3114,  2008,\n",
      "          4485,  2071,  2310,  2042,  8729,  2016,  2001,  1037,  9495,  3407,\n",
      "          4632,  2317,  7743,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2027,  2699,  2000,  2131,  2046, 10930,  4313,  2160,\n",
      "          2017,  2052, 15872,  2068,  2049,  2115,  2157,  2000,  6985,  7929,\n",
      "          2292,  7861,  1999,  2292,  2115,  2564,  2131, 15504,  2748,   102],\n",
      "        [  101,  5310,  5310,  1045,  2572,  2025,  5637,  2030,  1037, 11803,\n",
      "          2986,  2000,  2008,  2021,  1045,  2079,  6649,  2215,  2000,  2022,\n",
      "          1996,  2911, 19483,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  2593,  1037,  5152,  2030,  1037,  2128,  7559,\n",
      "          5732,  4314,  9944, 10841,  3600,  2008,  3061,  2067,  1998,  5599,\n",
      "          2068,  9530,  4160,  2121,  2115,  4915,  1998,  9040,  2115,   102],\n",
      "        [  101,  2320,  1996, 23431,  2317, 14383, 13429,  2003,  2207,  2049,\n",
      "          2058,  2005,  2017,  7570,  2229,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2342,  2062,  5637,  2814,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2009,  2001,  2126,  2488,  2084,  2365,\n",
      "          9626,  2065,  2017,  3342,  2115,  2417, 18278,  4441,  2180,  1996,\n",
      "          9465,  2036,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19313,  5310,  3331,  2055,  2329, 11573,  2111,  2664,  6343,\n",
      "          2003, 11383,  1996,  3768,  1997,  2490,  2000,  1996,  2769,  2108,\n",
      "          2985,  2006,  6206,  7489,  2612,  1997, 11573, 28101,  2015,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0230, 0.0880, 0.0880, 0.0880,\n",
      "         0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0020,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.2430, 0.0040, 0.0040, 0.2430, 0.2430, 0.2430, 0.0040,\n",
      "         0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0080, 0.1180],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.7340, 0.0130, 0.0130, 0.0510, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0790, 0.0790, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0210, 0.0210, 0.2990, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0080, 0.0020, 0.0020, 0.1120, 0.0300,\n",
      "         0.1120, 0.0300, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.1120, 0.1120, 0.1120, 0.1120, 0.1120, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  2279,  8579,  2121,  2040,  3084,  2070, 16939,  8257,\n",
      "          2006,  4004,  2015,  2893, 19055,  2006,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2425,  2033,  2129,  6064,  5604,  2003,  2025,  2613,  2084,\n",
      "          9616,  2129,  2009,  8239,  8275,  2017, 11382,  3489,  3538,  1997,\n",
      "          4485,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2112,  1997,  1996,  5365, 14636,  7473, 13350, 17903,\n",
      "         10823,  2046,  6586,  1998, 24859,  2015,  1997,  2028,  2828,  2030,\n",
      "          2178,  2008,  2339,  1045,  2097,  2025,  3422,  5691,  2007,   102],\n",
      "        [  101,  5310,  3835,  6402,  2121,  4070,  6343,  3415,  2037,  4845,\n",
      "         10049,  2050,  4983,  2027,  2024,  4108,  9117, 11669,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2009,  2182,  2015,  1037, 11689,  1997,  1996,  1039,\n",
      "          4160,  2140,  2308,  2108, 14726,  1999, 14464,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2448,  7698,  1997,  1996,  3513,  2193,  2069,  2053, 16011,\n",
      "          7829,  3647,  2686,  2079,  2025,  2707,  7829,  3689,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  4526,  1996,  2047,  2637,  2085,  2007,  2256,\n",
      "         18111,  4813,  2425,  2033,  2339,  1057,  2317, 24916,  2024,  2107,\n",
      "          2128,  7559,  5732, 12731, 10603,  2000, 11004,  2185,  2013,   102],\n",
      "        [  101,  2065,  1045,  2071,  2147, 19512,  2440,  2051, 15854,  1037,\n",
      "          2476,  1037,  9580,  1996,  3532, 10597, 14480, 19483,  9152, 13327,\n",
      "         11376,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2088,  2003,  3435,  5278,  2046,  1037,  4750, 19330,\n",
      "         13340, 29389,  2051,  2000,  6148,  7713,  1999,  2235,  2317, 25867,\n",
      "          2015,  7932,  2802,  1996,  2088,  2007,  5299,  6733,   102,     0],\n",
      "        [  101,  8037,  2013,  5135, 24247, 14163, 13793,  2063,  4485, 11484,\n",
      "          2024,  1996, 12873,  4355,  3424,  4841,  2045,  2024,  1047,  4135,\n",
      "         25987,  2906,  2028,  1997,  1996, 16360,  2015,  2003,  1037,   102],\n",
      "        [  101,  2002,  2015,  2074,  1037,  5472,  9152, 13327,  4942, 28600,\n",
      "          2319,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4717, 25706,  2003, 24004, 20200,  1998, 16939,  1998,  1045,\n",
      "          2123,  1521,  1056,  2215,  2000,  2963,  3087,  2360,  4728,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 26264, 14594,  5260,  2000,  1037, 16522,  4004, 11829, 10085,\n",
      "         22648,  2100, 16625, 28616, 28077,  2006,  4348,  2317,  4841,  2008,\n",
      "          2614,  2204,  2000,  3087,  2021,  5181,  4004,  2015,  1998,   102],\n",
      "        [  101,  5048,  2100,  2859,  2386,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2425,  2008,  2000,  1996,  3059,  9152, 13327, 11190,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  2025,  1037,  3399,  6775,  2014,  2171,  2001, 25869,\n",
      "         11474, 12482,  1998,  1996, 28543, 11401,  8040,  2819,  2020,  2680,\n",
      "          3331,  2055,  2009,  1996,  2610, 21746,  2039,  2009,  2288,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0100, 0.0030, 0.0030, 0.0030, 0.1400, 0.1400, 0.1400,\n",
      "         0.1400, 0.1400, 0.1400, 0.1400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0160, 0.0040, 0.0040, 0.2310, 0.2310, 0.2310,\n",
      "         0.2310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0020, 0.0060, 0.0930,\n",
      "         0.0930, 0.0930, 0.0930, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0930, 0.0930,\n",
      "         0.0930, 0.0930, 0.0930],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0300, 0.4370, 0.4370, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0490, 0.0490, 0.0490,\n",
      "         0.1860, 0.1860, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.4060, 0.0280, 0.0070, 0.0070, 0.1070,\n",
      "         0.1070, 0.1070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0060, 0.0060, 0.0060, 0.3270, 0.3270, 0.3270, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0440, 0.0440, 0.0440, 0.1680, 0.0440, 0.1680, 0.0440, 0.0440, 0.0440,\n",
      "         0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0430, 0.0430, 0.1620,\n",
      "         0.1620, 0.1620, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0320, 0.4670, 0.4670, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.2720, 0.2720, 0.2720, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050]]), 'label': tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 15876, 12171,  4241, 12171,  2107,  9576,  2854,  2065,  2256,\n",
      "         10585,  8289,  2041, 24430, 12593,  2015,  9040,  2308,  2066,  1996,\n",
      "          3354,  2390,  6139,  1997,  2193,  2012,  2560,  2057,  2097,   102],\n",
      "        [  101,  1051,  1996,  2317,  2158, 15508,  2021,  1996,  9152, 13327,\n",
      "          2079,  2025,  2729, 12731,  2480,  2012,  1996,  2203,  1997,  1996,\n",
      "         12954,  4246,  2010,  4638,  2097,  2022,  2045,   102,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2061,  2033,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2026,  2769,  2006,  1037,  5152, 11560,  2071,  2022,\n",
      "          3308,  2021, 21888,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8906,  2965, 11777,  2091,  1996,  2197,  2317,  2711,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 18961,  2166,  2003,  1037,  3307, 26699,  2239,  2166,  2003,\n",
      "          1037,  7743,  2154,  2028,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1037,  2093,  2095,  2214,  9152, 13327,  2007,  2091,\n",
      "          8715,  2939,  2039,  2000,  2033,  1998,  2318,  3228,  2033,  2166,\n",
      "          6040,  1045,  1040,  2763,  4952,  2059,  1045,  1040,  2175,   102],\n",
      "        [  101,  4608, 24185,  4430,  2015,  1998,  4139,  7570,  2229,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1999,  1996,  2171,  1997,  8438,  8956,  8711,  3198,\n",
      "          1996,  2878,  2088,  2000,  2022,  8673,  2007,  2068,  3233, 24415,\n",
      "          7895, 14702,  2890, 11263, 18372,  2015,   102,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2031,  2000,  4687,  2065,  2632,  4629,  2669,\n",
      "          2234,  2039,  2007,  2023,  2801,  2002,  2106,  1996,  2168,  2518,\n",
      "          2070,  2051,  2067,  2893,  1037,  2304,  2611,  2000,  2360,   102],\n",
      "        [  101,  4277,  4953,  7521,  2291,  3475,  2102,  2183,  2000,  2562,\n",
      "          1996, 17183,  2015,  2013, 25022, 11890,  2819, 26703,  1996,  2291,\n",
      "          2011,  4911,  1996,  2375,  2000,  3499,  3742,  7521,  1997,   102],\n",
      "        [  101,  5667,  2017,  2024,  4855,  1037,  8239, 27571,  2243, 24702,\n",
      "         27163,  3070,  2989,  2004, 10925,  4587, 12161, 14181, 14876,  3227,\n",
      "          1045,  2097, 12192,  6449,  2008,  1996,  3915,  2003,  1996,   102],\n",
      "        [  101,  2585, 27589,  2290,  2003,  6628,  1999,  2010,  9416, 16011,\n",
      "          2114,  2060,  5198, 10474,  6115,  1999,  1996,  2171,  1997,  2010,\n",
      "          5793,  2576,  6349,  2021,  6343,  2003,  3039,  2000,  6232,   102],\n",
      "        [  101,  2030,  2193,  2454,  5181,  1999,  2446,  4548,  2885,  2242,\n",
      "          2242,  2416,  2454,  4606,  5181,  2695,  2162,  2131, 16360, 25879,\n",
      "          8496,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2139,  6442,  2008, 14068,  2121, 11867,  2594,  2000,  3290,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2016,  2323,  2175,  3113,  7486,  2073, 21146,  4360,\n",
      "          2375,  2003,  1996,  3627,  1998,  6865,  2041,  2045,  1998,  2059,\n",
      "          2272,  2067,  1998,  2425,  2149,  2129,  2016,  2001,  5845,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1420, 0.1420, 0.1420, 0.1420, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.6690, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0100, 0.0100, 0.0100, 0.1420, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.1420],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1120, 0.4250, 0.1120, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1140, 0.0080, 0.4310, 0.4310, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170]]), 'label': tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2129,  2115, 11382,  3489,  1040,  1039,  6728,  2183,  2651,\n",
      "         14021, 12274,  2571,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5636,  4004,  2015,  2054,  2065,  1996,  2859,  2038,  1037,\n",
      "          2317, 10975,  3385,  2040,  2001,  2141,  1998, 15547,  2098,  2045,\n",
      "          2052,  1044,  2618,  2100,  2022, 10964,   102,     0,     0,     0],\n",
      "        [  101,  1996,  2069, 22889,  4904,  2003,  1996,  2028,  2040,  7110,\n",
      "          1056,  2992,  2032,  2157,  3722,  2004,  2008,  2016,  2442,  1997,\n",
      "          2042,  2205,  4548,  2006,  2014,  2273,  2000,  4125,  2032,   102],\n",
      "        [  101,  7906,  6230,  2295,  2619,  8826,  1037,  8957,  2000,  3648,\n",
      "          1037,  5053,  5049,  2108,  2019,  4763, 16939,  1996,  8957,  3856,\n",
      "          2035,  2317,  2308,  2061,  1996,  8957,  2001, 16360,  3217,   102],\n",
      "        [  101,  2053,  2062, 16939,  2084,  2054,  2017,  2074,  2056,  2017,\n",
      "          2113,  2498,  1998,  2115,  9152, 13327,  2814,  2024, 11809,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2224,  1996,  9152, 13327,  2773,  2017,  2488,\n",
      "          2196, 12134,  2005,  2009,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2079,  2009,  1045, 10587,  2131,  1996,  5025,  2616,\n",
      "          2317, 11669,  1999, 12392,  2050, 15489,  4873,  2006,  2033,  8840,\n",
      "          2140,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2024,  2690,  2465,  2317,  7789, 24247,  2015,  2061,\n",
      "          7537,  1037,  5152,  2001,  2700,  3664,  1997,  2414,  2515,  2025,\n",
      "          2008,  2425,  2017,  2129,  2116,  7486,  2444,  1999,  1996,   102],\n",
      "        [  101, 20287,  6300,  2050,  3198,  2008,  9152, 13327, 10556, 13699,\n",
      "         11795,  6799,  2015,  2055,  2010,  2317, 24615,  1998,  1996,  2293,\n",
      "          3399,  1037,  9152, 13327,  2003,  1037,  9152, 13327,  2008,   102],\n",
      "        [  101,  5310,  5310,  4481,  2021,  1045,  2097,  2224,  2008,  7188,\n",
      "          1045,  2031,  2000,  4952,  2000,  2028,  1997,  2026,  2940, 24457,\n",
      "          2100,  2417, 18278,  6304,  2175,  2006,  2055,  4419,  2739,   102],\n",
      "        [  101,  5310,  1045,  4748,  5686,  1996, 26731,  2035,  2317,  2028,\n",
      "         15537,  2033,  1997,  2028,  1997,  2026,  3337,  3407,  1045,  2699,\n",
      "          2028,  1997,  2216, 12849,  5092, 11867,  3899,  7438,  4487,   102],\n",
      "        [  101,  2611,  2003,  3492,  1998,  2016,  8134,  7425,  2015,  2033,\n",
      "          8840,  2140, 14145,  2080,  2339,  1045,  2572,  3492,  2128,  7559,\n",
      "          5732,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 12835,  2140,  3599,  2129,  1045,  2514,  2043,  9152,\n",
      "         23033,  2015,  2831, 10094,  5181,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6181,  2140,  2077, 21307, 10404, 21564,  7743,  2229,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1998,  2182,  2026, 14293,  1045,  2572,  2317,\n",
      "          1998,  1045,  5993,  2007,  2032,  1045,  2572,  2036,  2025,  1037,\n",
      "          4314,  2030,  1037,  5152,  2061,  2515,  2008,  2191,  2033,   102],\n",
      "        [  101,  6854,  2076,  1996,  2193,  2086,  2002,  2145,  2038,  2025,\n",
      "          4961,  1037,  4167,  2021,  2145, 19237,  8174,  9587, 25016,  2213,\n",
      "         10338,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0160, 0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2130, 0.2130, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2130,\n",
      "         0.2130, 0.0150, 0.0150, 0.0150, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0560, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0460, 0.6680, 0.0460, 0.0460, 0.0460, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0030, 0.0030, 0.0130, 0.0130, 0.1810, 0.0130, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1810, 0.1810, 0.1810,\n",
      "         0.1810, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4130,\n",
      "         0.4130, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.2000, 0.7580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0210, 0.3010, 0.3010, 0.3010,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  5667,  2027,  2024,  2035,  2074,  4138,  2317,\n",
      "          3017,  3767,  2085,  2027,  2031,  2053, 13815,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2066,  3038,  1996,  2329,  2359,  1037,  3972, 22890,\n",
      "          1997,  4004,  2015, 14560,  1998,  7486,  1999,  2019,  2525, 24827,\n",
      "          2104,  7692,  2094,  3842,  1998,  2085,  2057,  2442,  3422,   102],\n",
      "        [  101,  3956,  4122,  7795,  2005,  2993,  1998,  1996,  2717,  1997,\n",
      "          1996,  9636, 20837,  2205,  2008,  2054,  2023, 16477,  3644,  2162,\n",
      "          2057,  2031,  2042,  3554,  2144,  2193,  2003,  2035,  2055,   102],\n",
      "        [  101,  1045,  2031,  5717,  1042,  2000,  2507,  2000,  2619,  2040,\n",
      "          2018,  2009,  2035,  2021,  2145,  2071,  2025,  2131,  2041,  1997,\n",
      "          1996, 17276, 10597,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3374,  2018,  2070,  2477,  2000,  2079,  2054,  1037,\n",
      "          7170,  1997, 10958, 10958, 14068,  2121, 14636,  1045,  2245,  2210,\n",
      "         12043,  2001,  6057,  2059,  2002, 21100,  2010,  2219,  1045,   102],\n",
      "        [  101,  2053,  2995,  2099,  2616,  2004,  1045,  4756,  2012,  1996,\n",
      "          2522,  5644,  2040,  2272,  2182,  2000, 11693,  2005,  9920,  5310,\n",
      "          5310,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2234,  1999,  2000,  1996, 13882,  2652,  2962,  3379,  8221,\n",
      "          2205,  5189,  1998,  2001,  2356,  2339,  1045,  2001,  2652,  4854,\n",
      "          2189,  2011,  2026, 11190,  2953,  5484,  7743,  2009,  2025,   102],\n",
      "        [  101,  5310,  5310,  2196,  1056, 28394,  3064,  2008,  2128,  7559,\n",
      "          2094,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2066,  2129,  2027,  2031,  2000,  4919,  2360,  2512,\n",
      "          6696,  1999,  2317,  7236,  2006, 19287,  2138,  1996, 11382,  9681,\n",
      "          2097, 15116,  3087,  1999,  2007,  2149,  2000,  2191,  2256,   102],\n",
      "        [  101,  1999,  2047,  2259,  2103,  1037,  2047,  2375,  2003,  2746,\n",
      "          2008,  2052, 19104,  1996,  2224,  1997,  1996,  2744,  6206,  7344,\n",
      "          2079,  2017,  2228,  2009,  2003,  8335,  2007,  2256,  6543,   102],\n",
      "        [  101,  2651, 14686,  2013,  2026,  2200,  5637,  4256,  1045,  9471,\n",
      "          2273,  2071,  2031, 27408,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22301,  4658,  2145,  1037,  8239,  9152, 13327,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2085,  3335,  3035,  2100,  2866,  2097,  2022,  1996,  2925,\n",
      "          5152,  5949,  3122,  2885,  1998,  3915,  2097,  3477,  2035,  8711,\n",
      "          2000,  2175,  1998,  2994,  1999,  2563,  2017,  2342,  2070,   102],\n",
      "        [  101,  5310,  1040,  2213,  2033,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  1996, 29268,  1998,  2040,  2003,  4755,  2300,  2005,\n",
      "          1996,  5221, 16374,  1999,  2256,  2406,  2381,  8112,  2003,  2055,\n",
      "          2000,  2131,  2010,  4632,  2275,  2006,  2543,  1998,  1996,   102],\n",
      "        [  101,  2025,  2005,  2146,  8797,  2121,  1996, 11382,  9681,  2024,\n",
      "          6069,  2191,  2469,  2027,  2024,  2035,  1999,  3009,  2059,  2027,\n",
      "          2024,  6069,  2191,  2017,  5914,  2125, 24471,  2684,  2000,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0840, 0.0840,\n",
      "         0.0840, 0.0840, 0.0840, 0.0840, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0560, 0.0560,\n",
      "         0.0560, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.5960, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7630,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6380, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.3580,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0610, 0.8750, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0510, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0510, 0.1940, 0.0510, 0.0510, 0.0510, 0.0510,\n",
      "         0.0510, 0.0510, 0.0510],\n",
      "        [0.0100, 0.0100, 0.0100, 0.1400, 0.0100, 0.1400, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1400, 0.1400, 0.0100]]), 'label': tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  4490,  2193,  2193,  2021,  1996,  2317,  6548,  4206,  6638,\n",
      "          2317, 16795,  2594, 14512,  2015,  2145,  8627,  1998, 25250,  2008,\n",
      "          3071,  2003,  2141,  5020,  1037,  4682,  1997,  1996,  6548,   102],\n",
      "        [  101,  2023,  2097, 14719,  2063,  1996, 12896,  1999,  7016,  1998,\n",
      "          3279,  1997,  2166,  2004,  2027,  2097,  2022,  8949,  5003, 18696,\n",
      "          2011,  4830,  9953,  1037,  4160, 20474, 14560,  1998, 12896,   102],\n",
      "        [  101,  1996,  3484,  1997,  2017,  2040,  2831,  2091,  2006,  7489,\n",
      "          2071,  2025,  3413,  1037,  9068,  3231,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  2172,  1045,  2052,  2066,  2009,  2000,  2022,  2995,\n",
      "          8425, 11320, 14615,  1998,  3154,  1045,  2572, 21746,  2065,  1045,\n",
      "          2052,  2066,  2000,  2156,  6090,  2102,  4848,  3347,  3762,   102],\n",
      "        [  101,  1037,  2204,  3114,  2339,  6529,  2323,  3844,  1996,  6616,\n",
      "          2039,  2043,  2009,  3310,  2000,  4331,  2003,  2008,  2027,  2097,\n",
      "         18292,  2008,  9152, 13327,  2015,  1998, 14560,  2024,  9040,   102],\n",
      "        [  101,  2033,  9048, 25531,  2050, 24199,  4279,  2148,  1997,  1996,\n",
      "          3675,  3833,  1998,  9613,  2011,  7489,  2040,  6148,  8493,  2013,\n",
      "          1996,  5490,  8787,  2953,  2027,  6783,  1998, 12503,  1997,   102],\n",
      "        [  101,  2828,  1997,  9152, 23033,  2000,  2954,  1996,  3460,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2009,  3084,  2053,  3168,  2000,  2360,\n",
      "          2216,  2477,  2009,  3084,  2053,  3168,  2008,  2308,  1998,  2273,\n",
      "          2024,  2893, 15504,  2009,  3084,  2053,  3168,  2138,  2009,   102],\n",
      "        [  101,  5310,  2009,  1521,  2568,  9947,  7025,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2292,  2122,  6919,  2273,  1998,  2308,  5630,  2009,\n",
      "          2053,  2936,  4276,  2009,  2000,  2079,  2054,  2027,  2079,  1998,\n",
      "          2156,  2073,  2008,  4152,  2017, 13350,  6555,  2015,  2225,   102],\n",
      "        [  101,  1996,  2168,  1999,  2296,  2317,  2406,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2317,  2273,  1998,  2304,  2273,  2052,  2022,  6429,  6956,\n",
      "          2065,  2317,  2273,  2106,  2025,  2031,  2037, 19113,  3375,  2008,\n",
      "          2106,  2025,  2421,  1038,  2213,  3426,  1038,  2213,  5791,   102],\n",
      "        [  101, 10468,  1045,  2572,  2074,  6069,  2025,  2255,  2003,  1037,\n",
      "          8239,  5697,  3204,  2049,  1037,  2919,  3204,  2000,  2079,  2023,\n",
      "         17704,  4485,  2129, 10094,  2070, 10710,  7860,  1999,  2066,   102],\n",
      "        [  101,  6616,  2125,  2017,  9152, 13327,  8295, 17219,  2115,  3566,\n",
      "          2342,  1037, 14308, 14961,  1996,  2132,  2005, 11771,  2107,  1037,\n",
      "          7975,  4485,  6090,  6508,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2137,  8494,  7377,  8024, 17518,  3854,  2078,  2003,  1996,\n",
      "          6745,  2931,  8958,  2000,  2330,  2014,  2677,  1998, 11867,  7974,\n",
      "          7087, 26775,  9331,  1998,  2085,  2016,  3480,  2014,  2067,   102],\n",
      "        [  101,  2710,  2006,  2650,  2195,  2086,  2101,  2000, 25141,  9286,\n",
      "          1037,  8210,  2193,  2111,  2008,  2024,  5025, 13141,  3430,  2044,\n",
      "         15295,  1997,  5190,  1997,  9587, 25016,  2213, 16836,  2020,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0250, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0090, 0.0090],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0730, 0.0730, 0.0730, 0.0730, 0.0730,\n",
      "         0.0730, 0.0730, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0140, 0.1970, 0.1970, 0.1970, 0.1970, 0.1970, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0040],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.1080, 0.1080, 0.0070, 0.4080, 0.0280, 0.0280, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.1080, 0.1080, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.5220, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.5810, 0.1530, 0.0110, 0.0110, 0.0110,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2074,  1037, 14764,  2008,  5310,  2030,  2323,  1045,  2360,\n",
      "          7213,  7777,  2210, 11265, 17603,  4757, 14841,  6916,  2229,  1998,\n",
      "          2016,  5092,  5644,  1999,  2236,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  1045,  2053,  2017,  2024,  1037,\n",
      "          2317,  6548,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2025,  1037,  3808,  2181,  2005,  2256,  5152,  2814,\n",
      "          1998,  2037,  3644,  9585,  2869,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20287,  1045,  2572,  3331,  2000,  2308,  2651,  2040,  2024,\n",
      "         24114,  2060,  2308,  2005,  2035,  1997,  2023,  4424, 16011,  6815,\n",
      "          2205,  2116,  2308,  2552,  2126,  2205, 26422,  2135,  1999,   102],\n",
      "        [  101,  5310,  2014, 12335,  2031,  2085,  2443,  3496,  2990, 15315,\n",
      "         23918,  2669,  2029,  2016, 20665,  2014,  2132,  2005,  7592, 14433,\n",
      "         11690,  9099,  3442,  3937, 25976, 23503,  1998,  2085,  3937,   102],\n",
      "        [  101,  2070,  6203,  2814, 13141,  2013, 10958,  4160, 19062,  2074,\n",
      "          2741,  6316, 12129,  2050,  2188,  2007,  2070,  9042,  2844,  8808,\n",
      "          1998,  2026,  2293,  2005,  8808,  2003,  5091,  2904,   102,     0],\n",
      "        [  101,  5310,  5310,  5310,  2317,  2111,  2383,  6695,  2008, 13433,\n",
      "          2278,  2079,  2025,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2027,  2024,  2025,  8711,  2027,  2024,  2025, 14070,\n",
      "          2027,  2024,  2746,  2138,  2017,  2024,  1037,  7115,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  1996,  2350,  3114,  2008,  9587, 25016,  2213, 10797,\n",
      "          4028,  4385,  2003,  2138,  2008,  1996,  2069,  2126,  2037,  2338,\n",
      "          2758,  2008,  4443,  2046,  6014,  2003, 12361,  1998,  2027,   102],\n",
      "        [  101,  5310,  2008,  3065,  2149,  2129,  2116,  2317, 10514, 28139,\n",
      "         22911,  2923,  2024,  1999,  2637, 11228,  2854,  2763,  2193,  2193,\n",
      "          2024,  6394,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2016,  2074,  9990,  2009,  2138,  2016,  2038,\n",
      "          2042,  2893,  1037,  2843,  1997,  3980,  4953,  1996,  2689,  1045,\n",
      "          9826,  2079,  2025,  7499,  2014,  2005,  2437,  1996,  2689,   102],\n",
      "        [  101, 27793,  2368,  2757, 12054,  5338, 18609, 10861,  3393, 21307,\n",
      "          2050,  5292,  3401,  2632,  3995,  2632,  5955,  2080,  2021,  1037,\n",
      "          2005,  3947,  2026,  3124,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  4329,  2302,  4409,  2204,  6735,  2007,  2008,  2023,\n",
      "          2210,  6904, 13871,  4140,  3310, 10591,  2006,  2026,  2341,  2049,\n",
      "          2025,  2183,  2000,  2203,  2092,  2005,  2032,  2030,  2010,   102],\n",
      "        [  101,  1996,  2317,  7743,  8994,  3124,  4590,  2038,  2042,  5299,\n",
      "          2185,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2054,  2162,  2006,  2308,  2115,  3331,  2685,\n",
      "          2024,  5458,  1998,  2214,  2507,  2009,  2039,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1521,  2785,  1997,  7025,  9331,  6806, 13592,  2008,\n",
      "          2673,  2003,  2701,  2651,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.4540, 0.4540, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2750, 0.2750, 0.2750, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0090,\n",
      "         0.1350, 0.1350, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.1350, 0.1350, 0.1350],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2025,  2469,  2054,  2003,  1044, 22571, 10085, 14778,  7476,\n",
      "          2055,  2108,  3424,  4808,  2114,  2308,  1037,  2843,  1997,  1996,\n",
      "          2111,  2006, 11721,  2497,  2031,  3017,  5300,  2030,  2024,   102],\n",
      "        [  101, 14841, 15353,  3105,  4013,  9215,  1996,  2087, 29379,  4485,\n",
      "          1037,  7743,  2071,  2079,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2027,  2056,  2002,  2001,  2019,\n",
      "         12160,  2005, 22072,  4682,  2056,  2027,  2018,  3350,  1997,  8902,\n",
      "         24117,  4682,  2056,  2002,  2106,  2025, 28887,  9253, 13157,   102],\n",
      "        [  101,  1044,  2497,  2094,  2000,  2026,  9152, 13327,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2002,  5807,  1521,  1056,  2031,  5580,  2057,  2031,\n",
      "          7489,  2295,  2030,  2008,  3907, 10026,  2876,  1521,  1056,  2031,\n",
      "          2579,  2032,  2091,  2007,  1037,  6583,  2099,  2860,  8865,   102],\n",
      "        [  101, 10166,  1045,  1521,  1049,  2428,  2309,  2129, 17276,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  1521,  2128,  1999,  2082,  1996, 17276,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2339,  1996,  3109,  2106,  2023, 10597,  8315,  3265,\n",
      "          3008,  3499,  2032,  2000,  2175,  2000,  1037,  3637,  7840,  2007,\n",
      "          1037,  2128,  7559,  5732, 17276,  9152, 13327,  2672,  1996,   102],\n",
      "        [  101,  5310,  5310,  2027,  2024,  2025,  6206, 12114,  2027,  2024,\n",
      "          2111,  2074,  2066,  2017,  2027,  2024,  2053,  2367,  2061,  2644,\n",
      "          2007,  1996, 20187,  5698,  9355,  2653,  7564,  1997,  2317,   102],\n",
      "        [  101,  2009,  2941,  2437,  1038,  2721,  2595, 17076, 16252,  2004,\n",
      "          2009,  2003,  4760, 15876,  2860, 10536,  4570,  2054,  2003,  2428,\n",
      "          6230,  1998,  2008,  2087,  1997,  1996,  4808,  2856,  2012,   102],\n",
      "        [  101,  2017,  8271,  2009, 18636,  2008,  2002,  5178, 13327,  2001,\n",
      "          3378,  2007,  1996, 13157,  2033,  2241,  2008,  2001, 10468,  1996,\n",
      "          2069,  2025,  2919,  2518,  2055,  2032,   102,     0,     0,     0],\n",
      "        [  101,  1996,  2060,  9108,  2595,  2290,  9132,  2024,  2035,  8053,\n",
      "          7977,  5310,  2003,  1037,  4689,  2417, 18278,  2040,  2288,  5045,\n",
      "          2005,  3426,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025, 11341,  2043,  1996,  2317,  3484,  2038,  2018, 15511,\n",
      "         10398,  7468,  2091,  2037,  3759,  2015,  2011, 11382,  9681,  2005,\n",
      "          5109,  2013,  2035, 12113, 21877,  3527,  3702, 24380, 17084,   102],\n",
      "        [  101,  5310,  2339,  2052,  2017,  8073,  5482,  1996,  2097,  2000,\n",
      "          6160,  8711,  1998,  1996, 25920,  2000,  9040,  2648,  1997,  2115,\n",
      "          3899, 12644, 10869,  2023, 16902,  3084,  2053,  3168,  2012,   102],\n",
      "        [  101,  2429,  2000,  1996,  2972,  5069,  2065,  2017,  2024,  2317,\n",
      "          1998,  2017,  8108,  2000,  4874,  2000,  2115, 21171,  4487, 13102,\n",
      "         15094,  7971,  3258,  4808,  2114,  2017,  2003, 15123,  1037,   102],\n",
      "        [  101,  2053,  2009,  2347,  1056,  5152,  2273,  2020,  2467,  5689,\n",
      "          2461,  2402,  3057,  2256, 12954,  2052,  2360,  2994,  2185,  2013,\n",
      "          1996, 22190,  2483,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.1570, 0.1570, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5970,\n",
      "         0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0680, 0.0180, 0.0180, 0.0180, 0.2590, 0.2590, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1820, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0480, 0.0480, 0.0030, 0.0030, 0.0480, 0.0480,\n",
      "         0.0480, 0.0030, 0.0030],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0500, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1900, 0.1900, 0.1900],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0440, 0.0440,\n",
      "         0.0440, 0.0440, 0.6370, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  9152, 13327,  9152, 13327,  9152, 13327,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2123,  1521,  1056,  3404,  7743,  2229,  2040,  3153,\n",
      "          1999,  3848,  1521,  3595,  8840,  2140,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 10047,  3374,  1045,  6719,  2022, 17693,  2000,  4604,\n",
      "          1057,  2026,  4620,  3426,  1045,  6719,  2562,  2068,  2005,  2870,\n",
      "          2061, 17276,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748, 19739, 12190,  6616,  1057,  8275,  4632,  7570,  2063,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2054, 18138,  2229,  2033,  2125,  1996,\n",
      "          2087,  2003,  1045,  2354,  2115, 19116,  2100,  2317,  4632,  2229,\n",
      "          2020,  2183,  2000,  2265,  2039,  2007,  2023, 14636,  2138,   102],\n",
      "        [  101,  5310,  2115,  2107,  2019,  4632,  1045,  1521,  1049,  4365,\n",
      "          2379,  2128,  7559,  5732,  1045,  2293,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 18564, 10230,  2024,  5637,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 12043,  2045,  2035,  2204,  3272, 24185,  4430,  1998,\n",
      "         27856,  4013,  2497,  6881,  2080,  7570,  2229,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5236,  9152, 13327,  2445,  7022,  4748, 15630, 20763,  2378,\n",
      "          2000,  2082,  3105,  3014,  2597,  2002,  2196,  3687,  1998,  2987,\n",
      "          2102,  2031, 26264,  2005,  6616,  2125,   102,     0,     0,     0],\n",
      "        [  101,  6616,  1996,  9152, 13327,  4605,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2044,  1996,  7071,  1997, 20639, 18719,  2078,  3087,  2008,\n",
      "          4494,  2005,  1037,  9587,  2891, 17960,  2063,  2003,  1037, 17328,\n",
      "          2000,  2637,  9587,  2891, 17960,  2229,  2323,  2025,  2022,   102],\n",
      "        [  101,  5310, 10501,  3521, 17656,  3554,  5233,  1999,  2193,  3032,\n",
      "          2190, 15568,  3101,  1997,  4071,  2006,  4689,  4470, 16480,  2080,\n",
      "         16480,  2080,  2077,  2507,  4344,  2000,  9642,  8711,  1998,   102],\n",
      "        [  101,  2647,  9424,  2015,  4995,  2102,  2137,  4661,  2885,  3039,\n",
      "          1996, 14163, 13793,  2229,  1999,  4312,  2025,  2026,  3291,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2767, 19010,  2015,  3480,  2066,  1037,  7743,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  5152,  2040,  4264,  1037,  3392,  2030,  2061,  9333,\n",
      "          1037,  2492,  2013,  2029,  2158,  5055,  1998,  4176,  2064,  4521,\n",
      "          2003, 16873,  2019,  2552,  1997,  5952,  1524,  5152,   102,     0],\n",
      "        [  101,  1996,  5181,  8840,  2140,  2057,  2730,  4441,  1524,  2643,\n",
      "          2017,  2196,  2387,  2023,  2746,  1045, 18654,  8962,  1997, 22040,\n",
      "          2000,  4009,  2093,  3176,  5329,  2013,  2026,  5877,  1524,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.3310, 0.3310, 0.3310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0600, 0.8610, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.9650, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1510, 0.5720, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0400, 0.0400, 0.0400, 0.0100,\n",
      "         0.0100, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1470, 0.1470, 0.5580, 0.1470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3920, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3920, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0580, 0.0580, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8080,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.1800, 0.0030, 0.1800, 0.1800, 0.1800, 0.1800, 0.0130, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0000]]), 'label': tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  8840,  2140,  2012,  5310,  6732, 15478, 25518,  4590, 10608,\n",
      "         11190, 10777,  7425,  4691,  4534, 16584,  7747,  2024,  2635,  2058,\n",
      "          1996,  2088,  8840,  2140, 15478, 25518,  4590,  2017,  2128,   102],\n",
      "        [  101,  5310,  5310,  4004,  2015,  2031,  2467,  2042, 13433,  2278,\n",
      "          4004,  2015,  2264,  4004,  2015,  2020,  2641,  3756,  1998,  2112,\n",
      "          1997,  1996, 17450,  9314,  2679,  2256,  3949,  2802,  2137,   102],\n",
      "        [  101,  2012,  2560,  1996,  3097, 19483,  2015,  2024, 23218,  2009,\n",
      "          2041,  2085,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 10645,  8977,  2015,  2001, 11690,  2292,  1521,  2022,\n",
      "          7481,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  2664,  2000,  2156,  2619,  2019, 21499,  2273,\n",
      "          1996,  2168,  2126,  2308,  2131,  2589,  2151,  5573,  2929,  1998,\n",
      "          2010,  5294,  4907,  9354,  3632, 29262, 23769,  2571,   102,     0],\n",
      "        [  101,  1051,  6767, 22930,  1996,  5637, 14163, 13793,  2063,  2106,\n",
      "          2025,  2215,  2000,  4154,  2010, 12334,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3505, 28178,  2288,  2010,  4632,  4375,  2000,  2032,  2011,\n",
      "          1037,  4845, 12316,  2094,  2651,  2010,  5981,  4616,  2024,  4788,\n",
      "          2084,  2010,  2147,  2041,  9410,   102,     0,     0,     0,     0],\n",
      "        [  101,  6497, 16291,  2308,  2040, 10427, 28488,  5246, 25353,  8737,\n",
      "         25457, 11254,  2007,  6497,  3111,  4586, 16291,  2317,  2308,  2040,\n",
      "          9811,  2000,  2022,  4942, 27876,  2000,  5843,  2091,  1037,   102],\n",
      "        [  101,  2017,  2035,  4416,  2022,  2559, 11808,  2004,  4485,  2031,\n",
      "          1996,  9113,  2000,  6293,  2008,  2317,  4632,  4485,  2041,  7743,\n",
      "         19424,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2049,  4315, 18170,  7062,  2066,  2065,  1037,  2317,\n",
      "          2711,  2170,  2296,  1038,  2721,  9468,  2931, 17137, 18515,  6692,\n",
      "          2074,  3426,  2027,  1038,  2721,  9468,   102,     0,     0,     0],\n",
      "        [  101,  5310,  8507,  2234,  2000, 13493,  4174,  2005,  1037,  6302,\n",
      "          6728,  1997, 12771,  2300,  2000,  2945,  2016,  2025,  2130,  2013,\n",
      "          4174,  2256,  2047, 23298,  2081,  1037,  2502,  3066,  2000,   102],\n",
      "        [  101,  3243,  2157,  2205,  6616,  1996,  2128,  7559,  5732, 17768,\n",
      "         13038,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998,  2049, 14163, 13793,  2063, 10130,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2632, 11631, 19506,  2527,  2002,  2056, 28415,  7302,  2010,\n",
      "         19085,  2012,  1996, 11687,  7878,  2021,  2498,  3047,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  1996, 14163, 13793,  2229,  2131,  2037,  3374,  4485,\n",
      "          2362,  1998,  5968,  3956,  1045,  2097,  2025,  2514,  3374,  2030,\n",
      "          8328,  1037,  7697,  1045,  2097,  2069, 20342,  3372,  1996,   102],\n",
      "        [  101,  6517, 18515,  4967, 17710,  3676,  2497, 21025,  6371, 14163,\n",
      "         13793,  2063,  2293,  2651,  3084,  2033, 10587,  2079,  2023,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0220, 0.0220, 0.0220, 0.0220, 0.3190, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0840, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0130, 0.0130, 0.0130, 0.1870, 0.7090, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.8100, 0.0560, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1570,\n",
      "         0.1570, 0.1570, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1570, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0970, 0.0970, 0.0260, 0.0260,\n",
      "         0.3690, 0.0260, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0070, 0.0070, 0.0070, 0.1020, 0.1020, 0.3870, 0.3870, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.7690, 0.2030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.6380, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.6830, 0.1800, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1041, 11329,  2278,  2038,  2439,  2010, 11109,  2065,  2017,\n",
      "          2490,  2023,  2929,  6415,  1996,  4330,  5004,  2030,  2128,  2102,\n",
      "         28394,  2102, 26988,  1041, 11329,  2278,  2085,   102,     0,     0],\n",
      "        [  101,  5310,  5310,  2003,  2045,  2151,  2391,  1999,  7514,  2075,\n",
      "          2000,  2023,  2128,  7559,  2094,  1045,  3984,  2025,  2444,  1999,\n",
      "          2115, 13670,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  6300,  2080,  2006,  2643,  2149,  2008,  2154,\n",
      "          2068,  2317,  7243,  2277,  2234,  1998,  2018,  2035,  1997,  2149,\n",
      "          5457,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2200,  2460,  4451,  2005,  1037,  6696,  5819, 14560,  2036,\n",
      "          2031,  2146, 27518, 17494,  2015,  1998,  2167, 18076,  7166,  2025,\n",
      "          2000,  2002,  2071,  2022,  2013,  1996,  2690,  2264,  2021,   102],\n",
      "        [  101,  4172,  2072, 19808,  3501,  3038,  2613,  4632,  7743,  1999,\n",
      "          1996,  4281,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2467,  2131,  1037,  5926,  2041,  1997,  1996,  2755,\n",
      "         14163, 13793,  2229,  2031,  2193,  2942,  2916,  8917,  2015,  8851,\n",
      "         12285,  1999,  1996,  2149,  3081, 29080,  2099,  1996,  9089,   102],\n",
      "        [  101,  2111,  1999,  2026, 17276,  4632,  2082,  2109,  2000,  4929,\n",
      "         11344,  2066,  2122,  2066, 28712,  7451,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 23037,  3779,  4541,  2010,  3247,  2000, 23388, 16215, 12514,\n",
      "         17139,  5832,  2000,  1996,  4259,  2457,  2738,  2084,  1037,  2625,\n",
      "          3297,  2304,  3648,  2011,  3038,  2043,  1045, 16823,  1037,   102],\n",
      "        [  101,  8840,  2140,  2008,  7692,  3993,  4756,  2025, 25805,  5582,\n",
      "          2037,  4808,  5525,  2021,  2009,  2471, 11951,  2135, 17276,  2007,\n",
      "          2049,  3132,  3937,  4475,  2066,  2054,  1037,  3565,  3968,   102],\n",
      "        [  101,  1045,  2572,  3225,  2000,  2228,  2009,  1996,  5181,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6366,  2035,  7486,  1998,  9152, 13327,  2015,  1998, 11382,\n",
      "          9681,  2013,  1996,  2142,  2163,  1997,  2637,  2023,  2003,  1996,\n",
      "          6413,  3433,  2000,  2054,  2122,  4176,  2031,  2042,  2725,   102],\n",
      "        [  101,  1045,  3929,  2490,  8038,  4313,  5658, 19092, 21463,  4073,\n",
      "          1999,  5094, 14451,  2023,  4763,  2248, 11382,  3489,  4126, 16229,\n",
      "          2091,  2007,  1996,  5181,  2091,  2007,  1996, 20978,   102,     0],\n",
      "        [  101,  6838,  6157,  1998,  3725,  2034,  2079,  2062,  2204,  2000,\n",
      "          3288,  4808,  2646,  2450,  2611,  1998,  2336,  1999,  2330,  2061,\n",
      "          2111,  2097,  2025,  2425,  2017,  1045,  2079,   102,     0,     0],\n",
      "        [  101, 19483,  2015,  1999, 19330, 24335, 11514,  6169,  2024,  1996,\n",
      "          2168,  1999,  1996,  2510,  1037,  4121,  8239,  6707,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  2339,  2057,  2097,  2342,  1037,  3979,  2558,\n",
      "          3228,  2068,  1037,  3679, 20563,  1997,  9928, 11273, 11382,  3489,\n",
      "          9152, 13327, 11560,  6904, 13871,  4140, 22889, 16446,  2151,   102],\n",
      "        [  101,  1999,  1996,  2783, 12312,  1997, 20050,  2064,  3490, 10264,\n",
      "          6026,  2993,  2073,  2304,  1998,  2033, 16643,  4143,  2308,  2024,\n",
      "          7866,  2317,  2308,  2028, 12087,  2003,  2008,  2062,  3086,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.7630, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.5480, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0070, 0.0070, 0.0070, 0.4030, 0.4030, 0.1060, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3760,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0320, 0.4590, 0.4590, 0.0080,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0410, 0.0410, 0.1550, 0.1550, 0.1550, 0.1550, 0.1550, 0.0110, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0410, 0.0410, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.7130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.4540, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.1200, 0.1200, 0.1200, 0.1200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2050,\n",
      "         0.2050, 0.0140, 0.2050, 0.2050, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3780, 0.0070]]), 'label': tensor([1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2672,  2021,  1045,  2066,  2000,  2228,  2009,  1037, 17630,\n",
      "         28616, 21539,  1998,  1996,  2962,  2094,  9152, 13327,  2061,  2860,\n",
      "          2003,  2074,  2061, 15578,  3366,  1998,  2440,  1997, 22939,   102],\n",
      "        [  101,  1045,  2156,  1996,  2925,  1997,  3725,  2004,  2108,  1037,\n",
      "          5949,  3122,  1997,  3418, 23548,  4517, 22223,  1998, 14163, 16238,\n",
      "         14560,  2770,  2105,  2006, 19130,  3456,  2065,  2027,  2031,   102],\n",
      "        [  101, 28781,  8521,  1996,  1062,  8649,  2224,  7743, 10421,  2030,\n",
      "         29071,  7270,  2079,  2025,  2490,  2122, 11382,  3489,  9680,  5130,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2036,  2478,  1996,  6331,  2004,  1037,  2381,  2338,  2003,\n",
      "          8239,  2128,  7559,  5732,  2144,  3441,  2066,  7240,  1998,  1996,\n",
      "          7186,  2003,  1037, 10973,  2125,  1997,  1996, 27668, 12514,   102],\n",
      "        [  101, 10047,  2863,  2417,  2795,  2831,  2828,  1997,  7743,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5993,  2865,  2097,  2025,  3189,  2304,\n",
      "          2006,  2317,  4126,  2021,  2008, 12528,  2052,  2031,  2042,  2392,\n",
      "          3931,  2739,  2065,  2009,  2001,  1037,  2317,  2711,  6101,   102],\n",
      "        [  101,  2115,  2128,  7559,  5732,  4756,  1048,  2213,  7011,  2080,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2113,  2045,  1037,  9210,  1997,  2317, 19910,  2008,\n",
      "          2024,  1999,  2204,  3061,  2007,  1996,  7415, 15883,  2007,  2545,\n",
      "         24667,  2078,  1998,  6423, 25931,  2229,  2000,  2171,  1037,   102],\n",
      "        [  101,  2054,  2039,  2007,  4916,  2015,  5026,  2702,  2155,  2372,\n",
      "          2000,  1996, 13025,  3573, 15075,  3619,  2079,  1996,  2168,  2518,\n",
      "          2027,  3604,  1999, 15173,  2009,  3504,  2061, 17276,   102,     0],\n",
      "        [  101,  3398,  2216, 24581,  2015,  1045,  6135,  6807,  2216,  2013,\n",
      "          5887,  2033,  2694,  4687,  2450,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2886, 11704,  6904, 13871, 12868,  2040,  2507,  1996,\n",
      "          4487, 18719, 16454,  2157,  1037,  2919,  2171,  2026, 15793,  2003,\n",
      "          2000, 20716, 27082,  1996,  2474, 14536,  2157,   102,     0,     0],\n",
      "        [  101,  5310,  1998,  1996,  8817,  1997,  2489, 18570,  6206, 12114,\n",
      "          2024,  2025,  8020,  2000,  1996,  2373,  8192,  2012,  2035, 26476,\n",
      "          2015, 18138, 11484,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2354,  2008,  5212, 17107,  2001,  2200,  3424,  3234,\n",
      "          1998,  8615,  1037,  3234, 11560,  5274,  2179,  2041,  2002,  2036,\n",
      "          6878,  1996, 25097,  2052,  2693,  2000,  1996,  2149,  4298,   102],\n",
      "        [  101,  2016,  2038, 12316,  2094,  1998,  5472, 25518,  4590,  2668,\n",
      "         20868,  2140,  2016,  2003,  3243, 23624,  2278,  2058,  9006, 11837,\n",
      "         16846,  2075,  3383,  2014,  2034, 14670,  2007,  1996,  2813,   102],\n",
      "        [  101,  2002,  2056, 11382,  3489,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2035,  2026,  6550,  2203, 12731,  2480,  1045,  1521,  1049,\n",
      "          2025,  2053,  5410,  4632,  7743, 28549,  7113,  2080,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.5900, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2610, 0.2610,\n",
      "         0.0690, 0.0690, 0.0690, 0.0690, 0.0690, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.2610, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.2610, 0.2610, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.3840, 0.3840, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0170, 0.9010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0800, 0.0800, 0.0800, 0.0800, 0.0800, 0.0800,\n",
      "         0.0800, 0.0800, 0.0800, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.1260, 0.1260, 0.4800, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1260, 0.0090,\n",
      "         0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0290, 0.4140, 0.4140, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0290, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0070, 0.0070, 0.1020, 0.1020, 0.1020, 0.1020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.1020, 0.1020, 0.1020, 0.1020, 0.1020, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.9650, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  2017,  2066,  9152, 13327,  2015,  2061,  2172,  2689,\n",
      "          2115,  2171,  2000,  5232, 10128, 12722, 25518, 15776, 11693,  5643,\n",
      "          9152, 13327,  7089,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 21091,  2389,  1042,  2497,  7917,  2033,  2005,\n",
      "          2193,  2420,  2030,  1037,  7615,  2114,  2008, 17768,  4974,  3519,\n",
      "          9452,  5665,  2319, 13192,  1045,  2170,  2014,  1037,  9452,   102],\n",
      "        [  101,  5310,  3653, 16033,  2213,  2017,  2071,  2025,  2022,  2062,\n",
      "          3308,  9779,  2003,  3424,  2317, 18079,  2565,  2009,  2036, 13403,\n",
      "          1996,  4004,  2015,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2491,  1997,  6728, 10404,  2003,  2491,  2058,  2308, 18353,\n",
      "         19379,  2100,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 26264,  2061,  2659,  2027,  2024,  2006,  1996,  2128,  7559,\n",
      "          5732,  4094,  5717, 14982,  2491,  2672,  2009,  2051,  2000,  2941,\n",
      "         26264,  3231,  2005,  1996,  3937,  2504,  1997, 11581,  2245,   102],\n",
      "        [  101,  1996,  2878,  4392,  2300,  9526,  2035,  4485,  2003,  8275,\n",
      "          1045,  4392,  2012,  2560,  1037, 25234,  1037,  2154,  1998,  2031,\n",
      "          4485,  3096,  2606,  4167,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  2018,  2023,  2801,  2005,  1037,  2096,  2085,\n",
      "          1037,  1040, 27268,  7361,  2937, 16596, 10882,  2925,  2073, 12461,\n",
      "          2024,  1037,  2235,  7162,  1037,  2611,  2013,  1996, 17276,   102],\n",
      "        [  101,  5310,  2204,  6583,  4312,  2015,  2313,  7738, 10556,  2099,\n",
      "         10958, 15256, 15030,  2193,  4241,  2015,  4241,  2015, 10384,  5369,\n",
      "         15030,  1998, 13141,  1038,  4048,  1057,  2215,  2307,  1998,   102],\n",
      "        [  101,  6796, 19817, 27627,  2003,  1996,  2128,  7559,  5732, 22052,\n",
      "          8444,  2365,  1997, 26000,  2140, 11794,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2308,  2022,  2061,  9376,  2043,  2027,  2024,  7109,  2100,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2000,  6235,  1044, 22571, 10085,  6935,  2100,  2035,\n",
      "          1996, 12455,  4214,  2006,  8398,  2000,  2655,  2041,  2317, 14594,\n",
      "          2018,  2025,  2042,  2583,  2000,  2655,  2041,  3424,  7011,   102],\n",
      "        [  101,  7743,  1045,  2147,  1037,  2843,  2125,  1996,  5119,  3426,\n",
      "         10047, 29454, 29206,  2102,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6187,  3951, 18079,  4018,  4152, 12992,  2013,  8398,  2662,\n",
      "          3619,  2123,  1084,  1056,  2215,  2110,  2000,  1084,  2468,  8326,\n",
      "          1084,  2525,  2624, 23151,  6190,  3597, 11573,  7958,  2298,   102],\n",
      "        [  101,  2064,  2025,  3524,  2000,  2156,  1996,  2647,  8711,  9451,\n",
      "          2000,  2637,  2043,  2037,  3032,  2024, 24672,  2007,  4689,  3899,\n",
      "         12644,  4654,  7913, 23738,  2015,   102,     0,     0,     0,     0],\n",
      "        [  101,  2025,  4011,  2000,  2360,  1996,  1050,  2773,  2065,  2017,\n",
      "          2024,  2317, 11224,  2008,  2065,  2023,  4854,  7743,  2003,  2025,\n",
      "          1037,  9152, 13327,  2084,  2054,  2003,  2008,  2157,  1045,   102],\n",
      "        [  101,  1996,  3035,  2106,  2025,  2191,  2151,  2569, 18327,  2006,\n",
      "          5315,  1997,  5087,  7404,  2886,  2069,  3159,  2520,  2001,  1999,\n",
      "          5087,  2076,  5315,  2824,  1998,  5359,  1996,  4613,  2053,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0300, 0.0300, 0.0300, 0.1150, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.4360, 0.0300, 0.1150, 0.0300, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3500, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3500,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0030, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1460,\n",
      "         0.1460, 0.1460, 0.1460, 0.1460, 0.1460, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.2420, 0.2420, 0.2420, 0.0640, 0.0640,\n",
      "         0.0640, 0.0640, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0760, 0.0760, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.2880, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.2390,\n",
      "         0.2390, 0.2390, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.0110,\n",
      "         0.0110, 0.0110, 0.6250, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0110, 0.0110, 0.0110]]), 'label': tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3693,  1996,  2390,  4080, 17153,  3676,  3710,  2115,  2406,\n",
      "          1998,  2025, 16522,  5972,  2017,  6904, 13871,  4140,  6985,  2489,\n",
      "          4613,  2007,  2115,  2166,  2025,  2115, 15882, 11382,  3489,   102],\n",
      "        [  101,  8487,  6834,  2066,  3282,  2491,  2003,  2178,  2028,  1997,\n",
      "          2216,  4485, 29521,  5320,  2008,  2065,  2017, 10667,  1037,  2210,\n",
      "          6748,  2046,  2037, 14354,  2003,  2428,  2055, 15887,  1996,   102],\n",
      "        [  101,  2009,  2170,  2108,  1037,  6616,  2378, 11067,  2043,  1045,\n",
      "          7475,  2007,  1037, 16522,  1998,  2111,  3422,  1045,  2468,  1037,\n",
      "         16522,  2205,  2000, 25174, 16522,  2854,  1998, 14451,  1046,   102],\n",
      "        [  101,  2092,  2092,  9152, 13327,  2015,  1998, 14068,  2545,  2024,\n",
      "         25303,  4176,  2040,  4830, 16215, 16814,  2009,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  1037, 17276,  4845,  2870,  2383,  4961,  2039,\n",
      "          1999, 18592,  2018,  1045,  2025,  2081,  1996,  3247,  1997,  5738,\n",
      "          1996,  2390,  1045,  1040,  2763,  2025,  2022,  2182,  2651,   102],\n",
      "        [  101, 22212,  2655,  2033,  1039, 14163, 13639,  2611,  2065,  2017,\n",
      "          2079,  2025,  2131,  1996,  6616,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10262,  5076,  2525,  2003,  1037, 23458, 14737,  2065,  2002,\n",
      "          2001,  2000,  2022,  5152,  2002,  1521,  1040,  3477,  1069,  2193,\n",
      "          4551, 23564, 24498,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6203, 17276, 13160, 24520,  2229,  2404,  2091,  1996,  8579,\n",
      "          8667,  1998, 17901,  5310,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2025,  2317,  2002,  2015,  1037, 11382,  3489,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2052,  2619,  2145,  3039,  2006,  1056, 24281,  3334,  3531,\n",
      "         16636,  2026,  4283,  2000,  5310,  2005,  2010, 15873,  4721,  1997,\n",
      "          1996,  9524,  5793,  2000,  1996,  4797,  2075,  5310,  2008,   102],\n",
      "        [  101,  3116, 12855,  2001,  2763,  1996,  2190,  2518,  2412,  1999,\n",
      "          2166,  1045,  2293,  2008,  7743,  2026,  3899,  2005, 28632,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  1040,  2031,  2000,  2022,  1037,  3143,  2128,  7559,\n",
      "          2094,  2000,  2025,  2113,  2049, 19186,  2017,  1040,  2031,  2000,\n",
      "          2022,  2019,  2130,  7046,  2128,  7559,  2094,  2000,  2903,   102],\n",
      "        [  101,  1996,  2062, 14818,  2273,  2024,  1996,  2062, 12320,  2308,\n",
      "          2468,  2061,  2308,  2941,  2064,  2102,  2022, 12320,  2043,  2027,\n",
      "          2024,  5129,  2011,  2054,  2064,  2022, 23992,  2170,  8247,   102],\n",
      "        [  101,  1996,  3585,  2123,  2003,  2019,  5756,  9081,  2021,  2010,\n",
      "         12873, 12054,  2684,  2003,  1037, 11382,  3489,  2011, 10338,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2079,  2025,  2022,  5236,  2096, 18221, 17246,\n",
      "          1998,  3017,  2024,  2746,  2182,  1999,  2634,  2005,  7494,  2045,\n",
      "          2166,  1996,  5152,  2024,  2074,  6206,  7489, 13475,  2256,   102],\n",
      "        [  101,  2907,  2006,  2129,  1996,  6616,  2024,  2017,  6069,  2655,\n",
      "          2928, 24004, 20200,  2043,  2017,  7581,  8239,  6904, 13871,  4140,\n",
      "          2096,  2017,  2020,  4439,  2627,  2033,  1998,  2026,  2814,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0270, 0.0270, 0.0070, 0.3880, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3880, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0760],\n",
      "        [0.0080, 0.0080, 0.4280, 0.0080, 0.4280, 0.0080, 0.0080, 0.0300, 0.0300,\n",
      "         0.0300, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0960, 0.0960, 0.0960, 0.0960, 0.0960, 0.0960, 0.0960,\n",
      "         0.0960, 0.0960, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.3160, 0.3160, 0.3160, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0150, 0.2100, 0.2100,\n",
      "         0.2100, 0.0150, 0.0150],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.2190, 0.2190, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0670, 0.0670, 0.0050, 0.0050,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.2540, 0.2540, 0.2540, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0370, 0.0370, 0.0100, 0.0100, 0.0370, 0.0370, 0.5290,\n",
      "         0.0370, 0.0370, 0.0370],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300]]), 'label': tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 27668,  5003,  2860,  3762,  2003,  1037,  8494,  7377,  8024,\n",
      "          6854,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5674,  2035,  1996,  2489,  4485,  2317,  4903,  2140,  2052,\n",
      "          2131,  2065,  2027,  2018,  9152, 13327,  1999,  2068,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2123,  1521,  1056,  2812,  1996, 14560,  2000,\n",
      "          3288,  2068,  2362,  2021,  2017,  3214,  2111,  2057,  2113,  1037,\n",
      "          2843,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16401,  5181,  2000,  4441,  8998,  2003,  2025,  1996,  5576,\n",
      "         16401,  5181,  2000, 14163, 29358,  2003,  7300,  2008,  9611,  2013,\n",
      "          2136,  2860, 16584,  2063,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5181,  2031,  2632,  4140,  2000,  3437,  2005,  2164,  1996,\n",
      "          4325,  1997,  8275,  5472,  9152, 13327, 11822,  2066,  7988,  7025,\n",
      "          3625,  2005,  8991, 10085, 28173,  3070,  8817,  1997,  2317,   102],\n",
      "        [  101,  2000,  2035,  1996, 24004, 20200, 22052,  2015,  2040,  2024,\n",
      "          5506,  2012, 14556,  8873,  2721,  2045,  1521,  1037,  2569,  2173,\n",
      "          1999,  3109,  2005,  2017,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2021,  2106,  2025, 10900, 13675, 14194,  7810,  4828,\n",
      "          2061,  2339,  7499,  5181,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5665, 10189,  2243,  2004,  1045,  3298,  2083,  2115, 17276,\n",
      "          2064,  2102,  2644,  1045,  2031,  2317,  2449,  2000,  5463,  2000,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4312,  2017,  2035,  2156,  2122,  9944,  9152, 23033,  2015,\n",
      "          4795,  9587, 11263,  3600,  3022,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 23124,  3993,  2026, 14765,  2317,  4632,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7743,  2229,  2097,  2428,  3422,  2017,  2013, 12403,  2213,\n",
      "          6115,  1998,  2027,  1044,  5620,  5530,  1048,  2863,  2080,  3531,\n",
      "          2131,  1037,  2166,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2131,  7629,  2613,  5458,  2108,  7887,  2409,  2129,  5236,\n",
      "          4841,  2024,  2017,  2228,  2017,  2024,  2151,  2488,  2007,  2122,\n",
      "          5472,  9152, 13327,  2015,  6419,  2017,  3109,  2012,  2560,   102],\n",
      "        [  101,  6927,  8109,  1045,  2031,  2448,  2041,  1997,  6123,  1998,\n",
      "          4180,  2005, 21699,  3152,  1045,  2097,  2074,  7499,  8271,  1998,\n",
      "          1055,  3501,  2860,  2005,  2026, 11737,  5498, 12227,  5541,   102],\n",
      "        [  101,  5310,  5310,  2057,  2024,  3331,  2055,  2317,  2572, 27350,\n",
      "          2050,  2027,  2191,  1996,  4277,  2027,  2064,  2507,  2014,  2054,\n",
      "          2027,  2215,  2027,  2507,  2317,  3337, 19703,  2005,  9040,   102],\n",
      "        [  101,  3374,  6775,  2026,  7615,  2001,  2062,  2061,  6461,  2012,\n",
      "          1996,  2969, 11268, 23656, 11382,  3489,  6359,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2033,  2232,  2655,  2009,  2054,\n",
      "          2017,  2097,  2308,  2145,  2342,  2000,  2022,  5123,  2013, 15667,\n",
      "          2015,  2149,  3126,  4691,  2037,  3151,  7258,   102,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.7960, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650,\n",
      "         0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0460,\n",
      "         0.0460, 0.1760, 0.1760, 0.1760, 0.1760, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0460, 0.0460, 0.0030, 0.0460, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.3910, 0.3910, 0.1030, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0190, 0.0190, 0.0190, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.7730, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0910, 0.0910, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0910, 0.0910],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.4500, 0.4500, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  5310,  5310,  5310,  2748,  2065,  2027,  2020,\n",
      "          3287, 20649, 15942,  3619,  2052,  2022,  2062,  2039,  1999,  2608,\n",
      "          3337,  2020,  2036, 15504,  2011, 25303,  3767,  3188,  2000,   102],\n",
      "        [  101,  1045,  2572,  2053,  2936,  2583,  2000,  3853,  1999,  2023,\n",
      "         16522,  9152, 13327,  1056, 24281,  3226,  2026,  5394,  2003,  4327,\n",
      "          9679,  2480,  1998,  1045,  2572,  2025,  2146,  2005,  2023,   102],\n",
      "        [  101,  5310,  3087,  1999,  2115,  2166,  2040,  6732,  2009,  3308,\n",
      "          2000, 26944, 21877,  3527, 21850,  6632,  1998,  3073,  2008, 18558,\n",
      "          2000,  2375,  7285,  2031,  2068,  3336, 28032,  2115,  4268,   102],\n",
      "        [  101,  2023,  2003,  2026,  2197,  2095,  2108,  5637,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7743,  3103, 22212,  4231, 12731,  3372,  4803,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2228,  8923,  2080,  2003,  2488,  2084,  6752,\n",
      "          2072,  2017,  2024,  2593,  1037, 16374,  2030,  1037,  2128,  7559,\n",
      "          2094,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2024,  2122,  5181, 20540,  2004, 14560,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8840,  2140,  1045,  2572,  2074,  6069,  2360, 19902,\n",
      "          2003,  2019,  2390,  3046,  2000,  6033,  2149, 11865, 11263,  2025,\n",
      "          2008,  3733,  7743,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2061, 14398,  2007,  1037, 11867,  6657, 19099,\n",
      "          1997,  4424, 16011,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  2009,  2001,  2196,  1037,  4190,  4183,  3737,  4742,\n",
      "          2009,  2001,  2467,  1037,  2128,  7559,  5732,  8040,  3286,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2572,  1037,  6178,  7277,  9691,  8909,  2243,\n",
      "          2040,  1996,  6616,  2626,  2023,  2021,  1037,  9129,  1997,  2317,\n",
      "          7743,  2229,  1045, 13316,  7630,  4667,  2870,  2055,  2000,   102],\n",
      "        [  101,  2009,  4689,  2129,  2057,  3524,  2005,  2122,  9152, 23033,\n",
      "          2015,  2000,  2131,  2027,  4485,  2362,  2021,  2053,  9152, 23033,\n",
      "          2412,  3524,  2005,  2149,  2000,  2131,  2256,  4485,  2362,   102],\n",
      "        [  101, 10047,  6719,  2025,  1037, 21379,  2021,  6203,  2935,  2129,\n",
      "          2524,  2003,  2009,  2000,  2074,  6807,  2008,  2111,  2074, 15958,\n",
      "          4078, 18136,  2063,  5181,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2073,  1521,  1996,  5619, 26319,  2017,  2128,  7559,\n",
      "          5732, 12731,  3372,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16913,  2072, 16913,  2401,  1998,  2009,  3526,  2044,  3773,\n",
      "          1996,  2175,  2067, 16913,  2072,  9874, 14910,  2606, 14634, 15030,\n",
      "          2078, 10654, 12069,  7632,  4078,  2232,  2033, 10654,  8486,   102],\n",
      "        [  101,  2066, 19387,  1040,  2213,  2000,  2022,  2794,  2000,  1037,\n",
      "          1043,  2278,  2562,  2009,  3161,  1044, 18863,  2169,  2060,  2039,\n",
      "          2442,  2022,  2206,  2033,  2193, 26354,  9331, 21332, 23393,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3460, 0.3460, 0.0240, 0.0240, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0060, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.3150, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.2420, 0.2420, 0.2420, 0.2420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.7420, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.4700, 0.4700,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2030,  2317,  2304,  2006,  5637,  2304,  2006,  2317,  2304,\n",
      "          2006,  8398,  4808,  2003,  2691,  1996,  2865,  2816,  1998, 18079,\n",
      "          2097,  2031,  2017,  2903,  2009,  2003,  1996,  4500,   102,     0],\n",
      "        [  101,  1057,  2215,  3606,  3537, 19362,  3723,  2003,  4758,  2011,\n",
      "          4105,  2008,  4122,  2000, 27159, 15523,  1999,  3915,  2027,  2211,\n",
      "          2011, 11424,  6593, 11796,  3436,  3360,  1999,  2270,  2816,   102],\n",
      "        [  101,  5926,  1996,  4303,  2125,  3013,  1996, 13310,  2039,  6402,\n",
      "          2008,  7743,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2893,  3201,  2005,  2178,  2161,  1997,  9152, 13327, 12365,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2116,  2020,  5023,  2005,  2058,  2193,\n",
      "          2086,  2066,  1996, 26109,  3057,  2058,  2193,  2336, 15504,  2011,\n",
      "          5152,  6643, 26010, 24862,  2015,  1999,  2028,  2237,  2894,   102],\n",
      "        [  101,  5310,  2027,  2079,  1998, 23368,  2015,  2024,  1996,  3484,\n",
      "          1999,  1996,  2406,  2004,  2092,  2061,  2065,  2045,  2001,  1037,\n",
      "          3291,  2007,  2317, 22006,  2057,  1040,  2022,  3773, 20851,   102],\n",
      "        [  101,  6796, 16344, 27627,  2115,  2178,  7966,  2202,  1999,  1996,\n",
      "          5152,  7489,  2027,  2097,  2202,  2058,  2710,  3102,  2017,  2115,\n",
      "          2155,  2027,  4078, 18136,  2063,  2017,  3191,  2037,  2381,   102],\n",
      "        [  101,  1045,  2572,  1037,  2162,  3096,  2079,  2017,  2113,  2198,\n",
      "         20010, 19231,  4135,  2002,  2725,  2019,  1048,  6812,  2005, 21690,\n",
      "          1037, 12010,  4160, 26677,  2546,  1999,  1996,  2132,  1998,   102],\n",
      "        [  101,  5310,  2008,  4485,  2022,  5507,  1048,  2863,  2080,  2068,\n",
      "          9152, 23033,  2015,  3784,  2022,  3748, 27793,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  3398,  2797,  2816,  2097,  2292,  2115,  4845,\n",
      "          2131, 15504,  1998,  4400,  2009,  2125,  2004,  4535,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  8239,  5223,  2390,  2015,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10468,  2065,  1996,  8037,  2215,  2242,  2009,  2138,  2027,\n",
      "          3275,  2008,  1999,  1996,  2146,  2448,  2009,  3084,  2009,  6082,\n",
      "          2005,  5637,  7402,  7486,  2000,  9040,  2115,  4268,  6131,   102],\n",
      "        [  101,  1045,  2572,  5637,  2021,  2008,  2025, 19483,  2054,  2061,\n",
      "          4326,  2055,  3173,  2273,  6203,  1045,  2572, 15138,  2100,  2138,\n",
      "          1045,  2572,  5637,  1998,  1045,  2572,  3100,  2007,  2033,   102],\n",
      "        [  101,  2814,  2079,  2025,  2292,  2814,  5914,  5181,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6796, 19817, 27627,  1996, 17328,  2114,  2710, 17210,  2000,\n",
      "          2022, 12805,  3254,  1999,  1037,  2312,  8962,  1997,  4485,  2041,\n",
      "          1997,  2002,  4632,  2229,  1997,  2193, 24815,  2072,  9452,   102],\n",
      "        [  101,  3308,  7743,  4632,  9152, 23033,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.1510, 0.1510, 0.1510, 0.1510, 0.1510, 0.1510, 0.0400,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0540,\n",
      "         0.0540, 0.7780, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0430, 0.0110, 0.0110, 0.0110, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3410, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3410, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.1350, 0.1350, 0.1350, 0.1350, 0.1350, 0.1350, 0.1350,\n",
      "         0.0020, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0750, 0.0750, 0.0750,\n",
      "         0.0750, 0.0750, 0.0750, 0.0750, 0.0750, 0.0750, 0.0750, 0.0750, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0060, 0.3310, 0.3310, 0.3310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 14560,  2024,  2061, 21598,  1998,  4709,  2009,  7861, 20709,\n",
      "         18965,  2057,  2024,  2066,  1996,  2317,  2111,  1997,  1996,  5499,\n",
      "          2088,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4911,  2739, 11382,  3489,  6458,  9505,  2046,  4020,  2011,\n",
      "         17212,  2050,  2749, 12559, 21759,  5498,  2007,  8306,  4232,  2221,\n",
      "          2610, 16751,  2179,  1999,  3224, 12731, 26229,  2102,   102,     0],\n",
      "        [  101,  2339,  1999,  2193,  2193,  2020,  2045,  2304,  8711,  2013,\n",
      "          2148,  3088,  3039,  1999,  2149,  2106,  2017,  2113,  2008,  2097,\n",
      "          3046,  1998,  2131,  1996,  4957,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2021,  7486,  2024,  2919,  2005,  2725,  1996,  2643,\n",
      "          1521,  2147,  2041,  2045,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1048,  2863,  2080,  3393, 20058,  2175,  2424,  1037,\n",
      "          6293,  2061,  1045,  2064,  3477,  2070,  6904, 13871, 12868,  2000,\n",
      "          6616,  2017,  2066,  1037,  6904, 13871,  4140,  6904, 13871,   102],\n",
      "        [  101,  6616,  2008,  9152, 13327,  2017,  3403,  2000,  2131,  2115,\n",
      "          2003,  2232,  2024,  2017,  3403,  2000,  5510,  2009,  1045,  2288,\n",
      "          2000,  2130,  2023,  1045,  2288,  2630,   102,     0,     0,     0],\n",
      "        [  101,  2065,  1037,  2813,  3030,  2074,  2193,  1997,  2216,  2925,\n",
      "          6206,  2240,  8660, 20975,  1529,  2009,  2052,  3477,  2005,  2993,\n",
      "          1999, 10807, 10995,  2013,  7574,  2270,  2495, 25416, 18426,   102],\n",
      "        [  101,  2074, 11323,  2008,  4967,  2001, 14118,  8398,  2012,  4895,\n",
      "          3654,  2055, 13141,  5325,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2122,  7570,  2229,  7110,  1056,  4485, 22953,  1057,\n",
      "         10140,  2004,  3109,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2502,  2235,  2593,  2126,  1996,  5980,  2015,  2024,  1999,\n",
      "          2115,  2677,  9152, 13327,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2033,  2667,  2000,  3275,  2041,  2054,  4715,  9761,  2015,\n",
      "          2024,  3038,  2003,  2025,  2551,  1045,  2572,  1037, 11690,  1045,\n",
      "          2064,  2102,  3305,  3904,  1997,  2009,   102,     0,     0,     0],\n",
      "        [  101,  8494,  7377,  8024, 17072,  2000,  2175,  2007,  2115,  8494,\n",
      "          7377,  8024,  6501,  6073,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2162,  2003,  3423,  2138,  4808,  2003,  1037, 11476,  2965,\n",
      "          1997,  2417,  8303,  2075,  3056, 24665,  2666, 26711,  2157,  2075,\n",
      "          3056,  3308,  2015,  1998,  8650,  8995,  5426,  2065,  2009,   102],\n",
      "        [  101,  6616,  1996,  2193,  7489,  1996,  2231,  2439,  1045,  2069,\n",
      "          2729,  2055,  2193, 11560,  1996,  2231,  2439,  2073,  2003,  2016,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2044,  2057,  2985,  5606,  1997,  2086, 19080,  2667,  2000,\n",
      "          2942,  4697, 10823,  2027,  8826,  1056, 29548,  2075,  9680,  1996,\n",
      "         14255,  8737,  2192,  2358, 22134, 17276,  1038,  7138,  2092,   102],\n",
      "        [  101,  5532,  4419,  2758,  3058,  2193,  2012,  2051,  2054,  2052,\n",
      "          2017,  5987,  2013,  1996,  3190, 17276,  2111,  1998,  1996,  2053,\n",
      "          9789,  2350,  2865,  2293,  2068,  2138,  2027,  2024,  1997,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.7420, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3580, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0940, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.1380, 0.0030, 0.1380, 0.1380, 0.1380, 0.1380,\n",
      "         0.1380, 0.1380, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1390, 0.1390, 0.5280, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.8450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.7180, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1890, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.1280, 0.1280, 0.1280, 0.1280, 0.1280, 0.1280, 0.1280, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1430, 0.1430,\n",
      "         0.1430, 0.1430, 0.1430, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.2450, 0.2450, 0.2450, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170]]), 'label': tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  8112,  2003,  1037,  4688, 14163,  2480,  8609, 17328,  2061,\n",
      "          1997,  2607,  2673,  2002,  2106,  2001,  2919,  2005,  2637,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037, 12593,  6861,  8132,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2175,  3805,  2655,  2033,  1037, 24004,  8458, 20891,  2008,\n",
      "          1037,  4682,  1998,  3087,  2040,  2515,  2061,  2323,  2113,  2009,\n",
      "          1045,  2439,  2814,  1998,  2155,  7264,  2000,  6985,  5637,   102],\n",
      "        [  101,  2339,  2079,  1045,  2131,  3147,  2061,  4089,  2026,  2303,\n",
      "          5513,  2066,  2009,  2019,  8372,  2039,  1999,  2023,  7743,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  3835,  2000,  2113,  2070,  1997,  1996,  8711,  2024,\n",
      "         16401,  2000,  8135,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3407,  2000,  2156,  2008,  1996,  2047, 10474,  9874,  2003,\n",
      "         25043,  2075, 20066, 10735, 10288,  8787,  2015,  4647,  2026,  3442,\n",
      "         15111, 18328,  3555,  2008,  4485,  2035,  1996,  2051,  1998,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2061,  1037,  2282,  2440,  1997,\n",
      "          2317,  2111,  2106,  2025,  2228,  2008,  2178,  2317,  3124,  2725,\n",
      "          2304, 12172,  2001, 16939,  6581, 13384,   102,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2001,  2074,  7570,  2075,  2058, 12114,  2193,\n",
      "          2005,  2070,  3114,  1998,  2234,  2408, 12436, 22938,  2029,  2001,\n",
      "          2209,  2011,  1037, 16522,  9413,  3437,  2004,  2000,  2339,   102],\n",
      "        [  101,  1045,  2228,  2009,  2062,  2317, 24247,  2342,  2000,  2393,\n",
      "          1996,  3532,  2008,  5260,  2000,  1996,  2393,  1996, 14302,  2978,\n",
      "          1045,  2079,  2025,  2156,  3087,  6183,  2000,  3828,  1996,   102],\n",
      "        [  101,  2016,  2360,  7987,  2063,  2017,  2986,  1045,  2572,  2066,\n",
      "          7743,  3338,  8038,  2067,  2005,  1037,  9991,  7570,  2063,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821,  2024,  2027,  2024, 13157,  4288, 21524,  4078,  2696,\n",
      "         14454,  6026,  3032,  1999,  1996,  2690,  2264,  2024,  2027, 19670,\n",
      "         22165,  2000,  3288, 18076,  1998, 14560,  2046,  2885,   102,     0],\n",
      "        [  101,  4314,  7961,  2017,  2064,  2025,  2404,  1037,  2317,  2829,\n",
      "          2417,  2030,  3756, 19937,  2711,  1999,  3715,  1997,  3923,  2458,\n",
      "          2138,  2027,  2024,  2025,  4591,  2000,  2113,  2054,  1037,   102],\n",
      "        [  101,  1056, 24281,  3334,  2758,  1045,  5117,  1999,  9416, 16011,\n",
      "          1998,  6380,  2026,  5574,  2106,  2025,  3073,  1996,  1056, 28394,\n",
      "          2102,  2030,  2040,  1045, 10743, 28186,   102,     0,     0,     0],\n",
      "        [  101,  5310,  2138,  2017,  2024,  5152,  1998, 22190,  2003,  1037,\n",
      "          5152,  2406,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5962,  2000,  2774,  2055,  5850,  1998,  3282,  4808,  2006,\n",
      "          2026,  2126,  2000,  2026,  7554,  6370,  6594,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  1037, 19483, 21751,  2115,  2147,  2003,  2525,  7887,\n",
      "          2104, 10175,  5657,  2094,  1998, 20063,  2000,  2031,  2008,  2589,\n",
      "          2011,  2060,  6904, 13871, 12868,  2008, 26297,   102,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0140, 0.0140, 0.0140, 0.0140, 0.7540, 0.0520, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.3310, 0.3310, 0.3310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0550, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0550, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0640, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0550, 0.0550,\n",
      "         0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550,\n",
      "         0.0550, 0.0550, 0.0550],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5305,  7406,  2051,  2000, 18793,  2122,  2024,  8711,  2057,\n",
      "          2342,  2000,  2393,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2755,  2011,  1996,  2051,  1037,  9152, 26745,  2290,  6487,\n",
      "          2015,  2030, 10299,  1037,  2317,  4845,  2002,  2525,  2081,  2193,\n",
      "          9152, 23033,  2480,  1999,  1996,  7415,  2010,  6778,  2079,   102],\n",
      "        [  101,  2009,  2051,  2256,  2217,  3138,  1996,  7191,  2659,  2346,\n",
      "          1998,  2707,  4688,  2205,  1045,  2812,  2009,  2064,  2025,  2022,\n",
      "          2061,  3697,  2000,  3477,  2070, 14068,  2121,  7743,  2030,   102],\n",
      "        [  101,  2009,  2003,  2025,  2438,  2000,  2139,  6442,  2256,  6716,\n",
      "          2012,  2023,  2391,  2037, 16021,  9890,  5897,  1998, 19424,  5248,\n",
      "          7670,  2008,  2057, 10093,  6777,  5562,  1998,  3073,  2189,   102],\n",
      "        [  101,  1045,  3246,  8112,  1998,  2010, 13593,  9915,  2131,  3236,\n",
      "          2667,  3013,  1996,  2373,  2000,  2256,  8370,  1045,  1040,  2293,\n",
      "          2000,  2156,  2008,  5152, 13555, 11329,  5484,  8292, 29577,   102],\n",
      "        [  101,  2043,  1045,  2001,  2066,  2193,  1045,  2109,  1037,  6293,\n",
      "          2000, 13387,  1037,  4954,  3899, 10722,  4103,  2006,  1037,  2210,\n",
      "          6927,  3917,  9152, 13327,  2611,  1998,  2057,  4191,  2061,   102],\n",
      "        [  101,  2017,  2035,  7570,  2229,  2031,  2053, 25288,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2573,  2307,  2006, 14163, 13793,  2229,  2205,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1996,  4314,  4808,  2008, 11228,  2075,  2185,  9045,\n",
      "          5796,  2213,  6325,  2037, 12925,  1998,  8090,  2024,  2437,  2149,\n",
      "          2298, 25135,  2009,  1996,  2168,  3114,  1045,  2097,  2025,   102],\n",
      "        [  101,  3165,  4200,  1999,  2026,  6471, 15315,  5339,  2023,  9152,\n",
      "         13327,  4632, 28618,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2758,  1996,  5003,  2213,  6290, 11867,  2594,  3054, 18150,\n",
      "          2007,  1996,  2585, 27589,  2290,  6887,  7274,  7413,  2040, 12842,\n",
      "          2055,  8783, 15871,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 10514,  3366, 18414,  4017, 14181, 14876,  2041,  1997,\n",
      "          2023,  2406,  2017, 11809, 27256,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2122, 13012, 10258,  2075,  4632,  7570,  2229,  7987,\n",
      "         27225,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4701,  2013,  2054,  1045,  2031,  2042,  3773,  2009,\n",
      "          2003,  3492,  2919,  1045,  2228,  2039,  2000,  2193,  2610,  5136,\n",
      "          8046,  3436,  2138,  2027,  3685, 11997,  1037,  3761,  2013,   102],\n",
      "        [  101,  5310,  5310,  5310,  4136,  1996,  2088,  3791,  2062,  2293,\n",
      "          2016, 11277,  2014,  2269,  1998,  7659,  2032,  2757,  8840,  2140,\n",
      "          9117, 11669,  2012,  2049,  5409,   102,     0,     0,     0,     0],\n",
      "        [  101,  1045,  8239,  5223,  2017,  1045,  3246, 10047,  4550,  2013,\n",
      "          2023,  6752,  2004,  2574,  2004,  2825,  2030,  2842, 10047,  6069,\n",
      "          8011,  2017,  2091,  2007,  2033,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4190, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.1150, 0.1150, 0.1150, 0.1150, 0.0300,\n",
      "         0.0300, 0.0300, 0.1150],\n",
      "        [0.0080, 0.1200, 0.1200, 0.1200, 0.1200, 0.1200, 0.1200, 0.1200, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.2040, 0.2040, 0.2040, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.4900, 0.0340, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0170, 0.0170, 0.9160, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9320, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.7650, 0.0530, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0310, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4510, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.1670, 0.1670, 0.6320, 0.0120, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4190, 0.4190, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2017,  2035,  2317, 17219,  2015,  2024, 11669,  2100,  2004,\n",
      "          6616,  2009,  1996,  2193,  2301,  2017,  2035, 22418,  2003,  1037,\n",
      "         10576,  2017,  2035,  1038, 13687, 17353,  2024, 17276,  2004,   102],\n",
      "        [  101,  7955,  2323,  2131,  7144,  2651,  2049,  2120,  7144,  7743,\n",
      "          2154,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008, 11382,  3489,  2811,  3406,  3555,  2016,  2001,  1996,\n",
      "          6453,  2000,  1996,  3627,  1045,  3373,  2014, 15743,  6394,  2008,\n",
      "          1045,  2572,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  1037,  3203,  1057, 16303, 15878,  4765,  2050,\n",
      "          1998,  2981,  2017,  3298,  1037,  3835,  2482,  2017,  2219,  1037,\n",
      "          3835,  4545,  2017,  2024,  3376,  1998,  4569,  2021,  2296,   102],\n",
      "        [  101,  1045,  2031,  4149,  2093, 14464,  2006,  2023,  4440,  2027,\n",
      "          2024,  2035,  2317,  1998,  2304,  1045,  3984,  1996, 10800,  2000,\n",
      "          2022,  4342,  2003,  2008,  9787, 16419,  2964,  6742,  3012,   102],\n",
      "        [  101,  8398,  2038,  2053,  2224,  2005,  7489,  2021, 21237,  2015,\n",
      "          2024,  2986, 10166,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2036,  2356,  2065,  1045,  2424,  2068,  8702,  1998,\n",
      "          7743,  1045, 12444,  1998,  2001,  2066,  1057,  2546,  3398,  4365,\n",
      "         18168,  2290,  2748,  3398,  2026, 15197,  4313,  2140,  5598,   102],\n",
      "        [  101, 10130,  2003, 22300,  4808,  2114,  9272,  2005,  2576,  8704,\n",
      "          2061,  2066,  7490, 27256,  2015,  4288,  2111,  1999,  1996,  2171,\n",
      "          1997, 16455,  2317,  8986,  4288,  2111,  1997,  3609,  2000,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  2087,\n",
      "         12421,  2024,  7560,  8711,  2025,  3171,  5152, 16836, 18221,  2024,\n",
      "          2730, 15504, 20951,  4991,  1999,  4501,  1998,  7269,  2972,   102],\n",
      "        [  101,  4931,  9152, 13327,  2644,  2007,  2168,  2695,  2058,  1998,\n",
      "          2058,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  9422,  1037,  6904, 13871,  4140,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2502,  5213,  8224,  2003,  2128,  7559,  5732,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  4452,  3314,  2107,  2004,  1996,  5665,  3949,\n",
      "          1997,  2256,  2510,  8244,  7876,  1997,  2256,  9750,  1999,  3097,\n",
      "         21121,  2729,  5014, 19046,  1997,  2256, 11573,  8688,  1997,   102],\n",
      "        [  101, 16985, 18515,  2108,  1037,  7046,  9152, 13327,  2084,  1996,\n",
      "          2717,  2323,  2023,  3842,  2272,  4895, 23296,  5657,  2094,  2043,\n",
      "          2009,  3310,  2091,  2000, 16371, 13871,  8454,  1998, 19547,   102],\n",
      "        [  101,  5310,  2899,  5444,  2091,  2093,  2335,  2021,  4171,  6394,\n",
      "         16021, 10559,  3662,  2010,  2613, 18944,  1998,  2979,  2009,  4312,\n",
      "          2015,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3531,  2128,  3191,  2054,  2017,  2074,  6866,  2129,  2129,\n",
      "          2064,  2008,  2025,  4025,  6135,  2128,  7559,  5732,  2000,  2017,\n",
      "          2829, 19937,  2995,  2329,  2111, 21461,  2015,  2065,  2027,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0190, 0.0190, 0.2790, 0.2790, 0.0050, 0.0190, 0.0190, 0.0190, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0740, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.7520, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0600, 0.0600, 0.8640, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.1650, 0.1650, 0.6250, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0520,\n",
      "         0.0520, 0.0520, 0.0520],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.6860, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0260, 0.0070, 0.0070, 0.3710,\n",
      "         0.3710, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070]]), 'label': tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3984,  1996,  5181,  2245,  2008,  2009,  2001,  1996,  2171,\n",
      "          4419,  2008,  2081,  2111,  8694,  1999,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2009,  2168,  2043,  2017,  4607,  2151,  5499, 17276,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2156,  2028,  1997,  1996,  2307,  2477,  2055,  2633,\n",
      "          2074, 17927,  1996,  3291,  2007,  5181,  2003,  2043,  2017,  2156,\n",
      "          2505,  2027,  3046,  2000, 11867,  5833,  2125,  2017,  2064,   102],\n",
      "        [  101,  2009,  2051,  2000, 17757,  2673, 11284,  9321, 20128,  1998,\n",
      "          5365,  2013,  2085,  2006,  2424,  2060,  7570, 27982,  1045,  2097,\n",
      "          2196,  2175,  2000,  1996,  5691,  2153,  1045,  2097,  2196,   102],\n",
      "        [  101,  2033,  5168,  3564,  1999,  2465,  2007,  2026,  2767,  1998,\n",
      "          4760,  2125,  2026,  6007,  2000,  2014,  2298,  2026,  2767,  2115,\n",
      "          5637,  2003,  4760,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10469,  2015,  2040,  2024,  2061,  4986,  2055,  2931, 16011,\n",
      "          1998,  6905,  4769,  1996,  5152, 20731,  9040,  3291,  1999,  2885,\n",
      "          2030,  3844,  2039,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2469,  7510,  6197,  1997, 17768,  4974, 10722, 17811,\n",
      "          2035,  2058,  2762,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4855,  9997,  6007,  3500,  6007,  8218, 11875,  1998,  1037,\n",
      "          4880,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2001,  2141, 17276,  2017,  2020,  2141,  1037,  7743,\n",
      "          9152, 23033,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310, 14888,  2000, 24665, 10128,  7747,  2502,\n",
      "         11578,  1996,  3867, 22301,  2015,  2008, 25933,  4757,  2062,  2769,\n",
      "          2084,  3867,  1997,  1996,  2313,  4117,  4895,  4502, 18886,   102],\n",
      "        [  101,  2002,  2595,  2216,  6904, 13871, 12868,  2007,  2115,  6965,\n",
      "         23528,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3504,  2066,  1999,  2392,  1997,  3159,  2276,  1996,\n",
      "          2813,  2074,  2042, 12176,  2182,  2001,  2440,  1997,  2317,  4870,\n",
      "          2013,  4480,  2000,  5758,  1996,  2331,  2006, 16215,  2257,   102],\n",
      "        [  101,  5310,  2293,  2129,  2027,  5102,  1999,  6394,  4462,  4895,\n",
      "          3490, 22694,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2062,  2317,  9117, 11669,  8398,  6793,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998,  1996, 11382,  3489,  7657,  2370,  8840,  2140,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  2000,  1996,  9587, 25016,  5244,  2079,  2115, 19453,\n",
      "          2045,  2024,  2053,  8777, 25712,  1997,  7025,  1998,  2049, 21146,\n",
      "          4360,  2232,  2375,  1996,  2069,  2204,  9587, 25016,  2213,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0300, 0.0300, 0.0300, 0.0300, 0.4290, 0.4290,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0530, 0.0530, 0.0530, 0.0530, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.7220, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0170, 0.0170, 0.9010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0060, 0.0920, 0.0920, 0.0920, 0.0920, 0.0920, 0.3490, 0.0920, 0.0920,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.3250, 0.3250, 0.3250, 0.0060, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9160, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  1996, 15478, 25518,  4590,  2679,  6494, 15660,  1045,\n",
      "          3246,  2017,  2131, 15504,  1999,  2270,  2059,  3139,  1999, 10768,\n",
      "          9623,  5517,  8069,  1998,  5544,  2926,  6355,  3924,  2003,   102],\n",
      "        [  101,  2644,  2108, 27885,  5809,  2063,  2017,  2113,  4365,  2092,\n",
      "          3484,  1997,  2035,  4916,  2015,  2024,  2025,  2317,  6516,  2339,\n",
      "          2017,  2111,  7743,  1998, 13673,  2055,  2317, 14052,  2029,   102],\n",
      "        [  101,  5564,  2210,  3057,  2024,  2853,  1999, 13141,  7958,  2073,\n",
      "         10964,  2273,  2059,  4366,  2000,  2022,  2037, 11397,  2027,  2024,\n",
      "          2069, 15504,  1998, 13532,  2000,  1042, 21693,  1998,  8864,   102],\n",
      "        [  101,  5310,  4167, 27283, 10768, 10020,  2532,  5831,  2015,  2027,\n",
      "          2024,  2025,  4487, 25572,  3436,  2000,  2033,  2079,  2025,  4487,\n",
      "         10286,  2213,  1045,  9377,  2079,  2025,  4487, 10286,  2213,   102],\n",
      "        [  101,  3398,  2021,  2002, 28923,  2193,  5181,  1999,  2028,  2154,\n",
      "          2008,  3084,  7187,  2488,  2084,  2017,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2001,  4452,  1997,  2008,  1045,  2031,  9511,\n",
      "         25943,  2005,  2086,  2045,  2001,  1037,  2109,  2000,  2379,  2033,\n",
      "          2021,  2035,  1996,  5324,  2253,  2041,  1997,  2449,  2009,   102],\n",
      "        [  101,  2023,  2003,  1037,  2204,  2293, 14081,  1045,  2572,  5580,\n",
      "          2035,  1996,  1059, 20535,  3070, 11382,  9681,  4188,  2000,  2175,\n",
      "         21877, 10483,  2072,  2003,  2045,  1998,  2074,  4188,  2000,   102],\n",
      "        [  101,  5310, 10424,  7869,  1056,  1521,  9686,  5637,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9680,  6342, 10603,  7221,  1038, 13728, 11721,  2497,  6904,\n",
      "          2213,  3713, 10350,  2502,  5977, 23893,  8600,  3256,  1056,  2502,\n",
      "         11239,  2235,  2015,  2106,  2035,  2122,  6616,  7559,  2094,   102],\n",
      "        [  101,  2129,  2017,  2113,  9152, 23033,  2015,  7110,  1056,  2196,\n",
      "          2444,  2066,  2008,  2021,  2017,  2393,  7861,  3046,  2000,  2507,\n",
      "          2125,  1996,  3746,  2004,  2065,  2021,  2017,  7570,  2229,   102],\n",
      "        [  101, 12043,  1045,  1521,  2310,  2042,  2383,  2053,  4569,  2005,\n",
      "          1996,  2197,  2066,  2193,  2706, 10355,  2302,  1037,  4641,  3388,\n",
      "          2003,  8239,  2128,  7559,  5732,   102,     0,     0,     0,     0],\n",
      "        [  101,  2085,  2045,  2015,  1996,  5110,  6394,  4012,  6562,  2041,\n",
      "          2074,  2066,  2087,  2317,  2111,  2304,  3669,  6961, 18900,  3334,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9099,  2308,  2024,  2308,  1998,  2065,  2017, 21090,  6616,\n",
      "          2378,  4895, 14876,  7174,  2860,  2033,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2203,  2125,  2023,  2887,  2275,  2007, 11690, 16596, 24137,\n",
      "          4892, 24978,  2546,  2860,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3607,  1521,  9253,  6394,  2283,  4455,  2993,  1996,\n",
      "          2845,  4314,  3537,  2283,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2245,  1996, 20604,  5181,  2018,  1996,  2168, 26264,\n",
      "          2004,  1996, 14560,  2021,  2049,  1996,  2512, 20604,  3924,  2008,\n",
      "          2024,  2152, 26264,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0080, 0.0080, 0.4130, 0.4130, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0620, 0.0620, 0.0620, 0.0620, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0140, 0.0520, 0.7440, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0370, 0.0370, 0.0370, 0.5350, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.3980, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3980, 0.0070],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6770, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.7320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.2830, 0.2830, 0.0200, 0.0200, 0.0750, 0.0750,\n",
      "         0.0750, 0.0750, 0.0750, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0870, 0.0870, 0.0870, 0.0870, 0.0870, 0.0870,\n",
      "         0.0870, 0.0870, 0.0870, 0.0020, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  8840, 11263, 19766,  2140, 10047,  2025,  6616,  2368,  2007,\n",
      "          2122,  9152, 13327,  2015,  2651,   100,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2113,  2119,  1998,  2040, 14977,  2065,  2027,  2024,\n",
      "          2141,  2046,  7177,  1045,  2036,  2097,  2025,  2022,  4760,  1037,\n",
      "         12256, 17603,  2140,  4954,  5963,  2026,  7773,  2061,  2057,   102],\n",
      "        [  101,  2667,  2026,  2192,  2012,  5059, 18197, 15239,  1045,  2113,\n",
      "          2009,  2025,  1996,  2783, 18562,  2640,  1045,  2106,  2025,  4009,\n",
      "          2014,  2004,  1037, 17450,  9314,  1996,  2717,  1997,  2014,   102],\n",
      "        [  101,  5310,  2681,  2033,  2894,  7424, 10608,  8840,  2140,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2008,  5152,  3519,  2450,  6335,  4819, 13192,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2453,  2627,  2008, 13451,  7743,  2000,  2026,  8937,  2015,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  9565,  2098,  2023,  9152, 13327,  2000,  4000,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  2128,  7559,  5104,  2342,  4639, 10429,  1998, 13691,\n",
      "          3949,  2156,  2054,  6433,  2043,  2017,  3477,  1996, 10597,  2128,\n",
      "          7559,  5732,  2000,  2433, 11240,  2015,  2021,  3571,  2025,   102],\n",
      "        [  101,  2023,  2003, 10424,  8004,  4726, 19424,  2054,  1037,  9202,\n",
      "          2518,  2000,  2360,  2065,  2045,  2001,  1037,  3189,  2008, 10036,\n",
      "         14904,  4086,  6675,  2007,  9781, 23353,  2001, 12473,  2304,   102],\n",
      "        [  101,  5310,  3606,  2022,  2409,  2027,  2790,  3492, 19741,  2012,\n",
      "          2560,  2028,  6638,  6499,  2596,  2000,  2428,  2342,  1996,  6912,\n",
      "          2061,  2204,  2005,  2014,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2107,  1037, 16374,  6343,  4122,  2000,  9040,  2107,\n",
      "          1037, 19424, 15578,  3366,  9152, 13327,  2066, 12082, 14455,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2021,  2065,  1037,  2317,  2711,  2003,  4823,  1037,\n",
      "          2299,  2008,  2758,  9152, 23033,  1999,  2009,  2111,  2131,  5506,\n",
      "          2339,  2003,  2025,  2023,  1996,  2168,  2007,  6904, 13871,   102],\n",
      "        [  101,  4931,  4364, 14255,  2912, 14255,  2912,  7743,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  1996,  3124,  2008,  2573,  2012,  8934,  2232, 25483,\n",
      "          1998, 15504,  1037, 11690,  2003,  2008,  2157,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 19145,  1998,  8227,  2007,  1037,  2431,  6474,  9152,\n",
      "         13327,  4268,  1999,  1996,  2067,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2172,  2005,  2035,  2023,  5020,  6695,  8945,  7174,\n",
      "         10603,  1045,  2145,  2031,  2025,  2464,  1037,  2317,  3124,  2551,\n",
      "          1999,  2019,  2796,  4825,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3660, 0.3660, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.4780, 0.4780, 0.0090, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.2290, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0600, 0.0600, 0.0600, 0.2290, 0.0600,\n",
      "         0.0600, 0.0600, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.7220, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0500, 0.0500, 0.7260, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0550, 0.7980, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2071,  2074,  5674,  2012,  2560,  1045,  2113,  2025,\n",
      "          2000,  2892,  2017,  1045,  2097,  8367,  2017,  1996, 14163,  2480,\n",
      "          8609,  6359,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2453,  2074,  2228,  1045,  2572,  1037, 12873, 22889,\n",
      "          4904,  2021,  1045,  2097,  2031,  2017,  2113,  1045,  2572,  2941,\n",
      "          2019,  7789, 22889,  4904,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  3071,  4147,  2317,  2652, 24098,  2546,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  3331,  2055,  2111,  5980,  2025,  1049,  5796,\n",
      "          1998,  1996,  2168,  2064,  6611,  2005,  2317,  2273,  2323,  2057,\n",
      "          7221,  2317,  2273,  2030,  7221,  2068,  2013,  9343,  4409,   102],\n",
      "        [  101,  1996,  6638,  9152, 13327,  2038, 25671,  2006,  2014,  2067,\n",
      "          1998,  9047,  2229,  3652,  2041,  1997,  2014, 10974,  3593,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24247,  3648, 18227, 17276,  3158,  9305,  2964,  5171,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2048,  4314, 22212,  2015, 22822,  8458,  2037,  2879,  2046,\n",
      "          1037,  2611,  2023,  2003,  3599,  1996,  2034,  2177,  1997,  2111,\n",
      "          2040,  2097,  2022,  4654,  3334, 26972,  2104, 21146,  4360,   102],\n",
      "        [  101,  1037, 18286,  3310,  2000,  1037,  3056,  2237,  1998,  2022,\n",
      "          9148, 10649,  2229,  1996,  2308,  2187,  1998,  2157,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5064,  1045,  2439,  2650,  1997,  2129,  2116,  2273,  1045,\n",
      "          2031,  7771,  2007,  2021,  1045,  2064,  2145,  2171,  2035,  1996,\n",
      "          2308,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  1996,  2512,  2647, 11382,  3489,  2180, 12714,  2821,\n",
      "          2310,  2100,  2298,  2012,  1996,  8239,  2110,  1997,  2009,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2003,  2008,  2054,  2003,  2183,  2006,  2371,  2066,  1045,\n",
      "          2031,  2042, 11273,  2091,  1037,  2092,  1998,  7955,  2253,  2006,\n",
      "         10885,  2005,  1037,  2117,  1045,  2245,  2026, 13433, 14083,   102],\n",
      "        [  101,  5310,  5310,  2339,  2003,  2009,  2008,  3442,  2273,  2066,\n",
      "          2000,  3422, 22212,  2015,  2131,  5980,  2098,  2091,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4302,  4669,  2119, 16480,  1998,  2023,  2304,  2611,  1045,\n",
      "          2156,  2017,  2720, 10693,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 23033,  2015,  2428,  2022,  3046,  2532,  2562,  9805,\n",
      "          2105,  2074,  2000,  2022,  2006,  2070, 14636, 14202,  2100,  7743,\n",
      "          2229,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3288,  2067,  1996,  7777,  1997,  4831,  3923,  2462,  2061,\n",
      "          2057,  2064,  2031,  2009,  2041,  1059,  1996, 14163, 13793,  2229,\n",
      "          1998,  3102,  1996,  5181,  1999,  1996,  2832,  1059,  7619,   102],\n",
      "        [  101,  5310,  8840,  2140,  1045,  2572,  2667,  2524,  2000,  2131,\n",
      "          7463,  2125, 10474,  2157,  2085, 12731,  3372,  9152, 13327,  2128,\n",
      "          7559,  2094,  6616,  2317,  2373,  2145,  2893,  2109,  2000,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.6950, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0410, 0.5890, 0.0410, 0.0410, 0.0410,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0000, 0.0000],\n",
      "        [0.0080, 0.4430, 0.4430, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.2540, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0670, 0.0670, 0.0670, 0.0670, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.1490, 0.1490, 0.5660, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0820, 0.0820, 0.0820,\n",
      "         0.0820, 0.0820, 0.3110, 0.0820, 0.0820, 0.0820, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.1700, 0.6440, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.2160, 0.0150,\n",
      "         0.0150, 0.0150, 0.2160, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0420, 0.6080, 0.0420, 0.0110, 0.0420,\n",
      "         0.0420, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2304,  2111,  7627,  4027,  9508,  6328, 12619,  4862,  2332,\n",
      "          3781,  2035,  2018,  2400,  5103,  2058,  1996,  1061,  2869,  2005,\n",
      "          8398,  4073,  4804,  2051,  2920,  2007,  3532, 24827,  5110,   102],\n",
      "        [  101,  1045,  1040,  2738,  2131, 28273,  2011,  1037,  9152, 13327,\n",
      "         26419,  2232,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11721,  2497,  2154,  1045,  2228,  2009,  1037,  2307,  2154,\n",
      "          2000,  2131,  1996,  2773,  2041,  2000,  2035,  1997,  2256,  2814,\n",
      "          2155, 11190,  2953, 11451,  1998,  3507,  2406,  2386,  2055,   102],\n",
      "        [  101,  2017,  8037,  2323,  2022,  3517,  2000,  7939, 23709,  3401,\n",
      "         24247,  4808,  6206, 11560,  4808,  1998,  5499,  4808,  2127,  2008,\n",
      "          6433,  2507,  2149,  2035,  1037,  3338,  2013,  2115, 25506,   102],\n",
      "        [  101,  2360,  3062,  3022,  2106,  8307,  5254,  1996,  2341,  2000,\n",
      "          4768,  4950,  6090,  2015,  2000,  1037,  2304,  5435, 13681, 11021,\n",
      "          8000,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  2138,  2027,  2175,  2000,  2019, 10373,  2009,  2515,\n",
      "          2025,  2812,  1037, 16477,  2518,  2027,  2183,  2000,  2019, 10373,\n",
      "          2138,  2017,  2031,  2009, 16437,  2083, 11721,  2497,  2008,   102],\n",
      "        [  101,  5310,  1045,  2228,  1037,  2843,  1997, 14398,  3310,  2013,\n",
      "          6724,  2055, 10873,  1998,  3408,  2043,  1045,  3273,  5855,  2026,\n",
      "         14924,  2081,  2009,  3154,  2000,  2033,  2000,  6523,  2000,   102],\n",
      "        [  101,  2138,  2002,  2003,  2002,  9868,  2010,  2166,  2000, 24896,\n",
      "          1037,  5236,  8579,  2860, 16892,  2008,  2853,  2014,  2303,  2000,\n",
      "          1037,  8239,  9152, 13327,  2005,  1037,  8081,  2025,  2130,   102],\n",
      "        [  101,  2003,  2009,  2145,  1037,  8827,  2100,  6728,  2043,  1996,\n",
      "          4903,  2140,  2008,  2017,  2024,  2667,  2000,  8054,  2024,  2568,\n",
      "          3238,  8351,  2008,  2097,  3637,  3328, 11210,  2027,  2024,   102],\n",
      "        [  101,  1045,  2718,  2008, 21877,  3527, 11382,  3489,  6904,  2290,\n",
      "          6384,  9266,  2015,  2007,  1037,  2980, 16168,  2012,  1996, 25022,\n",
      "         12273,  3981,  6916,  6186,  2070,  2086,  2067,  2002,  2001,   102],\n",
      "        [  101,  5310,  5310,  2079,  2017,  2812, 27396,  2017, 14395,  2940,\n",
      "         24457,  2100,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2071, 10651,  1996, 13141,  2375,  2065,  1037, 13141,\n",
      "          8563,  2619,  2059,  2193,  2111,  2013,  2008, 13141,  2406,  2024,\n",
      "         17929,  2169,  2051,  2009,  6433,  2057,  3313,  1996,  2193,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  2002,  2003,\n",
      "          2008,  3124,  2008,  2064,  2025,  2202,  1037,  3279,  2130,  2295,\n",
      "          2010,  2136,  2003, 11669,  2612,  2002,  4122,  2000,  2954,   102],\n",
      "        [  101,  5796,  2213,  1998,  5925,  2024,  2652,  1996,  2679,  4003,\n",
      "          2021,  2009,  2003,  2428,  1996,  2755,  3123, 20147,  5799, 14264,\n",
      "         24503,  2000,  1996, 14163,  2480,  8609, 12865,   102,     0,     0],\n",
      "        [  101,  5310,  5310,  2017,  2488,  3844,  2039,  2017,  2113,  2498,\n",
      "          2055,  2149,  1998,  6027,  2003,  5499,  2406,  1524,  2061,  2064,\n",
      "          1057,  3531,  2031,  2070,  4847,   102,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2097, 14308,  4830,  4485, 24955,  2317,  2611,  7743,\n",
      "          2079,  2025,  2425,  2033,  2017,  2215,  2026,  9152, 13327, 10338,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0700, 0.2650, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.2650, 0.2650, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0290, 0.0290,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0780, 0.0780, 0.0780, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0560, 0.0560, 0.8010,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0700, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.6960, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0710, 0.0710, 0.0710,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.2710, 0.2710,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2087,  1997,  2008,  2417,  2003,  2349,  2000, 22611,  2137,\n",
      "         10823,  2079,  7425,  1996,  4167,  2757, 10687,  2962,  2099,  9580,\n",
      "          2000,  1996, 20010, 20026,  4765,  1997,  2037,  2219,  2336,   102],\n",
      "        [  101,  5310,  1045,  5223,  2017,  2907,  4487,  2015,  3796,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3398,  2045,  2035, 13157,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  9152, 13327,  2253,  2041,  2005,  1037,  5308,  1997,\n",
      "          5610,  2015,  1998,  1037,  4392,  2055,  1037,  2095,  3283,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2145,  2572,  2025,  1037,  9152, 13327,  7089, 27793,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2156,  2023,  2210,  2317, 10514, 28139, 22911,  2923, 10282,\n",
      "          2017,  2288,  2183,  2005,  2017,  2003,  2025,  2339, 10289,  8214,\n",
      "          2001,  2328,  2009,  2001,  2328,  2000,  3932,  1037,  2542,   102],\n",
      "        [  101,  5310,  2619,  3791,  2000,  2131,  2008,  4471,  2000, 17276,\n",
      "          9393,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2024,  2006, 10474, 11089,  6236,  2182,  1996,\n",
      "         16939,  9152, 13327,  6933,  2055,  2317,  2308,  2108,  4097, 22987,\n",
      "          2015,  2006, 28386,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 23848,  2050,  3713, 23301,  2135, 11721, 29292,  3286,  2043,\n",
      "          2097,  2619,  2655,  2137,  9152, 13327,  2015,  2041,  2005,  2108,\n",
      "         15554,  1045,  6655,  2065,  1996, 11808,  8711,  2018,  6670,   102],\n",
      "        [  101,  7743,  1045,  2572,  2428,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2088,  3432,  2097,  2025,  2022,  1037,  3647,  2686,  2127,\n",
      "          1996, 13555, 11263,  9102,  2015,  1998,  1062, 27511,  2015,  2024,\n",
      "          2908,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2064,  1521,  1056,  2903,  1061,  1521,  2035,  2428,\n",
      "          2022,  3564,  2105,  5983, 26666, 27130, 10329,  2013,  1996,  6240,\n",
      "         12901,  4318,  4632, 27130,  2129, 17276,   102,     0,     0,     0],\n",
      "        [  101,  1998,  2111,  2066,  2017,  1998,  2115,  6335,  2243,  2040,\n",
      "          2655,  2111, 11382,  9681,  9152, 13327,  2015, 11867,  6558,  5472,\n",
      "          9152, 13327,  2015,  1998,  8494, 12004, 12873,  6616,   102,     0],\n",
      "        [  101,  2941, 18993,  2193,  1997, 10823, 10797,  2008,  4126,  3336,\n",
      "          9588,  2015,  2066,  4426,  1998,  2317, 10514, 28139, 22911,  2923,\n",
      "          2611, 25219,  2078,  2024,  2025,  3599,  3819,  9908,  2021,   102],\n",
      "        [  101,  2009,  2003,  2200,  3733,  2000,  6232,  4697,  2317, 10134,\n",
      "          2065,  2027,  2024,  2725,  2242,  5236,  2066,  3554,  2060,  2317,\n",
      "         10134,  2138,  2027,  2024,  2013,  1037,  2367,  6102,  6080,   102],\n",
      "        [  101,  2515,  2308,  2374,  2031,  2037,  2219, 16405,  8337,  2015,\n",
      "          4696,  2138,  2216,  3289,  2008,  2288,  4222,  2131,  3195,  2296,\n",
      "          2674, 10259,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0730, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.7840, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.4740, 0.4740, 0.0090, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.7520, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0090, 0.0090, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.4660,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0090, 0.0090, 0.0090, 0.0090, 0.0320,\n",
      "         0.0320, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0760,\n",
      "         0.0760, 0.2890, 0.0760, 0.2890, 0.0760, 0.0760, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940,\n",
      "         0.0940, 0.0940, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0720, 0.0720, 0.0720, 0.2730, 0.2730, 0.0720, 0.0720, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2703,  4575,  2003,  1037,  2128,  7559,  2094,  2138,  4575,\n",
      "          2729,  2001,  2010,  3336,  2008,  2288,  5837,  1999,  3218,  4575,\n",
      "          2003,  5506,  8398, 16302,  2038,  1037, 18921, 19763,  3085,   102],\n",
      "        [  101,  1998,  2056, 16889,  2332,  1997,  1996,  5181,  1998,  2027,\n",
      "         15488, 12184,  2032,  2007,  2037,  2398,  2198,  2193,  2193,  4752,\n",
      "          6331,  2643,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2035,  1997,  2122,  9152, 23033,  2015,  2003,  2779,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2003,  2009,  2008,  5181,  2448,  1996,  2088,\n",
      "          2083,  7987, 26656,  2100,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2064,  2025,  1045, 27225, 20952, 17922,  5104,\n",
      "          2615,  2317,  2111,  2024,  2061, 12873,  2009,  4895, 22852,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2003,  2498,  1037,  2450, 14714,  2062,  2084,  2108,\n",
      "          2716,  2000, 12073,  2065,  2317,  2530,  2545,  2097,  2025,  2079,\n",
      "          2009,  2059,  2027,  2097, 21262,  2000,  1996, 14163, 13213,   102],\n",
      "        [  101,  2035,  2216,  3532,  2610,  3738,  1998,  2591,  3667,  1045,\n",
      "          2812,  2027,  2052,  2031,  2042, 22438,  2058,  1996,  5317,  2015,\n",
      "          1998,  2170,  2070,  9643,  2477,  2065,  2027,  1040,  2941,   102],\n",
      "        [  101,  1048,  2863,  2080,  5637,  2617,  2012,  1996,  2203,  2045,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2205,  2317,  2054, 14395, 14395,  8239, 14636,  2672,  2009,\n",
      "          2003,  2138,  1996, 10823,  2024,  2205, 12873,  2000,  4536,  1998,\n",
      "          4004,  2015,  2514,  2027,  3685,  3102,  2007,  1037,  5402,   102],\n",
      "        [  101,  5310,  2028,  1997,  2048,  2477,  2003,  6230,  2182,  2193,\n",
      "          2008,  2611,  2001, 15504,  1998,  2003, 28616, 24759, 26217,  2014,\n",
      "          3255,  2193,  1996,  2611,  2003,  9577,  2135,  9981,  1997,   102],\n",
      "        [  101,  1998,  2017,  1037,  6385, 16102,  2063, 11382,  3489,  5472,\n",
      "          9152, 13327,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3038,  5152,  2229,  2024,  2111,  2003,  2066,  3038,  4202,\n",
      "          9170,  2038,  5848,  2016,  2515,  2025,  1998,  2027,  2024,  2025,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7486,  2022,  4214,  2033,  7025,  9331,  6806,  4783,  2005,\n",
      "         27394,  2037, 21288, 11086,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3087, 15748,  1996, 18558,  2006,  2040,  2012,  7858,  2003,\n",
      "          1996,  2317, 10514, 28139, 22911,  2923, 16231, 16103, 10882, 21814,\n",
      "          2007,  1996,  2632,  3995,  3849,  2008,  2323,  4530,  2279,   102],\n",
      "        [  101,  1999,  4314, 26425,  2015,  7955,  2003,  2019,  6453,  7955,\n",
      "          2003,  6429,  2035,  2477,  2024,  5020,  2053,  3043,  2054,  1996,\n",
      "          2069,  8768,  4861,  2000,  2022,  2081,  2003,  2008,  8768,   102],\n",
      "        [  101,  6616,  2378,  5099,  6873,  2079, 27877, 24930,  2121, 11265,\n",
      "         17603,  4757,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.6030, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0220, 0.0060, 0.0060, 0.0060, 0.3130, 0.0820, 0.0820, 0.0820,\n",
      "         0.0820, 0.3130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.1090, 0.1090,\n",
      "         0.0290, 0.0290, 0.0020],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.3050, 0.3050, 0.3050, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.7630, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0570, 0.0570, 0.0570, 0.8280, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5875,  2135,  1045,  2387,  2019,  3720,  2022,  5302,  7088,\n",
      "          3070,  1996,  2755,  2008,  1996, 25670,  1037,  2317,  2711,  2003,\n",
      "          1996,  2062,  3497,  2002,  2003,  2000,  2022, 16939,  2061,   102],\n",
      "        [  101, 15501,  1045,  2079,  2025,  2228,  1045,  1040,  6592,  2009,\n",
      "          2012,  2023,  2391,  2205,  2172,  4126,  4321,  5533,  2011,  7489,\n",
      "          1998,  1996,  2755,  2008,  5841,  2024,  2893,  2524,  2000,   102],\n",
      "        [  101,  5310,  2054,  2038,  3047,  2000,  2035,  1997,  1057,  6904,\n",
      "         13871, 12868,  4394,  2033,  1045,  2031,  2973,  1999, 10309,  2005,\n",
      "          2028,  2733,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4067,  2643,  7025,  2038,  2081, 25022, 11890,  2819, 28472,\n",
      "         26471,  2031,  2017,  2464,  4895,  6895, 11890,  2819, 18380,  2094,\n",
      "          5980,  2015,  2027,  2024,  1996,  2087,  9200,  2559,  2477,   102],\n",
      "        [  101,  9808, 25636, 15593, 10861, 24728, 26199,  2273,  2618, 11382,\n",
      "          3489,  2033, 12324,  2050,  3948, 25176,  2015,  9765,  6279, 13820,\n",
      "          2015,  2137,  2891,  2139, 22640,  2099, 27427, 10735,  2004,   102],\n",
      "        [  101, 18204, 17276,  8006,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9444,  2404,  2830,  7758,  8117, 15361,  2063,  6213,  3449,\n",
      "          8551,  2072,  2004,  2825,  5889,  2000,  2377,  2198, 15675,  2488,\n",
      "          2031,  2042, 16644,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2115,  2028,  1997,  2216, 12731,  7666, 10851,  2039,\n",
      "          1996, 17141,  7381,  2015,  2061,  2017,  2064,  2131,  1037,  2489,\n",
      "          6849,  4157,  2115,  1037, 12731,  3372,   102,     0,     0,     0],\n",
      "        [  101,  2097,  2025,  3233,  2007,  1037,  5472,  9152, 13327,  5152,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  9152, 23033,  9457,  5172,  1996,  4602,  1997,  2035,\n",
      "          2051,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1057,  1054, 10140,  1056,  2546, 10047,  4469,  5637,\n",
      "          2005,  1057,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2151,  2406,  2008,  2038,  2053,  2175, 10019,  2073,  4480,\n",
      "          2024,  7420,  2000,  2994,  2041,  1997,  2138,  1997,  5377, 11560,\n",
      "          1998, 13141,  4808,  2003,  2053,  2936,  1037,  2406,   102,     0],\n",
      "        [  101,  7632,  2026,  2171,  2003,  3644,  1998,  1045,  2572,  4854,\n",
      "          2055,  1996,  2088, 18452,  2149,  5181,  1045,  2342, 16360, 25879,\n",
      "          8496,  2005,  5181,  2005, 10823,  2005,  4004,  2015,  2005,   102],\n",
      "        [  101,  5310,  5310,  2151, 22215,  2304,  2308,  1998,  2304, 19483,\n",
      "          2111,  2031,  2081,  2000, 24670,  5335,  2256,  3268,  2031,  2272,\n",
      "          2013,  2256,  2219,  4506,  5564,  2151,  2929,  2008,  2038,   102],\n",
      "        [  101,  2023,  6638,  9200,  9152, 13327,  7743,  2003,  1037,  3255,\n",
      "          1999,  2412, 23684,  4632,  3035, 15062,  5292, 23644, 23278, 23644,\n",
      "         23278,  3270, 23644, 23278,  1045,  2106,  2025,  2113,  4485,   102],\n",
      "        [  101,  5310,  2035,  2317,  2111,  2007,  3314,  1047,  2243,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.4010, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0380, 0.0380, 0.1460, 0.1460, 0.1460, 0.1460,\n",
      "         0.1460, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.1820, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0480, 0.0480, 0.0130, 0.0130, 0.0130, 0.1820, 0.1820, 0.1820,\n",
      "         0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7540, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0520, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0610, 0.8780, 0.0610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0360, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.1370, 0.1370, 0.5190, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.2320, 0.2320, 0.2320, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0020, 0.0020, 0.0020, 0.0300, 0.0300, 0.1130,\n",
      "         0.1130, 0.1130, 0.1130, 0.1130, 0.0020, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0040, 0.2320, 0.2320, 0.2320, 0.2320, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  4365,  1056,  2546,  2860,  2561,  2128,  7559,  2094,  2664,\n",
      "         12702, 23283, 24471, 17817,  2170,  2023,  3134,  3283,  5683,  3995,\n",
      "          3527,  9739, 16545,  2290,  3218,  8014,  2651,  4485,  2015,   102],\n",
      "        [  101,  5310,  1054,  1057,  2128,  7559,  5732,  1045,  3852,  2008,\n",
      "          1521,  2033,  2006,  1996,  3898,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1996,  6467,  2003, 21746,  2039,  2058,  2008,  2317,\n",
      "         17219,  2128,  7559,  5732,  8872,  1999,  3146,  2059,  2027,  2342,\n",
      "          2000,  2131,  2691,  3168,  2027,  2024,  5938,  2205,  2172,   102],\n",
      "        [  101,  5310,  5310,  5310,  2428,  2017,  2024,  2183,  2000,  2175,\n",
      "          2045,  2559,  2066,  1996, 27620,  2140,  7631,  1997,  1996,  2940,\n",
      "         24457,  2100,  2040, 15504, 12311,  3786,  2100,  1999,  8116,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  5310, 22872,  2066,\n",
      "          1045,  2056,  2298,  1999,  1996,  5259,  2017,  2453,  2215,  2000,\n",
      "         20703,  2013, 14739,  6737,  2009,  2025,  1037,  2204,  2298,   102],\n",
      "        [  101,  2045,  2442,  2031,  2042,  2205,  2116,  2434, 21490,  4630,\n",
      "          2317,  2414,  2545,  1999,  2008,  4545,  2311,  2061,  1996, 24815,\n",
      "          2072, 20067,  2414,  3664,  2741,  2461,  2070,  1997,  2010,   102],\n",
      "        [  101,  2005,  1996, 17688, 10098, 19181,  4305,  3995, 23088,  2630,\n",
      "         22681,  7407, 12264, 11290, 18367,  2015, 12264,  6967,  6147,  2317,\n",
      "          8079,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8398,  2003,  2025,  1037, 11382,  3489,  2002,  1037, 21146,\n",
      "         10322,  2891,  2175,  2100,  2040,  2573, 25493,  2005,  1996,  4712,\n",
      "          1997,  3956,  2034,  6043,  2175,  2128,  1999,  2115, 17276,   102],\n",
      "        [  101,  2096,  2027, 16405, 10623,  2075,  2489,  4613,  2006,  2591,\n",
      "          2865,  9826,  1045,  2228,  2027,  2580,  2489,  4613,  4773,  2000,\n",
      "          2156,  2129,  2116,  2111,  2272,  2182,  1998,  2054,  2027,   102],\n",
      "        [  101,  5310,  2707,  2026,  2047,  3105,  2006,  6928,  1998,  2342,\n",
      "          2000,  4965,  2070,  2047,  6007,  2013,  2004,  2891,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  1037,  2440, 10676,  3806,  1996, 11382,  3489,  6394,\n",
      "         27178, 18232,  8038,  2863, 16918,  2003,  1999,  2026,  2327,  2193,\n",
      "          8986,  7348,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2746,  2013,  2529, 21101,  2008,  4191,  2012,  1037,\n",
      "          2775,  9040,  6778,  2128,  6778,  3550,  2308,  2008,  2115,  3129,\n",
      "         15504,  1998, 17536,  2357,  2115,  2067,  2006,  1037,  2149,   102],\n",
      "        [  101,  5310,  5310,  2193,  2052,  2763,  4906,  3424,  7011,  6412,\n",
      "          1997,  4763, 16939,  5223,  3993,  1998,  3811, 24004, 20200,  2317,\n",
      "          2273,  1998,  4092,  1997,  2381,  2003,  2025,  2009,  5875,   102],\n",
      "        [  101,  3426,  7743,  1045,  2572,  1996,  4485,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2205,  2261,  6967,  2015,  2339,  2024,  2111,  2107,  6904,\n",
      "         13871, 12868,  4287,  1037,  8779,  2050,  2030,  2012,  2560,  1037,\n",
      "          5442,  1996,  4012,  9856,  2866,  2003,  2019,  9643, 18079,   102],\n",
      "        [  101,  2298,  2012,  2122,  5823,  4241,  7382,  3111,  1059,  2216,\n",
      "          2128,  7559,  5732,  2304,  8915, 16020,  4115, 14291,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.0130, 0.0130, 0.6880, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0480, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0510, 0.0510, 0.0510, 0.7380, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0520,\n",
      "         0.0520, 0.1960, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.1950, 0.1950,\n",
      "         0.0140, 0.0140, 0.0040, 0.0040, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510,\n",
      "         0.0510, 0.0510, 0.0510],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.2280, 0.0040, 0.0040, 0.2280, 0.2280,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2280, 0.0040, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8450, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2017,  5791,  2131,  1996, 20862, 26447,  2400,  2005,\n",
      "          9268,  1996, 11865, 25643, 11382,  3489,  4013, 15853, 22987,  1998,\n",
      "          6419,  2009,  2007,  2019, 12465,  3973,  8242, 23368,  4451,   102],\n",
      "        [  101,  2339,  2442,  9152, 13327,  2015,  7887,  2022,  2579,  2729,\n",
      "          1997,  2137,  9152, 13327,  2015,  3060,  9152, 13327,  2015,  2647,\n",
      "          9152, 13327,  2015,  4004,  5472,  9152, 13327,  2015,  4441,   102],\n",
      "        [  101, 14021, 21297,  2080,  2005,  1037,  2235,  7408,  1045,  2064,\n",
      "          2393,  2017,  2644, 11895, 13112,  2066,  1037, 28117, 22818, 17276,\n",
      "         16522, 21877, 21814,  8275, 11719,  2041,  1997,  1037, 17768,   102],\n",
      "        [  101,  2053,  4677,  9230,  2003,  1037,  3953,  3238,  6770,  1997,\n",
      "         11560,  9451,  2046,  1996,  2406,  2037,  5003, 14760,  1998,  3611,\n",
      "          2850,  2037,  3428,  1998,  5208,  2037, 14472,  2037,  5916,   102],\n",
      "        [  101,  2489,  4613,  2003,  2025,  2204,  3056, 10740,  1998,  4613,\n",
      "          2323,  2022,  6206, 16385,  3085,  2011,  2195,  2086,  2000,  2166,\n",
      "          1999,  3827,  1998,  2005,  2926,  2002,  5740,  2271,  5223,   102],\n",
      "        [  101,  2489,  2026,  8945,  2072,  1045,  2064,  2102,  5416,  1057,\n",
      "          2041,  2005,  4968,  4808, 10163, 25805,  2638,  1999, 16215,  2102,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3649,  3047,  2000,  9989,  4419,  2001,  2920,  2007, 14068,\n",
      "          2121,  4319, 21680,  2015,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1998,  2317,  9117, 11669,  1056, 28394,  3215,\n",
      "         12487,  3017,  3658,  3835,  3505,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  6548, 16168,  2017,  1998,  1045,  2119,  2113, 14560,\n",
      "          2735,  1998,  2448,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2758,  2033, 23644,  4313,  2004,  2002, 19237,  2125,  1037,\n",
      "         11867,  2594,  2474, 14536,  2075,  2004,  1037,  2317,  2879,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2053,  2002,  2003,  1037,  3282,  4518, 14255,\n",
      "          2989,  2417, 18278,  2026,  2155,  2003,  6881,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7929,  2502, 12868,  2051,  2000,  6297, 27741,  4143,  2050,\n",
      "          2007,  2008,  2128,  7559,  5732,  4469,  1037,  2053,  2625,  2019,\n",
      "          3691,  2084,  8141, 17886,  5577,  2129,  2009,  2234,  2000,   102],\n",
      "        [  101,  2048,  3980,  2193,  2129,  2106,  2017,  2131,  1037,  3861,\n",
      "          1997,  2026,  5980,  2193,  2040,  1996,  6616,  2404,  1037, 11382,\n",
      "          3489,  2732,  2006,  2009,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2125, 11382,  3489,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  2009,  1037,  8239,  2128,  7559,  5732,  2801,  2006,\n",
      "         11968,  2007,  2308, 15178,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2031,  2074,  5698,  5084,  2296,  2317,  2711,\n",
      "          1999,  1996,  2530,  2088,  2138,  2023,  2003,  6230,  2088,  2898,\n",
      "          1998,  2017,  2031,  2074,  3491,  2115,  7929,  2007,  9587,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0390, 0.5560, 0.0390, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0020, 0.0020, 0.0890, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0890,\n",
      "         0.0890, 0.0890, 0.0890, 0.0890, 0.0890, 0.0890, 0.0890, 0.0890, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0020, 0.0020, 0.0020, 0.0020, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0810, 0.0810, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0010, 0.0010,\n",
      "         0.0010, 0.0210, 0.0210],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0870,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0650],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8450,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.3160, 0.3160, 0.3160, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0780, 0.2950,\n",
      "         0.2950, 0.2950, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0430, 0.0430, 0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.1630,\n",
      "         0.1630, 0.1630, 0.1630, 0.1630, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.8080, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.1930,\n",
      "         0.1930, 0.1930, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.7220, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.9650, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0270, 0.0270, 0.3880, 0.3880, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.5630,\n",
      "         0.1480, 0.0100, 0.0100]]), 'label': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3817, 15033,  2001,  1037,  2158,  2002,  2001,  1037,  2502,\n",
      "          2158,  2021,  1045,  2001,  7046,  2061,  2002,  2743,  2066,  1037,\n",
      "          9152, 13327,  2039,  1037,  3392,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2001,  2175,  2078, 15301,  2021,  2049,  2025,\n",
      "          2026,  2492,  2317,  2291,  1999,  2148,  3088,  2038,  3908,  1996,\n",
      "          2304,  2568,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  1999,  1996,  2171,  1997,\n",
      "         19610,  7088,  3723,  8956,  8711,  3198,  2017,  3531,  2000,  3177,\n",
      "          2039,  1996,  6364,  1997,  2037,  6764,  3177,  2039,  1996,   102],\n",
      "        [  101,  2175,  6616,  1037,  9152, 13327,  2017,  6904, 13871,  4140,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2572,  5580,  2017,  2356,  2107,  2019,  9414,\n",
      "          3160,  2009,  2003,  1999,  2755,  2023,  2450,  2106,  2224,  1996,\n",
      "          2168,  4524,  2000,  3828,  1996, 16489,  2021,  2036,  2012,   102],\n",
      "        [  101,  2016,  4282,  2054,  2016,  2003,  2725,  2003,  3308,  1998,\n",
      "          2008,  2200,  2116,  2446,  2024,  2317,  2980,  4487, 13102, 19738,\n",
      "          6924,  2007,  1996,  3663,  1998,  2113,  3183,  2000,  7499,   102],\n",
      "        [  101,  6343, 22212,  2015, 10930,  2501,  2033,  2725,  2023,  2613,\n",
      "          4248,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045, 21392,  5669,  2115, 20704,  2072,  2017,  5791,\n",
      "          2298,  2066,  1996, 17276,  4632,  5916,  2666,  2008,  2017,  2024,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4897, 24471,  3239, 18510,  8736,  2157,  2000,  1996,  1051,\n",
      "         14693, 23270,  2389,  6841,  1997,  1996,  2492,  9875,  2580,  7025,\n",
      "          2205,  1999,  2755,  7187,  3080,  2564,  2001,  1037, 12316,   102],\n",
      "        [  101,  5310,  2009,  2003,  2919, 15876,  2078,  1060, 11636,  2080,\n",
      "          2065,  2017,  2131, 15504,  2079,  2025,  3198,  2005,  2393,  2017,\n",
      "          2031,  2042,  7420,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10047,  1996,  5637,  2028,  9152, 13327,  2017,  1996,  2028,\n",
      "          8239,  2026,  4632,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2624,  2050,  8945,  2140,  1045,  2293,  2017, 15765,  1045,\n",
      "          5223,  2017,  2149,  2912,  4500, 15765, 10686,  2232, 13583,  2100,\n",
      "         18454, 26086, 15765,  2532, 10936, 29278, 22507,  5310,  5310,   102],\n",
      "        [  101,  2115, 22418, 14163, 13793,  2063,  8295,  2231,  2003,  4288,\n",
      "          2017,  2125,  5514,  2084,  2151, 11686,  4998,  2013,  1037,  9210,\n",
      "          1997, 28101,  2115,  3228,  2115,  2406,  2039,  2074,  2066,   102],\n",
      "        [  101,  2919,  2909,  7361,  2006,  1996,  6616,  2007,  2149,  3769,\n",
      "          8091,  2023,  9152, 13327,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  2515,  2025,  2342, 26319,  2035,  2017,  2342,  2000,\n",
      "          2113,  2003,  2008,  9587, 25016,  5244,  2024,  2659, 26264, 19499,\n",
      "          2128,  7559,  5732,  9576,  2015,   102,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2003,  2008,  2178, 14068,  2121,  2040,  2180,  1996,\n",
      "         27352,  2895,  8906, 15213,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.7130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0080, 0.0080, 0.0080, 0.4310, 0.1140, 0.4310, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0070, 0.0070, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3910, 0.3910, 0.1030, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0110, 0.0110, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8450, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.3130, 0.0220, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.8580, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0580, 0.0580, 0.0580, 0.0580,\n",
      "         0.0580, 0.0580, 0.0580, 0.2210, 0.0580, 0.0580, 0.0580, 0.0580, 0.0580,\n",
      "         0.0580, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2053,  2062, 28063,  2733,  1999,  2047,  2259,  3426,  1996,\n",
      "         17276, 14992, 17276,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2049,  2138,  1997,  1996,  7777,  1997, 16686,\n",
      "          3593, 24443,  2078,  1996,  7486,  2024,  6233,  2893,  4167, 27283,\n",
      "          2007,  6270, 22143,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8042,  2001,  1037, 10975,  8490, 18900,  2923,  5627,  2000,\n",
      "          2147,  2007,  2241,  5181,  2156,  1996, 19346,  4277,  1998,  2007,\n",
      "          6904, 13871, 12868,  2000,  2019,  6698,   102,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  8909,  2243,  2339,  2094,\n",
      "          2017,  4957,  2009,  2000,  5782,  2000,  3102,  6206,  7489,  2017,\n",
      "          2079,  2113,  2008,  2512,  2317,  2111,  2064,  4965,  4409,   102],\n",
      "        [  101,  5674,  3241,  2008,  5310,  2003,  1037, 24004,  8458, 20891,\n",
      "          2138,  2002,  2056,  6904, 13871,  4140,  2320,  1048,  2863,  2080,\n",
      "          2071,  2025,  2022,  2033,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2292,  2149,  8849,  1996,  6569,  2015,  1037,  2617,  2043,\n",
      "          2009,  5609,  1045,  2001,  4909,  1037, 12538,  2400,  2005,  2108,\n",
      "          1037,  4408,  2402,  2518,  3061,  2362,  2893,  1037,  2177,   102],\n",
      "        [  101,  5310,  1045,  2572,  1037,  2317,  7743,  2061,  2009,  3100,\n",
      "          1045,  2064,  2360,  2023,  2079,  2025,  2033,  1041,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2648,  5887, 28536, 17752,  3917,  2356, 14910,  2050,  2065,\n",
      "          5152, 12865,  2001,  2183,  2000,  3477,  2014,  3423,  8236,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2193,  1998,  1045,  2628,  2026, 16160,  1045,\n",
      "          2196,  4669, 11265,  4590,  7384,  2196,  3427,  1996,  2128,  7559,\n",
      "          5732, 23648,  5092,  9610, 25370,   102,     0,     0,     0,     0],\n",
      "        [  101, 11184, 18220,  3594,  2010,  2019, 16585, 16383,  2000,  2360,\n",
      "          1996,  2616,  9152, 13327,  1998,  6904, 13871,  4140,  2302, 16360,\n",
      "          2121,  7874, 27466,  1998,  2061,  2116,  2111,  2006, 11721,   102],\n",
      "        [  101,  2941,  2028,  2518,  1045,  2572,  2025,  3154,  2055,  2003,\n",
      "          2065,  1996,  2313,  5835, 18278,  2193,  2193,  2086,  3283,  2043,\n",
      "          2027,  2020,  4359,  2000,  2069,  2193,  4903,  2140,  2187,   102],\n",
      "        [  101,  1045,  2253,  2000, 16233,  2000,  3191,  1996,  7928,  2005,\n",
      "          2008, 11895,  3363,  3720,  2005, 11184,  6173,  1998,  2471,  2035,\n",
      "          1996,  7928,  2191,  2033,  2514,  2066,  1045,  2572,  2006,   102],\n",
      "        [  101,  1045,  2215,  2000,  3046, 21006, 11754,  2063,  1998, 21006,\n",
      "          2606, 18623,  2229,  1998, 21006, 18059,  2015,  1998, 21006,  6007,\n",
      "          1998,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  1996, 14068,  2121,  2390, 18545,  1996,  3675,  2097,\n",
      "          8398,  2031,  1996,  4308,  2000,  2344,  3629,  2000,  2543,  2006,\n",
      "          2068,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6753,  9802, 22226,  1998,  2317, 22006, 26723,  6753,\n",
      "         14398,  1998,  4028,  1997, 14302,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12731, 10603,  2121, 20203,  3726,  2865,  4455,  8398,  1037,\n",
      "          4314,  4314, 11382,  3489,  2865,  4455,  2032,  2521,  2157,  5458,\n",
      "          1997,  2122, 11703, 20175,  3993, 10338,  6342,  9102,  2015,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440,\n",
      "         0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.1660, 0.0440,\n",
      "         0.0440, 0.0440, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4190, 0.0080, 0.4190, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0390, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0370, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0460, 0.0460, 0.1740, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "         0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "         0.0460, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0460, 0.6600, 0.0460,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0460, 0.0460,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  6603,  2065,  2017,  2031,  2204, 16958,  1999,  2308,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10163,  2156,  2129,  9152, 23033,  2015,  2022,  9680,  2075,\n",
      "          7743,  2229,  2027,  6719, 13041, 22418,  2041, 20702,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2035,  2017,  2831,  2055,  2003,  9152, 13327, 10338,  2015,\n",
      "          2033,  6732,  2017, 11891,  1998,  2131, 21746,  2011,  9152, 13327,\n",
      "         10338,  2015,  5570,  9346,  2098, 24004,   102,     0,     0,     0],\n",
      "        [  101,  5310,  7726,  2015,  5223,  2017,  5236, 16939,  4111,  2062,\n",
      "          2084,  2037,  4735, 11117,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11721,  2497,  2003,  1037,  2701,  2591,  2897,  2009,  2003,\n",
      "          5263,  2000,  2156,  2151,  8466,  2302, 25719,  2034,  2004,  2107,\n",
      "          2009,  2003,  2204,  2005,  9052,  4574,  2021,  4895, 10383,   102],\n",
      "        [  101,  8038,  5831,  4305,  2308,  2020,  2172,  4912,  2044,  2011,\n",
      "         18301,  9219,  2349,  2000,  2037,  3243,  6151,  4014, 12926, 26030,\n",
      "          5053,  4189,  3096,  2630,  2159,  2411,  9081,  2037,  4676,   102],\n",
      "        [  101,  3713, 23301,  2135, 23848,  2050,  2057,  2024,  2035,  3241,\n",
      "          2009,  2025,  1037,  2919, 17276,  2801,  2021,  4485,  2027,  2097,\n",
      "         14744,  2505,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2025,  5204,  1997,  2151,  4676,\n",
      "          2008,  2758,  2115,  2025,  3039,  2000,  4839,  2025,  5204,  1997,\n",
      "          2151,  4676,  2008,  2758,  2017,  2064,  2228,  2017,  2024,   102],\n",
      "        [  101,  2017, 27006,  2378,  7171,  2012,  1037,  7743,  2008,  1521,\n",
      "          2222, 11265,  3567,  2729,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2428, 22889,  4904,  4658,  7743,  1998,  2628,  2026,  6898,\n",
      "          2005,  2054, 10587,  6616,  2007,  2032,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  8239,  5223, 15536,  8873,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3087,  1045,  2156,  2007,  1037, 14255, 16898,  3013,\n",
      "          2030,  1037,  2431, 20665,  2518,  2012,  2147,  1045,  2655, 22212,\n",
      "          2015,  2027,  2024,  2467,  1996,  6304,  7743,  2075,  2012,   102],\n",
      "        [  101,  5310,  6861,  1045,  7110,  2102,  1057,  1054,  2074,  2046,\n",
      "         22212,  2015,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16480,  8737, 16480,  8737,  2003,  1037,  2502,  2304, 10336,\n",
      "          2008, 11286,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  3398,  2059,  2007,  2107,  7961,  1997, 17156,\n",
      "          2027, 18454,  2094,  2036,  2490,  2043,  2037,  5727,  2131, 15504,\n",
      "          2715,  2420,  2330,  3348,  9040, 10720,  2879,  2480,  3057,   102],\n",
      "        [  101,  5310,  2054,  2003,  1996,  4489,  2090,  2193,  2002,  2150,\n",
      "          5152,  1998, 15504,  2010,  2684,  1998,  2193,  2002, 15504,  2010,\n",
      "          2684,  1998,  2150,  5152,  1045,  2424,  2053,  4489,  7632,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0540, 0.0140, 0.0140, 0.7760, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2470, 0.0650, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0650, 0.0650, 0.2470, 0.0650, 0.0650,\n",
      "         0.0650, 0.0650, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0830, 0.3160, 0.3160, 0.0830, 0.0830, 0.0830, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.1830, 0.1830, 0.1830, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.2750, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.4060, 0.0070, 0.4060, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.1070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.5120,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240]]), 'label': tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  9554,  4149,  5396, 26509,  1998,  2026,  2317,  4632,  2064,\n",
      "          2025,  5047,  2008,  4485,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3442,  2317,  2158, 24240,  2000,  2156,  1037, 28616,\n",
      "         15707, 26942,  2594, 24004,  8458, 20891,  3713,  2012, 17117,  3034,\n",
      "          1999, 16880,  5436,  9792,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4921,  2063,  2042,  1999,  2023,  2522,  4904,  2854,  2005,\n",
      "          2035,  2026,  2193,  2086,  1998,  4921,  2063,  2196,  2657,  2151,\n",
      "          2572, 22420,  2078,  1999,  2082,  2267,  2510,  2030,  1999,   102],\n",
      "        [  101,  3783,  3189,  2611,  2373,  2611,  2373,  2611,  2373,  1998,\n",
      "          2264,  4004,  2015,  4593, 16083,  3177, 10080,  2085,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  7486,  2024,  5457,  2054,  2003,  2183,  2006,  1998,\n",
      "          2070,  7486,  4654, 18886, 23738,  2015,  2018,  4162,  9425,  2005,\n",
      "          7269,  1998,  4501,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2307,  2726,  2061,  4381,  2158,  1997,  9866, 12369,  5440,\n",
      "         13317,  3213,  2069,  2028,  4276,  3752,  2021,  3394,  8817,  6206,\n",
      "         17347, 14163, 18719,  2063,  8711,  2024, 23996,  6206,  2015,   102],\n",
      "        [  101,  2065,  1045,  2131,  2178,  3042,  2655,  1045,  2572,  3810,\n",
      "          2023,  7570,  2063,  2125,  6229,  4826,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  4364,  2061,  7098,  1997,  2370,  2002,  2288,  1037,\n",
      "          2868,  3038,  2298,  3566,  1045,  2288,  2046,  9152, 13327,  2267,\n",
      "          2651,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2425,  2008,  2000,  9152,  2050,  4267,  3008,  2030,\n",
      "          1061,  2099,  2214, 23564,  4360,  6498, 20766,  2078, 17754,  2388,\n",
      "          2044,  2014,  2269, 15504,  7129,  2014,  2672,  2425,  2008,   102],\n",
      "        [  101,  2188, 15239,  2015,  3086,  2017,  2442,  3477,  2061,  4952,\n",
      "          2485,  2000,  2054,  1045,  2360,  2079,  2025,  2202,  2023,  2004,\n",
      "          2053,  3722, 20622,  2138,  2023,  5939,  4502,  4485,  6433,   102],\n",
      "        [  101,  5310,  8112,  4608,  1998,  2713,  2003,  2019, 11113, 20936,\n",
      "          9323,  2006,  2637,  8112,  2323,  2022,  2218,  3625,  2005,  2296,\n",
      "          2137,  2040,  2003, 15504,  1998,  2730,  2011,  6206,  2015,   102],\n",
      "        [  101,  1037,  2317, 24262,  9107,  1996,  3451, 27226,  1997,  2605,\n",
      "          5499,  6368,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2025,  4527,  2008, 11235,  3779,  2081,  2009,\n",
      "          2000,  1996,  2862,  2021,  4527,  2008,  2256,  2193,  4960,  3124,\n",
      "          5064,  2038,  2053,  4424, 16011, 12087,  2114,  2032,  2030,   102],\n",
      "        [  101,  5310,  1996,  2417, 18278,  5583,  1998,  1996, 10017, 14398,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25283,  4890,  4638,  2033, 16643,  6844,  4638,  2034,  3058,\n",
      "          2007,  7985,  4638,  6534,  2100, 14901,  2282,  2006,  2034,  3058,\n",
      "          4638,  6206, 11560,  4638,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2064,  2074,  2156,  2009,  2009,  2003,  1996,  2407,\n",
      "          2021,  1045,  2079,  2025,  2156,  2339,  2045,  2442,  2022,  1037,\n",
      "          4434,  3140,  1045,  2079,  2025,  2514,  4198,  2000,  2137,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0780, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.2960, 0.2960, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.2030, 0.2030, 0.2030, 0.2030, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.1030, 0.1030, 0.1030, 0.3910, 0.1030,\n",
      "         0.1030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0150, 0.0150, 0.8100, 0.0560, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200]]), 'label': tensor([1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2130,  2026, 24529,  2050,  2522,  3667,  2182,  2066,\n",
      "          2017,  2215,  2008,  2813,  1998,  5223,  7489,  2008,  2172,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10930,  2611,  3109,  2050,  2831,  8082,  2105,  4138,  9152,\n",
      "         23033,  2015,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2304,  6620,  5637,  6620,  2317,  6620,  2115,  1037,  6394,\n",
      "          5637, 22747, 11589,  6824,  2361, 23848,  2050,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2613, 10458,  2518, 10930,  2317,  4632,  2412,  2056,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3889,  7221,  8540,  2003,  5637,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1048, 17137,  4430,  2000, 21927,  2000,  2026,  3507,  5181,\n",
      "          2041,  2045,  2089,  2017,  2031,  1037,  3407,  1998,  7965,  2193,\n",
      "         20996,  4095, 23325,  5162,  2232,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2049,  1999,  6027,  1998,  6239,  2205,  2024,  2035,\n",
      "          1997,  2216,  7025, 17710,  4241,  4095,  2386,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2166,  1037,  7743,  1998,  2059,  2017,  3280,  2008,\n",
      "          2339,  2057,  2131,  2152,  3426,  2017,  2196,  2113,  2043,  2017,\n",
      "          2024,  6069,  2175,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2092,  2008,  2054,  5817,  2056,  2000,  2131,  2014,\n",
      "          2000,  2681,  2021,  5817,  2001,  2036,  5191, 18467,  2453,  2191,\n",
      "          1037,  2693,  2006, 11940,  2138,  2008,  2074,  2129, 19483,   102],\n",
      "        [  101,  2023,  3849,  2066,  1996,  6534,  1997,  1037,  2307, 12014,\n",
      "          2057,  2097, 14574,  1996,  5181,  2182,  2017,  7486,  1998, 14560,\n",
      "         14574,  1996,  5181,  1999,  1996,  2690,  2264,  2131,  2041,   102],\n",
      "        [  101,  1998,  2043,  2017, 19148,  2008,  2187,  3358,  2576,  4243,\n",
      "          2069,  2215,  7489,  2000,  2272,  1999,  2037,  8817,  2061,  2008,\n",
      "          2027,  2071,  2131,  2062,  4494,  1999,  3864,  2017,  2707,   102],\n",
      "        [  101,  4365,  1045,  5223,  2023,  7743,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3548,  1998,  2610,  1997,  2885,  2024, 20895,  2075,  2037,\n",
      "          3032,  5094,  1996,  5181, 17607,  1996,  4750, 22064,  2080,  1999,\n",
      "          3863,  2005,  2037,  3477,  5403,  5705,  7167,  1997,  2068,   102],\n",
      "        [  101,  7188,  1037,  2317,  2711,  2758,  2242,  2003, 17276,  1524,\n",
      "          2030,  9350, 20318,  1524,  3198,  2068,  2054,  2009,  2965,  1998,\n",
      "          3422,  2068,  2707, 24646, 19567,   102,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2172,  5177, 11238, 28583,  4691,  2515,  2009,  5478,\n",
      "          2043,  2017,  2024,  3331,  2055,  2193,  2454,  7489,  1998,  1037,\n",
      "          3537,  2283,  2008, 11014,  2000,  4297,  4221,  2068,  2114,   102],\n",
      "        [  101,  5310,  7929,  8937,  2128,  7559,  2094,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.4400, 0.4400, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.1260, 0.1260, 0.1260, 0.1260, 0.1260, 0.1260, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0090, 0.0090, 0.1360, 0.1360, 0.1360, 0.1360, 0.1360, 0.1360, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.1490, 0.1490, 0.1490, 0.1490, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1490, 0.0030, 0.0030],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0090, 0.0090, 0.1350, 0.1350, 0.1350, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.1350, 0.1350, 0.1350],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  2940,  2004,  2467, 21438,  2009,  2039,  2009,  2025,\n",
      "          1996,  3412,  2157,  2009,  1996,  3412,  2187,  2008,  2448, 13141,\n",
      "         11073,  3454,  1998,  2107,  2066,  1996,  2990, 27241,  2015,   102],\n",
      "        [  101, 18528,  2378,  2053, 24004,  2021,  2017,  2024, 10140, 18712,\n",
      "          5575,  6499,  2080,  2053, 24004,  2021,  2115,  5980,  2001,  1999,\n",
      "          2026,  4632,  2197,  2305,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1037,  5236,  5152,  2066,  3160,  1045,  2572,  7537,\n",
      "          2115,  9421,  2125,  2438,  2000,  2831,  2041,  2115,  4632,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2644, 13599,  4004,  2015,  1996,  2744,  2003,  5041,  1998,\n",
      "          5218,  2000,  1037,  5294,  8674,  1997,  3226,  2381,  1998,  3922,\n",
      "          2264,  4004,  2015,  2024,  9398,  2148,  2264,  4004,  2015,   102],\n",
      "        [  101,  5310,  2009,  2139,  1038,  8523,  3695,  1037,  5622, 19279,\n",
      "          4232,  6206,  1998,  9587, 25016,  2213, 10129,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  9253, 14318,  4556, 12456,  2157,  2097,  7425,  1037,\n",
      "          5907,  4226,  2121, 26195,  1037,  5637,  8042,  1998,  1996, 16428,\n",
      "          2161,  1997,  1996,  7318,  2006, 14154,  4097,  6069,  2022,   102],\n",
      "        [  101,  2115,  2879,  1037,  9861,  1998,  2010,  7743, 20342,  5310,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3427,  2317,  2879,  6174,  2005,  1996,  2034,  2051,\n",
      "          2197,  2305,  1998, 23755,  4485,  2001,  2524,  8840,  2140,  6616,\n",
      "          4830,  7349,  2015,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2052,  2360, 27885,  5063,  2080,  2064,  2022,  2170,\n",
      "          1037,  9152, 13327,  2004,  2092,  2004,  2010,  3376,  2564,  2158,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2632, 13476, 13089,  2924, 28402,  2098, 12982,  7025,  9331,\n",
      "          6806, 11607,  2565,  2002,  2003,  2036,  1996, 17768,  4974, 10338,\n",
      "          6342,  9102,  2040,  7255,  2598,  5717,  1999,  2193,  2193,   102],\n",
      "        [  101,  8040, 28600,  2121,  2010,  6485,  8906,  9425,  2565,  2024,\n",
      "          3495,  3625,  2005,  5599,  2023,  5152,  9452,  2046,  2256,  2406,\n",
      "          1996,  7521,  2552,  1997,  2193,  2511,  1996,  2783,  4568,   102],\n",
      "        [  101,  2054,  2055,  1996,  2304,  4808,  1998,  2017,  2056,  2008,\n",
      "          2002, 13303,  2068,  1998,  2008,  2001,  2919,  2017,  2018,  2053,\n",
      "          2801,  2008,  1996,  3282,  2001,  6206,  2193,  9152, 13327,   102],\n",
      "        [  101,  2672,  2065,  7069,  2435,  2149,  2070, 22212,  2015,  2027,\n",
      "          2052,  2131,  1037, 16215,  2161,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2061,  2106,  1996, 13157,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2002,  2097,  2202,  2256,  2916,  2185,  2028,  2012,\n",
      "          1037,  2051, 21029, 12010,  2916,  1998,  2059,  2183,  2067,  2000,\n",
      "          2035,  2317, 18771,  2015,  1998,  4385,  2010,  2085,  9340,   102],\n",
      "        [  101, 26377, 12619, 19817, 27627,  2770,  1996,  4534,  3748,  1999,\n",
      "          4361,  2012,  1996,  5637,  6620, 22033,  1037, 17002,  7700,  2023,\n",
      "          5353,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.0110,\n",
      "         0.6250, 0.0110, 0.0110],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.1440, 0.1440, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.1440,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.4160, 0.1100, 0.1100, 0.1100,\n",
      "         0.1100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.5660,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1490, 0.1490, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.5130, 0.0360, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0670, 0.0670, 0.2530, 0.2530, 0.0670, 0.0670, 0.0670, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6090,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0610, 0.0160, 0.2320, 0.2320, 0.2320, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2017,  2113,  9152, 13327,  2015,  2293,  3492, 18411,  8376,\n",
      "          8292, 29577,  2098,  2007, 16290,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2323,  2025,  2008,  2022,  1037,  4341,  6510,  2005,  8398,\n",
      "          2545,  1045,  2018,  2053,  2801,  2040,  2002,  2003,  2196,  2657,\n",
      "          1997,  2032,  2021,  2013,  1996,  2171,  1045,  1040, 15559,   102],\n",
      "        [  101,  5221,  9038,  1999,  2166,  2003,  2025,  5962,  2000, 28776,\n",
      "         21906,  2063,  2096, 14684, 12588,  9231,  2050, 15270,  8883,  1999,\n",
      "          7359,  1998,  2065,  2008,  2515,  2025,  2360,  2317, 11669,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2003,  9701,  2028,  1997,  1996,\n",
      "          4485, 11484,  3032,  5310,  2001,  7727,  2000,  1037,  4485, 11484,\n",
      "          2406,  2515,  1037,  2488,  3105,  1997,  4346,  2005,  2049,   102],\n",
      "        [  101,  5310,  1996, 18201,  2003,  2027,  2042,  5637,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2024,  2017,  2128,  7559,  5732,  2023,  2003,  2025,\n",
      "          8935, 12873, 12054,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  2069, 14711, 14163, 23177,  2461,  1999,  1037,  8362,\n",
      "          9726,  1999,  1037,  2320,  2317, 17276,  3728,  2357,  2304,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8398,  2076,  1996,  2602,  1045,  2097,  2404,  7207,  1999,\n",
      "          7173,  8398,  2044,  1996,  2602,  2288,  2035,  3581,  2368, 23848,\n",
      "         10354, 26454,  2748,  4121,  3112,  2033,  2017,  4771,  1996,   102],\n",
      "        [  101,  5926,  2035,  6206,  7489,  2041,  2027,  2079,  2025,  7141,\n",
      "          2182,  2027,  2031,  2053,  2449,  2108,  2182,  2057, 12533,  2068,\n",
      "          2498,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  7098,  2000,  2022,  4013,  2166,  1998,  1045,  2572,\n",
      "          2053,  6394,  5292,  3270,  2017, 11867,  5833,  2075, 18667,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1038, 28074, 11382, 27327,  4328, 18066,  1996, 14165,  2008,\n",
      "          2003,  2716,  2011,  7804, 21352,  1999,  2796,  3226,  7610, 16913,\n",
      "          2072,  2170,  2005,  1037,  2929,  2000,  8439,  1996,  2308,   102],\n",
      "        [  101,  2087,  3644,  7896,  5769,  2008,  2054,  2057,  2655,  1037,\n",
      "         19113,  3375,  2003,  4117,  2007,  1037, 14522,  3375, 11867,  6657,\n",
      "         19859,  2007, 27890,  2129,  2842,  2064,  2009,  2022,  4541,   102],\n",
      "        [  101,  5310, 20976,  1049,  2546,  1057, 13366,  2128,  7559,  5732,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  7619,  2110,  1997,  2157,  3358,  2308,  8840,  2140,\n",
      "         26751,  2015,  1996, 19006,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  3398,  1998,  7865,  2097,  2025,  3466,  5152,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1057, 10424, 12377,  5104, 15966,  1037, 16522,  2030,\n",
      "          9152, 13327,  7939,  1057,  7110,  1056,  2053, 10424, 12377,  2094,\n",
      "          1997,  3067,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0190, 0.0190, 0.0730, 0.0190, 0.0190, 0.2770, 0.2770, 0.2770, 0.0190,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.2520, 0.2520, 0.2520, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.1960, 0.1960, 0.1960, 0.1960, 0.1960,\n",
      "         0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1730, 0.0120, 0.6580, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  1999,  2193,  2017,  2024, 17372,  2046,  4038,  3454,\n",
      "          2005,  1996,  2739,  2059,  2045,  2053,  2391,  1999,  2033,  2130,\n",
      "          3241,  1997,  2505, 12949,  2812,  2000,  2360,  2138,  2017,   102],\n",
      "        [  101,  5310,  2106,  2037, 14013,  2952,  3073,  2068,  2317, 14464,\n",
      "          2030,  2073,  2027,  4011,  2000,  3073,  2216,  2247,  2007,  1996,\n",
      "          8687,  2795, 10906,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  2025,  3713, 11113,  2102, 11690,  3314,  2017,\n",
      "          2024,  1037,  1047, 16340,  9761,  6289,  2748,  1045,  9471, 11810,\n",
      "          3683,  6559,  2165,  2185,  2026, 22212,  4003,   102,     0,     0],\n",
      "        [  101,  6904, 13871,  4140,  4632, 11190, 15239,  2015,  8038,  3363,\n",
      "          7110,  2102,  3769,  8091,  4485,  2461,  2182,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2033,  2108,  1037,  6904, 13871,  4140,  2006,  3721,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2614,  2066,  1037,  8239, 11382,  3489,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5622, 19279,  4232,  2273,  2024,  2893,  6643,  2361, 15488,\n",
      "         26492,  1998,  5622, 19279,  4232,  2308,  2024,  2893,  2037,  7279,\n",
      "          2072, 11792,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2024,  2062, 17276,  2084,  1037,  2304,  2611,\n",
      "          2017,  2323,  2203,  2115,  2166,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2438,  1045,  1049,  1037, 24004,  2074,  2066,  2009,  2003,\n",
      "          2061,  2057,  2109,  2152, 13284,  2002,  2288,  2010,  5637,  2227,\n",
      "          2006, 25312,  3593,  2061,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 10881, 22147,  2003,  1037,  9152, 13327,  2008,  7566,  2066,\n",
      "          2002,  2038,  1037, 28462,  1997,  7720,  2015,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2308,  2024,  2074,  2488,  4903,  2140,  2084,  2273,  2558,\n",
      "          2145,  2738,  2022,  1037,  3124,  2021,  6300,  2232,  2017,  2035,\n",
      "          2079,  5051, 16215,  2595,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  3071, 17210,  2000,  2031,  2037,  2219,  3802,  7295, 28696,\n",
      "          2618,  1045,  2228,  5181,  2024,  4689,  2005,  5782,  2009,  1999,\n",
      "          1996,  2690,  1997,  9576, 14163, 13793,  2229,  2021,  3649,   102],\n",
      "        [  101,  5310,  2339,  2323,  2017,  7221,  7489,  2013,  4082,  2235,\n",
      "          2449,  2296,  2449,  2707,  4873,  1998,  4826,  2008,  2097,  2507,\n",
      "          2111,  3105,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2017,  2024,  6069,  2022,  5189,  2006,  1045,  2290,\n",
      "          2055,  9680,  5130,  1998,  6293,  2039,  2005,  2308,  2664,  2017,\n",
      "          2031, 15504,  1998, 16999,  3674,  2308,  2164,  2870,  1998,   102],\n",
      "        [  101,  2052,  2293,  2023,  2000,  4148,  2074,  1996,  2245,  1997,\n",
      "          1037,  5980,  2625,  5472,  9152, 13327,  3084,  2033, 18138,  2870,\n",
      "          5870,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 20710, 22987,  2213,  2003,  2025,  2074,  2005,\n",
      "         10823, 13240,  7486,  4004,  2015,  2111,  2040,  5223,  2317,  2111,\n",
      "          2024, 20710, 22987,  2102,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0360, 0.0360, 0.0360],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.7220, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3220, 0.3220, 0.3220, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2710, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0740, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0200, 0.0200, 0.2820, 0.2820, 0.2820, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0410, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5950,\n",
      "         0.1570, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.4100, 0.4100, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.1260, 0.1260, 0.1260, 0.1260, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2025,  1037,  4365,  3969,  2502, 27428,  4603, 14163, 13793,\n",
      "          2229,  2007,  2053,  4145,  1997,  2529,  2916,  2033,  2063, 25818,\n",
      "          2232,  5152, 28144,  3512, 12053,  2063,  1047,  3270,  7911,   102],\n",
      "        [  101,  2023,  2003,  1996,  2087,  2128,  7559,  5732,  2518,  2017,\n",
      "          2097,  2156,  2651,  2017,  2024,  6160,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2040, 23755,  7743,  2003,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  8239,  5223, 29337,  1045,  5223,  2017,  1045,\n",
      "          5223,  2017,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003, 16436,  2066,  6171, 11757,  2200,  2200, 16436,\n",
      "          1996, 10960,  2013,  2122,  2154,  2214,  6090,  6906, 24905, 14163,\n",
      "         15379,  2015,  2003,  1037, 10467,  1997,  2129,  7078,  2969,   102],\n",
      "        [  101,  1996, 18301,  5210,  2758,  2035,  5181,  2193,  1998, 25602,\n",
      "          1999,  3956,  2903,  2008,  2643,  2580, 18301,  2478,  7048,  2000,\n",
      "         16385,  1996,  3741,  2008, 10107,  2000,  2022, 14248,  2122,   102],\n",
      "        [  101,  2009,  2025,  7596,  2671,  2000,  2156,  1996,  4957,  2090,\n",
      "          3742,  7521,  2013,  4485, 11484,  3032,  1998,  2414,  6080,  6997,\n",
      "          2414,  2038,  2042, 11963,  2098,  2007,  2659,  2166,  3060,   102],\n",
      "        [  101,  2298,  2017,  2020,  6179,  1999,  2008,  2017,  2435,  2033,\n",
      "          1996,  4495,  2000,  4671,  2026,  2219,  5328,  1998,  1037, 18876,\n",
      "          2114,  2029,  2000,  2275,  2009,  2021,  1045,  2572,  2589,   102],\n",
      "        [  101,  2028,  2137,  4152,  3480,  2011,  1037, 14163, 13793,  2063,\n",
      "          2013,  2122,  3032,  2122,  6794,  2323,  2022,  5112,  4077,  2068,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017, 11479,  2026,  2171,  3308,  1998,  2026,  2171,  2003,\n",
      "          6719,  1999,  2392,  1997,  2115,  2227,  2025,  2069,  2024,  2115,\n",
      "          3741, 13475,  1999,  5472,  9152, 13327,  2015,  2021,  2049,   102],\n",
      "        [  101,  1045,  3246,  2045,  1037, 10369,  3888,  3518,  2030,  2012,\n",
      "          2560,  2619,  2323, 11010,  2070, 10369,  2482, 15671,  8583,  2006,\n",
      "          2073,  2027,  2024,  2183,  2000,  3857,  2216,  9587, 25016,   102],\n",
      "        [  101,  2017,  2074,  4102,  2264,  4004,  2015,  2000,  5472, 25518,\n",
      "         15776,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2745,  7583,  7178,  1045,  5223,  2115, 18453,  2017,  2081,\n",
      "          2017,  2793,  7743,  1998,  2085,  2017,  2131,  2000,  3637,  1999,\n",
      "          2009,  2017,  2024,  2589, 12731,  3372,  6616,  2125,  1998,   102],\n",
      "        [  101,  1998,  1996,  7324,  2006,  3896,  2024,  1037,  7743,  6719,\n",
      "          2004,  2308,  5490, 13860,  4063,  2037,  3539, 12436, 20876,  2076,\n",
      "          3923,  2476,  2964,  2086,  1998,  7392,  2091,  2007,  2659,   102],\n",
      "        [  101,  1045,  3984,  2017,  2024,  2025,  2204,  2012,  6747,  2129,\n",
      "          2116,  3655,  2031, 12461,  5296,  1998, 27775,  2129,  2116, 17276,\n",
      "          2015,  2031,  2027,  2580,  2129,  2116,  2034,  2088, 24784,   102],\n",
      "        [  101, 10166,  2061,  2008, 13451,  2304,  2611,  2001,  4688,  2055,\n",
      "          2068,  2317,  3337,  6276,  2014, 14436,  2015,  2125,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0120, 0.0120, 0.0120, 0.0120, 0.0470, 0.0470, 0.6730, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0410, 0.0410, 0.0410, 0.0410, 0.5890, 0.0410, 0.0410, 0.0410, 0.0410,\n",
      "         0.0410, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0810, 0.3060, 0.3060, 0.3060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0050, 0.0180, 0.0050, 0.0050, 0.2520, 0.2520, 0.2520, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0180],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5870, 0.1550, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0830, 0.0830, 0.0830, 0.0830, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0830, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0920, 0.0020,\n",
      "         0.0020, 0.0240, 0.0920, 0.0920, 0.0920, 0.0920, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0020, 0.0020, 0.0020, 0.0020, 0.0920, 0.0920, 0.0920, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0240, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0240, 0.0060],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310, 13350,  2215,  2068,  2182,  2004,  7489,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3524,  8814,  2102,  4942, 15728,  2003,  1037, 11690,  2482,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2165,  2074,  2028,  2454,  8711,  2000,  3288,  2041,\n",
      "          1996,  2601,  2217,  1997,  2647,  4331,  1998,  4895, 21678,  2571,\n",
      "          8777,  6867,  2079,  2057,  2428,  2228,  2045,  2282,  1049,   102],\n",
      "        [  101,  5310,  5310,  4794,  3305,  3085,  2027,  2031,  9706, 25785,\n",
      "          2339,  7486,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2228,  2009,  2051,  2005,  2178,  7560, 13970,  4095,\n",
      "          2069,  2518,  1996, 14163, 13793,  2229,  2412,  2106,  2008,  2001,\n",
      "          4276,  1037,  4485,  2001, 14052,  2055,  2193, 23689,  1997,   102],\n",
      "        [  101,  5791,  2043,  2027,  2318,  7694,  4004,  2308,  1998, 11382,\n",
      "          3489,  7743,  2229,  2058,  8119,  2317,  2308,  1045,  2354,  2027,\n",
      "          2020, 12045,  3424,  2317,  6904, 13871, 12868,  6616,  2068,   102],\n",
      "        [  101,  2605,  3471,  2024,  2025,  2183,  2000,  8081,  3209,  1998,\n",
      "          2023,  2886,  2001,  2074,  1996,  5955,  1997,  1996,  3256,  4059,\n",
      "          4895,  8663, 13181, 11001,  7521,  2038,  2042,  2019,  7552,   102],\n",
      "        [  101,  2417, 10966,  2288,  2170,  2304,  2214,  1998, 24004, 20200,\n",
      "          2035,  2011,  2037,  2219,  5470,  9527,  1045,  2064,  1521,  1056,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2053, 29094,  2064,  8246,  2004,  2092,\n",
      "          2004,  1996, 17357,  1998,  2823,  2111,  2131, 15504, 11324,  2015,\n",
      "          2323,  2022,  3423,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5035, 18528,  4895, 11586, 27584, 16093, 16294,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 14717,  2078, 11560, 15508,  2055,  2010, 21025,  5910,\n",
      "          2054,  2210,  3815,  1997,  4737,  2010, 26136,  2100, 19124, 24423,\n",
      "          3499,  2032,  2000,  2031,  2144,  2002,  2003,  6719,  4039,   102],\n",
      "        [  101,  8871,  2026,  2035,  2317, 21994,  2005,  2026,  6209,  2027,\n",
      "          2031,  2908,  3756,  8840,  2140,  1045,  2215,  2000,  5390,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1998,  2043,  8322,  2102,  2515,  2025,  2147,\n",
      "          2043,  2308,  2024,  2108, 15504,  2074,  2079,  2498,  1998,  2360,\n",
      "          2092,  2057,  2097,  2147,  2006,  9740,  2612,  1997,  2667,   102],\n",
      "        [  101, 21090,  2057,  2323,  2022, 21442, 26336,  2000,  1996,  2128,\n",
      "          7559,  5732,  1998,  2096,  2027,  2323,  2025,  2022,  2022,  7936,\n",
      "          2000,  8843,  2030,  2187,  2894,  2105,  2336,  2027,  2064,   102],\n",
      "        [  101,  5875,  3602,  2000,  2969,  5646,  2029,  6064,  3231,  1996,\n",
      "          5611,  2231,  3594,  2000,  3231,  7489,  2061,  2008, 15140, 28616,\n",
      "          8720,  2015,  2064,  2022,  9511,  2076, 26822,  4430,  2193,   102],\n",
      "        [  101,  1045,  3728,  2777,  1037,  3394,  2976,  6688,  2040,  2772,\n",
      "          2039,  2000,  2022,  1037,  3677,  2005,  9042,  8711,  2007,  2250,\n",
      "          1038,  1038,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0690, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.2610, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0270,\n",
      "         0.3880, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0270, 0.0270, 0.3880, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0500, 0.0500, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.1650, 0.1650, 0.1650, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0020, 0.0020,\n",
      "         0.0020, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2342,  2619,  2000,  2272,  2156,  1996,  5637, 15912,  3185,\n",
      "          1059,  2033,  1045,  2064,  2025,  2156,  2009,  2894,  2153,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6289,  5843,  3406,  5677,  2029,  2028,  1997,  2017,  2317,\n",
      "          7743,  2229,  2024,  3201,  2000,  2022, 12581, 10206,  2005,  1037,\n",
      "          3204,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  1521,  2128,  2128,  7559,  5732,  1517,  2066,\n",
      "          2941,  1517,  2008,  3632,  2005,  2035,  2017, 28625,  6483,  2111,\n",
      "          2041,  2045,  2004,  4381,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3297,  2005,  4288,  2019, 11560,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616, 12727,  1996,  9152, 13327,  7089,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2187,  2515,  2025,  2507,  1037,  6616,  2055,  5694,\n",
      "          1997,  5152,  7404,  4491,  2030,  9040,  2015,  2027,  2156,  2068,\n",
      "          2004,  2919, 10975,  2037,  5221,  5142,  2003,  2467,  2008,   102],\n",
      "        [  101,  2748,  1998,  2053,  1996,  2613,  3277,  2003, 25707,  1997,\n",
      "          7177, 28946,  2035,  7489,  2052,  3322,  2022, 22023,  2005,  2833,\n",
      "         12133,  2740,  5427,  4385,  1999,  6187,  2106,  2008,  2009,   102],\n",
      "        [  101,  8840,  2140,  2145,  3241,  2055,  1996,  6394,  4477, 13950,\n",
      "          2075,  2041,  1996,  2146, 10689,  2044,  2066,  2048,  2420,  1997,\n",
      "         24209, 20486, 10196,  2023,  4485,  2003,  6069,  2131,  3748,   102],\n",
      "        [  101,  5310,  6195,  2027,  2187,  2041,  1996,  2317,  3287, 10044,\n",
      "          2013,  1996,  4812,  2348,  2002,  2018,  2042,  2443,  1999,  1996,\n",
      "         12087,  1045,  2228,  2016, 17210,  2000,  2202,  1996,  4035,   102],\n",
      "        [  101,  5310,  5621,  1996, 17276,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2292,  3442,  2015,  3442,  1998, 22212,  2015, 22212,  1999,\n",
      "          3521,  1998,  2644,  2108,  2107,  2019,  3834,  8239, 24761,  6508,\n",
      "          2265,  2125,  2055,  2296,  4365,  2518,  2017,  2024,  2025,   102],\n",
      "        [  101,  5310,  2061,  4903,  2140,  2079,  2025,  2175,  2000,  2277,\n",
      "          4647,  1045,  2056,  4147,  2630,  6312,  2020, 17276,  2025,  2138,\n",
      "          2115,  2307,  5916, 18210, 11530,  2356,  2115, 22212,  4632,   102],\n",
      "        [  101,  2009,  1037, 10003,  2966,  2755,  2008,  2128,  7559,  5104,\n",
      "          2079,  2025,  2113,  2129,  2000,  2224, 26136,  6593, 14505,  1999,\n",
      "          1037,  6251,  2009,  2036,  1037,  2755,  2008,  2069,  1037,   102],\n",
      "        [  101,  2304,  2273,  2288,  2000,  3789,  1998,  2022,  2343,  2077,\n",
      "          2317,  2308,  2061,  1045,  2079,  2025,  2215,  2000,  2963,  2055,\n",
      "         23382, 20502,  2015,  3801,  2024,  1996,  9152, 13327,  1997,   102],\n",
      "        [  101,  1517,  2025,  2000,  2022,  1037, 22889,  4904,  2023,  2220,\n",
      "          2021,  1045,  2215,  1044,  4859,  8292, 29577,  2098,  1044, 24573,\n",
      "          8292, 29577,  2098,  1517,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  3968,  6292,  1043,  2290,  9761,  2015,  2228,  2108, 16939,\n",
      "          2003,  7929,  1045,  5223,  6904, 13871, 12868,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.7520, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0540, 0.0540, 0.0540, 0.0540, 0.7710, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1040, 0.1040, 0.0070, 0.3930, 0.3930, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.3010, 0.3010, 0.0210, 0.0210, 0.0210, 0.0210, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0320, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4600, 0.1210,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1160, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.1160, 0.1160, 0.1160, 0.1160, 0.1160,\n",
      "         0.1160, 0.0020, 0.0020],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.5080, 0.1340, 0.1340,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1570,\n",
      "         0.1570, 0.5970, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2033,  2821,  2879,  1045,  2633,  2215,  2000,  7367,  2860,\n",
      "          1998,  2572,  3407,  2055,  2009, 20014,  7946,  3512,  4301,  3102,\n",
      "          4426,  2033,  1059,  2232,  1517,  4167,  5698,  3398,  3071,   102],\n",
      "        [  101,  2530, 13481,  2142,  2114,  1996, 14092,  4942, 28600,  2319,\n",
      "          8494, 14540, 14428, 10882, 24658,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6517,  2129,  2057,  6570,  3057,  2129,  2000,  2025,  2131,\n",
      "         15504,  2079,  2025,  3328,  2012,  2305,  4287, 11565, 12509,  2079,\n",
      "          2025,  3404, 12358,  2612,  1997,  4252,  3337,  2129,  2025,   102],\n",
      "        [  101,  4931,  2175, 10139,  5244,  2026,  2171,  2003,  8181,  1998,\n",
      "          1045,  2074,  5720,  2000,  2643,  1998,  2054,  2106,  2002,  2360,\n",
      "          2000,  2017,  2008,  1996,  2455,  1997,  1996, 14560,  7460,   102],\n",
      "        [  101,  2023,  9152, 23033,  2003,  3564,  2408,  2013,  2033,  1998,\n",
      "          2562, 22889, 12243,  2075,  5637,  2111,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 23156,  6160,  2000,  1996,  2317, 10189,  4801,  8579,  2121,\n",
      "          2252,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049, 12873,  7743,  2161,  2035,  2095,  2461,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  2023,  2003,  2128,  7559,  5732,  1998,  1045,  2572,\n",
      "          2025,  4699,  1999, 11131,  2009,  2582,  2009,  3458,  1037,  5949,\n",
      "          1997,  2051,  2000,  2404,  2616,  1999,  7243, 15076,  2043,   102],\n",
      "        [  101,  5310,  2036,  2045,  2066,  2317,  6505,  2066,  2428,  2317,\n",
      "          2317,  2099,  2084,  1037,  2317,  2711,  2317, 17498, 13329,  2483,\n",
      "          4385,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2317, 12655,  2644,  3038, 12593,  4119,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2151,  9152, 23033,  2008,  6154,  1999,  2931, 12486,  1998,\n",
      "          5587,  2000,  2009,  2612,  1997,  2667,  2000,  2644,  2009,  2003,\n",
      "          1037,  2878,  3143,  6904, 13871,  4140,   102,     0,     0,     0],\n",
      "        [  101,  5409,  6707,  2412,  2323,  3726, 15920,  2125,  1996,  7395,\n",
      "          1997,  2035, 18076,  2730,  2068,  2074,  2066,  1996, 14560,  5171,\n",
      "          4828, 12731,  3600, 16405, 18719,  2229,  2339,  1996,  6616,   102],\n",
      "        [  101,  1045,  2572,  2183,  2000, 13558,  1996, 19318,  3185,  1045,\n",
      "          2228,  1045,  2074,  2079,  2025,  2228,  1045,  2031,  1996,  3977,\n",
      "          2000,  2202,  2006,  2008,  2504,  1997,  2317,  3287,  2601,   102],\n",
      "        [  101,  5310,  5310,  2009,  2001,  2025, 12085,  2009,  2001,  2070,\n",
      "         12487,  1042,  5004,  2140,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2008,  2015,  9826,  2128,  7559,  5732,  1998, 12726,\n",
      "         24471, 22650,  2006,  2193,  2095,  2214,  4268, 20912,  2070,  2024,\n",
      "         11704, 12726,  2812,  2440,  1997,  3658,  2021,  2008,  1057,   102],\n",
      "        [  101,  2065,  2017,  7200,  2115,  2063,  1037, 11382,  3489,  1998,\n",
      "          1037, 27793,  2102,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0310, 0.4480, 0.4480, 0.0310,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0030, 0.0030, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1800, 0.1800, 0.1800,\n",
      "         0.1800, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.3230, 0.3230, 0.3230, 0.0060, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.4280, 0.4280, 0.1130, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.1620, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.6140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0090, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.6950, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8350, 0.0150, 0.0150, 0.0580,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2023,  2003,  1996, 17276,  1045,  5223,  2009,  2182,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4639,  2075,  2061, 17276,  1045,  2106,  2025,  3696,  2039,\n",
      "          2005,  2023,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061, 10474,  2003,  2085, 14889,  2111,  2041,  2153,  2009,\n",
      "          2074,  2062,  1997,  1996,  2168, 17276, 16011,  2011,  1037,  2521,\n",
      "          2187,  6555, 15158,  2923,  2194,  2027,  2024,  2025,  4699,   102],\n",
      "        [  101,  5310,  7743,  2302,  2033,  1057, 19483,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310, 10166,  1996,  2304, 13681,  2111,  2024,\n",
      "          2035,  2317,  2040,  2052,  3726, 11445,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2069,  9152, 13327,  2015,  9040,  2193,  2095,  2214,  2308,\n",
      "          1996, 14163,  2232,  4487,  2243,  4895,  3334, 22903,  1997,  8438,\n",
      "          2003, 11158,  1999,  1996,  5860, 20026, 19185, 16958,  2008,   102],\n",
      "        [  101,  5310, 11382,  3489, 14855,  5620,  2039,  2011,  2193, 14595,\n",
      "          2015,  2129, 13004,  2008,  2514,  1048,  2213,  7011,  2080,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  4797,  2028,  2154,  2008,  2210,  9152, 24679,  2102,\n",
      "          2097,  2022,  4755,  2041,  1999,  1996,  2330,  8239, 11870,  4742,\n",
      "          2121,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2045,  2024,  2193,  4551,  7486,  1999,  1996,\n",
      "          2088,  2644,  2236,  6026,  2017,  2417, 18278, 16655,  8566, 12921,\n",
      "         25189,  2502,  4140,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  2179,  2195,  4790,  9104,  2119,  2024,  5799,\n",
      "          2000,  1996,  5152, 12865,  2339,  2024,  2122,  2308,  2025,  2104,\n",
      "          4812,  2339,  2003,  2025,  8112,  3447,  2104,  4812,  2005,   102],\n",
      "        [  101,  5310,  5310,  1045,  2572,  2193,  7570,  2063,  2175,  5390,\n",
      "         24471,  2317,  4000,  4873,  2842,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2106,  2025,  2031,  2026,  5593, 20275,  2011,  3140,\n",
      "          2082,  3902,  2075,  1045,  2001,  2525,  2542,  1999,  2019,  6377,\n",
      "          5101,  1998,  2253,  2000,  2019,  6377,  2082,  2021,  2008,   102],\n",
      "        [  101,  2002,  2074,  6886,  2008,  7570,  2063,  2039,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2035, 28257,  2831,  2378, 10094,  1045,  2288,  2115,\n",
      "          7743, 16021, 23091,  2288,  2115,  7743, 29270,  2225,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3342,  2273,  2009,  2025,  4424, 16011,  2043,  2308,  2024,\n",
      "          1996,  2566,  4523,  6569,  4783,  8167, 28629, 17643, 29325,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  3308,  2065,  6617,  3685,  8984,  2000,\n",
      "          2202,  2729,  1997,  2037,  8765,  2302,  2478,  6206, 12114,  2027,\n",
      "          2342,  2000,  5271,  2037,  3888,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1550, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0140, 0.7480, 0.0140, 0.0140, 0.0140, 0.1970, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.2130, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0140, 0.7840, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1710, 0.6500, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.2360, 0.2360, 0.2360, 0.2360, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740,\n",
      "         0.0740, 0.0740, 0.0190, 0.2790, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  1045,  2079,  2025,  2031,  2505,  1045,  2031,  7025,\n",
      "          2061,  2054,  2842,  2428,  5609,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4931,  6253,  2017,  2024,  5637,  8840,  2140,  5572,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2008,  2074,  2054,  2002,  2003,  1037,  8239, 10041,\n",
      "          1998,  1997,  1996,  5221, 27980,  2010,  2132,  2003,  2428,  2521,\n",
      "          2039,  6289,  4632,  2079,  2025,  8572,  2007,  2032,  2002,   102],\n",
      "        [  101,  2755,  4638,  1996,  5152, 12865,  2024,  4351,  1037,  9452,\n",
      "          5502,  1999,  8174,  9264,  1998,  5279,  2138,  2027,  2024, 15554,\n",
      "          2298,  2008,  4485,  2039,  2049,  2428,  2025,  2524,  2077,   102],\n",
      "        [  101,  1045,  5223,  2008, 23701,  2989, 14163,  2480,  8609,  4485,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20228,  2015,  2655,  2023,  2522,  2239,  2041,  2005,  1996,\n",
      "          1997, 25488,  1038, 13687,  2015,  2542,  2006,  2002, 20911,  2096,\n",
      "          2002,  1998,  2010, 15912, 17603, 28231,  2389, 21657,  2482,   102],\n",
      "        [  101,  5310,  2757, 12054, 16773,  2013, 12071, 10214,  2000,  4366,\n",
      "          2317,  2791,  2138,  2066,  4593,  1999,  1996,  2045,  2020, 18076,\n",
      "          2006,  1996,  2479,  1045,  2572,  2025,  8239, 12489,  1045,   102],\n",
      "        [  101,  5310,  2017,  2024,  1999,  2082, 13451,  6904, 13871,  4140,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1057,  6297,  6213,  2066, 19108,  1057,  1037,  2128,\n",
      "          7559,  2094,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4895,  5017,  3401,  8292, 29577,  2098,  2003,  2074,  2178,\n",
      "          2317,  7743,  2667,  2000,  2298,  2004,  2304,  2004,  2825,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3844,  1996,  6616,  2039,  2017,  8740, 16774,  2594,  2128,\n",
      "          7559,  2094,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19387,  2000,  3693,  1037,  3057,  2069,  1043, 22117,  8318,\n",
      "          2193,  2007,  5310, 11333,  2290,  2006,  2015,  2193, 11374, 13228,\n",
      "          7263,  2364,  3654,  2100,  2193,  3057,  2069,  2100,   102,     0],\n",
      "        [  101,  2073,  2003,  1996,  4524,  1997,  2769,  9152, 13327,  2073,\n",
      "          2003,  1996,  4524,  1997,  2769,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 11082,  2025,  5293,  1996,  5939,  8458,  9314,\n",
      "          8293,  1999,  2662,  2748,  2716,  1999,  2011,  6206,  7489,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2014,  2361,  4315,  2361,  1045,  2245,  1996,  8224, 17637,\n",
      "          2052,  6135,  2191,  2033,  2298,  6047,  2074,  2066,  1045,  2245,\n",
      "          2026,  5637, 16012,  2052,  2191,  2033,  2298,  7823,  2014,   102],\n",
      "        [  101,  5310,  5310,  6206,  7489,  4995,  1521,  1056,  4841,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0010, 0.0010, 0.0210, 0.0790, 0.0790, 0.0790, 0.0790, 0.0210, 0.0790,\n",
      "         0.0790, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0190, 0.2780, 0.0730, 0.0730, 0.2780, 0.2780, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.6450, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0540, 0.7760, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0370, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.1400, 0.1400],\n",
      "        [0.0030, 0.0030, 0.1660, 0.1660, 0.1660, 0.1660, 0.1660, 0.1660, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  4080, 17153,  3676,  2003,  1037,  9152, 13327,  6904, 13871,\n",
      "          4140,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  5181,  1998,  7486,  3473,  2039,  2362,  1998,  1996,\n",
      "          5181,  2435,  4182,  2000,  7988, 16138,  1998,  2101,  2006, 15111,\n",
      "          2964,  2066,  1037,  2502,  4676,  2155,   102,     0,     0,     0],\n",
      "        [  101,  2025,  1045,  2027,  3844,  2033,  2041,  2005,  5517,  1996,\n",
      "          2457,  2323,  3102,  1996, 14068,  2121,  2040,  2056,  2002,  2001,\n",
      "          3374,  2002,  2071,  2025,  2030,  2106,  2025,  3102,  2062,   102],\n",
      "        [  101,  9090,  5669,  2304, 13774,  3907,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2821,  2008,  2074, 27136,  2100,  2519, 16985, 18515,\n",
      "          1996, 16939,  4942, 22769,  9152, 13327,  3331,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  1996,  6616,  2003,  2009,  1041, 16020, 19269,  2000,\n",
      "          2224,  1037,  8239,  8153,  2079,  2017, 13387,  2115,  4632,  2007,\n",
      "          2115,  2398,  2066,  1037, 13555, 28600,  4842,  2205,  1998,   102],\n",
      "        [  101,  1996,  9152, 13327,  2003,  5327,  1996, 10558,  3786,  2032,\n",
      "          2039,  1998,  6545,  2032,  2061,  2002,  2064, 23701,  2140,  1998,\n",
      "          5390,  2006,  4950,  1998,  2131,  1037,  4121, 17276, 15213,   102],\n",
      "        [  101,  5310,  2053,  3102,  4426,  3031,  2361,  1042, 24759,  3124,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6331,  8135,  2342,  2000,  2644, 27394,  2330,  3424,  4828,\n",
      "          2015,  2066, 20359,  2040, 14977,  2054,  8239,  6904, 13871, 12868,\n",
      "          2031,  2000,  2360,  1998,  4295,  2094, 22212,  2015,  2066,   102],\n",
      "        [  101,  2057,  2323,  2911,  4409,  2000, 13481,  2061,  2027,  2064,\n",
      "         24694,  1996, 18294,  8040,  2819,  2008,  2001,  2716,  2588,  2037,\n",
      "          2341,  4084,  2144,  8112,  4757,  2106,  2025,  2031,  1037,   102],\n",
      "        [  101,  2025,  2004,  2524,  2004,  2009,  2442,  2022,  2005,  2017,\n",
      "          1037,  3937,  7743, 19297,  9652, 12731,  3600, 19894,  2075,  2128,\n",
      "          7559,  5732,  2033,  7834,  2000,  2115,  4274,  2304,  2767,   102],\n",
      "        [  101,  5310,  1045, 21090,  2007,  2017,  2006,  6970, 22648,  4818,\n",
      "         12743,  1045,  2572,  1037,  2358,  4245,  2137,  2822,  2496,  2000,\n",
      "          1037,  2317,  2158,  2057,  2119,  2031,  2179,  1996,  4828,   102],\n",
      "        [  101,  1996, 18235,  2497, 10069,  1996, 14163, 14672,  3736,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2515,  2009,  6523,  2000,  1996,  2613,  5181, 13599,  2068,\n",
      "          2000,  2216,  2040,  2655,  3209,  5181,  2651,  2003, 13599, 18108,\n",
      "          2000,  4589,  2015,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  1521,  1049,  6427,  2035,  2317,  3057,  2024,  7570,\n",
      "          2229,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15310,  4061,  1996, 13157,  2061, 10558,  2591,  3667,  2071,\n",
      "          9811,  2000,  2025,  2156,  5472, 25518, 15776,  9680,  2075,  2210,\n",
      "          2317,  3057,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0090, 0.0090, 0.0090, 0.0090, 0.4820, 0.4820, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.6030, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0220, 0.3110,\n",
      "         0.3110, 0.3110, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0010, 0.0010, 0.0010, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0010, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0340, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0340, 0.4900, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0270, 0.1040, 0.1040, 0.1040, 0.0270, 0.1040, 0.1040, 0.1040, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.2350, 0.2350, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.2350, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0610, 0.2310, 0.2310, 0.2310, 0.2310,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0950, 0.0950, 0.3590, 0.0950, 0.0950, 0.0950, 0.0950,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1048,  5339,  2003,  1037,  8239,  2655,  5833,  5292,  3270,\n",
      "          3270,  3270, 23644, 23278,  2038,  1037,  5294,  2391, 27793, 15315,\n",
      "          6711,  6711,  5705,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5292,  3270,  5674, 16663,  4044,  2081,  1058,  2100,\n",
      "          2025,  1037,  6904, 13871,  4140,  6080,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8840,  2140,  1996, 14255, 11362,  3639,  4250,  2041,\n",
      "          1999,  2486,  1999,  1996, 14054,  2022,  2066,  2092,  3067, 11586,\n",
      "          8566, 16371, 15379,  2008,  2025,  2129,  6747,  2147,   102,     0],\n",
      "        [  101, 11867,  7646, 11261,  2148,  2637,  9152, 25708, 14735,  2024,\n",
      "          3080,  2084,  2637,  1998,  2087,  2060,  2317,  3032,  1998,  4693,\n",
      "          2369,  2068,  2035,  2027,  2024,  2035,  6135, 14092,  1998,   102],\n",
      "        [  101,  3084,  2033,  2215,  2000, 16405,  3489,  2061,  8239,  5458,\n",
      "          1997,  2023,  9587, 25016,  2213,  4485,  2063, 10439, 19500,  3672,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2507,  2008,  2317,  7743,  2193,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9105,  5346,  2003, 17276,  2061,  2123,  1521,  1056,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2106,  2025, 22212,  2014,  2606, 12690,  2106,  2016,\n",
      "         23755,  8945,  2094, 27793,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1045,  5223,  2017,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2402,  6238,  3880,  2007, 10256,  4474,  2428,  2821,  4845,\n",
      "          3492,  2172,  2035,  1996,  2816,  2020,  2035,  2317,  2000,  2707,\n",
      "          2007,  1998,  1057,  3654,  2001,  2028,  1997,  1996,  2936,   102],\n",
      "        [  101,  2003,  6135,  2025, 16939, 18029,  2050, 22226,  2725,  1037,\n",
      "          2569,  2013,  7136,  2006,  1996,  6065,  4515, 17012, 17012,  2193,\n",
      "         11660,  2006, 11687, 14647,  2015,  3300, 17012,  4441,  1996,   102],\n",
      "        [  101, 22953,  4451,  2100,  4632,  7743,  2229,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2024,  2522, 14343, 22248,  7538,  3616,  2007,\n",
      "         13141,  3343,  4298,  2028,  1997,  1996, 12873,  4355,  9918,  1045,\n",
      "          2031,  2464,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2022,  1037,  2204,  9152, 13327,  1998,  3713,  2017,\n",
      "          2568,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2016,  2071,  2025,  2022,  2343,  1997,  1996,\n",
      "         17768,  2132,  2252,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6229,  1045,  3280,  6616,  1996,  7610, 11890, 22716,  1040,\n",
      "         12458,  2050,  8915,  8737, 24413,  2735,  1997,  1996,  2301,  6904,\n",
      "         13871, 12868,  1045,  2228,  2005,  2870,  1998,  1045,  1040,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.8320, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0630, 0.0040, 0.0040, 0.0630, 0.0040, 0.0040, 0.0040, 0.0040, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0040, 0.0040, 0.0040, 0.0630, 0.0630, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0530, 0.0140, 0.0140,\n",
      "         0.0140, 0.7560, 0.0530, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.4870, 0.4870, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.8450, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1190, 0.1190, 0.4520, 0.1190,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3160, 0.3160, 0.3160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740,\n",
      "         0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050]]), 'label': tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2307,  2017,  2224,  2490,  2011,  9253,  6394,\n",
      "         11087,  2157,  3358,  2000,  2022,  3569,  2004,  1037,  2317, 10514,\n",
      "         28139, 22911,  2923, 16939,  2785,  1997,  3653,  2015,   102,     0],\n",
      "        [  101,  2023,  2158,  3504,  2061,  8239,  2986,  2007,  2074,  2010,\n",
      "          2317,  1056,  3797, 23713,  2751,  4677,  2006,  1517,  7987,  2497,\n",
      "          6069,  2191,  2032,  2026,  2158,   102,     0,     0,     0,     0],\n",
      "        [  101,  2111,  2024,  2205,  5627,  2000,  7499,  1996,  7486,  2005,\n",
      "          2673,  2612,  1997, 17067,  2000,  3945,  2005,  1996,  3606,  1996,\n",
      "          6623,  5152,  2003,  2004,  2172,  1037,  6778,  2004,  2057,   102],\n",
      "        [  101,  5310,  5310,  2175,  2006,  2009, 15544, 19510,  2075,  2061,\n",
      "          2521,  2515,  2151,  1997,  2009,  2110,  2008,  2009,  2052,  2025,\n",
      "          2031,  2042,  1037,  4126,  2065,  1037,  2317,  2711,  2001,   102],\n",
      "        [  101,  5621,  6517,  2007,  2035,  2008, 10469,  9686,  6873,  8557,\n",
      "          2017,  1040,  2228,  2027,  1040,  2022,  2583,  2000,  2147,  2092,\n",
      "          2004,  1037,  2136,  3849,  2008,  2087,  3144,  2308,  2145,   102],\n",
      "        [  101,  2193, 10095,  6853,  7331,  1998,  2193,  2062,  6731,  1999,\n",
      "          8142,  2005,  9680,  2075,  1998, 18087,  2075,  2336,  2339,  2003,\n",
      "          2025,  2023, 17653,  2739,  4035,  1045,  2097,  2425,  2017,   102],\n",
      "        [  101,  5310,  2002, 11586,  8566, 16371, 15379,  1998,  1996, 13433,\n",
      "         13433,  2589,  2915,  2032,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2040,  2016,  2003,  2987,  1521,  1056,  2113,  2021,\n",
      "          5152,  2025,  1037,  6778,  2182,  1999,  2634,  2116, 18221,  2327,\n",
      "         11240, 11404,  2098,  2011,  7486,   102,     0,     0,     0,     0],\n",
      "        [  101, 13451, 10216,  2757, 12054,  2109,  1037,  5762, 22889,  3126,\n",
      "          2875,  4004,  2015,  1999,  2010,  4581,  2021,  2085,  2002,  2041,\n",
      "          2182,  2035,  2039,  1999, 18411,  2015,  4632,  1996, 21555,   102],\n",
      "        [  101,  2054,  6919,  2739, 14560,  2024,  2893,  4086,  9144,  1998,\n",
      "          3119,  2007,  2149,  5564,  2057,  2024,  2058,  2448,  2011,  2659,\n",
      "         26264,  4485, 21049, 21054,  2317,  2308,  1998,  2023,  8239,   102],\n",
      "        [  101,  2045,  2003,  1037,  4957,  2006,  2899, 19684,  2008,  6083,\n",
      "          1996,  1040,  9333,  2009, 22190,  2072,  2009, 14895,  2038,  9452,\n",
      "          7208,  2021,  1996,  4957,  2097,  2025,  2695,  2339,  2899,   102],\n",
      "        [  101,  1045,  2134,  2102,  5382,  2129, 16360, 16119,  2108,  2006,\n",
      "         10474,  2001,  2437,  2033,  1045,  2074,  2514,  2066,  3038,  9152,\n",
      "         13327,  1998,  6904, 13871,  4140,  7887,  1998, 14739,  2004,   102],\n",
      "        [  101,  3451, 27255,  9319,  2008,  2035,  2529,  9164,  2003,  1037,\n",
      "          2765,  1997,  3226,  2025,  2182, 25469,  2679,  1998,  2947,  6670,\n",
      "          5243,  3468,  3451, 27255, 11014,  1996, 15336,  1997,  2495,   102],\n",
      "        [  101,  5310,  4428,  4832,  2004,  1037,  7098,  9698,  2114, 14398,\n",
      "          2004,  2146,  2004,  2017,  2024,  2025,  1037,  2210,  2611,  2108,\n",
      "         18087,  2098,  1998, 15504,  2011,  2214,  4004,  2273,  3644,   102],\n",
      "        [  101,  2061,  2116,  2308,  2024, 12491,  1998,  2007,  2659,  2969,\n",
      "         19593,  2008,  2045,  2003,  2019, 12492,  2008,  2308,  5373,  2024,\n",
      "         13451,  2063,  2008,  1045,  2079,  2025,  5138,  2008,  3115,   102],\n",
      "        [  101,  5796,  1998, 12202, 11891,  2613,  2166,  9587, 25016,  2213,\n",
      "          5980,  2015,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.7130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1580,\n",
      "         0.1580, 0.1580, 0.1580, 0.1580, 0.1580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0060, 0.0060, 0.0220, 0.0060, 0.0060, 0.0830,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0830, 0.3140, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0120, 0.1680, 0.1680, 0.1680, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440,\n",
      "         0.0440, 0.0440, 0.0440],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.4040, 0.0070,\n",
      "         0.4040, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8480, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  1045,  2079,  2025,  2215,  2000,  2444,  1999,  1037,\n",
      "          2695,  4602,  2293,  2466,  2412,  2409,  2088,  1045,  6655,  2017,\n",
      "          6904, 13871, 12868,  2066,  3585,  2051,  3288,  2067, 15544,   102],\n",
      "        [  101,  6616,  2378,  5472,  9152, 13327,  2015,  2342,  2037,  5980,\n",
      "          2015,  5648,  8871,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  7570,  2229,  2097,  2025,  2175,  2185,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4569,  2755,  2984,  8183,  2317,  2040,  4146,  5310,  4837,\n",
      "          3189,  2046,  4424, 16011,  9989,  2003,  5052,  2176,  2372,  1997,\n",
      "          1996, 12803,  3917,  2155,  2040,  2491, 19749,  6887, 27292,   102],\n",
      "        [  101,  2008,  2818,  2003,  6069, 22590,  2010,  2564,  1998,  4287,\n",
      "          5310,  2000,  2037,  2282,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  8042,  2109,  2317, 14594,  1998,  3424, 11560,\n",
      "          3571, 12256,  4590,  2478,  7275,  3572,  2000,  6773,  3644,  7489,\n",
      "          2004, 25047,  9680,  2923,  2074,  2004,  2115,  6203,  3003,   102],\n",
      "        [  101,  2273,  2022, 17949,  2055,  2308,  4147,  2205,  2460,  4253,\n",
      "          2096,  2027,  2145,  4929,  2037,  2214,  4632,  7518, 27578,  2007,\n",
      "          2193,  2706,  2214, 13988,  2006,  2009,   102,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  2025,  2191,  1037,  7570,  2063,  1037,  2160,\n",
      "         19993, 17757,  5003, 10343,  5003, 10343,  4887,  5003, 10343,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 21442, 11705,  2279, 10605,  2597,  2323,  2022, 13141,  3409,\n",
      "         17219,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  8239,  5223,  2017,  2193,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  1059,  3363,  6655,  1999,  2008,  2193,  3867,\n",
      "          3415,  1999,  2008,  2862,  2052,  2022,  7486,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2157,  2023,  2003,  2028,  1997,  2216, 11937,  4160,\n",
      "         14702, 19903,  5312,  2003,  2025,  2009,  2073,  2009,  2986,  2000,\n",
      "          4682,  2000,  2512,  7486,  9826,  1037,  2317,  2450, 16401,   102],\n",
      "        [  101,  1048,  5339,  1045,  2310,  2056,  2023,  2077,  1998,  1045,\n",
      "          2097,  2360,  2009,  2153,  2065,  2017,  2655,  2033, 19483,  1045,\n",
      "          2572,  3442,  2039,  7727,  2000,  2017,  1998,  2115,  2972,   102],\n",
      "        [  101,  1045,  2001,  8642,  6731,  2005,  5378,  1037,  2047,  2208,\n",
      "          1999,  2029,  2017,  3984,  2054, 12330,  2018,  2000,  2079,  2000,\n",
      "          2131,  3297,  1045, 11445, 13772, 13970, 10649,  2121,  2165,   102],\n",
      "        [  101,  1049,  2546,  2056,  2008,  1037,  2001,  1996,  2190,  3348,\n",
      "          1997,  2010,  2166,  7743,  1045,  2113,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2097,  2022,  2157,  2012,  2188,  1999,  1996,  4101,\n",
      "          2843,  2696,  7087, 22212,  2015, 24430,  2105,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.1530, 0.5810, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1380, 0.1380, 0.1380, 0.1380, 0.0360, 0.1380, 0.1380, 0.1380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.9160, 0.0170, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3220, 0.3220, 0.3220,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0660, 0.0660, 0.0170, 0.0170, 0.0660, 0.0660, 0.0660, 0.0660, 0.0660,\n",
      "         0.0170, 0.0170, 0.0170],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.6450],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.7840, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.4500, 0.4500, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996, 15667,  9820,  3291,  2003,  2085,  1996,  2304,  2111,\n",
      "          3291,  3768,  1997, 25288,  1999,  1996,  2304,  3287,  2765,  2003,\n",
      "          2008,  2308,  2040,  2031,  3348,  2007,  2304,  2273,  2024,   102],\n",
      "        [  101,  1041,  2860,  2860,  1037,  8494,  7377,  8024,  2007,  1037,\n",
      "          9152,  9354,  2102,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2064,  2017,  5674,  2054,  2052,  2022,  6230,  2006,  1996,\n",
      "          4534,  1997,  1996,  2866,  2157,  2085,  2065,  2008,  2018,  2042,\n",
      "          2019,  2886,  2006,  1037,  5152,  2724,   102,     0,     0,     0],\n",
      "        [  101,  5310,  2026, 26264,  2003,  7882,  2043,  2619,  2008,  2038,\n",
      "          2196,  2777,  2033, 15980,  1045,  2572,  2128,  7559,  5732,  6732,\n",
      "          2027,  2064,  2404,  2033,  2091,  2007, 11238,  9739,  2102,   102],\n",
      "        [  101,  2023,  2733,  2182,  1999,  5858,  2103,  1037,  2158,  2730,\n",
      "          1037,  2317,  2158,  1998, 15504,  2010,  2564,  1999,  2178,  2188,\n",
      "          5274,  1996,  5694,  2024,  2471,  2467,  2317,  1998,  1996,   102],\n",
      "        [  101,  5181,  6411,  2037, 29245,  1997, 12461,  2004,  2065,  2009,\n",
      "          2020,  1037, 11177,  3433,  2000,  6721,  4808,  2008,  2057, 19974,\n",
      "         16721,  2588,  2068,  2138,  1997,  2256,  3347, 25990,  2278,   102],\n",
      "        [  101, 10667,  1037, 14033,  2005,  1037,  7743,  2065,  2016,  2908,\n",
      "          5466,  6900,  3331,  2035,  2008,  4485,  2066,  2017,  2180,  1521,\n",
      "          1056,  2131,  3480,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 11704,  3241,  2003,  3599,  1996, 14636,  2008,  2003,\n",
      "          2877,  2000,  1996, 14173,  1997,  2256,  2406,  3233,  2005,  2115,\n",
      "          9029,  2030,  2444,  1999,  1037,  2088,  1997, 25283, 15580,   102],\n",
      "        [  101,  4013,  5955,  2005,  2151,  1997,  2256,  2489,  4613,  9130,\n",
      "          2177,  8711,  2182, 11562,  2115,  6337,  6302,  1999,  1996,  3356,\n",
      "          2157,  3420,  7276,  2601,  5549,  3404,  2033,  2017,  2097,   102],\n",
      "        [  101,  6796, 19817, 27627,  2003,  1037,  6904, 13871,  4140,  2040,\n",
      "          7459, 14163, 13793,  2229,  2062,  2084, 16485,  1045,  2031,  2657,\n",
      "          2002,  2003,  1037, 10463,  2000, 13555, 14910,  4691,   102,     0],\n",
      "        [  101,  7987, 20175,  8237,  2102,  2058,  2006, 10474,  2428,  2515,\n",
      "          3209,  1037,  2350,  4487, 18116,  7903,  2063,  2011,  3015,  2070,\n",
      "          2128,  7559,  5732,  8040,  3089, 15343,  2612,  1997,  1037,   102],\n",
      "        [  101,  5310,  5310,  2034,  2047,  3343, 19483,  2308,  2131, 26587,\n",
      "          2125,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19130, 11382,  3489, 24307,  2006, 26030,  2450,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4468,  4397,  2179, 27256,  4654,  7913, 26725,  1999,\n",
      "          4977,  4468,  1996,  3942,  1996,  4397,  2179,  4977,  5241,  2398,\n",
      "          2007,  4501,  6027,  2000,  2433,  2047, 24815,  2072, 26041,   102],\n",
      "        [  101,  6257,  2017,  2052,  4895, 26746,  2033,  6394,  6904, 13871,\n",
      "          4140,  5310,  2017,  2024,  2025,  2130,  2667,  4902,  7743,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2183,  2000,  2022,  2725,  1037,  5460,  2006,  4172, 11865,\n",
      "         26933,  2023, 11382,  3489,  4320,  6904, 13871,  4140, 25176,  2879,\n",
      "          3859,  2069,  2317, 14085,  4048, 16026, 28032,  2024,  6160,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0050, 0.0050, 0.0050, 0.0010, 0.0010, 0.0010, 0.0740, 0.0740,\n",
      "         0.0740, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0740, 0.0740, 0.0010,\n",
      "         0.0010, 0.0010, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0740, 0.0740,\n",
      "         0.0740, 0.0740, 0.0740],\n",
      "        [0.0080, 0.0080, 0.4600, 0.0320, 0.0320, 0.4600, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.1370, 0.1370, 0.1370, 0.1370, 0.1370, 0.1370, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5960, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0170, 0.0170, 0.0650,\n",
      "         0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.3760, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0260, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1300,\n",
      "         0.1300, 0.1300, 0.1300],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0740, 0.0050, 0.0050, 0.2800, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2800, 0.2800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.6120, 0.0110, 0.0110, 0.1610, 0.1610, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.1690, 0.1690, 0.0030, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.1690, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5230, 0.0100, 0.0360, 0.0360, 0.0360, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0360]]), 'label': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  6436,  6248,  7025,  2716,  2000,  2017,  2011,  1996,  6436,\n",
      "          6248,  6456,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2074,  4299,  2027,  2106,  1037,  2732, 10313,  2544,\n",
      "          1997, 21643,  2130,  1996,  5472,  9152, 13327,  2015,  2024,  2317,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2828,  2066,  1037,  9152, 13327,  2021,  2115,  4471,\n",
      "          2003,  5760, 11382,  3489,  2024,  2017,  1037,  9152, 13327,  3211,\n",
      "          3489,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 24761,  2015,  2339,  2017, 14739,  2128,  7559,\n",
      "          4305,  1038,  2106,  2016,  2469,  2017,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2593,  2126, 11382,  9681,  1998,  5472,  9152, 13327,  2015,\n",
      "          2097,  2087,  3497,  3280,  2023,  2003,  2200,  2204,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7743,  2057,  2165,  2193,  2847,  2000,  3154,  1037,  2463,\n",
      "          9389,  9350, 20318,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2963,  1057,  2428,  2024,  2128,  7559,  5732,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24209, 20486,  7292,  2288,  2068,  5152,  4430,  2514,  2378,\n",
      "          5292, 13088,  4890, 18765,  2050,  5310,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2111,  2040,  2224,  1996,  2317,  9152, 13327,  2033,  4168,\n",
      "          2024,  8040,  2819,  1045,  4468,  2068,  2066,  1996, 11629, 24380,\n",
      "          2594,  8740, 16774,  2015,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1047, 16340,  9761,  2015,  2024,  2061, 16939,  2875,  4004,\n",
      "          2015,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3492,  2204,  2193,  2454,  4480,  1998,  2087,  1997,  2149,\n",
      "          2031,  4409,  1045,  2031,  2026, 14256, 11172,  1998,  2175,  5008,\n",
      "          2471,  2296,  5353,  2017,  2113,  2339,  2383,  1037,  6105,   102],\n",
      "        [  101,  5310,  5310,  1045,  2031,  2085,  3191,  1996,  2518,  1998,\n",
      "          5993,  2008,  1996,  3033,  1997,  2009,  2008,  2024,  2055,  1996,\n",
      "          2338,  2030,  2428,  2055,  2505,  3563,  2024,  2986,  2021,   102],\n",
      "        [  101,  2633,  2179,  2009,  2579,  3053,  2019,  3178,  9432,  3149,\n",
      "          2193,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748,  2138,  3038, 11324,  2003,  3308,  1998,  2008,  2057,\n",
      "          2323,  2562,  2166,  9062,  2003,  1996,  2168,  2004,  3038,  6970,\n",
      "         22648,  4818, 19780,  2003,  1996,  2069,  2126,  2017,  2677,   102],\n",
      "        [  101,  3174,  2273,  5449,  4485, 29334, 17347,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2317,  2111,  3039,  2037,  4268,  2000,  2022, 15504,  2011,\n",
      "         22190,  2483,  2339,  2027,  2253,  2770,  2000,  1996,  2610,  2339,\n",
      "          2003,  2025,  2009,  1037, 11397,  3105,  2000,  4047,  2010,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.2810, 0.2810, 0.2810, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.4400, 0.4400, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.3110, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.3110, 0.0060, 0.0060, 0.0060, 0.3110, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.2890, 0.0200, 0.2890, 0.2890, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.5590, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.6180, 0.1630, 0.1630, 0.0110, 0.0110, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.4400, 0.4400, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2470, 0.2470, 0.0650, 0.0650, 0.0650, 0.0650, 0.2470, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9320, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1190, 0.1190,\n",
      "         0.4500, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080]]), 'label': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2009,  2109,  2000,  2022,  4632, 10085, 15370,  2007,  5181,\n",
      "          3214,  2017,  2018,  1037,  2204, 17907,  2030,  3460,  1998,  2019,\n",
      "          4469,  4596,  2283,  2000,  2928,  2006,  1996,  8094,  2085,   102],\n",
      "        [  101,  6221, 10722,  8737,  2003,  5637,  2007,  2010,  2365,  4388,\n",
      "         10722,  8737,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2008,  1521, 26838,  1998,  5637,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3102,  4426,  9152, 13327,  6616,  2121,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2298,  2040,  3107, 14781,  2089,  2000, 10852,  2089,  2467,\n",
      "          1037,  4434,  2004,  2000,  2339, 22190,  2072,  7486,  2031, 15504,\n",
      "          2007, 17727, 19496,  3723, 18227,  1996, 18087,  2075, 18542,   102],\n",
      "        [  101,  1045,  2253,  2000,  4539,  3892,  1998,  2288,  6827,  3514,\n",
      "          1998, 13774,  3907,  2031,  1045,  2584,  4672,  5637,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 22953,  2017,  2409,  2043,  2017,  2105,  4317,  2317,\n",
      "          7743,  2229,  2017,  2707, 18972,  1998, 15023,  2022,  1999,  8038,\n",
      "          4308,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  1996,  3924,  2040,  3422,  2008, 22212,  9155,  2024,\n",
      "          3492,  8239, 12873,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2758,  1996,  2450,  2040,  3084,  2019,  4274,  9152, 13327,\n",
      "          1997,  2841,  2008,  2015,  2307,  2008,  2003,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 13675, 16103,  4355,  2087, 17276,  4485,  6433,  1999,\n",
      "          2026,  5101,  2158,  4560,  1998,  1045,  2064,  2025, 10720,  1999,\n",
      "          2010,  2482,  1998,  2831,  2005,  4485,  2122,  2317,  4903,   102],\n",
      "        [  101,  5310,  5310,  2027,  2342,  2000,  2031,  2037,  2219,  2929,\n",
      "          5459,  2013, 11690,  1998,  5637,  5750, 12731,  2480,  2027,  1521,\n",
      "          2128,  2428,  2025,  1996,  2168,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2051,  2000, 16360,  4017,  4360,  2618, 16831,  8711,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7910,  9616,  2029,  2003,  2339,  2043,  8135,  9844,  2008,\n",
      "          4011,  6412,  4758,  2019,  7619,  1998, 10827,  3484,  1999,  2023,\n",
      "          2406,  1998,  1996,  2878,  2225, 13986,  1998, 15523,  1998,   102],\n",
      "        [  101, 22226,  4978,  1996,  2034, 23801,  1999,  1996, 10818,  7888,\n",
      "          8209,  2048, 21100,  4875,  3608,  2000,  3557,  1999,  2157,  2005,\n",
      "          2041,  2093,  3953,  1997,  2176,  2193,  2193,   102,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2017,  2655,  2033,  3415,  1998,  2059,\n",
      "          2017,  3582,  2033,  1045,  2572,  3374,  1045,  2572,  2025,  2008,\n",
      "          7143,  2000,  7392,  2005,  9117, 11669,  2066,  2017,   102,     0],\n",
      "        [  101, 12330, 13847,  3426,  1997,  8398, 15820,  1051, 18016,  9295,\n",
      "         28213, 11284,  2577, 18856,  7828,  3240,  2577,  2202,  2072, 24188,\n",
      "          9321, 20128,  2728,  2139,  9152,  3217,  2097,  2151,  2022,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.1420, 0.1420, 0.1420, 0.1420, 0.1420, 0.1420, 0.1420, 0.0030, 0.0030,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.4910, 0.4910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3230, 0.3230, 0.0850, 0.0850,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4330,\n",
      "         0.4330, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.1730, 0.1730, 0.1730, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "         0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.4070, 0.4070, 0.0070, 0.0070,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210]]), 'label': tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2672,  2027,  2071, 12666,  1037,  2334,  9587, 25016,  2213,\n",
      "          2612,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3407,  5798, 14163, 28753,  4283,  2005,  2108,  2017,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572, 10210,  2618,  1062,  2666,  2069,  2204, 14068,\n",
      "          2121,  2003,  2028,  2008,  2015,  2757,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1054,  2027,  2941,  2128,  7559,  5732,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  2657,  3143, 22822,  2239,  3331,  2132,  2006, 13229,\n",
      "          3331,  2055,  8398,  7521,  7221,  2006,  2193,  2193,  5152,  3032,\n",
      "          3632,  2006,  2000,  2360,  2065,  2002,  2003,  2114,  5152,   102],\n",
      "        [  101,  5310,  5310,  2027,  2031,  1037,  3291,  2007,  5152,  8711,\n",
      "          1998,  2157,  2135,  2061,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4940,  2309,  8703,  1997,  7025,  2023,  2001,  1996,  9452,\n",
      "          8038,  2278, 28940,  2497,  1047, 24180,  2890,  3602,  2008,  2002,\n",
      "          2025,  4147,  5424,  2030,  9587, 25016,  2213,  4253,  2002,   102],\n",
      "        [  101,  1996, 19728,  2003,  2065,  2017,  2024,  1037,  3442,  2317,\n",
      "          3287,  1999, 11519,  4338,  2027,  2024,  2183,  2000,  3830,  2017,\n",
      "          1037,  6394,  4312,  2453,  2004,  2092,  2600,  2009,   102,     0],\n",
      "        [  101,  2065,  2017,  2079,  2025,  4521, 15505,  1045,  2113,  2017,\n",
      "          2064,  2025,  2954,  4831,  6672,  2001,  2040,  7361,  2378,  4632,\n",
      "          2125,  6714,  6776,  9152, 23033,  2008,  4485,  2288, 29502,   102],\n",
      "        [  101,  5310,  2009,  2859,  2386,  6045,  2479,  2058,  2026,  2132,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2175,  5051,  2145,  2515,  2025,  2131,  2009, 22692,  3612,\n",
      "         26813,  2750,  2893,  3674,  6616,  2017,  2015,  2013,  2637,  2017,\n",
      "          2128,  7559,  5732,  2228,  2009,  2053,  2502,  3066,  6616,   102],\n",
      "        [  101,  2025,  1037,  5470,  1997,  1996,  2610,  2486,  2021,  9353,\n",
      "          7875,  2003,  2128,  7559,  5732, 10047,  2080,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2431,  2122,  7570,  2229,  2123,  1521,  1056,  2729,  2055,\n",
      "          2027,  9152, 23033,  2027,  2074,  7501,  1998,  3652,  2041,  2027,\n",
      "          2214,  4253,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  5164,  2039,  1037, 14163, 13793,  2063,  2866,  3664,\n",
      "          2011,  1996,  3300,  1998,  1996, 26880,  2097,  2067,  2125, 12361,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037, 11867,  2594,  2030,  1037,  5413,  2243,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  1041,  2035,  5637,  4501,  2038,  2062,  3287, 20833,\n",
      "          2084,  2151,  2060,  2406,  2087, 22190,  2072,  2273,  2031,  2018,\n",
      "         15667,  3348,  2007,  2060,  2273,  1998,  3337,  5305,  6616,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0990, 0.0990, 0.3770, 0.0990, 0.0990,\n",
      "         0.0990, 0.0990, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0440, 0.0440, 0.0440, 0.0440, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0440, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.1630, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0060, 0.0060, 0.0020,\n",
      "         0.0060, 0.0920, 0.0920, 0.0920, 0.0920, 0.0920, 0.0920, 0.0920, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0920, 0.0920, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3160,\n",
      "         0.3160, 0.3160, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.4330, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4330, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.2360, 0.2360, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.4870, 0.0090, 0.0090, 0.4870, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0530, 0.0530, 0.0040, 0.0040, 0.0530, 0.0530,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0140, 0.2010, 0.0140, 0.0140, 0.0140,\n",
      "         0.2010, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.2010,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2008,  2204,  2021,  2204,  6735,  4363,  1996,  9152, 13327,\n",
      "          2015,  1998, 14560,  2041,  2043,  2027,  2031,  2579,  2058,  2885,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  5263,  2000,  2022, 16939,  2114,  2317, 13664,  2092,\n",
      "          2003,  2025,  2008, 14057,  4728,  1996,  2111,  4942, 11020,  3089,\n",
      "         10472,  2000,  2023,  7961, 11324,  2052,  2022,  5294, 21226,   102],\n",
      "        [  101,  2016, 26765,  2041,  1037,  6706,  5460,  1997,  5760, 11382,\n",
      "          3489, 13044,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6276,  3341, 11867,  2594,  4274,  7221,  5753,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16215,  2102, 22437,  2711,  2040,  2056, 22212, 17806,  2005,\n",
      "          2009,  1998, 17159,  1996,  1056, 28394,  2102,  1998,  2035,  4903,\n",
      "          2140,  2024,  7514,  2075,  2104,  1996, 12480,  2003,  5460,   102],\n",
      "        [  101,  1045,  2165,  2026,  2304,  9898,  2193, 10250, 14163, 13793,\n",
      "          2063,  7170,  2121,  2041,  2000,  1996,  2346,  5614,  2006,  1996,\n",
      "          9531,  1045,  2064,  2130,  2224,  5749,  2043,  1045,  2448,   102],\n",
      "        [  101,  5310,  5310,  2017,  2024,  2157,  2009,  2515,  2025,  2031,\n",
      "          2000,  6927,  8109,  2064,  2191,  1996,  6865,  7840,  2193,  1998,\n",
      "          2031,  1037,  2317,  3124,  2079,  1037, 19992, 24008,  3358,   102],\n",
      "        [  101,  9889,  9587, 25016,  2213,  2007,  4957,  2000,  9452,  2215,\n",
      "          2000,  2644,  1037,  2317,  3017,  2132,  1997,  2110,  1997,  2178,\n",
      "          2406,  5873,  1996,  2647,  2406,  2010,  2388,  2001,  2141,   102],\n",
      "        [  101,  5310,  5310,  2009,  2003,  1996,  2755,  2008,  2002,  6984,\n",
      "          2019, 24004, 20200,  2317, 10514, 28139, 22911,  2923,  3005,  1037,\n",
      "          2767,  2758,  2009,  2035,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 10691,  2003,  1037,  5236,  9152, 13327,  2040,  2097,  2196,\n",
      "          2131, 10823,  2000,  3789,  3951,  1999, 15902,  3616,  2077,  1996,\n",
      "         11867,  6558,  2525, 15982,  3973,  2202,  2058,  1996,  2406,   102],\n",
      "        [  101,  2129,  2064,  2017,  2131,  9436,  1997,  2028,  9152, 13327,\n",
      "          1998,  5672,  2009,  2007,  2178,  9152, 13327,  1060,  1998,  1061,\n",
      "          2001,  2172,  2488,  2053, 16842,  2080,  1999,  4356,   102,     0],\n",
      "        [  101, 21357,  2000,  6426, 11794,  1998,  2036,  4636, 11324,  2015,\n",
      "          3100,  1045,  2572, 15899,  2125,  9061,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6638,  1999, 13578,  2094,  2282,  4860, 26264,  9152, 13327,\n",
      "          7743,  2229,  2323,  2025,  2022,  2583,  2000,  3789,  1999,  2329,\n",
      "          3864,  2025,  2069,  2323,  2329,  4485, 19980,  2015,  2022,   102],\n",
      "        [  101,  5310,  3707,  2892,  3475,  2102,  6394,  2021,  2040, 14977,\n",
      "          4902,  2157,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6034,  2187,  1055,  3501,  2860, 25283, 15580,  2024,  1996,\n",
      "          3924,  2566, 22327, 24133,  4808,  2114,  2054,  2057,  2655, 22856,\n",
      "          1998, 11581,  2111,  2558,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  8016,  2005,  2149,  2025,  2000,  3749, 13141,  3570,\n",
      "          2000,  2317,  8711,  1999,  2148,  3088,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7090,\n",
      "         0.1870, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9320, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5830, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0640, 0.2420, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.2420, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0720, 0.0720, 0.0720, 0.0720, 0.2720, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0720, 0.2720, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0190, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0850, 0.0850, 0.0220, 0.0220, 0.0220, 0.0850, 0.0850, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0060, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0750, 0.2840, 0.2840, 0.2840, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  3374,  2025,  2995,  1996,  2317,  3032,  2066,\n",
      "          4701,  1998,  2446,  2024,  8134,  5451,  2011,  5637,  2015,  1998,\n",
      "          6570,  3040, 23757,  1999, 11793, 21461,  2015,  6168,  3365,   102],\n",
      "        [  101,  2635,  2115,  4268,  2000,  2082,  1999,  1037, 11225, 11739,\n",
      "          2003,  1037,  2978,  2066,  3159,  4302,  2108, 15504,  2011,  7779,\n",
      "         29058,  8625, 13327,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7910, 10166,  2074,  7039,  2037,  5246,  1998,  1059, 24475,\n",
      "         15972,  3270, 21144,  2006, 16428, 13323,  1998,  3565,  2213,  2006,\n",
      "         16215, 13323,  2024,  2027,  2183,  2000,  3102,  2035,  1997,   102],\n",
      "        [  101,  8112,  2000,  9642,  2015,  2017,  2064,  2025,  2994,  3374,\n",
      "          9642,  2015,  2021,  2054,  2055,  1996,  6206,  7489,  2013,  3290,\n",
      "          8112,  2027,  2131,  2000,  2994,  2027,  3789,  7672,  2765,   102],\n",
      "        [  101,  2008,  2210,  4586, 10258, 13808,  2097,  2025,  5047,  2216,\n",
      "          2502,  7937, 22212,  2015,  2200,  2092,  4506,  2031,  8465,  4586,\n",
      "         10258, 13808,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5060,  2129,  2035,  1996, 12593,  2015,  1045,  1999,\n",
      "          2023, 11689,  9200,  2004,  2546,  1048,  2863,  2080,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  2317,  2111,  2644,  2108,  1037,  9152, 13327,\n",
      "          9706,  8662,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2915,  2012,  1037,  8872,  2016,  2001,  5292, 28483,\n",
      "         10623,  2075,  2032,  2014,  2773,  2016,  2056,  2016,  2106,  2025,\n",
      "          2021,  2016,  2106,  1998,  2016,  2001,  2025,  5338,  1045,   102],\n",
      "        [  101,  2026,  5152,  9587, 12868, 14115,  7847,  2003,  2746,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2079,  2025,  6331,  2092,  2593, 29450,  2154,  2065,\n",
      "          2017,  2106,  2017,  2052,  2113,  6904, 13871, 12868,  2131,  2543,\n",
      "          1998,  2017,  2052,  2036,  2113,  2008,  5181,  2024,  1996,   102],\n",
      "        [  101,  1037, 22212,  1037, 19483,  1998,  1037, 16522,  2058,  2045,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9706, 24755, 15000,  3366,  1037,  2004,  5637,  2015, 19817,\n",
      "          5358, 20915,  3022,  3527, 17479,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2821,  1047,  4283,  1045,  2052,  3191,  1996,  2695,\n",
      "          2065,  2026,  3042,  2347,  1056,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5171, 14163,  2480,  8609,  9887,  2228,  2027,  2024,  1999,\n",
      "          1037,  2204,  2597,  2027, 11867,  7974,  2037,  5223,  2021,  2043,\n",
      "          4320,  2007,  3997,  2027,  4897,  2006,  2037,  2067,   102,     0],\n",
      "        [  101,  7743,  2131,  2125,  2026,  4485,  6904,  2290,  1045,  2572,\n",
      "          1037, 14383,  7743,  2025,  1037,  6904,  2290,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11082,  2507,  1996,  2308,  1997,  2885,  2070,  9290,  1998,\n",
      "          2731,  2061,  2027,  2064,  6985,  3209,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0130, 0.0130, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1490, 0.1490,\n",
      "         0.5660, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7560, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0530, 0.0530, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8350, 0.0580,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0080, 0.4310, 0.4310, 0.1140, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0170, 0.0170, 0.0170, 0.0660, 0.0660, 0.0660, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0660, 0.0660, 0.0660, 0.0660,\n",
      "         0.0170, 0.0170, 0.0170],\n",
      "        [0.0130, 0.7180, 0.0130, 0.1890, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.7040, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0290, 0.0290, 0.0290, 0.0290, 0.4120, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.4120, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2066, 10468,  6616,  2054,  2017,  2056,  2055,  2129,  2017,\n",
      "          2514,  2026,  2317,  4632,  2007,  5717,  6123,  1997,  2040,  2017,\n",
      "          2428,  2024,  2097,  2425,  2017,  2129,  2017,  2514,   102,     0],\n",
      "        [  101,  1045,  2079,  2025,  2228,  4889, 11397,  3214,  7025,  2030,\n",
      "         13007, 23108,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  1996,  6616,  2003,  2023,  6638, 18278,  6740,  4974,\n",
      "          2128,  7559,  2094,  2006,  2026,  1056,  2140,  4151,  4485,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22091,  2106,  1045,  9495,  2017,  2007,  1996, 11867,  2594,\n",
      "          7615,  1045,  2572,  2061,  3374,  3189,  2033,  2000,  1996, 11721,\n",
      "          2497,  4614,  2210,  2611,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2339,  2003,  2009,  1996,  2187,  2064,  3288,  2039,\n",
      "          5571,  2006,  2074,  2055,  3087,  2027,  4299,  1998,  1996,  2157,\n",
      "          7719,  2067,  1998, 12197,  2064,  1996,  4001,  2025,  3288,   102],\n",
      "        [  101,  8006,  2003,  1037, 17276,  4023,  2004, 16021,  8898,  1998,\n",
      "          4895, 18447, 18702,  3436,  2004,  1996,  5095,  4676,  5530,  1997,\n",
      "          1996,  2334,  3259,  2643,  4282,  2009,  2003,  2524,  2000,   102],\n",
      "        [  101,  2035,  1996,  7731,  2865,  1999,  4701,  2003,  1997,  2607,\n",
      "         24247,  4750, 11867,  7974,  2075,  2041,  3658,  1998, 10398,  2006,\n",
      "          1037,  3679,  3978,  2069,  2128,  7559,  5732,  2111,  2903,   102],\n",
      "        [  101,  8398,  3791,  2000,  5466,  1037,  2757,  3899,  2576,  5656,\n",
      "          2006,  1996,  2795,  2000, 15886,  2010,  2128,  7559,  5732,  2918,\n",
      "          2096,  2002,  5751,  2008,  4830,  3540,  3259,  2369,  2037,   102],\n",
      "        [  101,  1045,  2066,  2026,  2317,  3096,  2057,  3603,  2637,  1998,\n",
      "          2328,  2009,  2164,  2087, 21644,  3374,  9152, 13327,  2015, 14068,\n",
      "          2545,  1998,  5413,  5705,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 16757,  2024,  4004,  2021,  1045,  6814,  1037,  2659,\n",
      "          2465, 20969,  2128,  7559,  5732,  2137,  2052,  2025,  2022,  2583,\n",
      "          2000,  2425,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2469,  2339, 19483,  2015,  2066, 15523,  1045,  3984,\n",
      "          1996,  2228,  2008,  2035,  2477,  2097,  2468,  2270,  2691,  3200,\n",
      "          5037, 19692,  2005,  2035,  5091,   102,     0,     0,     0,     0],\n",
      "        [  101,  2167,  4420,  2071,  2022,  1037,  2172,  2488,  2173,  2065,\n",
      "          2027,  2074,  2018,  8906,  2057,  2342,  2000,  8116,  2068,  2070,\n",
      "          9042,  8711,  3060, 16836,  3202,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3437,  2009,  1062,  5310,  2024,  2017,  4637,  5152,\n",
      "          8711,  2000,  2131,  2796,  9068,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2035,  2308,  2040,  2079,  2025,  2031, 10768,  7811,  3111,\n",
      "          2031,  1996,  2157,  2000,  3789,  1999,  2023,  2406,  2073,  2024,\n",
      "          2017,  2893,  2023, 18558,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4151,  2158,  2013,  5288,  4136,  3679,  5653,  2008,  4456,\n",
      "          3303,  2011,  7489,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053, 22856,  2317,  2158,  2006,  1996,  4774,  3504,  2012,\n",
      "          2619,  4129,  2032,  2009,  7929,  2005,  2032,  2000,  2022,  7098,\n",
      "          2000,  2022,  2317,  1998,  2758,  2053,  2053,  2053,  1045,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.1280, 0.1280, 0.1280, 0.1280, 0.1280, 0.1280,\n",
      "         0.1280, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0210, 0.0060, 0.0060, 0.3040, 0.3040, 0.3040, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0210, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7320, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0360, 0.0100, 0.0100, 0.0360,\n",
      "         0.0360, 0.0360, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.5190, 0.1370, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0220, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0850,\n",
      "         0.0850, 0.0850, 0.0850],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3040, 0.3040, 0.0060,\n",
      "         0.3040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.7520, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2400,\n",
      "         0.2400, 0.2400, 0.2400, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320]]), 'label': tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  2210,  6904, 13871,  4140,  4845,  2040,  2003, 29536,\n",
      "         23553,  2023,  2010,  3611,  2003,  1037,  2569,  4005,  2005,  1996,\n",
      "          8495,  2569,  3136,  3131,  1045,  2031,  2042,  3752,   102,     0],\n",
      "        [  101,  5310,  5310,  2016,  2288,  1996,  4524,  2044,  4689,  4138,\n",
      "          4004,  2015,  1998,  2085,  2016,  2015, 23592,  2016,  2038,  2000,\n",
      "          2709,  2005,  4840,  2125,  1996,  4049,  1048,  2213,  7011,   102],\n",
      "        [  101,  2057,  2288,  1037,  2843,  1997,  2630, 17357,  2098,  6904,\n",
      "         13871, 12868,  2006,  2182,  2651,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310, 18411,  2015,  2402,  5091,  2317,  2544,\n",
      "          1998,  3565,  2213,  2142,  2544,  5310,  5310,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2017,  2064,  2025,  3102,  4426,  2474,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15854,  4523,  1045,  2572,  7678,  3596,  1998,  2031,  3167,\n",
      "         18558,  1999,  2026,  2132,  1045,  2572, 11065,  9152, 13327, 10245,\n",
      "          6666,  1998,  2059,  4826, 11243,  2005,  4923,  5329,  1999,   102],\n",
      "        [  101,  2428,  1998,  2017,  2024,  2028,  1997,  2116,  5181,  2040,\n",
      "          2215,  1996,  2203,  1997,  2035,  2317,  2111,  2074,  2066,  1037,\n",
      "          6394,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2064,  2017,  5674,  1996,  2865,  1998,  2270, 19006,\n",
      "          2065,  2008,  2018,  2612,  2042,  2070,  2317,  9117, 11669, 18820,\n",
      "         18965,  2111,  2183,  2000,  1037,  6620,  7700,  2030,  2000,   102],\n",
      "        [  101,  2178, 21591, 23178,  1996,  1999, 19792,  2015,  2024,  7489,\n",
      "          2066,  2149,  8239, 17450, 17086,  2013,  4021,  2074,  2066,  5181,\n",
      "          2021,  2027,  2020,  7489,  2025, 11382,  3489,  4915, 16211,   102],\n",
      "        [  101,  5564,  1996,  9350, 11382,  3489,  2928, 20206,  2003,  2743,\n",
      "          3436,  2055, 14163,  2232,  2489,  3119,  1998,  3860,  2964,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2193,  2845,  2013, 10474,  2024, 22173, 11382,  3489,\n",
      "          2455,  2070,  2016, 11705,  2015,  8987, 12456,  2157,  3347, 25990,\n",
      "          2278,  1047,  3270,  9057, 11382,  3489,   102,     0,     0,     0],\n",
      "        [  101,  2193,  2086,  2044,  1045,  2001, 15504,  1998,  2196,  2245,\n",
      "          1045,  2071,  2444,  2153,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2298,  2012,  2054,  2017,  2626,  2017, 19313,  6904, 13871,\n",
      "          4140,  2017, 19483,  2015,  2024,  3554,  2114,  3071,  2006,  2023,\n",
      "          2609,  1998,  2057,  2035,  5223,  2017,  6616,  2125,   102,     0],\n",
      "        [  101,  5060,  2027,  2069,  3745,  2122,  4620,  4235,  2005,  1037,\n",
      "          3800,  9040, 11263, 18372,  5274,  1997,  2885,  9042,  9767,  2196,\n",
      "          2265,  1996,  5694,  1997,  5499,  7404,  2030, 18993, 17276,   102],\n",
      "        [  101,  1045,  2293,  8797,  8797,  2015,  2205,  6904, 13871, 12868,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2024,  2069,  2193,  1997,  1996,  2088,  2313,  1998,\n",
      "          2667,  2000,  9811,  2008,  8112, 24503,  7207,  2015,  2079,  2025,\n",
      "          2293,  1996, 14163, 13793,  2229,  2062,  2084,  1996,  5181,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.0130, 0.7040, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0470, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.1790, 0.1790, 0.1790, 0.1790, 0.0120, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5900, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0020, 0.0020, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.1030, 0.1030, 0.1030, 0.1030, 0.1030, 0.1030, 0.1030,\n",
      "         0.1030, 0.1030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2610, 0.2610, 0.2610,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0150, 0.0570, 0.0570, 0.0570, 0.0570, 0.0150, 0.0570, 0.0150, 0.0150,\n",
      "         0.0150, 0.0570, 0.0570, 0.0150, 0.0150, 0.0150, 0.0570, 0.0570, 0.0150,\n",
      "         0.0150, 0.0570, 0.0570, 0.2140, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.1780, 0.6740, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0480, 0.0480,\n",
      "         0.0130, 0.0480, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.6910, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0390, 0.5620, 0.0390,\n",
      "         0.0390, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0390, 0.0390, 0.0390, 0.0390, 0.0100, 0.0100, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.2000, 0.0530, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0140, 0.0140, 0.0140, 0.2000, 0.2000, 0.2000,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.4460, 0.0080, 0.0080, 0.0080, 0.1180, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080]]), 'label': tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  2016,  2106,  2025,  2215,  2000,  2131, 15504,  2011,\n",
      "          2193, 21767,  2016,  2323,  2025,  2031,  5407,  2046,  9048, 12921,\n",
      "          2016,  2763, 12999,  2005,  2009,  2077,  2027,  2106,  2009,   102],\n",
      "        [  101,  2129,  2079,  1045,  2562, 12447,  2039,  2309,  8840,  2140,\n",
      "          1996, 17276,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  1996, 13108,  1517, 17235,  5714, 12943, 14945,\n",
      "          3286,  1037, 14163, 13793,  2063, 11560,  2013,  4238,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2023,  2003,  1037,  3959,  2272,  2995,  2633,  2308,\n",
      "          2024,  2893,  4847,  1999, 11700,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2471,  2035,  1997,  1996,  5929,  3316,  2024,  7694,\n",
      "          1996, 22252,  1997,  2149, 12461,  2112,  2193,  1996,  9152, 13327,\n",
      "          2003,  2034,  1999,  1996,  3861, 19927,  1996,  2317,  3057,   102],\n",
      "        [  101,  5519,  3900,  1045,  2064,  2031,  3348,  2007,  3183, 22507,\n",
      "          1998,  7188,  1045,  2215,  2036,  5519,  3900,  1045,  2064,  2025,\n",
      "          2903,  2008,  3203,  2018,  3348,  2007,  2014,  2934,  2054,   102],\n",
      "        [  101,  5310, 10468,  2081,  1037, 10257,  4974,  8257,  2055, 17498,\n",
      "          4903,  2140,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2079,  2017,  2655,  2193,  7489,  2012,  1996,  3953,\n",
      "          1997,  1996,  4153,  1037,  2204,  2707,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  9152, 13327,  2015, 11867,  6558,  9413, 29441,  2075,\n",
      "         26346,  2024,  3140,  2046,  2317, 11681,  2011,  1996,  8239,  7349,\n",
      "          2015,  2009,  2480,  2180, 22196,  2271,  8906,  2043,  2769,   102],\n",
      "        [  101,  2065,  1996,  5576,  2003,  2000,  2507,  6744,  2248,  3570,\n",
      "          2074, 10216,  2009,  2440,  1997,  7489,  2066,  1996, 16522, 21123,\n",
      "          2031,  2589,  2000,  2035,  2256,  3655,  2065,  2009,  3071,   102],\n",
      "        [  101,  2026, 26264,  2003,  2008, 13857,  8112,  4182,  8196,  2003,\n",
      "         14477,  4779, 26884,  2119,  2503,  1998,  1045,  2097,  2191,  3290,\n",
      "          3477,  2005,  2308,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045, 14071,  2050,  7570,  2063,  2041,  2296,  2051,  1045,\n",
      "          2963, 27793, 10772,  2050,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  1996,  5499,  4742,  2027,  2024,  3201,  1998,  5627,\n",
      "          2000,  2022, 20302,  2135, 13680,  2011, 17977,  2030,  2178,  9587,\n",
      "         25016,  2213,  5525,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008, 13843,  4328, 10439,  2003,  4415,  2025,  2005, 11690,\n",
      "          2015,  8840,  2140,  2027,  2031,  4562,  1998,  5519,  2243,  1998,\n",
      "         22437,  1998,  5252,  2099,  2004,  7047,  2000,  6235,  4426,   102],\n",
      "        [  101,  1045,  8239,  5223,  4701,  2005,  2437,  1996,  2553,  2008,\n",
      "          2308,  2323,  2025,  2022,  2920,  1999,  4331, 14163,  2232, 10469,\n",
      "         22410,  2003,  1037,  8257,  4467,  3694,  2082, 28208,  5152,   102],\n",
      "        [  101,  5310,  5310,  1045,  2079,  2025,  2113,  2065,  1045,  2064,\n",
      "          2412,  9641,  2068,  2005,  1996,  2792,  2073,  2027,  2056,  6904,\n",
      "         13871,  4140,  2347,  1056, 24004, 20200,  2030,  1996,  2028,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410,\n",
      "         0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.0030,\n",
      "         0.0030, 0.0410, 0.0410, 0.0410, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6090,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0890, 0.3360, 0.0890, 0.0890, 0.0890,\n",
      "         0.0890, 0.0890, 0.0890, 0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.1270, 0.1270, 0.1270, 0.1270, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.1270, 0.1270, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0420,\n",
      "         0.5970, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0340, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0090,\n",
      "         0.0090, 0.0090, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300,\n",
      "         0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0220, 0.0220, 0.0220, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0010, 0.0010, 0.0010, 0.0010, 0.0220,\n",
      "         0.0220, 0.0010, 0.0010],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230]]), 'label': tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2036, 10722,  3540,  1998, 20743,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6160,  2000,  2784,  2637,  2693, 25488,  2084,  2151,  2304,\n",
      "          5110,  2103,  2625,  2231,  3454,  1998,  7574,  2084,  2151, 17276,\n",
      "         24433,  2011,  2019,  6728,  3695,  3593, 16311,  2664,  2009,   102],\n",
      "        [  101,  2033,  2000,  2033,  7743,  2017,  6911,  2075,  2033,  1056,\n",
      "          2546,  2041,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  2115, 22418,  2969,  2003,  4276,  1037, 24402,  2135,\n",
      "          2614,  1998,  5372,  9260,  2059,  3383,  2017,  2097,  2131,  2000,\n",
      "          3191,  2302,  2478,  2115,  2210,  4167,  2000, 11703, 11514,   102],\n",
      "        [  101,  4906,  2063,  2033,  9152, 13327,  2015,  2034,  8833,  2378,\n",
      "          1999,  2193,  2454,  2086,  1999,  2712,  8241,  1998,  9535,  1037,\n",
      "         11865, 23064,  2057,  9331,  5292,  3270,  3270,  3270,  8909,   102],\n",
      "        [  101,  5862,  2335,  2392,  3931,  2758,  1039, 20184,  2482,  6359,\n",
      "          2001,  1037,  6394, 25353,  8737, 25457,  6290,  2062,  8275,  2739,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15624,  4842,  2178,  2154,  2007,  5236,  3398, 15686,  7327,\n",
      "          2007, 26269, 18138,  3071,  2125,  1998,  2735,  1057,  2046,  1037,\n",
      "          4485, 11484,  2406,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9130,  2003, 12106,  1037,  5306, 10439,  2009,  2204,  2000,\n",
      "          2633,  2156,  1037,  2173,  2043,  2128,  7559,  5732,  4314, 21633,\n",
      "          2064,  8103,  2039,  2007,  2060,  8315,  3633,   102,     0,     0],\n",
      "        [  101,  2016,  2003,  6314,  2011,  2054,  2016,  6732,  2097,  2022,\n",
      "          1996,  3433,  2000,  2014,  2139, 16307,  2075,  2132, 18982,  2021,\n",
      "          7025,  8771,  5466,  5648,  1999,  1996,  5344,  1997,  2317,   102],\n",
      "        [  101,  1996,  8037,  2024,  1999,  2019,  2039,  3217,  2906,  1996,\n",
      "          2343,  3138,  1996, 14477,  4246,  8551,  3085, 10859,  1997,  1996,\n",
      "         15184,  2729,  2552,  2125,  1996, 10457,  1997,  4841,  1998,   102],\n",
      "        [  101,  2053,  2000,  3337,  2069,  5637,  2015,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2122,  3032,  2097,  2991,  2046,  2225,  7389,  8132,\n",
      "          2000,  6033,  2048,  5152,  3032,  2339,  2079,  2025,  2122,  2048,\n",
      "          5152,  3032, 11582,  1996,  2088,  1997,  2162,  2007,  3956,   102],\n",
      "        [  101,  2009,  2028,  1997,  1996,  9017,  1997, 17276, 21435,  2008,\n",
      "          2038,  3133,  4274, 21435,  2083,  1996,  5396,  1997, 19728, 13958,\n",
      "          2434, 20067,  2074,  3191,  2009,  2004,  2434,   102,     0,     0],\n",
      "        [  101,  2138,  2009,  2026,  2051,  1998,  2009,  2026,  2166,  2017,\n",
      "          2035,  5292,  3270,  2054,  2027,  2022,  9391,  2066,  1045,  3984,\n",
      "          2061,  1045,  3984,  7570,  2063,   102,     0,     0,     0,     0],\n",
      "        [  101,  4931,  5495,  2115,  6007,  1045,  2079,  2025,  2215,  2017,\n",
      "          4634,  2005,  3087,  2842,  2986,  4682,  2890,  6873, 13102,  8820,\n",
      "         29108, 11921,  9067,  2140,  2089, 25943, 14406,  9033,  4682,   102],\n",
      "        [  101,  3653,  2015,  3779,  9343,  2046,  1996, 12991, 13874,  2008,\n",
      "         10823,  2020,  4452,  1997, 12971,  2040,  2003,  2025,  4452,  1997,\n",
      "         12971,  2002,  1040,  3298,  2000,  3806,  3703,  2007,  2028,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0610, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0120, 0.0120, 0.6770, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.7540, 0.0520, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1130, 0.1130, 0.1130,\n",
      "         0.4290, 0.1130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.2320, 0.2320, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260]]), 'label': tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  2936,  1996, 20703,  3672,  2013,  2478,  2486,  2000,\n",
      "          2644,  5274,  1996,  2062,  2486,  2008,  2097,  4821,  2031,  2000,\n",
      "          2022,  2109,  2061,  4808,  2085,  2052,  2022, 15123,  2004,   102],\n",
      "        [  101,  2660,  2003,  2025,  1037,  3842,  1997,  7489,  2021,  7322,\n",
      "          1998, 13200,  2148,  2660,  2003,  1996,  2069,  2112,  2008,  2001,\n",
      "          3876,  2011,  9944,  7521,  1998,  2049,  2028,  1997,  1996,   102],\n",
      "        [  101, 11865, 27431,  2863,  2792,  2055,  6080,  4808,  2017,  2035,\n",
      "          2020,  4285,  2205,  2524,  1998,  2009,  2200, 12991, 27086,  1998,\n",
      "         21591,  1998,  3791,  2000,  2022,  7917,  1997,  2250,   102,     0],\n",
      "        [  101,  7036,  8711,  2024,  2074,  2559,  2000,  2147,  2524,  1998,\n",
      "         12867,  2038,  2070,  6919,  6695,  1999,  2810,  1998, 10571, 14279,\n",
      "          2036, 12075, 18537,  2005,  2627,  2037,  3539, 12330,  2006,   102],\n",
      "        [  101,  8275,  2739,  2038,  2053,  2801,  2339, 22418,  6045,  4147,\n",
      "         15941, 22953,  8797,  2121,  3424,  8398,  6186,  2121,  2007,  2444,\n",
      "          1999,  9003,  9587, 25016,  2213, 12436, 20876, 11758,  2193,   102],\n",
      "        [  101,  4151,  4485, 12043,  2673,  2023, 11382,  3489,  8466,  2003,\n",
      "          4257,  2041,  5637,  5310,  2122, 11382,  9681,  2074,  2064,  2025,\n",
      "          9507,  2037,  2566, 27774,  2015,  2064,  2027,   102,     0,     0],\n",
      "        [  101,  2402,  2304,  2611,  3046,  2532,  2022,  1996,  2190,  2016,\n",
      "          2064,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4314,  7961,  6206,  7344,  8563,  5736, 14233,  2571, 11992,\n",
      "          6314,  2058,  9353, 15549, 28200,  9413,  3995, 11992,  5223,  7489,\n",
      "          4603,  7961,  6206,  7344,  8563,  5736, 14233,  2571,  4282,   102],\n",
      "        [  101,  8962,  2271,  3504,  2061,  2204,  2011,  7831,  2054,  2003,\n",
      "         24166, 13196,  3689,  2055,  2002,  2089,  2030,  2089,  2025,  2031,\n",
      "          2018,  9530,  5054,  6342,  2389,  4262,  2116,  2086,  3283,   102],\n",
      "        [  101,  2027,  2941,  2024,  2995, 26030,  2015,  5762,  2135,  4092,\n",
      "          2008,  2003,  1996,  7117,  1997,  1996,  2171,  4238,  2027,  2024,\n",
      "          2025,  2012,  2035,  4198,  2000, 14560,  5762,  2135,   102,     0],\n",
      "        [  101,  6102, 21237,  6102, 10469,  2365,  1997,  1037, 17219,  2686,\n",
      "         12738, 19582,  7743, 24646, 19567, 11286,  2100, 24646, 19567,  9324,\n",
      "         11263,  3600,  1996,  2829, 15912,  1996, 16480,  5358, 20067,   102],\n",
      "        [  101,  2108,  2006,  2070, 10439,  3573,  2108,  2070,  2502, 15007,\n",
      "          7743,  2064,  2022,  7917, 15933,  4558,  2193,  1997,  6599,  2146,\n",
      "          6226,  2832,  1999,  1996,  2190,  2553,  2079,  2025,  6555,   102],\n",
      "        [  101,  2043,  2106,  2009,  2707,  2008,  1996,  2865,  5271,  1996,\n",
      "          4895, 12131,  9067,  2004,  3180,  2129,  2116, 15667,  5381,  2079,\n",
      "          2017,  2113,  1999,  2115,  2613,  2166,  1998,  2129,  2411,   102],\n",
      "        [  101,  2017,  2113,  2054,  1045,  5560,  8587,  2013,  2068, 21029,\n",
      "          2033,  2005,  3038,  2008,  1045,  8587,  1996,  5023,  4471,  2008,\n",
      "          1045,  2572,  4011,  2000,  2022,  8239, 10823,  1998, 14560,   102],\n",
      "        [  101,  2054,  1037,  2417, 18278,  6261,  1037,  2698,  2095,  2214,\n",
      "          2008,  2064,  2448,  5514,  2084,  2014,  3428,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061, 25218,  2015,  1996,  2069,  3924,  3554,  1996, 14163,\n",
      "         13793,  2229,  2012,  2556,  1999,  1996,  7327,  2079,  2025,  4175,\n",
      "          1996,  3907,  8664,  2020,  2105,  2193,  2757,  1998,  2193,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0950, 0.0950, 0.0950, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0950, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0950, 0.0950, 0.0950],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0540, 0.0540, 0.0140, 0.2040,\n",
      "         0.2040, 0.2040, 0.0140, 0.0140, 0.0540, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640,\n",
      "         0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0140, 0.0140, 0.0530, 0.0530, 0.0530, 0.0530, 0.0140,\n",
      "         0.0140, 0.0140, 0.0530, 0.0140, 0.0140, 0.0140, 0.0140, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1030, 0.1030, 0.1030,\n",
      "         0.1030, 0.0020, 0.0020],\n",
      "        [0.0060, 0.0060, 0.0820, 0.0820, 0.0060, 0.0820, 0.0820, 0.0820, 0.0820,\n",
      "         0.0820, 0.0820, 0.0820, 0.0820, 0.0820, 0.0820, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.1460, 0.0100, 0.0100, 0.0100, 0.0380, 0.0380, 0.5540, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  3844,  2039,  9152, 13327,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1037,  2317,  2879,  2008,  2064,  2025,  5607,  1045,\n",
      "          2022,  5506,  2004,  3109,  1045,  2064,  5607,  2488,  2059,  2028,\n",
      "          1997,  2027,  4632,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2116,  2329,  2006,  1996,  9983,  2228,  2027,\n",
      "          1521,  2128,  1996,  4441,  2138,  2027,  1521,  2128,  2025,  7489,\n",
      "          2027,  1521,  2128,  4654,  4502,  3215,   102,     0,     0,     0],\n",
      "        [  101,  5310,  2027, 20114,  2068,  2096,  3529,  3504,  2205,  1998,\n",
      "          2027, 20114,  1996,  6613,  2688, 26419,  2232,  2062,  3065,  2323,\n",
      "          2022,  2055, 19483,  2111, 11065,  2013,  2317, 20199, 27065,   102],\n",
      "        [  101,  2074,  4384,  2008,  9152, 13327,  2038,  9081,  2606,  8038,\n",
      "          2156, 12455,  2035,  1997,  1996,  9467,  1998, 15516,  2027,  2404,\n",
      "          2006, 12461,  2003,  2025,  2055,  9945,  2030, 26935,  4385,   102],\n",
      "        [  101,  2136,  2171,  2899,  2162, 25852,  2015,  2136,  6087,  2417,\n",
      "          2317,  1998,  2630,  2136,  3295,  2899,  5887,  2136,  2343, 10334,\n",
      "          2021,  5503,  5297,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2718,  3538,  5363,  2000,  6773,  3424,  7632,  3501,\n",
      "          2527,  7423,  2522, 29566,  5521,  2004,  1037,  1044, 22571, 10085,\n",
      "         17625,  2144,  2014,  3008,  2024,  7489,  2013,  3163,  1998,   102],\n",
      "        [  101,  2023,  2051,  2009,  2515,  2025,  2017,  5587,  2498,  2000,\n",
      "          2317,  4915,  2085,  2008,  2057, 10887,  3096,  4309,  2058,  8066,\n",
      "          1999,  2256,  2740,  2729,  3068,  2331,  2011,  3460,  2003,   102],\n",
      "        [  101,  1996,  2345,  5576,  2005,  1996, 19483,  2015,  1998,  1996,\n",
      "          2522,  5644,  1998,  1996, 12281,  1998,  1996,  5181,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  7538,  2323,  3942,  2634,  2000,  2131, 15504,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4013,  5955,  1996,  9152, 13327,  2015,  2079,  2025,  2729,\n",
      "          2065,  2017,  2196,  3079,  7179,  2882, 14697,  5149,  4061,  1996,\n",
      "         14085,  5831,  2015,  2030,  2307,  2307,  2882,  4215,  2598,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  6300,  2050,  1045,  2572,  5458,\n",
      "          1997,  2296,  2157,  3358, 17490,  2667,  2000,  2735,  1996,  7251,\n",
      "          2011,  3038, 21633,  2024,  1996, 13157,  2043,  2009,  2068,   102],\n",
      "        [  101,  2057,  8627,  2317,  3128,  2141,  4841,  2000,  4553,  2178,\n",
      "          2653,  2021,  2057,  2156,  2009,  2004,  1037, 15074,  2005, 11560,\n",
      "          2336,  2008,  2024,  8078,  2004,  2896,  2465,  2000,  5441,   102],\n",
      "        [  101, 20996, 10258,  4747,  2004,  2065,  1037,  9129,  1997, 19483,\n",
      "          2015,  2038,  2151,  4145,  1997,  2054,  1037,  2204,  3017,  2030,\n",
      "          2151,  2785,  1997,  3017,  2003,  2030,  2515,  2030,  2052,   102],\n",
      "        [  101,  1045,  2113,  2026,  3105,  2525,  5458,  1997,  2026,  4632,\n",
      "          2021,  9826, 10047,  5458,  1997,  2023,  2317,  4632,  5145,  2205,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2122,  2024,  1996,  2785,  1997,  7489,  2057,\n",
      "          2035,  2323,  6160,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.3680, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.1250, 0.1250, 0.1250, 0.1250, 0.4740, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.3690, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0970, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2023, 11596,  1996,  3145,  5387,  1997,  2339,  2057,  2323,\n",
      "          2360,  2009,  1998,  2054,  2003,  1996,  3291,  1996, 13948,  1997,\n",
      "          7489,  2000,  4632, 27605, 13806,  2046,  2256,  2783,  3226,   102],\n",
      "        [  101, 22052,  9152, 13327,  5348,  3766,  2003,  2006,  1996,  2274,\n",
      "          1059, 20535,  3070,  2055,  2865, 26242,  2111,  2005,  2037,  3789,\n",
      "          1999,  1996,  2715,  3690,  2096,  9428, 17693,  2010,  2878,   102],\n",
      "        [  101,  6343,  2412,  2435,  1037,  2309,  6616,  2055,  5805,  2653,\n",
      "          1999,  4331,  2127,  2308,  2288,  1996,  3789,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2003,  1037,  2204,  2518,  2027,  7448,  2035,  1997,\n",
      "          1996,  2047,  5979, 16864,  8711,  2000,  5395,  2027,  2097,  2022,\n",
      "          1997,  2307,  2393,  4252,  1996, 10575,  2129,  2000,  5047,   102],\n",
      "        [  101,  2178,  2317,  7584,  2000,  7025,  2017,  2113,  2115,  2406,\n",
      "          2003, 11865, 19658,  2098,  2043,  2115,  2219, 10463,  2000,  7025,\n",
      "          2017,  2113,  2115,  2406,  2003, 11865, 19658,  2098,  2043,   102],\n",
      "        [  101,  1045,  1521,  1049,  2025, 10094,  2696,  2292, 18411,  2015,\n",
      "          2022,  2070, 10200, 10487,  2005,  2023,  7025, 20200,  6616,  3531,\n",
      "          2131,  2068,  2125,  2008,  2754,   102,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2079,  2025,  2228,  8398,  8754,  2215,  2000,\n",
      "          3102,  2037,  3507,  4841,  2017,  2031,  2025,  2042,  7079,  3086,\n",
      "          2000,  1996,  2193,  1997,  2317,  2273,  4727,  2144,  1996,   102],\n",
      "        [  101,  1045,  2572,  1996,  2317, 13664, 17219,  2026, 10748,  2442,\n",
      "          2022,  2061,  9364,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2001,  2036,  1996,  2190,  2447,  1998,  2117,  2327,\n",
      "         28602,  2007,  1996,  3565, 14929,  2040,  2180,  1996,  2193,  2193,\n",
      "          2193,  3060,  2308,  2528,  2255,  2358,  2437,  7387,  7098,   102],\n",
      "        [  101,  2009,  2205,  2397,  2027,  2024,  2525,  1999,  1037,  9587,\n",
      "         25016,  2213,  7221,  2013,  1996,  2927,  2052,  2031,  2042,  2488,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16047,  1999,  1996,  2142,  2163,  4603,  2308,  9979,  1996,\n",
      "          2373,  1997,  2108, 12320,  2027,  8439,  1999,  1996,  8294,  1997,\n",
      "          1996,  5966,  2090,  1996,  2048, 21024,  4406,  4314, 10469,   102],\n",
      "        [  101,  6721,  4355,  3124,  2318,  3331,  2000,  2033,  1998,  2001,\n",
      "          2200, 11770,  2011,  1996,  2755,  2008,  1045,  1521,  1049,  1037,\n",
      "          9889,  5637,  5152,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 24004, 20200,  5637,  2015,  2024,  1996, 21505,  1997,\n",
      "          1996,  2451,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4481,  2008,  2023, 24004,  2052,  5326, 11382,  3489,  5248,\n",
      "          2096,  3038, 11382,  9681, 11113, 16368,  2009,  1998,  1038,  8523,\n",
      "          8458, 21382,  2012,  1996,  2168,  2051, 10163,   102,     0,     0],\n",
      "        [  101,  5060,  2129,  1996,  4035,  3975,  1996,  7521,  3275,  2039,\n",
      "          2061,  2009,  3544,  2625,  2084,  2193,  2672,  2027,  2064,  2036,\n",
      "          3975,  2009,  2061,  2009,  3065,  2193,  1997,  9587, 25016,   102],\n",
      "        [  101,  1045,  2293,  2009,  1045,  2031,  6861, 13734,  2004,  2092,\n",
      "          2079,  2025,  2113,  2073,  2115,  2012,  2021,  2182,  1045,  2018,\n",
      "          2000,  2404,  1037,  8638,  2105,  2009,  2000,  2562,  1996,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0160,\n",
      "         0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.3520, 0.3520, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3150,\n",
      "         0.0830, 0.0830, 0.0830],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.6210, 0.1640, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0060, 0.0060, 0.0060, 0.3120, 0.3120, 0.3120, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4400,\n",
      "         0.4400, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0350, 0.5020,\n",
      "         0.1320, 0.0090, 0.0090],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1420, 0.5390, 0.1420, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.4200, 0.0080, 0.0080, 0.4200, 0.0080, 0.0080,\n",
      "         0.0080, 0.0290, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6320,\n",
      "         0.0440, 0.0120, 0.0120],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290]]), 'label': tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2045,  2320,  2001,  1037,  3507,  2315,  3505,  3005, 16110,\n",
      "          2001,  3733,  2000,  2066,  2002,  3253,  4847,  1998, 27128,  2000,\n",
      "         17710,  2243,  2021, 11041,  2008,  2002,  1040,  2496,  1037,   102],\n",
      "        [  101,  1045,  2196,  2354,  1037, 16522,  5223,  2099,  2127,  1045,\n",
      "          2587, 11721,  2497, 11721,  2497,  2003, 15927,  2007,  2068, 17727,\n",
      "         12184,  3372,  2210,  6616,  2015,  7143,  2000,  7499,  5181,   102],\n",
      "        [  101,  5310,  5310,  5310,  2035,  2216,  6206, 12114,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2026,  2814,  2024,  2066,  2026,  2155,  4983,  1045, 10082,\n",
      "          5223,  2017,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25283,  4890,  6904, 13871,  4140, 12440, 11350,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2279,  2317,  2158,  2024, 13026, 11177,  2304,  2273,\n",
      "          2144,  5181,  2024,  2525,  1999,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3841,  2003,  4658,  2021,  2002,  2003,  2145,  1037,  9152,\n",
      "         13327,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2158, 15315, 21105,  2068,  2317, 22619,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  8797,  2121,  7823, 12193,  2100,  2150,  2026,  4874,\n",
      "          1997,  2236,  8840, 22314,  2044, 14158,  2028,  2006,  1037,  3345,\n",
      "         13217, 21935,  2007,  1037, 21396,  6834,  2016,  5092,  2239,   102],\n",
      "        [  101,  1045,  2156,  2017,  2024,  5689,  2006,  2026,  2296,  2773,\n",
      "          9152, 13327,  8295, 17219,  3374,  1045,  2079,  2025,  3058,  8494,\n",
      "          7377, 19987,  2295,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 28543, 11382,  3489,  2787,  2000,  3443,  1037,  2177,\n",
      "          2170,  6394,  8246,  2030,  2070,  2107, 16522,  2854,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2097,  2025,  3857,  1037,  2813,  2105,  1996, 14518,\n",
      "          8711,  2559,  2000, 10574,  3017, 14522,  1998,  6148,  3171, 12637,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2003,  2009,  2976,  2375,  2008,  2019,  6206, 11560,  3236,\n",
      "          6830,  2097,  2022,  3202, 17929,  2065,  2025,  2339,  2025,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5262,  2292,  2033,  9377,  2008, 16371, 13871,  3388,  1997,\n",
      "          9866, 14649,  2003,  8864,  2025,  2074,  2317,  8864,  2009,  2003,\n",
      "          8864,  2005,  2035,  2529, 18824,  2021,  2009,  2003,  2108,   102],\n",
      "        [  101,  1037, 28101,  1037, 25430, 14728,  1998,  2019,  2137,  2024,\n",
      "          1999,  1037,  2282,  2362,  2079,  2027,  2035,  2031,  1996,  2168,\n",
      "          3226,  2030,  2079,  2027,  2169,  2031,  2037,  2219,  4767,   102],\n",
      "        [  101,  5310,  2339,  2024,  2111,  2025, 13847,  2041,  2058,  2023,\n",
      "          2980, 11690,  2943,  1045,  2074,  2123,  1521,  1056,  2131,  2009,\n",
      "          1045,  2342,  1037,  7525,  5470,  2252,   102,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.1040, 0.1040, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1040,\n",
      "         0.1040, 0.1040, 0.1040, 0.1040, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.1040, 0.0070, 0.0020],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4620, 0.4620, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3960, 0.3960, 0.1040, 0.1040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.1230, 0.1230, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.4650, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.2340, 0.2340, 0.2340, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2340,\n",
      "         0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0530, 0.7650, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0190,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0720],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.1560, 0.5940, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3099,  6609, 22432, 15859, 16020,  4161,  1037,  2110,  1997,\n",
      "          5057,  2044, 13475,  1037,  6474,  9152, 13327, 10338,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8840,  2140,  2025,  2033,  1045,  2123,  1521,  1056,\n",
      "          3066,  2007,  1038,  5244,  2025,  2648,  2336,  1521,  7020,  1045,\n",
      "          2681,  2008, 17276,  6752,  2005,  7955,  2842,   102,     0,     0],\n",
      "        [  101,  5310,  1998, 22072,  1998,  1996, 28511, 18832,  2024,  2193,\n",
      "          6149,  2035,  7486,  2442,  2994,  1999,  5152,  4915,  5717, 11790,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2052,  2036,  2360,  2008,  2025,  2205,  2919,\n",
      "          6195,  1996,  2406,  2288, 15504,  2011,  1996,  2149,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  1521,  1049,  3046,  2532,  2644,  1996,  4808,  2021,\n",
      "          1045,  2064,  1521,  1056,  2393,  2021,  3102,  2122,  7570,  2229,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4931,  6456,  2106,  2017,  2113,  2008,  8529, 11810,  3683,\n",
      "          6559,  5637,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2026, 12954,  3331,  2055,  2129,  2043,  1045,  2234,  2041,\n",
      "          2004, 19483,  2016,  2018,  2000,  9587, 14287,  1996,  2544,  1997,\n",
      "          2033,  2016,  2245,  1045,  2001,  2077,  1998,  2129,  1045,   102],\n",
      "        [  101,  3782, 13727, 19894,  2098,  2055,  1996,  2304, 11320,  8091,\n",
      "         10228,  5705,  2155,  1998,  6343,  4282,  2339,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8288,  4143, 25572, 25574,  2080, 12593, 10047,  2074,\n",
      "          3038, 10047,  2559, 27046,  2014,  1056, 28394,  3215,  1998, 10163,\n",
      "          2228,  2016,  4152,  2009,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2342,  2000,  4847,  5152,  2390,  2138,  2027,  2024,\n",
      "          2529,  2205,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 19992, 24008,  2193,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  2057, 15697,  1999,  4526,  1041, 28298,  6695,  2005,\n",
      "          2308,  2000, 25220,  1996,  2765,  2003,  6428,  2945,  4279,  1998,\n",
      "         18730,  2023,  2950,  1041, 28298,  6695,  2005, 11690, 22437,   102],\n",
      "        [  101,  2002,  4165,  2066,  1037,  5929,  2240,  1045,  2097,  2707,\n",
      "          1037,  2240,  1997, 17925,  2170,  6838, 13555, 11263,  9102,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2031,  2525,  2699,  1996,  3115,  4485,  1045,  2156,\n",
      "          2182,  3679,  2017,  6069,  3437,  2030,  3046,  1998, 11382,  3489,\n",
      "          2033,  2153,  2197,  3382, 22953,  2079,  2025,  3153,  2007,   102],\n",
      "        [  101,  9152, 23033,  2023,  2001,  4013,  9215,  2074,  1037, 13141,\n",
      "         27006,  2378,  1037, 18138,  2008,  7110,  1056,  8962,  3723,  4738,\n",
      "          1998,  2064,  2025,  3275,  2041,  2129,  2000,  2907,  2010,   102],\n",
      "        [  101,  1045,  4660,  2115,  3160,  2085,  3437,  3067,  2024, 25602,\n",
      "          2040, 11891,  3336, 19085, 21877,  3527, 24862,  2015,  2024,  2017,\n",
      "          2205,  7975,  4485,  2000,  3437,  1037,  3722,  3160,  1045,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.1520, 0.0110, 0.0110, 0.5780, 0.1520, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.6770, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300, 0.0340,\n",
      "         0.0340, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.2810, 0.2810, 0.2810, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1890, 0.7180,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.4350, 0.4350, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7840, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6160,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0950, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0950, 0.0950, 0.0950,\n",
      "         0.0950, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.1030, 0.1030, 0.1030, 0.1030, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070]]), 'label': tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  5310,  1045,  2079,  2025,  3305,  1996, 10661,\n",
      "          1997,  2111,  2040,  2024,  2114,  1996,  2331,  6531,  2021,  2788,\n",
      "          9075,  1996, 22410,  2000,  2507,  1996,  2331,  6531,  2000,   102],\n",
      "        [  101, 17901,  2003,  2139,  6914, 22139,  2021,  1996,  2028,  2204,\n",
      "          2518,  2055,  3423,  3989,  2003,  2008,  2317,  9282,  4268,  2097,\n",
      "          2025,  2031,  2000, 11835,  2007, 17276,  2053,  5620,  2000,   102],\n",
      "        [  101,  2000,  1996,  9548, 10452,  2040,  2718,  2006,  2033,  1999,\n",
      "          2256,  2200,  2034,  5499,  2913,  2607,  2655,  2033,  2388,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2026, 18328,  1998,  1045,  2024, 20767,  3251,  2010,  4937,\n",
      "          1037, 11690,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4931,  4067,  2017,  2005,  2206,  2033,  2067,  2017,\n",
      "          2024,  1996,  3124,  2007, 11382,  3489, 22128,  2013,  1058, 10695,\n",
      "         29278,  2819,  2157,  1045,  2572,  1037,  5470, 18411,  2860,   102],\n",
      "        [  101,  2069,  6616,  2378,  6904, 13871, 12868, 20578,  2111,  2000,\n",
      "          2562,  2068,  2041,  1997,  3105,  1998,  2769,  2005,  1037,  2261,\n",
      "          2086,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 19313,  2821,  3524, 22198, 13085,  2001,  9253,  8663,\n",
      "          8275,  2638,  9333,  1037,  3653, 18209,  2005, 17657,  5712,  2005,\n",
      "          1996, 21379,  2015,  2008,  1996,  2865, 17858,  2253,  2247,   102],\n",
      "        [  101,  5310,  5310,  5310,  3053,  2035,  2014,  4599,  2024,  2317,\n",
      "         23368,  2015,  2129,  7910, 19313,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  6425, 29058,  2038,  4197,  2041,  1999,  2755,  3725,\n",
      "          2651,  8267,  2062,  7489,  1999,  1037,  2309,  2095,  2084,  2009,\n",
      "          2106,  1999,  1996,  2972,  2558,  2013,  2193,  2000,  2193,   102],\n",
      "        [  101,  2061,  2762,  2129,  2116,  2062,  1997,  2115,  2406,  3549,\n",
      "          2024,  2017,  2183,  2000,  2292, 21442, 11705,  2014, 14163, 13793,\n",
      "          2063, 28882,  4028,  8711, 17048,  8545, 22499,  4168,  2417,   102],\n",
      "        [  101,  5310,  1045,  2293,  1057,  2062,  6904, 13871,  4140,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2404,  2039,  2062,  2128,  7559,  5732, 11344,\n",
      "          2005,  2033,  2000,  4965, 22953,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 26419,  2232,  1057,  1521,  2128,  2028,  1997,  1996,\n",
      "          2087,  2128,  7559,  5732, 13675, 10054, 22341,  1045,  1521,  2310,\n",
      "          2412,  2777,  2664,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2699,  5128,  2026,  4344,  1999,  1037,  4487,  3489,\n",
      "          2320,  2016,  7210, 11159,  2033,  1998,  2743,  2125,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1996,  6707,  2001,  2008,  1996, 18148,  2106,\n",
      "          2025,  3102,  2035,  4286,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2064,  2017,  4298,  2025,  2022,  1037,  2128,  7559,  2094,\n",
      "          1998,  2644,  9530, 10258,  5844,  3644,  4750, 16795,  2964,  2007,\n",
      "          2120, 14649,  2008,  2003,  6719,  1996,  4500,  1997,  2035,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.1100, 0.1100, 0.1100, 0.1100, 0.1100, 0.1100, 0.1100, 0.1100,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.6610, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0000],\n",
      "        [0.0230, 0.3290, 0.3290, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0040, 0.0040, 0.0040, 0.0040, 0.0010,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0570, 0.0570, 0.0570,\n",
      "         0.0570, 0.0570, 0.0570],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.1980, 0.1980, 0.1980,\n",
      "         0.1980, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.7630, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  7955, 14739,  6816,  8909,  2278,  1997,  1996,  9152, 23033,\n",
      "         21391,  5305,  2571,  3526,  2007,  2028,  2192,  5079,  2369,  2010,\n",
      "          2067,  4147,  1037,  6397, 10371,  6616,  6816,   102,     0,     0],\n",
      "        [  101, 27231,  2001,  1996,  2087,  3937,  2317,  7743,  2021, 10853,\n",
      "          2904,  2032,  2046,  1037,  2317,  7743,  2040,  2064,  2012,  2560,\n",
      "          2022,  5541,  2007,  2010, 16021,  2696, 27263,  2015,  4067,   102],\n",
      "        [  101,  5310,  2027,  2035,  2298,  2066,  2033,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2022,  2204,  2005,  2017,  2000,  7324,  2125,  7694,  1996,\n",
      "          7214, 11382,  3489,  6904, 13871,  4140,  4441,  4828, 19272,  2566,\n",
      "         27774,  1999,  2236,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6637,  5762,  2967,  2066,  2304,  2780,  6431,  2317,  2780,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5223,  2017,  2205,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998,  2035,  1996,  3348,  2097,  2022,  5637,  2030, 11690,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2024,  2317,  2111,  5472,  2401,  6910,  1998,  2304,\n",
      "          2111,  1037,  5305,  2135,  2665,  1998,  4004,  2015,  2035, 23187,\n",
      "          3756,  1998,  3534, 16422,  4589,  1998,  1996,  7397, 12493,   102],\n",
      "        [  101,  3342,  4268,  2065,  2115,  5637,  2552,  2004,  3442,  2004,\n",
      "          2017,  2064,  1999,  2082,  2138,  2115,  2074,  6069,  2131,  2170,\n",
      "          1037,  6904,  2290,  2030, 19483,  2065,  2017,  2079,  2025,   102],\n",
      "        [  101,  5310,  5310,  1996,  8037,  2024,  1996,  5221,  5081,  2000,\n",
      "          2137,  4071,  2062,  2084,  3607,  2859,  4238,  1998, 24815,  2483,\n",
      "          2404,  2362,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2123,  1521,  1056,  5223,  4426,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  1999,  1996, 23299,  1997,  1996,  8370,  2015,\n",
      "          2017,  2128,  7559,  5732,  2336,  9587,  2860,  1999, 28781,  6887,\n",
      "         27292, 23496,  2595,  4842,  2102,   102,     0,     0,     0,     0],\n",
      "        [  101, 10474,  2428,  2022, 17261, 10424,  8038,  2140,  9152, 13327,\n",
      "          2015,  2024, 26316,  1999,  5312,  1997, 12039,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2113,  1996,  2828, 20505,  8103,  4451, 11382,  3489,\n",
      "          2052,  4604,  1037,  2406,  2046, 15625,  2065,  1996,  2016, 11705,\n",
      "          2015,  2020,  2157,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5607,  1037,  9152, 23033,  2006,  2010,  7424,  1998,  2191,\n",
      "          2032,  2991,  1999,  2010,  3829,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2064,  2025,  5630,  2065,  2017,  2024,  2128,\n",
      "          7559,  5732,  2030,  1037, 18792,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.1840, 0.1840, 0.1840, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.1840, 0.1840, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.4360, 0.4360, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.1890, 0.1890, 0.1890, 0.1890, 0.1890,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.6390, 0.1690, 0.1690, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0030, 0.0030, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.1810,\n",
      "         0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.6660, 0.0120, 0.0120, 0.0120, 0.1760, 0.0120, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.1280, 0.1280, 0.1280, 0.4840, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0480, 0.0480, 0.6860,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310, 15537,  2033, 15221,  1997,  1996, 20907,  3185,  2073,\n",
      "          1996, 11587,  2136,  2001, 15504,  1998,  2059,  2081,  2000, 28667,\n",
      "          4630,  2069,  2193,  2086,  2101,  2000,  2424,  2041,  2500,   102],\n",
      "        [  101, 13229, 23890,  2075,  2638,  9333,  2023,  5027,  2012,  1996,\n",
      "          6465,  8398,  4711,  1037,  2109,  1047, 24129, 10288,  2646,  1037,\n",
      "          5949, 23298, 10810,  1998,  4771,  2009,  3662,  2010,  5719,   102],\n",
      "        [  101, 16877,  6708,  2836,  1999, 19318,  2003,  2054,  8348,  5470,\n",
      "          2228,  2728,  2091,  3240,  3781,  2836,  1999,  2203, 16650,  2001,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5221,  3647,  2686,  3784,  2027,  7917,  2033,  2005,  2108,\n",
      "          2205,  4013,  8398,  1998, 11242,  8247,  6904, 13871, 12868,  2040,\n",
      "          2018,  2025, 10741, 14588,  2000,  1996,  2643,  3750,  4593,   102],\n",
      "        [  101,  2023,  2128,  7559,  5732,  6394,  2228,  2008,  1045,  2056,\n",
      "          8042,  7917,  4409,  2003,  2037,  2151,  3246,  2005,  2122,  4314,\n",
      "         21633,  1045,  2228,  2025,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2115,  2783,  8801,  2024, 11382,  3489, 26101,  2885,  2097,\n",
      "          3477,  2037,  8711,  2000,  2681,  2005,  2866,  1998,  2605,  1996,\n",
      "          2925,  5152,  5949,  8653, 10888, 29602, 14277,  4710,   102,     0],\n",
      "        [  101,  1996, 26033,  2000,  6413,  1996,  7655, 22889,  4904, 25850,\n",
      "          2075,  1999,  1037, 11689,  2008,  3294, 26663, 21358,  7875, 19483,\n",
      "          5936,  2003,  6016,  2033, 26419,  2232,   102,     0,     0,     0],\n",
      "        [  101,  2079,  2025,  2681,  2041,  1996, 11382,  3489, 24477,  4329,\n",
      "          2303,  3597, 16671,  1997,  2193,  2454,  8042,  2001,  1037,  3017,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2144,  1045,  2042,  2012,  2023,  2082,  2017,  9152, 13327,\n",
      "          2015,  2031,  2196,  2025, 10865,  2055,  1996, 20772,  3063,  2507,\n",
      "          2009,  2039,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6160,  7548,  2057,  2024,  1037,  2455,  1997,  8711,\n",
      "          2013,  1996,  1052,  1039,  3226,  2008,  2069,  1052,  1039,  2043,\n",
      "          2027,  2215,  2000,  2022,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 19817,  6305,  2072,  4482,  2061,  7352,  2769,  2003,  5094,\n",
      "          2662,  8073,  2862,  3071,  1999,  2037,  7809,  2004,  7792,  7206,\n",
      "         20287,  2024,  2025,  6206,  7489,  1039,  1054,  2006,  1996,   102],\n",
      "        [  101,  2612,  1997, 21029,  4409,  2057,  2323,  2074,  7221,  2008,\n",
      "         13852, 22212,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2317,  2879,  2003,  1037,  8239,  8579,  2132,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  9413,  2850,  7446,  2097,  2202,  2729,  1997,  2008,\n",
      "          2002,  2097,  5672,  2068,  2007, 14560,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2069,  3968,  6292,  2489,  4613,  3039,  2003, 22555,\n",
      "          1998, 15523,  1996,  8797,  2545,  1998, 12731, 10603,  2121, 20203,\n",
      "          6961,  5993,  2065,  2017,  2079,  2025,  2672,  1045,  2323,   102],\n",
      "        [  101,  5310,  2003,  2009,  1996,  2168,  2028,  2008,  2003, 16939,\n",
      "          2875,  4004,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0070, 0.4080, 0.4080, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0280, 0.0280,\n",
      "         0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.1080, 0.1080, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.1080, 0.1080, 0.1080, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7840, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740,\n",
      "         0.0740, 0.0740, 0.0740],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0560, 0.8100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.2320, 0.2320, 0.0040, 0.0040, 0.0610, 0.2320, 0.2320, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0550, 0.0140, 0.0140, 0.7870, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2928, 16950,  9102,  4059,  9875,  2928, 12731,  9102, 11755,\n",
      "          2003,  2019, 14868,  2128,  7559,  5732, 22330, 11755, 15450,  7344,\n",
      "          2040,  7365, 15056,  7566, 15056,  8451, 15056,  1998,  2003,   102],\n",
      "        [  101,  8840,  2140,  2009, 16880,  2739,  2000, 13373,  3111,  2008,\n",
      "          2027,  2079,  2025,  2031,  2151,  9152, 13327,  9165,  2027,  2903,\n",
      "          2008,  2679,  2003,  2025,  2613,  2174,  2065,  2045,  2024,   102],\n",
      "        [  101,  5310,  6300,  2232,  2425,  2008,  2000,  2336,  1999, 27157,\n",
      "         15504,  2308, 23206,  2111,  2915,  2011,  2610,  2216,  1999,  6375,\n",
      "          2025,  2017,  2216,  5996,  4647,  2053, 16021,  5694,  1997,   102],\n",
      "        [  101,  1045,  2453,  2022,  6638,  2021,  2012,  2560,  1045,  2572,\n",
      "          2025,  1037, 18224,  6578, 11868, 11351,  2227,  9761,  2243,  7570,\n",
      "          2063,  4632,  7743,  6616,  2017,  7743,   102,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2003,  2025,  1049, 22564, 21147,\n",
      "          1043, 13958, 24997,  2559,  2012,  2478, 15594,  2099,  2000, 11027,\n",
      "         19465,  2317, 17934,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2138,  8040, 25438, 26454,  2145,  5223, 16773,  2004, 13481,\n",
      "          2021,  2293, 11867,  2594,  8040,  2819,  7402, 11669,  8641, 11867,\n",
      "          6558,  1997,  2035,  7957,  2131,  1037,  3413,  2130,  2295,   102],\n",
      "        [  101,  2074,  5674,  1996,  4808,  1998,  2668, 14740, 22416,  2065,\n",
      "          2057,  2424,  2008,  6887, 27292,  2050,  2038,  2018,  1996,  9526,\n",
      "          2005,  2116,  9932, 13728, 11187,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  7570, 24729, 10441,  2595,  2001,  2061,  8114,  1996,\n",
      "          3463,  2941, 23449,  2094,  1998,  2580,  2062,  5181,  2084,  2045,\n",
      "          2020,  2077,  2030,  2242,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3046,  2000,  2507,  2304,  3079,  5661,  1037,  3382,\n",
      "          1045,  2428,  2079,  2021,  2017,  9152, 13327,  2015,  2293,  2652,\n",
      "          2007,  2111,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2204,  4436,  2339,  2025,  2000,  8494,  7377,  8024,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3234,  2277,  2144, 14512, 12784,  2165,  2058,  1037,  3234,\n",
      "          2277,  4528,  1999,  3304,  2073,  1037, 14085,  7730,  3496,  2018,\n",
      "          2042,  6913,  2296,  4234,  2005,  5109,  1996, 14512,  2787,   102],\n",
      "        [  101,  2009,  1521,  2035,  2028, 17276,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2031,  2069,  3491,  2008, 25288,  2079,  2025,  3043,\n",
      "          2000,  2017,  2129,  2172,  9152, 13327, 10338,  2106,  2115,  6898,\n",
      "          2202,  3892,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2293,  2023,  6904, 13871,  4140, 22889,  4904,\n",
      "          3723,  2376,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2812,  6206,  7489,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3666,  1037, 27243,  2317,  4845,  1998,  1037,  2431,  9152,\n",
      "         13327,  6616,  2242,  2039,  2003,  6517,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0080, 0.0080, 0.0080, 0.1190, 0.1190, 0.0080, 0.0080, 0.1190, 0.1190,\n",
      "         0.1190, 0.1190, 0.1190, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.2150, 0.2150, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.2150],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0120, 0.1750,\n",
      "         0.1750, 0.1750, 0.0120, 0.0120, 0.1750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1890, 0.1890, 0.1890, 0.0130, 0.0130, 0.0500, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0500, 0.0030, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.2620, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0050, 0.0050,\n",
      "         0.0050, 0.0180, 0.2620, 0.2620, 0.0180, 0.0180, 0.0180, 0.0180, 0.0050,\n",
      "         0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6520, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0400, 0.0400, 0.5690, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8610, 0.0600, 0.0160, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4500, 0.4500,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5747,  3026,  2318,  1996,  2047,  2088,  2344,  2056,  2009,\n",
      "          1037,  2502,  2801,  7207,  2018,  2822,  8645,  2198, 15469,  1999,\n",
      "          5239,  2853,  2149,  2000,  2859,  2296,  4031,  2085, 20834,   102],\n",
      "        [  101,  1037, 10597,  5665,  2659, 26264,  9152, 13327,  3632,  2440,\n",
      "          2128,  7559,  2094,  2044,  2108,  2041,  2006,  1037, 24496,  1998,\n",
      "          1996,  2088,  2003,  7135,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2059,  2017,  2468,  9117, 11669,  2006,  2115,  2219, 19199,\n",
      "          2044,  2008,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  2000,  2292,  1996, 14560,  1999,  3956,  2113,  2651,\n",
      "          2003,  2154,  2193,  1997,  1996,  2193,  2154,  7385,  2067,  2000,\n",
      "         13555,  8239,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  1037,  9152, 13327,  2489,  4224,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2003,  9084,  5190,  1997,  2336,  2035,  2058,  1996,\n",
      "          2149,  2024,  2302,  2216, 22977,  2015,  2009,  2515,  2031,  2000,\n",
      "          2022,  2008,  2126,  2679,  5609,  2026,  5917,  2317,  2530,   102],\n",
      "        [  101,  5310,  1045,  5993,  2009,  2003,  1037,  2200,  2152,  3382,\n",
      "          2023,  2003,  1037,  2317,  2711,  3038,  2009,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2196,  8725,  2055,  2054,  2178,  7743,  2288,  2183,  2006,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  2145,  2019, 16021, 16093, 27709,  3468,  4586,\n",
      "          9152, 13327,  1998,  2796,  4841,  7796,  2062,  2084,  2017,  9117,\n",
      "         11669,  2417, 26082,  2131, 21746,   102,     0,     0,     0,     0],\n",
      "        [  101,  2414,  2003,  1037, 16428,  1059, 17276,  2085,  1999,  2116,\n",
      "          3033,  4283,  2000,  4116, 28522,  4313,  1996,  9151,  2099,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2031,  2931, 12655,  2182,  2040, 16957,  2012,  2055,\n",
      "          2193,  1996,  3977,  1997,  2037,  3287, 14562,  2896, 26264,  2006,\n",
      "          2779, 13971, 11424, 16136,  2205,  5410,  1998, 12731, 18141,   102],\n",
      "        [  101,  1061,  2869,  2193,  2317,  2308, 15504,  2011,  9152, 13327,\n",
      "          2015,  2193, 11265, 17603,  4757, 15504,  2011,  1037,  8579,  2121,\n",
      "          3120,  8495,  4126, 26319,  5256,  2039,  4125,  2039,   102,     0],\n",
      "        [  101,  1045,  5223,  2129,  2027, 17279, 22212,  2015,  1999,  5691,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2158,  2035,  2122,  2829,  2026,  3008,  2097,  2025,  5138,\n",
      "          2026,  2317,  4256,  3441,  2024,  2061, 11333,  3600,  2066,  2017,\n",
      "          2113,  4365,  2092,  2009,  2061,  2172,  6211,  2005,  1996,   102],\n",
      "        [  101,  2026,  9152, 23033,  2015,  2066,  1037,  2317,  2611,  1999,\n",
      "          1037, 12459,  3185,  2027,  2022,  4440,  8091,  2005, 24218,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  3609,  2079,  2017,  2228,  4441,  3096,  2001,  2054,\n",
      "          2055,  1996,  2200,  2200,  2200,  2034,  2273,  1998,  2308,  1999,\n",
      "          2381,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0110, 0.0110, 0.0110, 0.0110, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0110, 0.0110, 0.0110, 0.0110, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0050, 0.0180, 0.0180, 0.2560, 0.2560, 0.2560, 0.0050, 0.0680, 0.0680,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.1090, 0.4150, 0.4150, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2320,\n",
      "         0.2320, 0.2320, 0.2320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.6320, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0110, 0.1560, 0.1560, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1560, 0.1560, 0.1560, 0.1560,\n",
      "         0.0110, 0.0110, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0260,\n",
      "         0.0260, 0.0260, 0.0070, 0.0070, 0.0070, 0.0070, 0.0990, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0070, 0.0070, 0.0070, 0.1060, 0.1060, 0.1060,\n",
      "         0.1060, 0.1060, 0.1060, 0.1060, 0.1060, 0.1060, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2045,  2024,  6719, 13157,  2035,  2058,  2035,\n",
      "          1996,  2051, 19838,  3501,  2102,  2085,  5466,  1037,  2600,  2017,\n",
      "          2718,  1037,  6394,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  9152, 23033,  2054,  5553,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3071,  1045, 21090,  2007,  2003,  1037, 11382,  3489, 10303,\n",
      "          1045,  3984,  2008,  1996,  2217,  1045,  2097,  3693,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3909,  2007,  1037,  5835,  1997, 27270,  7570,  2546,  2417,\n",
      "          1999,  1037, 15940,  2440,  1997,  2317,  5929,  2057,  2024,  2055,\n",
      "          2000,  2424,  2041,  2129,  2172, 19902,  2038,  1999,  3573,   102],\n",
      "        [  101,  5292,  3270,  3270,  2053,  4687,  2027,  2052,  2066,  2000,\n",
      "          1060,  2032,  1999,  2151,  2126,  2027,  2064,  8840,  2140,  2002,\n",
      "          2003, 25672,  2075,  2035, 27885,  2819, 16862, 14712,  3560,   102],\n",
      "        [  101,  1996,  7584,  2000, 12046,  2052,  2191,  2008,  2193, 10147,\n",
      "          3654,  5092,  2080, 11042,  1045,  2064,  2079,  2009,  2006,  1996,\n",
      "          4875,  2138,  1045,  2572,  2467,  2383,  2000, 10463,  9152,   102],\n",
      "        [  101,  2092, 14115,  7847,  1998,  2009,  2003,  2025,  1037,  9587,\n",
      "         25016,  2213,  1999, 13578,  2098,  2085,  2045,  1037, 21160,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2123,  1521,  1056,  4737, 10094,  2008,  7743,  6616,  2378,\n",
      "         10930,  4830, 27767,  1057, 10657,  2292,  2033,  5454,  1045,  1521,\n",
      "          1049, 15966,  4830,  3045,  3626,  2123,  1521,  1056,  2393,   102],\n",
      "        [  101,  2016,  1996,  6210,  1997,  1037,  2919,  7743,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2612,  3338,  4501,  2053,  6206, 22190,\n",
      "          5152,  7489,  3039,  1999,  2634,  1045,  2812,  1996,  2773,  6206,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1996,  2160, 12593,  2003,  2467,  1996,  2034,  2000,\n",
      "          6985,  1996,  3040,  2003,  1996,  2317,  4487,  2278,  2008,  2204,\n",
      "          5310,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2272,  2006, 12731,  3372,  7543,  2017,  2064, 10667,  2784,\n",
      "          2046,  2008, 15301, 11721,  2497, 14812,  1998,  2655,  2033,  1037,\n",
      "         11382,  3489,  2153,  2214,  2158,  5292,  3270, 23278,  2232,   102],\n",
      "        [  101,  5310,  1045,  1521,  2572,  2074,  5637,  1524,  1062,  9654,\n",
      "          2121,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2062,  3424,  2317,  9152, 13327, 14636,  2746,  2574,  2000,\n",
      "          1037,  3898,  2379,  2017,  6207,  6728, 10404,  2000,  2136,  2039,\n",
      "          1999,  4526,  2434,  4180,  4419,  2739,   102,     0,     0,     0],\n",
      "        [  101,  2879, 10158,  1998,  2611, 10158,  2031,  2428,  2042,  2204,\n",
      "          2005,  2137,  3360,  2829,  3111,  2003,  1996,  3057,  2252,  2077,\n",
      "          2611, 10158,  2030,  2001,  2339,  6752,  2007,  3112,  2339,   102],\n",
      "        [  101,  5310,  2002, 11586,  8566, 16371, 15379,  3308,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1390, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.5260, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.9320, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7840, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.1070, 0.1070, 0.1070, 0.0070, 0.0070, 0.0070, 0.4050, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.2550, 0.2550,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3700, 0.3700, 0.0260,\n",
      "         0.0260, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0260, 0.0070, 0.0070],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1920, 0.7280, 0.0130, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.6140, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1620,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.7130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0930, 0.0930],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2131,  2247,  2007,  4004,  2015,  1998, 12461,  2200,\n",
      "          2092, 14163, 20051, 13122,  2025,  2061,  2172,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  2003,  5637,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2023,  2299,  2011,  6864,  4511,  4580,  1045,\n",
      "          2572,  4129,  2017,  2175,  2000, 13173, 11045,  5973,  1998,  1996,\n",
      "          2317,  7743,  2229,  2097,  2035, 15645,  6682,  2043,  2009,   102],\n",
      "        [  101,  2079,  2025,  2066,  8398, 11382,  3489,  4434,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2043,  1045,  2156,  2030,  2963,  2739,  2055,  2151,\n",
      "          2406, 11322,  2075,  1037,  9587, 25016,  2213,  3761,  2009,  2066,\n",
      "          2893,  2739,  1997,  2619,  5996,  1997,  1037,  9252,  4295,   102],\n",
      "        [  101, 14203,  8663,  7959, 28231,  2015,  8112,  1045, 10887,  2308,\n",
      "          2138,  2027,  2024,  2502,  6638,  1038, 20470,  5677, 14359,  2015,\n",
      "         12903, 14971, 13716,  6294, 17599,   102,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2025,  1996, 11865,  2595,  6834,  2391,  2017,  7861,\n",
      "         13592,  9463,  2130,  1996,  2235,  7017,  1997, 12461,  2008,  3218,\n",
      "          7025,  2024,  2145, 13047,  2000, 10130,  2017,  6380, 13165,   102],\n",
      "        [  101,  5310,  5310,  2664,  2000,  2156,  2151,  1997,  1996,  8711,\n",
      "          6160,  3626,  2202,  2028,  2061,  2170, 13141,  1999,  2008,  3065,\n",
      "          2129,  2172,  2027,  2941,  2729,   102,     0,     0,     0,     0],\n",
      "        [  101, 26450, 10930,  7743,  9152, 23033,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3532,  7987, 10497,  2239,  2002,  3791,  2000,  2404,\n",
      "          2037,  4632,  2229,  1999,  7173,  2008,  3442,  2039, 16011,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2000,  2023,  2154,  1037,  9152, 23033,  2145,  3331, 10094,\n",
      "          2027,  4299,  2027,  2106,  2157,  2011,  2033,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8398,  2652,  1040,  7433,  2030,  2074,  2108,  1037, 18294,\n",
      "         11382,  3489,  2358,  9541,  3351,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1999,  1037,  2406,  3262, 10357,  2011, 10823,\n",
      "          1998,  1996,  4903,  2140,  2007,  2769,  2191,  2039,  2055,  3867,\n",
      "          1997,  1996,  2313,  2052,  2017,  2145,  2360,  2008,  1996,   102],\n",
      "        [  101,  5310,  5138,  2009,  2634,  2003,  2025,  2005,  5152,  8711,\n",
      "          2027,  2031,  4372, 16093,  2546,  3032,  2002,  2038,  2288,  2490,\n",
      "          2182,  4121,  2028,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9036,  2253,  8239,  8035,  6394,  2006,  2026,  4632,  2061,\n",
      "          2065,  3087,  4122,  2014,  1996,  3225,  7226,  2003,  1037,  3538,\n",
      "          1997,  7967,  9850,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3484,  1997,  2149,  4494,  2114,  5152,  7521,  1998,\n",
      "          4283,  2000,  1996,  2561,  2331,  1997,  4701,  2008,  2003,  6230,\n",
      "          2157,  2085,  2057,  2097,  4088,  2007,  3742, 23702,  2015,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.6140, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0920, 0.3490,\n",
      "         0.3490, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0020, 0.0020, 0.0320, 0.1200, 0.1200, 0.1200, 0.1200, 0.1200, 0.1200,\n",
      "         0.1200, 0.1200, 0.0020, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0810, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.4910, 0.4910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0550, 0.7980, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470,\n",
      "         0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470,\n",
      "         0.0470, 0.0470, 0.0470, 0.0470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040]]), 'label': tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  2017,  2123,  2102,  2525,  2113,  2008,  1045,  2572,\n",
      "          2200,  5637,  2059,  2115,  2063,  2025,  7079,  3086,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2273,  3222,  1045,  1040,  2022,  4527,  2065,  5310,\n",
      "          2130,  4282,  2008,  2273,  3337,  2024, 15504,  1998, 17536,  1999,\n",
      "          2634,  2002,  3849,  2000,  2831,  2055,  2498,  2021,  6655,   102],\n",
      "        [  101,  2995,  2348,  1045,  2196,  2018,  2000, 16500,  4469,  3036,\n",
      "          3426,  2070,  4004,  2015,  2333,  2046,  1996,  5101,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2498, 17076,  4115,  7009,  2651,  2097,  2412,  3786,  2129,\n",
      "          2000,  2022,  1037,  9152, 13327,  2006, 10474,  2008,  3720,  2018,\n",
      "          2033, 22298,  2005,  2420,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2514,  2008,  7025,  7361,  6806, 11607,  2003,  2488,\n",
      "          2084, 15504,  7129,  2336,  2954,  5963,  8551,  2666,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2514,  2428,  2919,  2005,  6047,  2524,  2551,  2304,\n",
      "         12455,  2040,  2024, 25400,  2007,  1037,  2919, 16360,  2011, 17276,\n",
      "         10823,  1999,  4507,  1996,  7574,  2110,  1998,  3451, 27255,   102],\n",
      "        [  101,  2026,  9152, 23033,  2026,  9152, 23033,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2317,  2158,  2218,  1996,  2341,  2330,  2005,  2033,\n",
      "          1998,  1045,  2106,  2025,  5382,  2127,  1045,  2018,  2441,  1996,\n",
      "          2060,  2341,  2005,  2870,  1998,  2939,  2041,  1045,  4771,   102],\n",
      "        [  101,  5310,  3239,  5223,  2017,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2758,  1996,  2128,  7559,  5732, 12256,  2290,  2008,  2018,\n",
      "          2010,  2182,  2004, 21363, 11253,  8029, 14716,  1045,  3631,  2017,\n",
      "          1061,  2869,  3283,  1998,  2017,  2031,  2196,  6757,   102,     0],\n",
      "        [  101,  2431,  8843, 17183,  9152, 13327,  2006,  5796, 28957,  2758,\n",
      "          7279,  3401,  2038,  1037,  3247,  2000,  2191,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2183,  2000,  2131, 21746,  2011,  1996,  2187,  1045,\n",
      "          7499,  2023,  2006,  8398,  2015,  3768,  1997, 11382,  3489,  7073,\n",
      "          2010,  2365,  1999,  2375,  2005,  2742,   102,     0,     0,     0],\n",
      "        [  101, 19902,  1037,  7743,  2467,  3342,  2054,  3632,  2105,  3310,\n",
      "          2105,  1998,  2017,  2097,  2131, 19203,  1999,  1996,  2227,  2007,\n",
      "          2009,  2028,  2154, 16374,  4487, 21338,  2229,  5051,  6593,   102],\n",
      "        [  101,  5310,  6616,  2115,  2406,  9129,  1997, 13555, 11263,  9102,\n",
      "          2015,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4931, 28576,  6887, 15878,  2271,  2017,  2031,  2145,\n",
      "          2196,  4541,  2115,  7208,  2000, 16522,  9559,  1998,  4314,  2552,\n",
      "         11365,  3215,  2066,  8906,  2375,  2177,  2035,  2017,  2018,   102],\n",
      "        [  101,  6864,  7459,  2000, 19739, 17644,  2091,  9152, 13327, 13988,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1160, 0.1160, 0.1160,\n",
      "         0.0310, 0.0310, 0.1160, 0.1160, 0.1160, 0.1160, 0.1160, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.5980, 0.0420, 0.0420, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.1380, 0.1380, 0.1380, 0.1380, 0.1380, 0.1380,\n",
      "         0.1380, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0220, 0.0220, 0.0220,\n",
      "         0.3170, 0.3170, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.3630, 0.3630, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2400, 0.2400, 0.2400, 0.2400, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0320, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.1200, 0.1200, 0.4570, 0.1200, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.2410, 0.2410, 0.2410, 0.0170, 0.0170, 0.2410, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  4907,  2290,  5223,  2115,  2496,  2017,  4025,  2000,\n",
      "          4658,  1045,  2145,  2763,  5807,  1521,  1056,  2360,  8840,  2140,\n",
      "          2123,  1521,  1056,  2215,  2000,  2125, 10497,  8038,  2012,   102],\n",
      "        [  101,  2008,  9152, 23033,  2232,  2079,  2025,  2079,  2498,  2021,\n",
      "          2191,  2017,  5390,  2611,  2017,  5306,  1037, 20949,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2079,  2025,  7438,  2068, 24815,  2072,  6545,  2068,\n",
      "          1998,  5607,  2068,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3909,  3904,  3084,  2033, 16405,  3489,  9636,  2000,  3109,\n",
      "         19483,  2015,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 18162,  2160, 10367,  2042,  4214,  6206, 12114, 25672,\n",
      "         24894, 14088,  7489,  2205,  2146,  7327,  8458, 23238, 19230,  2024,\n",
      "          1037, 22274,  9663,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2043,  2024,  2017,  1998, 22330,  8458,  2183,  2000,\n",
      "          2693,  2000,  3088,  2000,  2191,  3376,  2304, 10834,  2054,  2821,\n",
      "          2017,  2342,  1996,  2317,  2158,  2000,  3073,  1996,  2034,   102],\n",
      "        [  101,  2053, 15508,  1996,  2048,  2057,  2079,  2031,  2024,  5121,\n",
      "          8494, 14540, 14428, 25353,  8737, 25457, 16750,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2467,  2293,  2009,  2043,  6904, 13871, 12868,  1059,\n",
      "         14014,  2000,  1996,  4748, 21266,  2182,  2066,  2023,  2003, 10474,\n",
      "          2065,  1045,  2131,  7917,  2009,  2074,  3065,  2008, 11721,   102],\n",
      "        [  101,  5310,  2941,  2317,  2111,  2024,  5306,  2067,  2000,  2193,\n",
      "          4485,  2763,  2130,  2077,  2008,  2017,  2035,  2514,  2061,  4709,\n",
      "          2000,  2673,  2043,  2017,  2035,  6719,  2074,  3288,  4295,   102],\n",
      "        [  101,  2061,  2009,  2003,  2014,  6346,  2941,  2054,  3047,  2003,\n",
      "          2008,  2016,  2288,  2125,  1997,  1037,  3345,  1998,  2939,  2011,\n",
      "          2070,  9152, 13327,  2616,  2605,  1037,  3232,  1997,  2086,   102],\n",
      "        [  101,  2339,  2064,  2025,  2009,  2022,  5101,  2030,  2334,  2814,\n",
      "          2007,  2122,  2111,  2009,  2467,  2038,  2000,  2022,  2256,  2451,\n",
      "          1996,  2773,  6661,  1037,  7117,  2007, 15523,  1998,  2008,   102],\n",
      "        [  101,  2092,  1996,  2317, 22674,  2024,  1996,  2270,  4262,  3589,\n",
      "          1997, 18301,  2061,  5681,  2027,  2024,  2183,  2000,  2892,  5682,\n",
      "         10930, 14163,  3511,  9821,  4550,  2039,  2023,  6752,  1045,   102],\n",
      "        [  101,  5310,  2002,  2036, 15504,  1998,  7129,  3960, 10878,  2102,\n",
      "          1999,  2193,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4775, 10984,  2015, 10740,  2024,  2069,  2216,  1997,\n",
      "          1037,  9152, 13327, 10338, 26476,  3568,  2027,  2024, 19528,  2193,\n",
      "          1047,  2243,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2613,  9152, 13327,  4485,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2129,  2116,  3280,  2296,  2154,  2926,  1996,\n",
      "         13499,  1999,  3190,  2079, 19140,  1998,  2115,  6933,  2055,  3449,\n",
      "         17161,  2065,  2619,  3344,  1996,  2331,  4175,  2052,  2031,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0240, 0.3390, 0.0890, 0.0890,\n",
      "         0.3390, 0.0890, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0110, 0.0110, 0.0110, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.7000, 0.1850, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6300, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1680,\n",
      "         0.1680, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.6690, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0010, 0.0010, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0690],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3050, 0.3050, 0.3050, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0610, 0.8780, 0.0610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230]]), 'label': tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1048,  2213,  7011,  2080,  3398,  2009,  2001,  2074,  1037,\n",
      "          3043,  1997,  2051,  2009,  2097,  2574,  2022,  1037,  2971,  1997,\n",
      "          2058, 11179, 26464, 10469, 11690,  2015,  2007,  6910,  2606,   102],\n",
      "        [  101,  5310,  5310,  5310,  1998,  2017,  2064,  2022, 16939,  2000,\n",
      "          3071,  2011, 10468,  3038,  2035,  2317,  2111,  2024, 16939,  2138,\n",
      "          1997,  2037,  3096,  6120,  2003, 16939,  2993,  2017,  2342,   102],\n",
      "        [  101,  2637,  2097,  2468,  1037,  9253,  4380,  2065,  1996,  2157,\n",
      "          7822,  2015,  2046,  1996, 17276,  2229,  1997, 13216,  3802,  7295,\n",
      "          7856,  3508, 13911,  2102, 12288,  7822,  2015,  2046,  1996,   102],\n",
      "        [  101,  5310,  1037,  2193,  1061,  2099,  7486,  4845,  2096,  6933,\n",
      "          2758,  2000,  2053,  2000,  1047, 12707,  2532,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  7929,  2002,  2003, 12316,  2094,  4312,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  2183,  2000,  3102,  5181, 16655, 15549,  6767,\n",
      "          9289,  2135,  1998,  2486,  2068,  8843,  2007,  9152, 13327,  2015,\n",
      "          1998,  5472,  9152, 13327,  2015,  1998, 11867,  6558,   102,     0],\n",
      "        [  101,  3228,  4487,  2015,  7570,  2063,  2067,  2000,  4830,  4534,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15060,  2003,  1037,  2307,  2154,  4485, 19894,  2075,  2000,\n",
      "          9495, 11265, 10976,  4588,  4485, 29521,  2015,  2021,  2017,  2113,\n",
      "          2054,  1045,  2097,  3828,  2008,  2005,  1996,  6904, 13871,   102],\n",
      "        [  101,  2023,  7570,  2063,  3791,  2000,  2131,  3786,  2091, 18168,\n",
      "          2290,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3087,  5136,  2672,  1996, 10815,  2020,  6728, 19811,  2149,\n",
      "          8711,  2559,  2005, 11386,  1999,  7795,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2708,  2003,  1996,  3291,  7087, 22212,  4314,  2016,\n",
      "          2003,  4352,  4808,  1998,  2442,  2022,  3718,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9345, 25540,  4059,  2193,  2086,  2214,  2001,  2730,  2011,\n",
      "          1037, 17929,  7726, 11560,  2138,  2002,  2001,  2583,  2000,  4089,\n",
      "          2709,  2000,  1996,  2406,  4895,  5403, 18141, 10424,  2401,   102],\n",
      "        [  101,  1045,  2064,  1521,  1056,  3524,  2000,  2022,  1999,  1037,\n",
      "          3276,  2008,  3084,  2111,  7887,  2228,  2000,  3209,  2339,  1056,\n",
      "          2546,  2016,  2007,  2008,  9200,  4632,  9152, 23033,  1524,   102],\n",
      "        [  101,  1996,  3679,  5653,  6732,  2008,  2049,  4297, 20026, 19185,\n",
      "          2000,  2360,  9152, 13327,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2193,  2001,  2589,  2011,  3956,  8174,  9264,  1998,  5181,\n",
      "          1999,  2137, 18079,  1056,  5256,  2039,  2637,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2057,  2024,  2108, 23197,  7481,  2182,  1045,  2572,\n",
      "          2025,  4013,  2138,  5310,  2003,  1037,  8040, 25438,  8490,  3538,\n",
      "          1997,  4485, 21196,  2019,  9057,  2072,  2828, 15818,  4709,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6380,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.4820, 0.4820, 0.0090, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0040, 0.0040, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0380, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.5490, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4430, 0.4430, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.2140, 0.2140, 0.2140, 0.0040,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1780, 0.1780, 0.1780, 0.1780, 0.1780, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0690, 0.0690, 0.0690,\n",
      "         0.0690, 0.0690, 0.0690, 0.0050, 0.0690, 0.0690, 0.2630, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050]]), 'label': tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996, 20340,  2078,  5526,  5963,  2138,  2065, 12461,  2024,\n",
      "          2599,  2011,  1996,  8777,  8388,  8986, 19297,  2157, 12456, 21379,\n",
      "          2025,  2035,  5181,  2241,  9152, 13327,  6043,  1997,  1996,   102],\n",
      "        [  101,  6904, 13871, 12868,  2024, 21877,  3527, 24862,  2015,  2008,\n",
      "          2129,  1996, 13024,  6904,  5620,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  6460, 12248, 19330, 19098,  8840,  2140,  6655,  2037,\n",
      "          2613,  2171,  2242,  2428, 17276,  2066,  5939,  6285,  2030,  2242,\n",
      "          1045,  5060,  2008,  1996,  8271,  3060,  4841,  2293,  2000,   102],\n",
      "        [  101,  2193,  2193, 17664,  2567,  2049,  1996,  1996,  3606,  1998,\n",
      "          2498,  2021,  1996,  3606,  5959,  1998,  2292,  2009,  4503,  2115,\n",
      "          4167,  1998,  2224,  2009,  2114,  2115, 11382,  3489,  2231,   102],\n",
      "        [  101,  6343,  3957,  1037,  4485,  2054,  2023,  9587, 25016,  2213,\n",
      "          8040, 25438,  8490,  6753,  2065,  1996, 16592,  2758,  2505,  4315,\n",
      "         18170,  7062,  2055,  8398,  3247,  2002,  4485,  2006, 10041,   102],\n",
      "        [  101,  7025, 21288,  2965,  4485,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2562,  3752,  2009,  2004, 16266,  8663,  2965, 15667,\n",
      "          1999,  3009, 21435,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1045,  2020, 15553,  1999,  2762,  1045,  2052,  2022,\n",
      "          5241,  2068,  1996, 13970, 17811,  2024,  5305,  1998,  5458,  1997,\n",
      "         14560,  1998,  2216,  2040,  2024,  6355,  1998,  1996, 13970,   102],\n",
      "        [  101,  2821,  2057,  2288,  2149,  1037,  2152, 26264, 11382,  3489,\n",
      "          2182,  9616,  2064,  2115,  2152, 26264,  4863,  2339,  3644,  2879,\n",
      "          9473,  8096,  7129,  2193,  4268,  2138,  2002,  3644,   102,     0],\n",
      "        [  101,  5310,  2045,  2323,  2022,  2053,  2210,  9587, 16102,  4509,\n",
      "          2226,  1999,  2637,  2139,  6442,  6206,  7486,  4632, 27605, 13806,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2387,  1037,  2132,  4524,  4590,  1999, 24547, 22345,  3892,\n",
      "          2358,  6658,  1045,  2031,  2464,  1999,  2026,  2221,  2440, 26666,\n",
      "         17447, 12322,  9307,  5689,  2006,  1996,  2392,  1045,  2424,   102],\n",
      "        [  101,  8038,  2021,  2012,  2560,  2009,  2445,  4125,  2000,  2632,\n",
      "         14517,  2050,  2344,  1998,  6502,  2495,  2015,  2012,  1996, 22727,\n",
      "          2402,  2816,  4385,  2021,  8038,  1045,  2963,  2054,  2017,   102],\n",
      "        [  101,  3679,  9866,  2013,  2026,  5440,  2859,  2386, 11417,  4819,\n",
      "          9327,  2006,  1056,  9148,  2102,  2026,  2814,  2572, 10754, 16042,\n",
      "         14910, 15148,  2147,  2524,  2974,  2097,  2196,  5914,  3057,   102],\n",
      "        [  101,  2053,  2016,  1037, 17276, 23185,  6658,  7743,  2008,  3791,\n",
      "          2000,  3280,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5292,  2017, 12731, 10603,  2064,  2025,  2130,  6985, 25035,\n",
      "          2096,  2115,  4485, 29334,  3664,  1999,  2414,  4455,  2005,  1996,\n",
      "         11537,  1997,  3087,  2040, 15867,  2000,  2079,  2061,  6057,   102],\n",
      "        [  101,  2000,  3917,  3085, 22889, 29553,  3009, 16773,  3306,  5292,\n",
      "         19707,  2887,  2672, 24651,  2822,  6716, 10823, 14560,  2148,  2430,\n",
      "          4841,  2033,  5831, 16033,  2015, 14163, 20051,  2891,  6505,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.5770, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.2420, 0.2420, 0.2420, 0.0040, 0.0040, 0.0040, 0.0170, 0.2420, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.2970, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0050, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6770, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3700, 0.3700, 0.0070,\n",
      "         0.0070, 0.0070, 0.0980, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0360, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1360, 0.1360, 0.1360, 0.1360,\n",
      "         0.1360, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0140,\n",
      "         0.1980, 0.1980, 0.1980, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0530, 0.0530, 0.0010, 0.0010, 0.0010, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0010, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0030, 0.0030, 0.0030, 0.1420, 0.1420, 0.1420, 0.1420, 0.1420, 0.1420,\n",
      "         0.1420, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0310, 0.0310, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450]]), 'label': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2027,  2097,  4139,  4277,  2041,  2027,  4632,  2000,\n",
      "          2292,  2068,  2317, 10558,  2131,  2185,  2007,  4028,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  9152, 23033,  1061,  2078,  2860, 11463,  2135,  2196,\n",
      "          2893,  2207,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2317,  2273, 11576,  2033,  2041,  2027,  2035,  2298, 11455,\n",
      "          1998, 10047,  2074,  7078, 10215,  2008,  2026,  2878,  2166,  2035,\n",
      "          1997,  2122,  3297,  4364,  2031,  2074,  2042,  2028,  2158,   102],\n",
      "        [  101, 10514,  2361,  9152, 23033,  2099,  1045,  2985,  2193,  2086,\n",
      "          1999,  2019,  2035,  2304,  2082,  1045,  2939,  1996, 27534, 13461,\n",
      "          2026,  2034, 10188,  2347,  1056,  2317,   102,     0,     0,     0],\n",
      "        [  101,  1045, 12006,  2296,  6685,  2017,  2191,  2061,  2017,  2655,\n",
      "          2033, 12873,  8840,  2140,  7929, 11382,  3489,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  1054,  7537,  2000,  2031,  2777, 19556,  6904,  2290,\n",
      "         24234,  2545,  6012,  2107,  2380, 19483,  2015,  2130,  2114,  5294,\n",
      "         28093,  2923,  6074, 11253,  6499,  9527,   102,     0,     0,     0],\n",
      "        [  101,  3704,  3003,  9406,  7148,  2180,  1037, 18315,  2006,  1996,\n",
      "          5477, 18396,  8118,  2002,  2018,  1037, 18604,  2170,  9152, 13327,\n",
      "          2027,  2409,  2149,  2025,  2000,  2655,  2068,  2008,  4902,   102],\n",
      "        [  101,  6203,  2304,  9152, 13327,  2015,  6616,  2115,  5635,  6616,\n",
      "          2115,  2152,  4126, 11681,  6616,  2115,  9152,  9354,  3215,  2302,\n",
      "         11397,  6616,  2115,  9152, 13327,  2015,  2730,  2011, 10558,   102],\n",
      "        [  101,  2017,  2024,  2183,  2000,  2022, 12599,  1037,  6394,  2053,\n",
      "          3043,  2054,  2017,  2079,  2017,  2031,  3037,  1999,  2647,  6147,\n",
      "          2317,  3226,  2317,  5154, 19544,  1998,  2317,  4752,  2015,   102],\n",
      "        [  101,  2016,  1037, 22212,  1998,  1045,  2572,  1037, 26893,  2009,\n",
      "          1037, 10675,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2160, 10643, 24783,  5444,  1999,  2490,  1997,  1037,  5813,\n",
      "          2128, 10354, 27972,  2075,  1996,  2142,  2163,  8426,  2000,  3956,\n",
      "          2193,  8037,  3662,  2027,  2024,  2053,  2936,  1996,  2283,   102],\n",
      "        [  101,  5310,  5310, 15125, 11607,  1998,  2060,  4485, 11484,  3032,\n",
      "          3233,  3201,  2007, 24636,  1997,  4469,  2522,  2615,  7959,  7959,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2320,  2035,  2317,  2181,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2025,  2896, 12456,  2317, 21553,  2011,  3038,  1996,\n",
      "         11513,  2196,  3047,  2612,  2360,  1996, 11513,  2001, 27564, 16903,\n",
      "          5600,  1998,  4895,  5714,  6442,  4630,  2279,  2000,  1996,   102],\n",
      "        [  101,  2162,  2003,  2025,  4808,  1998,  4288,  5760,  1998,  3722,\n",
      "          2162,  2003,  4758,  4808,  2005,  1037,  3800,  2728,  2002,  2378,\n",
      "         19856,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7743,  2229,  3058,  2028,  9152, 23033,  1998,  2131,  2000,\n",
      "          3241,  2027,  2013,  1996,  7415,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.8080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1480, 0.0030, 0.0030, 0.0030, 0.0100, 0.0100, 0.0100, 0.0100, 0.1480,\n",
      "         0.1480, 0.0100, 0.0100, 0.1480, 0.1480, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6030,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0040, 0.0040, 0.2440, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0170, 0.0170, 0.2440, 0.0040, 0.0040, 0.0170, 0.0170,\n",
      "         0.2440, 0.0170, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3420, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6740, 0.1780, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.8320, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2023,  2003,  2054,  6433,  2043,  9152, 13327,  2015,  5114,\n",
      "          2373,  2045,  2003,  2025,  2028,  2395,  2028,  5101,  2028,  2103,\n",
      "          2028,  2110,  2030,  2028,  2406,  2008,  2003,  2488,  2125,   102],\n",
      "        [  101,  5310,  3342,  2043,  1041, 24290,  2001,  1999,  2137,  2739,\n",
      "          1998,  2035,  2317,  2111,  2045,  2288,  6015,  2043,  2027,  2024,\n",
      "          2025,  2130,  2485,  2000,  3088,   102,     0,     0,     0,     0],\n",
      "        [  101,  2026,  9152, 23033,  2056,  2002,  2001, 12771,  2070,  4485,\n",
      "          2000,  1037,  3573,  1996,  5640,  3954,  2409,  2032,  1045,  2097,\n",
      "          4965,  2017,  1045,  6880,  2245,  2055,  1996, 12917,  6658,   102],\n",
      "        [  101,  4701, 18079, 14814,  2003,  2012,  2162,  2007,  2009,  2219,\n",
      "          2111,  2023,  2003,  2025,  1037, 28616, 21539,  1997,  3425,  2009,\n",
      "          2003,  1037, 15063,  3343,  2000,  4942,  9103,  5867,  1996,   102],\n",
      "        [  101,  1045,  2572,  3046,  2532,  2175,  2424,  2041,  1996,  3976,\n",
      "          2006,  1996,  4049,  2026, 13451,  7743,  2552,  2066, 12756, 14992,\n",
      "         19122,  2016, 17276,  1998, 11808,  2016,  4439,  1996,  4049,   102],\n",
      "        [  101,  3674, 12107,  2073,  2017,  4675,  4742,  2064,  2102,  4381,\n",
      "          2005,  3331,  2000,  1996,  7349,  2015,  2128,  3424,  7011,  2017,\n",
      "         25022, 29207,  2102, 19483,  2015,  6985,  3424,  7011,  2011,   102],\n",
      "        [  101,  5310,  2139, 29168,  7743,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  3374,  7591, 10474,  2021,  1045,  9826,  2514,\n",
      "          2066,  2065,  2017,  2131, 15504,  1998,  2215,  2000,  2022, 29258,\n",
      "          2115,  1037, 19215,  2017,  2323,  2022,  2667,  2000,  2131,   102],\n",
      "        [  101,  2204,  2862,  3272, 21766,  5369,  2061,  9527,  4221,  2314,\n",
      "          2080, 11382,  3489,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2347,  1056,  2108,  3835,  2438,  2003,  1996,  3114,\n",
      "          2339,  9889,  9587, 25016,  2213,  2273,  2253,  2105,  6080,  9680,\n",
      "          2075,  2317,  2336,  2429,  2000,  1996,  8801,  2865,   102,     0],\n",
      "        [  101,  5310,  6555,  2015,  2040,  2215,  3282,  3808,  4277,  1998,\n",
      "          2040,  2215,  7489,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2040, 14977,  2055,  2149,  2024,  2057,  3061,\n",
      "          2894,  1999,  2023,  2088,  2030,  2097,  5788,  2011,  9587, 25016,\n",
      "          2213,  2894,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  9734, 10239,  4311,  9889,  5152,  2158, 22664,  2317,\n",
      "          2158,  2003, 16939,  2886,  2942, 16591,  2004,  4126,  2114,  2394,\n",
      "          2111,  2013,  7489,  9466,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2128,  4168,  5677,  2043,  2017,  2071,  2360,  2128,  7559,\n",
      "          2094,  6904, 13871,  4140,  1998,  9152, 13327,  2004,  1037,  8257,\n",
      "          1998,  2053,  2028,  2052,  2131,  6314,  2204,  2335,   102,     0],\n",
      "        [  101,  5310, 12043,  2079,  2025,  3102,  4426,  2667,  2000,  2524,\n",
      "          2717,  2003,  1996,  2190,  4200,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3246,  2045,  2024,  2025,  2116,  1997,  2026,  3507,\n",
      "          4004,  2015,  1999,  4701,  2152,  3382,  1997,  4634,  6778,  2000,\n",
      "          5499,  9040, 18542,  1999,  2008,  2406,   102,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.2590, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0680, 0.0680, 0.0680],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.2610, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4100, 0.4100, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3620, 0.3620, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2810, 0.2810, 0.0740, 0.2810,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0160, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0600, 0.0600, 0.0600,\n",
      "         0.2260, 0.2260, 0.2260, 0.0600, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2821, 14021, 14433,  2265,  2033,  2115,  5152,  7385, 20228,\n",
      "          4402, 13213,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22889,  4904,  2017,  2071,  2025,  8984,  1037,  8239,  2769,\n",
      "          5030, 10036,  4632,  2892, 13578,  2098,  4954,  5963, 23526,  9201,\n",
      "          4111,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11721,  2232,  1999, 18426,  3064,  2011,  2814,  1998,  4728,\n",
      "          6047,  2111,  2725,  7789,  9530, 25485,  8496,  2000,  3046,  1998,\n",
      "         16114,  1996,  4808,  2114,  1996, 15908, 12399, 18743, 12455,   102],\n",
      "        [  101,  1045,  2288,  2208,  2005,  2017,  2402,  7570,  2229,  2079,\n",
      "          2025,  4982,  2000,  2022,  1037, 12873,  7570,  2063,  2008,  1037,\n",
      "          2053,  2053,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2064,  2131, 11586, 17619,  2000,  2486,  5199,\n",
      "          7968,  2000,  2444,  1999,  1996,  7415,  1998,  2059,  2027,  2428,\n",
      "          6570,  2032,  2055, 17276,  2166,  1998,  2057,  2064,  2156,   102],\n",
      "        [  101,  2024,  2057,  2428,  2023,  5236,  2004,  1037,  2427,  2885,\n",
      "          2003,  3810,  2046,  1037, 14163, 13793,  2063,  1999, 14081,  2098,\n",
      "          3109,  4920,  2021,  1051,  1996,  2548, 11382,  9681,  2024,   102],\n",
      "        [  101,  1045,  2288,  1037, 13108,  2006,  2026,  2157,  2074,  1999,\n",
      "          2553,  1037,  7743,  3046,  2193,  2079,  2033,  3308,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2903,  1996,  2149,  2510,  2003, 20419,  1998,  2256,\n",
      "          4099,  2339,  5181,  2219,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2066,  1998,  1045,  2018,  2000,  1996, 17834, 25852,  2052,\n",
      "          6616,  3209,  1999,  1996,  5221, 17490,  9152, 13327,  2015,  2022,\n",
      "          2066,  6300,  3388,  7743,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2009, 15536, 21285,  2022, 13805,  3425,  2005,  1037,\n",
      "          2450,  1997,  6120,  2000,  2202,  2023,  6394,  6071,  2091,  2054,\n",
      "          2360,  2017,  5310,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8495,  3104,  2039, 14747,  1997,  2178, 14163,  2480,  8609,\n",
      "          9452,  2886,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7010, 14540,  2923,  4748, 14763,  2308,  2005,  1996,  3076,\n",
      "          2419,  2082,  3328,  2041,  2005,  2233,  2339,  2024,  2027,  7079,\n",
      "          2111,  2000,  2265,  2039,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2035,  6904, 13871, 12868,  2293,  5519,  5705,  2116,\n",
      "          2215,  2000,  2022,  4632, 15504,  2011, 14818,  6541,  2015,  2066,\n",
      "          2033,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10657,  9641,  2122,  2308,  2935,  2027,  2113,  2025,  2129,\n",
      "          2000,  3298,  2061,  2129,  2064,  2057,  5987,  2068,  2000,  2113,\n",
      "          2129,  2000,  2224,  1996,  4274,  4756,   102,     0,     0,     0],\n",
      "        [  101,  2009,  3138,  1037,  3056,  2785,  1997,  5236,  2000,  2903,\n",
      "          1055,  3501,  2860,  7961,  2073,  2027,  2064,  2360,  4933,  2066,\n",
      "          5907,  2003,  1037,  2591,  9570,  2021,  2059,  2175,  2006,   102],\n",
      "        [  101, 20976,  2009,  2066,  3666,  1037,  2128,  7559,  5732,  2520,\n",
      "          1042, 17898,  2004,  1045,  2066,  2000,  2228,  1997,  2870,  2009,\n",
      "          2323,  2022, 19142, 11504,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0080, 0.0080, 0.0320, 0.1210, 0.1210, 0.1210, 0.4590, 0.1210, 0.0080,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0440, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.6360, 0.1680, 0.0120, 0.0120, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6350, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1670, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.1380, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5250, 0.0100],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.1470, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.5570, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.2710, 0.2710, 0.2710, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6520, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6110, 0.1610, 0.1610,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0440, 0.0440, 0.1680, 0.1680, 0.1680, 0.0120, 0.0120, 0.0030, 0.0030,\n",
      "         0.1680, 0.1680, 0.0120, 0.0120, 0.0120, 0.0030, 0.0030, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6580, 0.0460, 0.0460, 0.0460,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2074,  2066,  1037,  2317,  2879,  2052,  2360,  2879,  1057,\n",
      "          2440,  1997, 10231,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3601,  5307,  2530,  2308,  2003,  2025,  1996, 20934,\n",
      "         22379,  2030,  1996, 27308,  2021,  1996, 17962,  5686,  6593, 16940,\n",
      "          2030,  1996, 18856, 10054,  3334, 12461, 18428,  2050,   102,     0],\n",
      "        [  101,  5310,  4416,  2317,  2205,  7743,  2229,  2293, 11808,  9152,\n",
      "         23033,  2015,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7618,  2061,  8202,  2063,  2007,  1037,  2317,  4632,  4416,\n",
      "          2003,  2062, 11808,  1999,  2026,  5448,  2021,  1045,  3984,  1045,\n",
      "          2572, 11808, 12731,  2480,  1045,  2852, 13669,  1999,  2111,   102],\n",
      "        [  101,  5310,  1037,  1053, 10376, 13476,  2072,  2209,  2013,  5189,\n",
      "         13102, 25508,  2545,  2006, 21922,  2043, 18221,  2020,  2108, 15504,\n",
      "          2730,  1998, 13303,  2041,  1997, 13329,  2009,  2001,  1053,   102],\n",
      "        [  101, 11382,  9148,  6873, 11393,  5310,  1996, 24185, 23706,  2695,\n",
      "          6083,  4728,  2009,  2055,  1996,  5223, 14512,  2008,  7490, 13087,\n",
      "          1996,  5152,  2313,  2320,  2027,  5955,  2058,  1996,  2193,   102],\n",
      "        [  101,  2116,  2062, 19817, 27627, 17768,  4974,  4372, 14545,  2015,\n",
      "          2000,  2272, 26177,  2116,  2062,  9592,  2005,  2017,  2000, 19194,\n",
      "          2135,  4653,  2115, 13986,  5443,  8398, 25531,  2319,  1060,   102],\n",
      "        [  101, 23281, 23281,  4214,  2035, 11382,  9681,  1998,  9152, 13327,\n",
      "          2015,  1996,  2852, 13910,  2015,  1997, 11721,  2497,  2003,  1037,\n",
      "          2978,  2205,  8271,  2130,  2005,  2033,   102,     0,     0,     0],\n",
      "        [  101,  2025,  2074,  1037,  9152, 13327,  2019, 11560,  9152, 13327,\n",
      "          2061,  1996,  2277,  2288,  4469, 20547, 25202,  2011, 17026,  8906,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2036,  2008,  2002,  1037,  6904, 13871,  4140,  1998,  7642,\n",
      "          8494,  7377,  8024,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3478,  2343, 13857,  7025, 16429,  8067,  1998,  2010,  1050,\n",
      "          2094, 13593, 12943, 28493, 11404,  5302,  2497,  8275,  3037,  1999,\n",
      "          3190,  5008,  2015,  2011,  7995,  2069,  2006,  3924,  5994,   102],\n",
      "        [  101,  2026,  2155, 11146,  2003,  1037,  8239,  5202,  7743,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1045,  2064,  1048,  2863,  2080,  4258,  6010,\n",
      "         17276,  1045,  2097, 10245,  2068,  1999,  1037,  2117,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3504,  2066, 10474,  4363,  2026,  4485,  6616,  2990,  2128,\n",
      "          2102, 28394,  2102,  2000,  2393,  1037,  9152, 23033,  2041,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  2043,  3492,  3057,  2024,  7743,  2100,  2066,\n",
      "          2017,  2018,  2061,  2172,  4022,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  4238,  2038,  1996,  1050,  5221,  2451,  1999,\n",
      "          2690,  2264,  7486,  4013, 18209,  2098,  5181,  1999,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0600,\n",
      "         0.0600, 0.0600, 0.0600, 0.0040, 0.0040, 0.2280, 0.0160, 0.0160, 0.2280,\n",
      "         0.2280, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0410, 0.0410, 0.0410, 0.0410, 0.1570, 0.0410, 0.0410, 0.5950, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0930, 0.0930, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0190, 0.0190, 0.0190, 0.2680, 0.2680, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0650, 0.0650, 0.2480, 0.2480, 0.2480, 0.0650, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.4360, 0.0080, 0.1150, 0.1150, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1150, 0.1150,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.2460, 0.2460, 0.2460, 0.2460, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.2540, 0.0670, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1048,  2863,  2080,  1045,  2572,  2053, 10216,  1998, 15653,\n",
      "          2121,  4496,  2572,  1045,  1037, 11382,  3489,  2021,  1045,  5791,\n",
      "          3582,  2070, 11382,  3489, 22807,   102,     0,     0,     0,     0],\n",
      "        [  101,  1998,  2009,  2590,  2000,  2425,  2068,  1045,  2293,  2033,\n",
      "          1037,  2204, 19483,  2466,  2007,  1037,  3407,  4566,  2021,  1045,\n",
      "          2036,  2293,  2033,  1037, 12689,  2466, 17274,  5593, 12603,   102],\n",
      "        [  101,  2065, 17266,  8663,  2063, 12386,  2070,  3951,  2450,  1999,\n",
      "         15505,  4645,  6643,  2003,  6069,  2131,  2006,  2327,  1997,  1037,\n",
      "          2482,  3892,  1998,  6978,  2292,  6402,  2023,  7743,  2091,   102],\n",
      "        [  101,  2021,  2009,  2062,  2084,  2008,  2009,  2428,  2055,  2111,\n",
      "          2025, 10564,  5637,  2015,  9099, 11690,  2015,  2138,  2065,  2037,\n",
      "          3412,  9029,  2005,  2008,  3114,  2009,  3957, 11992,  1996,   102],\n",
      "        [  101,  6581,  3241,  1998,  2019,  6581,  2695,  2216,  2040,  2655,\n",
      "          2009,  2317, 14052,  2024,  2485,  2000,  1996,  3606,  2085,  2009,\n",
      "          2003,  2074,  1037,  3043,  1997,  4824,  2040,  2003,  2369,   102],\n",
      "        [  101,  7632,  3022,  6836, 11560,  4681,  2554, 23678,  2098,  2006,\n",
      "          2049,  9927,  7483,  2008,  1999,  1037,  6222,  9108,  2457,  2009,\n",
      "          5552, 16831,  6206,  7344,  8038, 21369,  2099,  2013, 23702,   102],\n",
      "        [  101,  5310,  2296,  4945,  2424,  2619,  2842,  2000,  2404,  1996,\n",
      "          7499,  2006, 20934, 18428,  2003,  1037,  8239,  4945,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  7955,  1999,  2885,  5927,  8398,  2038,  2404,  1999,\n",
      "          1037,  5152,  7221,  2296,  2309,  2028,  1997,  2068,  2097,  3198,\n",
      "          2339,  2064,  2025,  2057,  2079,  2008,   102,     0,     0,     0],\n",
      "        [  101,  2053,  4035,  2739,  6325,  1997,  3907,  3232,  2040,  2020,\n",
      "          7854,  1998,  6080, 15504,  1999,  3304,  1999,  6878, 20731,  2886,\n",
      "          2027,  2179,  2282,  2005,  2023,  2295,   102,     0,     0,     0],\n",
      "        [  101,  2065,  2017,  2507,  2039,  2115,  4409,  2037,  6879,  2097,\n",
      "          2022, 21918,  2006,  2115,  2227,  5091,  1999, 13578,  2094,  7486,\n",
      "          1998, 25283,  4890, 22889, 16446,  2008,  2003,  2127,  2017,   102],\n",
      "        [  101,  5310,  2323,  2031,  2196,  2042,  1037,  2120,  2739,  2466,\n",
      "          2000,  4088,  2007,  2009,  2003,  2069,  2000,  5245,  1996,  4125,\n",
      "          1997,  5223,  2076,  8398,  8798,  7984,  2029,  2003,  1037,   102],\n",
      "        [  101,  2061,  2024,  2057,  6069,  2131,  2292,  1521,  2131,  2496,\n",
      "          2030,  2003,  3336,  2879,  1996,  7541,  2518,  2000,  2009,  2057,\n",
      "          1521,  2222,  2412,  2131,  5310, 17276,  3676,  3762,   102,     0],\n",
      "        [  101,  2040,  3957,  1037,  4485,  2055, 11867, 10606, 21162,  2139,\n",
      "         14068,  2121,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2139,  6442,  2035,  5472,  9152, 13327,  2015,  3202,  2302,\n",
      "          3160,  4399,  4747, 13700,  2051,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2113, 16663,  2273,  2003, 17276,  2021,  1045,  1521,\n",
      "          1049,  2367,  1045,  8415,  1045,  1521,  1049,  1037,  7743,  4632,\n",
      "          9152, 23033, 10158,  3932,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2123,  1521,  1056,  2131,  8534,  2128,  7559,  2094,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0050, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2570, 0.2570, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.1950, 0.0510, 0.1950, 0.1950, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510,\n",
      "         0.0510, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0400, 0.1520, 0.0110,\n",
      "         0.1520, 0.1520, 0.0030, 0.0030, 0.0030, 0.0400, 0.0400, 0.0400, 0.0030,\n",
      "         0.0400, 0.1520, 0.0400],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2250, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.2250, 0.2250, 0.2250, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2033,  2003,  1037,  5410,  7743,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7743,  2339,  2003, 11929,  2061,  2980,  2651,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 13327,  9152, 13327,  7975,  4596,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13555,  8239,  2450,  6012,  2775,  9680,  2075,  5472,  9152,\n",
      "         13327,  2015,  7249,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2193,  1997,  3607,  2145, 29158,  5637,  2916, 24004,\n",
      "          8458, 20891,  2015,  3249, 13157,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2064,  3345,  2035,  1996, 18787,  7489,  1999,  1996,\n",
      "          2866,  2525,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10474,  2003, 12964,  2023,  2154,  2170,  9099,  2154,  1997,\n",
      "         16476,  2009,  2061,  5236,  2122,  2273,  4147, 14464,  1998,  2191,\n",
      "          2039,  2024,  2667,  2000,  2655,  3209,  2308,  1998,  2122,   102],\n",
      "        [  101,  2502, 22017,  2854,  7570,  2229,  2005,  9743, 29337,  3070,\n",
      "          1998,  2502, 14841, 14141,  3111,  7570,  2229,  2005, 22770,  4783,\n",
      "          5358,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2001,  2008,  2394,  8840,  2140,  2008,  2001,  2028,\n",
      "          2205,  2116,  4997,  2015,  1999,  1037,  6251,  2053,  1045,  2106,\n",
      "          2025,  2360,  2017,  4919,  2474,  4103,  4632,  1045,  2056,   102],\n",
      "        [  101,  1045,  2572,  2183,  2000,  3857,  2017,  1037,  2567,  6616,\n",
      "          1996,  5472, 25518, 15776,  1996, 14560,  2024, 14695,  1998,  2182,\n",
      "          2017,  2024,  6984,  2068,  2122, 14560,  2024,  1996,  3924,   102],\n",
      "        [  101,  1996,  3899,  2106,  2025,  4521, 18520,  7207, 19453,  1996,\n",
      "          3899,  2036,  2106,  2025,  4521,  1996,  8495,  6981,  1045,  2572,\n",
      "          5458,  1997,  2128,  7559,  5732,  8037, 24114,  2673,  2006,   102],\n",
      "        [  101,  5310,  5310,  6300,  2050,  2138,  2027,  2123,  2102,  2113,\n",
      "          8956, 14560,  2004,  2172,  2004,  1045,  2079,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4931, 16522,  2666,  1057,  2145, 11891,  2378, 16522,\n",
      "         10338,  1999,  2115, 10474,  2365,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3114,  5181,  4485, 29521,  2015,  6904, 13871, 12868,\n",
      "          5223,  2886,  8135,  2096,  6984,  7486,  2003,  2138,  2027,  2113,\n",
      "          1996,  8135,  2097,  2196,  2954,  2067,  2096,  1996,  5472,   102],\n",
      "        [  101,  1045,  2228,  1996, 13157,  4900,  1996,  3308,  5030,  2000,\n",
      "          5823,  2046,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20480,  2003,  1996,  2087, 17276,  7415,  1045,  1521,  2310,\n",
      "          2412,  2042,  1999,  7743,  1045,  5223,  2009,  2182,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.9010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.4910, 0.4910, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1240, 0.1240, 0.1240, 0.1240, 0.1240, 0.1240, 0.1240, 0.1240, 0.0090,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0770, 0.0770, 0.0050,\n",
      "         0.0050, 0.0770, 0.0770, 0.2910, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0770, 0.0770, 0.0050,\n",
      "         0.0050, 0.0050, 0.0770],\n",
      "        [0.0430, 0.0430, 0.1610, 0.0110, 0.0110, 0.0110, 0.0430, 0.0430, 0.6120,\n",
      "         0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0650, 0.0650, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0650, 0.0650],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0220,\n",
      "         0.0220, 0.3240, 0.0220, 0.0220, 0.0220, 0.0220, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.5360, 0.0370, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1410, 0.0100, 0.0100],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.3110, 0.0060, 0.0060, 0.0220, 0.3110, 0.3110, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0070, 0.0070, 0.0070, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2025, 25850,  2075,  2317,  3287, 16592,  6610,  5248,  2003,\n",
      "          1996,  2350,  4945,  1997,  2715,  2530,  2554,  2317,  2273,  9085,\n",
      "          2125, 28386,  2005,  9152, 13327,  2015,  1998,  7425,  4691,   102],\n",
      "        [  101,  5310,  2096,  3644,  6624,  2003,  6151, 19825,  3468,  7486,\n",
      "          2024,  1996,  3924,  2040,  2024,  2941,  9680,  2075,  1998, 21054,\n",
      "          2408,  2885,  2079,  2025,  2131,  2033,  3308, 17428,  1996,   102],\n",
      "        [  101, 21500,  3527,  2546,  2003, 11654,  2002,  2038,  2053,  9152,\n",
      "         13327,  2000,  3102, 12461,  2007,  6655,  2016,  2730, 12570,  8661,\n",
      "          3401,  1996,  6530, 12593,  7743,   102,     0,     0,     0,     0],\n",
      "        [  101,  4485,  1045,  2031,  2074, 15504,  1037,  2193,  2095,  2214,\n",
      "          1045,  2228,  1045,  2031,  2000,  2425,  1996,  2111,  2008, 16455,\n",
      "          2409,  2033,  2000,  2079,  2009,  1998,  2008,  2129,  7025,   102],\n",
      "        [  101,  4931,  6394,  6900, 16078,  2003,  2115,  2304,  7087,  4363,\n",
      "          2017,  4548,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9130,  6731,  2033,  2005,  2725,  2471,  1996,  2168,  2518,\n",
      "          1045,  2165,  1037,  4714,  2471,  6721, 11867, 13231,  2013,  1996,\n",
      "         12849,  5521,  1998,  2404,  5152,  2073,  2009,  2056,  4895,   102],\n",
      "        [  101,  5310,  2049,  2763,  9003, 11843,  7486,  2040,  2128,  2102,\n",
      "         28394,  3064,  2009,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2632,  4140,  1997,  2017,  7570,  2229,  2003, 25448,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8840,  2140,  7743, 14308,  2256,  2126,  2000,  3377,  2745,\n",
      "          9534,  3695,  5310,  8529,  2065,  2023,  2003,  2054,  2057,  2024,\n",
      "          2039,  2114,  2043,  2057,  2175,  2000,  2942,  2162,  2057,   102],\n",
      "        [  101,  2151,  9152, 23033,  2008,  3499,  2027,  2969,  2000, 12486,\n",
      "          2007,  1037,  2931,  2003,  1037,  6904, 13871,  4140,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  5011,  2012,  1996,  5030,  3138,  2019,  4495,  2000,\n",
      "          5326,  3088,  5235,  2041,  1037, 10810,  2005,  1996,  3532, 27359,\n",
      "          2015,  2008,  2064,  2025,  3888,  1037,  3937,  6546,  8962,   102],\n",
      "        [  101,  5310,  1998,  1045,  6814,  1996,  5472,  9152, 13327,  2015,\n",
      "          2097,  2025,  3013,  2125,  4641,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11966,  2003,  1037,  8239,  9436,  5149,  1997,  1037,  4368,\n",
      "          2065,  2045,  4214,  2125,  9590,  3426,  1037,  7659,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2015,  2039,  2007,  7955,  2040,  2064,  2171,  1996,\n",
      "         16522,  2021,  2015, 16614,  9152, 19466,  6553,  6904, 13871, 12868,\n",
      "          1999,  2037,  2055,  2033,  2428, 12943, 17643, 16952,  2015,   102],\n",
      "        [  101,  2298,  1037, 14163,  2480,  8609,  2404,  2041,  1037, 13523,\n",
      "          2005,  2115,  6077,  2000,  4485,  2006,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748,  2061,  2065,  2017,  5223,  6904, 13871, 12868,  2021,\n",
      "          2024,  2025,  1037,  6904, 13871,  4140,  4426,  2643,  2097,  2066,\n",
      "          2008,  2017,  5223,  6904, 13871, 12868,  2138,  4474,  2643,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830],\n",
      "        [0.0020, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.1100, 0.1100, 0.1100, 0.0290, 0.0290,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.1100],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0180, 0.0050, 0.0690,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0690, 0.0050, 0.0050, 0.2610, 0.2610,\n",
      "         0.2610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0010, 0.0010, 0.0170, 0.0660, 0.0050, 0.0660, 0.0660, 0.0660,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0660, 0.0660, 0.0660, 0.0660, 0.0660, 0.0050, 0.0010, 0.0170, 0.0660,\n",
      "         0.0660, 0.0660, 0.0660],\n",
      "        [0.0020, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.1110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0290, 0.0020, 0.0020, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.1110],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0120, 0.1780, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.6740, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4100, 0.4100, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1220,\n",
      "         0.0080, 0.0080, 0.0080, 0.4610, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0050, 0.0050, 0.2720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0720, 0.0720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0090, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0090, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0090, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.0350, 0.0350, 0.0350,\n",
      "         0.0350, 0.0350, 0.0350]]), 'label': tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1061,  9033, 11865,  6906,  2327,  2193,  2033,  6904, 24458,\n",
      "          6862,  2129,  2000,  2131,  2185,  2007,  4028, 13761,  2611,  1996,\n",
      "          2197,  2911, 18211,  2304,  2091,  2669,  6103,   102,     0,     0],\n",
      "        [  101,  2632, 24264, 12519,  2696,  3342,  2023,  2171,  2023, 16806,\n",
      "         10893,  9152, 24679,  2102,  2003,  3045,  2023,  5583,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2354,  2057,  1040,  2131,  1996, 16985,  4402,  4160,\n",
      "          2015,  1998, 14405,  7447,  2015,  2000,  2633,  3275,  2041,  2216,\n",
      "         14068,  2545,  2024,  2058,  2075,  2006,  2035,  1996,  2489,   102],\n",
      "        [  101,  2017, 28781,  2024,  7889,  2138,  2017,  3499,  2128,  7559,\n",
      "          5732, 13350,  2000,  7186,  2115,  2103,  2007,  7486,  2040,  2031,\n",
      "          2053,  2449,  2108,  1999,  1996,  3915,  1999,  1996,  2034,   102],\n",
      "        [  101,  2009,  2515,  2572,  8557,  2033,  2008,  2027,  2064,  9841,\n",
      "          2009,  2041,  2035,  2154,  2021,  2027,  2064,  2025,  2202,  2009,\n",
      "          2926,  5310,  2008,  6904, 13871,  4140,  2038,  5717,  3231,   102],\n",
      "        [  101,  2065,  6969,  4152,  2700,  1045,  1521,  1049,  2183,  2000,\n",
      "          3013,  2125,  2026,  5637,  4540,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2015,  2757,  4223,  6616,  9152, 23033,  3022,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8037,  5091,  1996,  2283, 11253, 14540, 21055,  2035,  2027,\n",
      "          2412,  2079,  2003, 27885,  3367,  6820,  6593,  2008,  2061,  2027,\n",
      "          2064,  2562,  2017,  1999,  8859,  2160, 25518,  4590, 14255,   102],\n",
      "        [  101,  2205,  2919,  2002,  2003,  1037, 11382,  3489,  7089,  2065,\n",
      "          2002,  2253,  2440,  2193,  1996,  2866,  2052,  2022,  2489,  2011,\n",
      "          2085,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  2016,  2428,  3866,  1996,  9200,  9152, 13327,  8840,\n",
      "          2140,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  3849,  1037,  2307, 19240,  1996,  2387,  2003,  1996,\n",
      "          5499, 11560, 21038,  2015,  2008,  2024,  2108, 17519,  2098,  2011,\n",
      "          1996, 16349,  2158,  2029,  5836,  1996,  3795,  2923, 27021,   102],\n",
      "        [  101,  6057,  2129,  1996,  2111,  2008,  2175,  2440,  2128,  7559,\n",
      "          2094,  2439,  2037,  2193,  2781,  2066,  2193,  2086,  3283,  2130,\n",
      "          6972,  2439,  2008,  2193,  2253,  2440,  2128,  7559,  2094,   102],\n",
      "        [  101,  1056,  2546,  2860,  1037, 11867,  2594,  2003,  1037,  9253,\n",
      "          6394,  1048,  2863,  2080,  3867,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8398,  2409,  3071,  2008, 21510,  2638,  5380,  2001,  2659,\n",
      "         26264,  2002,  9471,  2000,  5587,  5437,  2100, 13593,  7743,  4632,\n",
      "         11265, 17603,  4757, 17219,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1056, 17311,  1037,  2617,  2043,  1045,  3651,  2008,  2026,\n",
      "          2767,  2003,  2941,  2026,  5637,  2767,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  1037, 17082,  3160,  2000,  3198,  2021,  2054,\n",
      "          2785,  1997,  2566, 16874,  2015,  2515,  3460,  2040,  4139,  1999,\n",
      "          4035,  2097,  2031,  1037, 25283,  4890,  9152, 13327,  3035,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.1650, 0.0440,\n",
      "         0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.1650, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.1200, 0.1200, 0.1200, 0.4560, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.8080, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0130, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1830, 0.1830, 0.1830, 0.1830, 0.0030, 0.0030, 0.0030, 0.1830, 0.0030,\n",
      "         0.0030, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7240, 0.0500, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0590, 0.8480, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0190, 0.0190, 0.2690, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0190, 0.2690, 0.0190, 0.0190, 0.0050,\n",
      "         0.2690, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.7400, 0.0510, 0.0510, 0.0510, 0.0510, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0650, 0.0650,\n",
      "         0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.2480,\n",
      "         0.0650, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.3670, 0.3670, 0.0250, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2061,  2339,  2003,  2025,  1996,  5152,  2088,\n",
      "          6016,  8817,  1997,  2037, 24815,  2923,  2000,  2859,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3756, 15129,  7777,  2000,  4929,  2308,  5929,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2183,  2000,  2131,  2821,  2061,  2172,  4788,  2005,\n",
      "          2017, 29276, 11579,  8275,  8135,  6183, 16522,  2139,  6914,  6906,\n",
      "          5666,  3031,  2256,  2111,  9981, 17219,  2637,  7460,  2000,   102],\n",
      "        [  101,  2339,  2023,  3124,  2003,  2667,  2000,  6611,  2530,  4314,\n",
      "          4372,  7138,  6675,  2245,  2000,  2019,  4004,  5152,  2406,  2003,\n",
      "          3458,  2033,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3599,  2021,  2428,  2035,  9704,  1997,  5181,  4919,  2018,\n",
      "          2042, 27820,  3272,  2005,  1996, 11513,  7984,  2057,  2024,  2025,\n",
      "         17730,  2000,  3773,  2111,  2004,  2967,  4606,  4983,  2017,   102],\n",
      "        [  101,  2308,  2323,  2022, 14984,  1997,  3209,  2005,  5599, 16824,\n",
      "         11690,  2158, 22650, 22212,  2015,  3713,  2005,  2068,  9467,  2006,\n",
      "          2017,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2008,  4165,  2066,  1037,  2919, 12054, 16251,  2171,\n",
      "          1045,  2572,  2183,  2007,  3719, 19483,  2035,  1996,  2126,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3744,  2474,  8873,  4674,  5310,  2193,  3823,  3283,  2062,\n",
      "          3744,  2474,  8873,  4674,  2128,  2102, 28394,  3064,  2928,  6090,\n",
      "          5794,  2080,  2129,  2116,  2062,  7489,  2079,  2057,  2342,   102],\n",
      "        [  101,  2035,  2061,  1996,  5472,  9152, 13327,  2015,  2064,  9040,\n",
      "          2031,  2489, 21269,  2000,  9040,  1998,  8954,  2013,  2017,  1998,\n",
      "          2079,  2025,  2130,  2131,  2033,  2318,  2006,  1996,  5887,   102],\n",
      "        [  101,  2664,  2043,  1037,  3232,  1997, 18294, 22212,  2015,  2215,\n",
      "          2017,  2000,  6090,  4063,  2000,  2037, 15516,  2004,  2017,  2156,\n",
      "          2068,  2017,  2442, 14037,  2011,  2375,  2051,  2000,  2707,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  2174,  2005,  4748,\n",
      "          2891,  2000,  2085,  4539,  2304,  7489,  1998,  3292,  3209,  2013,\n",
      "          1996,  3060,  2972,  4365,  4180,  2038,  2042, 15504,  1998,   102],\n",
      "        [  101,  2710, 13141,  2291,  2003, 28466,  2389,  2021,  4445,  1996,\n",
      "         11870, 21919,  2250,  4974,  9875,  7610,  1996,  9841, 21821,  2102,\n",
      "          2865,  4496,  1996, 16592,  8043, 20203,  6961,  2729,  2710,   102],\n",
      "        [  101,  5310,  5310, 25627,  9808,  2109,  1999,  2036, 11901,  1997,\n",
      "          2974, 13918,  2015,  2003,  2074,  1037,  2112,  1997,  1996,  3469,\n",
      "          2449,  3088,  4247,  2000,  2022, 15504,  2011,  2615, 10760,   102],\n",
      "        [  101,  1998,  2085,  6819, 20142, 12956, 16011,  1997,  2149,  2880,\n",
      "          4755,  2041,  2037,  5841,  1999, 12362,  2000,  6206,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2054,  2017,  2113,  2017, 15594,  4855, 24858,\n",
      "          2160,  1996,  8711,  2017,  2562,  2006,  2055,  2017, 14557, 21146,\n",
      "         12588, 12731,  3372,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  3582,  1037,  5472,  9152, 13327,  4676,  2017, 14163,\n",
      "         29519,  2017,  2024,  2504,  1997, 12532, 10087,  6593,  2003, 13352,\n",
      "          2140,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0810, 0.0810,\n",
      "         0.0810, 0.0810, 0.0810, 0.0810, 0.3090, 0.0810, 0.0810, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0690, 0.0690, 0.0690, 0.0690, 0.0690, 0.0050,\n",
      "         0.0050, 0.0050, 0.0690, 0.0690, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0050, 0.0050, 0.0690],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0120, 0.0120,\n",
      "         0.1780, 0.1780, 0.0120, 0.0120, 0.1780, 0.1780, 0.1780, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0140, 0.0140, 0.0140, 0.1960, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.6520, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0070, 0.0070, 0.0070, 0.1070, 0.1070, 0.1070, 0.1070, 0.1070, 0.1070,\n",
      "         0.1070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3760, 0.3760, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0020, 0.0020, 0.0020, 0.0020, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1600, 0.1600,\n",
      "         0.0110, 0.0110, 0.0420, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1600,\n",
      "         0.1600, 0.1600, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.2880, 0.2880, 0.2880, 0.0200, 0.0200, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2043,  1996,  2225,  2003,  2130,  6195,  2457,  3641,\n",
      "          3459,  8156,  1997,  2193,  2095, 19457,  7025,  2015,  2025,  2559,\n",
      "          2061,  2919,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  1996, 11382,  3489,  2852,  7416, 10362,  4332,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 14163,  2480,  8609, 11669,  2655,  3071,  1037, 16939,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1999,  1996,  2940, 24457,  2100,  2106,  1045,  2074,\n",
      "          2963,  5310,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4283,  2008,  2001,  2941, 14044,  2000,  2033,  2004,  1045,\n",
      "          2347,  1056,  2206,  5310,  2467,  2204,  2000,  2424,  2062, 11382,\n",
      "          3489,  3806,  8043,  2015,  2004,  2045,  1037,  2843,  2696,   102],\n",
      "        [  101,  2045,  2024,  2205,  2116, 21922,  3568,  2027,  2031,  2053,\n",
      "          2342,  2000, 11839,  1999,  1996,  4534,  2009,  2003,  1037,  2433,\n",
      "          1997, 28973,  2008,  9587, 25016,  2213,  4485,  2063,  2224,   102],\n",
      "        [  101,  5310,  1048,  2863,  2080,  2748,  1045,  1521,  1049,  4004,\n",
      "          2008,  1521,  2339,  1045,  2056,  2151,  2060,  4004,  2015,  1524,\n",
      "         17170, 21030,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  7091,  2115,  3566,  2015,  1037,  7570,  2063,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1048,  2863,  2080,  1045,  2572,  2025,  2028,  1997,  1996,\n",
      "         22212,  2015,  2040,  2017,  2052,  4608,  2007,  2151,  7743,  2040,\n",
      "          2038,  1037,  3336,  3722,  2049,  1037,  3066, 24733,  2005,   102],\n",
      "        [  101,  1996,  4872,  1997,  1037,  2613,  2173,  2000,  2175,  2044,\n",
      "          2152,  2082,  2005,  6638,  1998, 19483,  4268,  2071,  6719,  2562,\n",
      "          2068,  4142,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2941,  8670, 18142,  2015,  2033,  2129,  2619,  2064,\n",
      "          2022, 16939, 24004, 20200,  9099, 20200,  7025,  9331,  6806, 13592,\n",
      "          3424, 20604,  4385,  2066,  2129,  1998,  2339,   102,     0,     0],\n",
      "        [  101,  2053,  4474, 10759,  3036,  2794,  2317, 22006,  2004,  1037,\n",
      "          9452,  5081,  3188,  2000,  2009,  8840,  2140,  9714, 22953,  8322,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2663, 12412,  2232,  2030,  3649,  6904, 13871,  4140,\n",
      "          3791,  2000,  2175, 13433,  6499, 11283,  2278,  2205,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2062,  2204, 14754,  2748,  2008,  2551,  2041,  2092,\n",
      "          4126,  2003,  2025,  3712, 16901, 20624,  3070,  2030,  2505,  2031,\n",
      "          1057,  2464,  2054,  6433,  1999,  7327,  2007,  4895,  5403,   102],\n",
      "        [  101,  8840,  2140,  8398,  3781, 21746,  2105,  2006,  2010, 11382,\n",
      "          3489,  2564,  2007,  8494,  7377,  8024, 18961,  1051,  2154,  1996,\n",
      "         12456, 15950,  2428,  4282,  2129,  2000,  4060,  7861,   102,     0],\n",
      "        [  101, 17276,  2003,  2242,  1996,  3265,  4473,  2000,  2202,  7117,\n",
      "          1999,  2068,  3802,  7413,  4674,  2591,  4813,  1998,  9128,  2064,\n",
      "         17678,  2884,  2017,  2041,  1997,  2056, 17276,  3633,  2066,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0130, 0.1870,\n",
      "         0.1870, 0.0130, 0.1870, 0.1870, 0.1870, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9320, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.4780, 0.4780, 0.0090, 0.0090, 0.0090, 0.0090, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.2540, 0.2540, 0.0050, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.1130, 0.1130, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1550, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.5870, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.7590, 0.0530, 0.0530, 0.0530, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2990, 0.0790,\n",
      "         0.0050, 0.2990, 0.0790, 0.0790, 0.0790, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2470, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.2470, 0.0170, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050]]), 'label': tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2049,  2061, 21746,  2039,  2008,  2619,  2004,  6047,  2004,\n",
      "          2033,  4152,  4167,  4456,  2008,  2052,  2022,  1037,  2066,  1037,\n",
      "         16522,  2893, 15882,  4456,  2030,  1037,  9152, 13327,  2893,   102],\n",
      "        [  101,  1045,  2572,  3374,  2021,  2200,  3835,  2111,  2031,  8916,\n",
      "          2149,  2008,  2077,  1996,  4763,  6053,  3501, 26448,  2098, 10823,\n",
      "          3031,  2010, 17276, 17829,  2027,  2196,  5462,  2151,  6997,   102],\n",
      "        [  101,  5310,  2017,  2147,  1037,  2193,  3178,  5670,  1045,  8239,\n",
      "          5223,  7695,  1045,  2022,  2757,  2011,  1996,  2203,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2024,  2061,  8239,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5181,  2031,  2037,  2219,  2406,  2027,  2323,  2644,\n",
      "         19960, 14423,  1998,  2667,  2000,  7186,  2256,  3741,  2007,  7489,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  2763,  4647,  2480,  2017,  2024, 12873,  2008,  2015,\n",
      "          2035,  2017,  2079,  2025,  2031,  2000,  2022,  5152,  2000,  2156,\n",
      "          6841,  1997,  1996,  2492,  2193,  2024,  8239,  2039,  2035,   102],\n",
      "        [  101,  2054,  2064,  1045,  2360,  2055,  1996,  7623,  2886,  2008,\n",
      "          2038,  2025,  2525,  2042,  2056,  2151,  7863,  2711,  3666,  1996,\n",
      "          4668,  2000,  5904,  9337,  5443,  7623,  2064,  2069, 16519,   102],\n",
      "        [  101, 10166,  2017,  2024,  2061,  6541,  8273,  7741,  2308,  2006,\n",
      "          1996,  4274, 22530,  2075, 17076,  4115, 18792,  4790,  2017,  2074,\n",
      "          1040,  3654,  2546,  2054,  2122,  7743,  2229,  2193,  2242,   102],\n",
      "        [  101,  2065,  2027,  2079,  2025,  2066,  2009,  2182,  2027,  2342,\n",
      "          2000,  2131,  1996,  6616,  1997,  2256,  4915,  1998,  2175,  2067,\n",
      "          2000,  5472,  9152, 13327,  2406, 16282,  7486,  2131,  5833,   102],\n",
      "        [  101,  2106,  2025,  1996, 14560,  2490,  8042,  1045,  2113,  2026,\n",
      "          2269,  2915,  2062, 14560,  1999,  2167,  3088,  2084,  7074,  2926,\n",
      "          2043,  2027,  2020,  5697,  4288,  1996,  5303,  1998, 26211,   102],\n",
      "        [  101,  2025,  2008,  1045,  2031,  2699,  2009,  2021,  7302,  2012,\n",
      "          2593,  1996,  5409, 10257,  4974,  1999, 14081,  2098,  2181,  2030,\n",
      "          1996,  6745, 19483,  2879, 14301,  2063,  2233,  1998,  4851,   102],\n",
      "        [  101,  5310, 13857, 16543,  8112,  1996,  2034,  5152,  2343,  1997,\n",
      "          1996,  3915,  2003,  2471,  2908,  2023,  2097,  2203,  2574,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2178,  2524,  6947,  2008,  2002,  2187,  2003, 12580, 16939,\n",
      "          1998,  1996,  2128,  7559,  5732,  2304,  2451,  2145,  4214,  3071,\n",
      "          2025,  2521,  2187, 16939,  6160,  2000,  8909,  3695, 26775,   102],\n",
      "        [  101,  5310,  8711,  9920,  3791,  2000,  2022, 10817,  3686,  2000,\n",
      "         13141,  4325,  1996,  2149,  2323,  2202,  2087,  1997,  2068,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3308, 16510,  6182,  2102,  2637,  2001,  2525,  1037,  3565,\n",
      "         11452,  2077,  1996,  5181,  2288,  2182,  2057,  2150,  1996,  2193,\n",
      "          4610,  2006,  1996,  4774,  1999,  1996, 16215,  2301,  2017,   102],\n",
      "        [  101,  1045,  3246,  5310,  2003,  2718,  2011,  1037,  3345,  2247,\n",
      "          2007,  2009,  6530, 11382,  3489,  2564,  2383,  1037,  3246,  2003,\n",
      "          5123,  3423,  4613, 13451,  9152, 23033,   102,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0810, 0.0810, 0.0810, 0.0810, 0.0060, 0.0060, 0.3060,\n",
      "         0.0810, 0.0810, 0.0810],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0390, 0.0030, 0.1460, 0.1460, 0.1460,\n",
      "         0.1460, 0.1460, 0.1460, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.4870, 0.4870, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0200, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0630],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5710, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0580, 0.0580, 0.0580, 0.0580, 0.0580, 0.0580, 0.0580, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0580,\n",
      "         0.0580, 0.0580, 0.0580, 0.0580, 0.0580, 0.0150, 0.0150, 0.0580, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0090],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.2610, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.2610, 0.2610, 0.0180, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0030, 0.0390, 0.0390, 0.0390, 0.0390, 0.1490, 0.1490, 0.1490, 0.0390,\n",
      "         0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0340, 0.0340,\n",
      "         0.0090, 0.0090, 0.4840, 0.1280, 0.1280, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0340, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.2220, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.2220, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0150,\n",
      "         0.2220, 0.2220, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.4190, 0.4190, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2023,  3185,  2003, 17276,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2138,  6206,  7489,  2064,  2025,  2428,  5788,  2006,  1996,\n",
      "         12678,  2027,  2024,  3825,  2061,  1996,  2231, 17351,  4942,  5332,\n",
      "          4305, 11254,  1996, 12433,  2011,  3228,  6206, 12114,  7574,   102],\n",
      "        [  101,  2008,  7743,  2022,  5607,  2378,  2066,  2009,  1521, 13952,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2425,  2014,  2000,  6616,  2125,  2054,  1996,\n",
      "          3109,  2003,  2016,  2725, 20540,  2004,  1037,  7907, 25047,  2691,\n",
      "          4485,  7743,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2941,  1045,  2572,  5327,  1999,  1996,  2925,  2005,  1037,\n",
      "          2317,  4004,  4707,  2000,  9239, 15982, 24004,  6914, 20175,  2100,\n",
      "          1999,  2119,  2317,  1998,  4004,  4279,  1045,  2228,  1996,   102],\n",
      "        [  101,  2954,  2317,  9706, 16886,  1045,  2572,  2317,  1045,  2031,\n",
      "          2025,  7404,  3550,  3087,  3531,  2079,  2025,  3713,  2005,  2033,\n",
      "          1998,  2079,  2025,  8239,  2412, 12134,  2005,  2033,   102,     0],\n",
      "        [  101,  2016,  2018,  2091,  8715,  2016,  2001,  6719,  2128,  7559,\n",
      "          5732,  1998,  2017,  2228,  2016, 10849,  9040,  2412,  2777,  2619,\n",
      "          2007, 12482,  2027,  2079,  2025, 10107,  2008,  4485,   102,     0],\n",
      "        [  101, 19522,  8292,  7384,  2891,  3504,  2066,  2010,  6007,  2024,\n",
      "          2205,  2502,  2005,  2032,  2746,  2066,  2009, 21877,  1999,  2095,\n",
      "          2193,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2036,  1996,  4330,  7774,  2005, 26264,  2025,  2069,  2038,\n",
      "          2116,  2062,  2273,  2012,  1996,  2152, 26264, 17448,  2021,  2036,\n",
      "          2012,  1996,  2659, 26264, 17448,  2061,  2045,  2024,  2128,   102],\n",
      "        [  101,  1998,  2054,  2065,  2057,  2409,  2014,  2008,  1037,  9129,\n",
      "          1997, 28616, 15707, 27803,  2102, 24004, 20200,  3424,  3017,  3424,\n",
      "          4100,  4570,  2342,  2000,  2175,  2444,  2007,  1996,  2060,   102],\n",
      "        [  101,  1045,  2064,  1521,  1056,  2175,  2041,  6517,  2058,  2053,\n",
      "          9152, 23033,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2196,  6943,  2006,  1996,  2317,  3203, 22017, 20536,  2012,\n",
      "          1996,  2502, 15589,  2417, 18278,  3153,  2288,  2009,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2077,  8398,  3030,  2009,  2129,  2116,  6904, 13871, 12868,\n",
      "          9417,  2000,  2031, 23689,  3477,  2000, 24494,  2037, 18082,  2545,\n",
      "          2125,  4372, 15549,  4892,  9273, 10587,  2113,   102,     0,     0],\n",
      "        [  101,  5310,  2339,  2003,  1996, 13300, 16558, 25114,  1037,  2002,\n",
      "          1045,  2428,  3246,  2009,  1037,  2016,  2030,  2672,  2019, 11560,\n",
      "          2013,  1037,  4485, 11484,  2406,  2030,  2619,  5907,  2512,   102],\n",
      "        [  101,  2339,  2024,  9160,  9761,  2015,  2107,  6904, 13871, 12868,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4998,  2013,  6316,  2135,  5297,  4665, 24569,  1998,  2148,\n",
      "          2430,  6643, 11867,  2594,  3655,  6643,  2003,  2019,  7619, 14013,\n",
      "          3959,  2043,  2017,  2131,  2000,  1996,  2406, 11974,  2530,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0130, 0.0130, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1850, 0.1850,\n",
      "         0.1850, 0.1850, 0.1850, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0650, 0.0650, 0.0650, 0.0170, 0.0170, 0.0650, 0.0650, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0650, 0.0650,\n",
      "         0.0650, 0.0650, 0.0170],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0830, 0.0830, 0.0060, 0.0060, 0.0060, 0.3160, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.3160, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0030, 0.0030, 0.0030,\n",
      "         0.1910, 0.0030, 0.0030],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.2020, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.8580, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0350, 0.0350, 0.5050, 0.0350, 0.0350,\n",
      "         0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0790, 0.0790,\n",
      "         0.0790, 0.3010, 0.3010, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250]]), 'label': tensor([1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2061,  1037,  2317,  5984, 13641,  7397,  2078,  5152, 29525,\n",
      "          3632,  2046,  1037,  3347,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2071,  2196,  2191,  2033,  5223,  2017,  2130,  2295,\n",
      "          2054,  2017,  2001, 24341,  2347,  1056,  5510,  3993,  2130,  2295,\n",
      "          2017,  2041,  2182,  2298,  2378,  2061,  4895, 22780,  3993,   102],\n",
      "        [  101, 28101,  2015,  2017,  2323,  2672,  4040,  1996,  3827,  3725,\n",
      "         19022, 14083,  9463,  3272,  2681,  1996,  8494, 14540, 14428,  2015,\n",
      "          1999,  2045,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 18372,  2099,  8444,  2080, 18609, 11462,  3050, 18414,\n",
      "         20617,  2015,  3393,  3653, 14117,  2239, 23957,  6894,  3527,  2139,\n",
      "          9686, 20464, 11431,  2080, 10514,  2015,  8273, 18349,  2015,   102],\n",
      "        [  101,  2054,  2106,  2002,  2812,  2011,  2023,  2193,  2420,  2077,\n",
      "          1037, 11867,  2594,  2515,  1037,  5008,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2079,  2308,  2729,  2061,  2172,  2055,  2108,  2006,\n",
      "          1996,  2168,  2504,  2004,  2273,  2043,  2273,  2941,  2079,  2025,\n",
      "          2507, 14352,  8292, 29577,  2098,  2342,  2070,  2495,  2182,   102],\n",
      "        [  101,  5310,  5310,  2031,  2017,  2412, 27793, 18743,  2055,  2040,\n",
      "          2031,  2187, 16215,  3771,  2188, 23097,  3183,  5727, 15504,  1998,\n",
      "          2111,  2730,  2019,  2015,  2053,  2017,  2024,  5305,   102,     0],\n",
      "        [  101,  2013,  2054,  1045,  2572,  3752,  2087,  2350,  2866,  3655,\n",
      "          2031, 14163, 13793,  2063,  3664,  2515,  1996,  4105,  1999,  1996,\n",
      "          2866,  2298,  2012,  4701,  1998,  3198,  3209,  2339,  2027,   102],\n",
      "        [  101,  2632, 25340,  2232,  2283,  2019,  8727,  2000,  5152, 12865,\n",
      "          4076,  4830,  9953,  5152, 12618, 12399,  9021,  6155, 13181, 14147,\n",
      "          6672,  3549,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10047,  2863,  3942,  2017,  2007,  1037, 10722, 19498,  3797,\n",
      "          2007,  1037,  7960, 18907, 17447,  7650,  1998,  2831,  2035, 17276,\n",
      "          1998,  7632,  3388, 10047,  2863,  2655, 16137,  2884,  2546,   102],\n",
      "        [  101,  1037, 22692,  9152, 13327,  2040,  2853,  2041,  2000,  3795,\n",
      "          5130,  2138,  6343,  2165,  2032,  5667,  2004,  1037, 17689,  2085,\n",
      "          2002,  2074,  1037,  1059, 20535,  3070,  3249,  2038,  2042,   102],\n",
      "        [  101, 26980,  6363,  2323,  2025,  2022,  2109,  2000, 10377,  6206,\n",
      "          7489,  2040,  3338,  2046,  2023,  2406,  2057,  2024,  2108,  2579,\n",
      "          5056,  1997,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2228,  2009,  5637,  2004,  6616,  7955,  8466,  6971,\n",
      "          2000, 10474,  2013,  2182,  1998,  2045,  1037,  6616,  2378,  3745,\n",
      "          2695, 10474,  6462,  2006,  1996,  3953,  1997,  1996,  3931,   102],\n",
      "        [  101,  4532,  3165,  2386,  2003,  1037,  5236,  7743,  1996,  2510,\n",
      "          7459,  8398,  2008,  5152,  6904, 13871,  4140,  8112,  2699,  2000,\n",
      "          6033,  1996,  2149,  2510,  4717,  2483,  2003, 10819,  3207,   102],\n",
      "        [  101,  1056,  9148,  4779,  2869,  5637,  2004,  4429,  2243,  2078,\n",
      "          1042,  2497,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  2467,  1996, 10823,  2040,  2024,  2635,  1996,  6181,\n",
      "          1998, 13350,  2024,  2191,  2075,  2023,  2055,  2679,  2029,  2003,\n",
      "          1037,  2502,  4682,  2008,  2003,  2054,  1045,  3517,  2013,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.8080, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2840, 0.0750, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2840, 0.2840,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.8080, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5540, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0130, 0.0130, 0.7040, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.2910, 0.2910, 0.2910, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0060, 0.0060, 0.0060, 0.0900, 0.0900, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0900, 0.0900, 0.0900, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0020, 0.0020, 0.0020, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0900],\n",
      "        [0.0060, 0.3290, 0.3290, 0.3290, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.2210, 0.2210]]), 'label': tensor([1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2097,  7324,  1037, 22212,  2157,  1996,  6616,  2041,\n",
      "          2066,  2009,  1037, 12043,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2061,  5305,  1997,  2122, 10823,  3772,  2035,\n",
      "         17276,  2066,  2210, 11793,  2545,  6886,  1037,  4906,  2007,  2053,\n",
      "         14632,  2027,  2064,  2025,  2022,  2151,  2062,  5793,  2008,   102],\n",
      "        [  101,  2053,  2644,  7302,  1996,  4344,  2012,  2273,  9467,  2308,\n",
      "          2040,  8179,  2040,  2202,  1996,  4268,  5157,  4862, 22847,  2005,\n",
      "          2166,  6570,  2037,  4124,  2000,  5223,  2037, 11397, 10468,   102],\n",
      "        [  101,  5310,  2739,  7858,  2074,  3662,  1037,  6398, 27805,  4011,\n",
      "          9042,  2308, 12858,  2005,  2769,  2006,  1996,  4534,  1999,  2605,\n",
      "          2027,  2357,  2041,  2000,  2022,  7056,  1043, 22571, 14625,   102],\n",
      "        [  101,  2074,  8534,  2035,  1996,  3492,  3801,  2054,  8038,  3363,\n",
      "          9200,  7743,  2229,  2039,  2000,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2024, 10678,  2000, 14257,  5091,  2784,  1999,  1996,\n",
      "         16499, 19573,  2521,  3458,  1996,  2422,  3362,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2582, 12800,  2193, 10256,  2128,  7559, 20207,  2001,  4417,\n",
      "          2012, 26264,  2193,  2320,  1996, 16522,  3753,  4895,  6895, 14762,\n",
      "          2916,  9152, 13327,  4712,  8040,  3286,  2001, 14128,  2009,   102],\n",
      "        [  101,  7069,  8840, 12184,  2869,  3046,  2000,  6033,  2381,  2053,\n",
      "          2270,  2082, 12011,  2008,  9587, 25016,  5244, 10836,  2885,  2007,\n",
      "          2393,  2013,  3644, 17328,  2015,  2012,  1996,  4796,  2030,   102],\n",
      "        [  101,  5310,  1045,  3422,  4419,  4024,  1045,  3191,  1996,  2120,\n",
      "          4372, 15549, 14544,  1998,  1996,  7595,  2932,  2064,  2025,  2424,\n",
      "          2505,  4735,  8398,  2038,  2589,  2035,  2060,  2739, 11730,   102],\n",
      "        [  101,  2009,  2003,  2053,  4926,  2008,  1996,  4245, 15807,  2097,\n",
      "         17727,  4135,  3207,  2006,  2993,  2043,  2035,  2317,  9706, 16886,\n",
      "          2131,  1037,  5510,  1997,  5223,  5837,  2011,  1038, 13728,   102],\n",
      "        [  101,  5310,  2003,  2045,  2019,  5724,  2000,  7901,  1996,  3193,\n",
      "          2000,  1037,  2601,  4281,  2023,  2317,  4281,  2003,  4288,  2026,\n",
      "          2159,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2015,  1037, 12050,  2368,  2074,  1996,  2168,  2004,\n",
      "          2296,  5152,  1999,  1996,  2088, 15470,  2075,  1996, 23183,  2019,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5962,  2000,  2193,  2157,  2085,  1998,  2158,  2122, 20587,\n",
      "          2015,  2024, 22822,  5644,  1999,  2940, 24457,  2100,  2376,  2054,\n",
      "          2065,  2057,  7237, 19128,  7632, 12680,  2007,  3021,  1051,   102],\n",
      "        [  101,  2061,  2995,  1996,  2189,  1045,  6866,  3892,  2003,  3262,\n",
      "          4013,  2317,  1998,  2512,  3644,  2672, 11798,  2003,  2070,  2054,\n",
      "          2025,  2009,  2001,  2207,  2011,  1037,  3644,  3079,  2996,   102],\n",
      "        [  101, 18520,  2000,  2139,  6914, 22139,  2028, 22212,  2000,  2178,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2057,  2123,  2102,  2031,  1996,  3754,  2000,  2832,\n",
      "          8711,  2138,  1997,  1996,  7186,  1997,  6206,  7489,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0140, 0.0140, 0.0140, 0.0140, 0.7560, 0.0140, 0.0140, 0.0530, 0.0530,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2910, 0.0770, 0.0770,\n",
      "         0.2910, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0030, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1690, 0.1690,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4580,\n",
      "         0.4580, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0630, 0.0040, 0.0040, 0.0040, 0.2390, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2390, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8250, 0.0570, 0.0570, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2572,  4527, 10474,  2106,  2025,  5326,  1996,  9152,\n",
      "         13327,  2008,  2106,  2023,  2054,  2081, 10474, 12731,  3600,  2000,\n",
      "          1996,  2157,  2012,  1996,  2197,  3371,  1996,  7743,  2229,   102],\n",
      "        [  101,  1045, 10094,  2000,  2380,  4241,  2015,  3902,  1999,  4830,\n",
      "          2690,  1997,  2702,  2078,  2358,  1998,  2202,  1037, 11865, 14693,\n",
      "          2078, 18996,  1045,  2572, 10094,  2000,  2448,  2023,  7743,   102],\n",
      "        [  101,  3599,  1045,  1040,  2738,  3280,  2084,  2031,  1037,  9152,\n",
      "         13327,  2030,  5472, 25518,  4590,  3460,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2079,  2017,  6366,  2381,  2002,  2001, 15667,  1998,\n",
      "          2017,  2215,  2000,  2317,  9378,  1996,  2839,  2007,  2025,  2028,\n",
      "          2021,  2048,  3057,  8068, 19258,  2003,  9449,   102,     0,     0],\n",
      "        [  101,  2025,  2012,  2035,  2017,  2056,  4119,  1996,  2137,  7971,\n",
      "          1997,  2512, 12461,  2005,  1996,  2317,  3802,  7295, 28696,  2618,\n",
      "          2045,  2115,  3105,  2175,  4119,  2008,  9152, 13327,  2008,   102],\n",
      "        [  101,  2644,  1038, 19738,  8450,  1996,  2417,  9245,  2317,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2061, 10468,  1996,  2193, 26417,  2444,  2182,\n",
      "          1998,  2035,  2193,  2024,  2128,  7559,  5732, 22555,  3340,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 27263,  3065,  3112,  1998,  1996, 17276,  2035,  1999,\n",
      "          2028,  2181,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2296, 17219,  1999,  5365,  2003,  6815, 11417, 23808,  9013,\n",
      "         15504,  2068,  1996,  3606,  2003,  2008,  2122,  2308,  4711,  3209,\n",
      "          2012,  2032,  6975,  2135,  2122,  2308,  2939,  2157,  2046,   102],\n",
      "        [  101,  2023, 11507,  4516,  2006, 11704, 16137, 10841, 22153,  3723,\n",
      "          1998,  1996,  9570,  1997, 16137, 10841, 22153,  3723,  2003,  2437,\n",
      "          2033,  2031,  2162, 28945,  2000,  2043,  1045,  1040,  2659,   102],\n",
      "        [  101,  2057,  2064, 19242,  5771, 19483,  2015,  6904, 13871, 12868,\n",
      "          1998,  4382, 19483,  2015,  1060, 10772,  2015,  2065,  2027,  9346,\n",
      "          2037,  3653,  4305,  2571, 22014,  2021,  1996,  2679,  3426,   102],\n",
      "        [  101,  5962,  2000,  2317,  2308,  2831,  2055,  6830,  1999,  2465,\n",
      "          1998,  7989,  2000,  8054,  2037, 10756,  2025,  2000,  3789,  4603,\n",
      "          1045,  2572,  2061,  5458,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1038, 16102,  1038, 25459,  2666,  2057,  5223,  2115, 11808,\n",
      "          5437,  2100,  4632,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310, 20976,  3337, 20976, 10047,  2041,  9152,\n",
      "         13327,  2015,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  9074,  2003,  4485,  3436,  2010,  6471,  2040,  2003,\n",
      "          2023,  9152, 13327,  4241, 24888,  2015, 28879,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  6300,  2232,  2490,  2032,  2005,  7987, 10288,\n",
      "          4183,  7539,  1997,  2010,  7729,  2875,  7486,  2017,  2079,  2490,\n",
      "          1996,  4028,  1998,  5292, 11335,  6491,  4765,  1997,  7486,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.4040,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.4040, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0280, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0040, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.2220,\n",
      "         0.2220, 0.2220, 0.2220, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.5660, 0.1490, 0.1490, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8450, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0050, 0.0050, 0.0710, 0.0710, 0.0710, 0.2710, 0.2710, 0.0710, 0.0710,\n",
      "         0.0190, 0.0190, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0220, 0.0220, 0.3130, 0.3130, 0.3130, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240]]), 'label': tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  8650,  6206, 12114,  1998,  2025,  2273,  1998,  2308,\n",
      "          1999,  2630,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4931,  2065,  2017,  2215,  2000,  3058,  1037,  9152, 13327,\n",
      "          2059,  2057,  2215,  2498,  2000,  2079,  2007,  2017,  5959,  2115,\n",
      "         18294,  8239, 23957, 17219,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5275,  2007,  2032,  2114,  6016,  3629,  1998,  2769,\n",
      "          2000,  4485, 11484,  3088,  2002,  2035, 13970, 11201,  3148,  2058,\n",
      "          7494, 18076,  2013, 14163, 13793,  2229,  1998,  6732,  2057,   102],\n",
      "        [  101,  5310,  3495, 10262,  1998, 17678, 16098,  3436,  2008,  2019,\n",
      "          2035, 24225,  2094,  9680,  2923,  2003,  1037,  5152, 13141,  2003,\n",
      "          6135, 22856,  1998,  4189,  2059,  2053,  2009,  1037,  4795,   102],\n",
      "        [  101,  1037,  9587, 25016,  2213,  3015,  2007,  2010,  4632, 14612,\n",
      "          2192,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  3772,  2066,  2256,  6685,  2003,  2023,  2003,\n",
      "          2919,  2079,  2025,  7438,  2308,  2008,  2126,  2026,  6685,  2003,\n",
      "          2017,  2024, 10047, 22930,  5844,  7025,  2644, 10047, 22930,   102],\n",
      "        [  101,  4967,  2754,  1037,  8275, 15071,  4501,  3100,  2040,  4967,\n",
      "          2033,  3198,  2005,  2769,  4551, 16540,  2017,  2064,  2224,  2008,\n",
      "          2769,  2000,  4636,  9452,  4491,  1999,  2885,  4501,  1045,   102],\n",
      "        [  101,  2053,  2009,  2941,  2515,  4647,  2087,  4903,  2140,  2024,\n",
      "          2061,  5458,  1997, 26505,  2008,  2027, 25734, 25748,  1999,  6881,\n",
      "          3971,  2061,  2027,  5223,  3795,  5130,  2029,  3084,  2068,   102],\n",
      "        [  101,  2027,  2020,  9152,  9354,  2102, 10834,  1045,  2572,  2025,\n",
      "          3038,  2009,  2003,  2025,  9643,  2021,  2009,  3492,  2172,  3671,\n",
      "          5248,  2005, 17276, 17059,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2317,  2158,  2024,  1996,  2995,  6206,  7489,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2066,  1996,  2274,  5637,  4364,  2009,  2039, 26644,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2157,  2017,  2024,  2035,  9152, 13327,  2015, 16780,\n",
      "          2017,  2024,  2035,  5472,  9152, 13327,  2015,  2330,  2115,  6645,\n",
      "          5181,  2024,  5932,  4217,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2004,  2273,  2057,  2031, 19085,  2229,  2008,  2298,\n",
      "          2066, 12501, 14006,  2021,  2308,  2131,  2242,  4658,  2004,  2037,\n",
      "         16405, 18719,  2229,  2298,  2066,  1996,  8239, 15267,   102,     0],\n",
      "        [  101,  1045,  2066,  2026,  2308,  2066,  1045,  2066,  2026,  7198,\n",
      "          2300,  2061,  2980,  1045,  2064,  2069,  2994,  1999,  2005,  2193,\n",
      "          3823,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4332,  2091,  1996,  2938, 18924,  2006,  1996,  5637,  5210,\n",
      "          1047,  2128,  2102, 28394,  3215,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2024,  2017,  5152,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0450, 0.0450, 0.1720, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1720, 0.1720, 0.1720, 0.1720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2860, 0.2860, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2860, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0160, 0.8480, 0.0160, 0.0160, 0.0160, 0.0590, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0010, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0010, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0010, 0.0010, 0.0170],\n",
      "        [0.0340, 0.0340, 0.1290, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.1290, 0.1290, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0930, 0.0930, 0.0060, 0.0060, 0.0930, 0.3510, 0.3510, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4330, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.1140, 0.1140, 0.1140, 0.0080, 0.0080, 0.1140, 0.0080, 0.0080,\n",
      "         0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0780, 0.0780, 0.0780, 0.0780,\n",
      "         0.0780, 0.0780, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0780, 0.0780, 0.0780, 0.0780, 0.0780, 0.0780, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5580,  2023,  6900, 16078, 17768,  4974,  2288,  4727,  2055,\n",
      "          2051,  2023,  4627,  2000,  4148,  2043, 13350,  1998,  9587, 25016,\n",
      "          5244,  2707,  4485,  8038,  2100,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2821,  3398,  2008,  2205,  2077, 10474,  1998,  2077,\n",
      "          2193,  2706,  3283,  1045,  2069,  2354,  2028, 11690,  3232,  2008,\n",
      "          2009,  2035,  2026,  2814,  2020, 20199, 27065,  2317,  9282,   102],\n",
      "        [  101,  5310,  1045,  2245,  2017,  2020,  2066,  1037, 13758,  2393,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2006,  4419,  2085,  2128,  7559,  2094,  3782,  2522,  5644,\n",
      "          1040,  2139,  2003,  3038,  2002,  4122,  2019,  4812,  2046,  3251,\n",
      "          6521, 14424,  2010, 28667, 10383,  2140,  4953,  3607,  9246,   102],\n",
      "        [  101,  5310,  5993,  2007,  9617, 17238,  3336,  2296,  7560,  5152,\n",
      "         17246, 18061,  2072,  2323,  3604,  1999,  4610,  2465,  2365,  3286,\n",
      "         17129,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2304,  3057,  3362,  2273,  8583,  2025,  2193,  1038,  5457,\n",
      "          1059,  2273,  3736,  2172,  3041,  1999,  2755, 10823,  4503,  8186,\n",
      "          3041,  2084, 12461, 17059,  4503,  8186,  3041,  2084, 10823,   102],\n",
      "        [  101,  4748,  2140, 11382,  9681,  2136,  2007, 16522,  9541,  9354,\n",
      "          1998,  2035,  2157,  3358,  4573,  2131,  4457,  2030,  3844,  2091,\n",
      "          2023,  2097,  2025,  2644,  2149,  2009,  2097,  2069,  2191,   102],\n",
      "        [  101,  2157,  2116,  4916,  2015,  2453,  2228,  1045,  2572, 16939,\n",
      "          2021,  1045,  2572,  2025,  2295,  2009,  2074,  2008,  2045,  2518,\n",
      "          2008,  2038,  2467,  2081,  1996,  3915,  2147,  1998,  2009,   102],\n",
      "        [  101,  5310,  5310,  2339,  2515, 17518,  1056, 28394,  2102,  2002,\n",
      "          8466,  2242, 12873,  1998,  2059,  4152,  7944,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2120, 16498,  2085,  2053,  5782,  2111,  2000,  2031,  2769,\n",
      "          2003, 16424, 28084,  2818,  1998,  2644,  4214,  2009,  2120, 16498,\n",
      "          2057,  5181,  2787,  2576, 24116,  2545,  1997, 19999,  2964,   102],\n",
      "        [  101,  5310,  5310, 15333,  9351,  2017,  4929,  2028,  2391,  2100,\n",
      "          2317,  7415,  1998,  2111,  7868,  4931,  2057,  2031,  2035,  2589,\n",
      "          2009,  2043,  2057,  2020,  2402,  1041,  2290,  1999,  2256,   102],\n",
      "        [  101,  5310, 18168,  2290,  2057,  1521,  2128,  2061,  5637,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2296,  7292, 24665,  9314,  3653,  2480, 15578,  9351,  2100,\n",
      "          2441,  2010,  2677,  2317,  4841,  4149,  4409,  2572,  5302, 16611,\n",
      "          2087, 11508,  6026,  2343,  2412,  8112,  3555,  2002,  1040,   102],\n",
      "        [  101,  2265,  2023,  2004,  2019,  3517,  9095,  2005,  7489,  2000,\n",
      "          2994,  1999,  1996,  2149,  1998,  3422,  2068,  2681,  2074,  4863,\n",
      "          2008,  2023,  2003,  2054,  1996,  2816,  2735,  2115,  4268,   102],\n",
      "        [  101,  1998,  2058,  2193,  9252,  5152,  7404,  4491,  1999,  2625,\n",
      "          2084,  2193,  2086,  2965,  2498,  2429,  2000,  2017,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2467,  5223, 12447, 11382,  3489,  2039,  2077,  1045,\n",
      "          2031,  2000,  2175,  2000,  2147,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0890, 0.0890, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.3380, 0.0240, 0.3380, 0.0240, 0.0240,\n",
      "         0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0130, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0280, 0.1060, 0.1060, 0.1060,\n",
      "         0.1060, 0.1060, 0.1060, 0.1060, 0.1060, 0.1060, 0.0020, 0.0020, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0050, 0.2700, 0.0190, 0.0050, 0.2700, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.1700, 0.1700, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0030],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0500, 0.0500, 0.7260, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2003,  2025,  2023,  3124,  5637,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  3291, 10324,  1996, 11382,  3489,  2003,  2074,  1998,\n",
      "         19556,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2823,  2043, 10047,  2007,  2060, 19483,  4004,  2015,  1045,\n",
      "          2514,  2066, 10047,  1996,  2069,  2028,  2040,  2025,  2317,  1998,\n",
      "          3442,  2036,  2005,  2714,  4436,   102,     0,     0,     0,     0],\n",
      "        [  101,  2092,  2065,  2057,  2035,  2175,  2105,  4288,  2111,  2256,\n",
      "          2291, 16475,  4747,  6961,  2013,  2344,  2000,  8488, 17276,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  1998,  2017,  7425,  2012,  1996,\n",
      "          2519,  1997,  1037,  2317, 10514, 28139, 22911,  2923, 17727,  5243,\n",
      "          2818,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2017,  2035,  2562,  3038,  8271,  6373,  2021,\n",
      "          1996,  2604,  1997,  5501,  1998, 11274,  2024,  2035,  2317,  4661,\n",
      "          2028,  3124,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2016,  4536,  2033,  2066,  1037, 15606,  4521,  2008,  7743,\n",
      "          2041,  2066, 14102,  8112,  2729,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2062,  1998,  2062,  1045,  2424,  2870, 12145,  7714,  1999,\n",
      "          7258,  2008,  2024,  9197, 20199,  1998,  3442,  2007,  7570, 27982,\n",
      "          2008,  1045,  2079,  2025,  3113,  2116, 19483,  2111,  2012,   102],\n",
      "        [  101,  2065,  2317,  2111,  1999,  2193,  2024,  4011,  2000,  2514,\n",
      "          8056,  2138,  2060,  2111,  2040,  2020,  2317,  2025,  9352,  2130,\n",
      "          2151, 27136,  2075,  7189,  3079,  7179,  2059,  2304,  2111,   102],\n",
      "        [  101,  1999,  1037, 20478,  2376,  3956,  2003,  2256,  4602,  9698,\n",
      "          2027,  6135,  2079,  2025,  2074,  2202, 25501,  1997,  2256,  4171,\n",
      "          6363,  1998,  2079,  2498,  1999,  2709,  2021,  8011,  2149,   102],\n",
      "        [  101,  2064,  2404,  2115,  2769,  2006,  1996,  2128,  7559,  2094,\n",
      "         12268,  3038,  2044,  2193,  3823,  2225, 22953,  2213,  2031,  2081,\n",
      "          1037,  2488,  2707,  2084,  2027,  2106,  1999,  2023, 15083,   102],\n",
      "        [  101,  1996,  2245,  1997,  3802,  7295,  7856,  3508, 13911,  2213,\n",
      "         25966,  6132,  1996,  1038,  2721,  4160,  2158,  2025,  2074,  2138,\n",
      "          2002,  5191,  2055,  4808,  2108,  2589,  2000,  2010,  4903,   102],\n",
      "        [  101,  2017,  9152, 13327, 12170,  8376,  7110,  1056,  2412,  6069,\n",
      "          2031,  3442,  2317,  2611,  2606,  2061,  3013,  4830,  4485, 15966,\n",
      "          4830,  3586, 26227, 25308,  2015,   102,     0,     0,     0,     0],\n",
      "        [  101,  5924,  2003,  6719,  2104,  2149,  2491,  1998,  2122, 13157,\n",
      "          2024,  2061,  7352, 25631,  2017,  2024,  1037,  8275,  2030,  1996,\n",
      "          2087, 19739,  6894,  3468,  2158,  2006,  3011, 10086,  1045,   102],\n",
      "        [  101,  5310,  2070, 25380,  2024, 10218,  1998,  2013,  1996,  2540,\n",
      "          2023,  2003, 20342,  6414,  4053,  2491,  2021,  2017,  2064,  2025,\n",
      "          2491,  1996,  4053,  1997,  2054,  8310,  2000, 11513, 14920,   102],\n",
      "        [  101,  2417, 23194,  7221,  2015,  1054,  4297,  9050,  2138,  2009,\n",
      "          2001,  6355,  2114,  2308,  3373,  1999,  4372, 14540, 18891,  3070,\n",
      "          2308,  2245,  2308,  2323,  2031,  2037, 17962,  2015,  3013,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1390, 0.1390, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0070, 0.3880, 0.3880, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1020, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1320,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.1320, 0.1320, 0.1320],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0720, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0720, 0.0720, 0.0720, 0.0720, 0.0050, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0720, 0.0720, 0.0010, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050]]), 'label': tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2009,  2524,  2005,  2070,  2000, 10236,  2037,\n",
      "          9273,  2105,  2129, 20676,  2308,  2064,  2022,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3058,  1997,  4182,  2089, 16215, 14866, 25329, 28516,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3956,  2034,  2057,  2134,  2102,  6271,  2039,  1996,  5519,\n",
      "          7626,  2007,  1996, 28550,  2618,  2061,  2008,  2017,  2425,  2149,\n",
      "          2017,  2180,  2102,  2202,  1996, 14560,  2013,  5712,  2008,   102],\n",
      "        [  101,  2049,  2025,  1037,  3522,  5152,  5274,  2009,  3047,  2000,\n",
      "          8135,  1999, 12917,  5279,  7795,  1998, 17831,  2015,  1999,  5924,\n",
      "          2045,  2024,  2919,  5181,  2008,  3288,  2919,  2000,  3209,   102],\n",
      "        [  101,  5310,  5310,  5310,  2053,  4297,  4221,  3672,  2021,  2079,\n",
      "         19612,  9454,  4268,  5719,  2000,  4297,  4221,  4808,  3081,  3424,\n",
      "          7011,  1998,  4214,  2005,  2336,  2000,  2022, 15504,  2003,   102],\n",
      "        [  101, 27256,  2015,  2024,  2141,  2013,  4297,  4355,  8918,  6550,\n",
      "          2193,  1997,  4297,  4355,  8918, 18250,  3280,  2013,  7570, 14343,\n",
      "         15482,  2271,  4182, 18419,  1996,  2060,  2193,  5788,  2007,   102],\n",
      "        [  101, 14063,  2041,  2182, 22889,  4904, 25850,  2075,  2010,  2219,\n",
      "          2388,  2005,  2108, 15504,  2004,  1037, 10563,  1045,  2228,  1996,\n",
      "          6616,  2025,  2879,  2080,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  7093,  2095, 19457,  2123,  2102,  7367,  8004,  2002,  4014,\n",
      "          5472,  9152, 13327,  1999,  1037, 11641,  8840,  4135,  4135,  4135,\n",
      "          2140,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25283,  4890, 28942,  9587, 25016,  2213,  3179,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2035,  2739,  3703,  2323,  6869,  2000,  1996,  9587, 25016,\n",
      "          2213, 20109,  2007,  2907,  2006,  2057,  2128,  8130,  2039,  1996,\n",
      "          4109,  2182,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3849,  2004,  2065,  2017,  2020,  2157,  2053,  2062,  9152,\n",
      "         13327,  2030,  5472, 25518,  4590, 21123,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7955,  2360, 22212,  2562,  2009, 17249,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 18411,  2860,  2023,  2003,  2025,  3214,  2000, 13366,  2571,\n",
      "          6593,  2013,  1996, 20489,  1998,  4808,  2008,  2026,  9099, 19033,\n",
      "          2227,  2021,  2738,  2000, 12944,  2008,  2035,  8239,  2308,   102],\n",
      "        [  101,  2241,  3735,  2097, 21296,  1996, 14880,  3489,  2486,  9152,\n",
      "         13327, 27686, 13507,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4688, 11382,  3489, 10882, 24658,  1996,  6270,  4487,  9905,\n",
      "         20389,  2100,  2182,  2003,  2115,  6270,  4487,  9905, 20389,  2100,\n",
      "          2090, 16498,  2008, 11094, 16416,  3215,  3667,  1998, 27255,   102],\n",
      "        [  101,  2288,  9573,  2098,  1997,  1042,  2497,  2193,  4214,  1037,\n",
      "         23288,  1037, 23288,  2092,  1037,  6904, 13871,  4140,  1037,  6904,\n",
      "         13871,  4140,  2021,  8038,  2113, 20856, 20856,  2063,  2054,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.1530, 0.1530, 0.1530, 0.1530, 0.1530, 0.1530, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0110, 0.0110, 0.0110, 0.6280, 0.1650, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4580, 0.4580, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.7690, 0.0140, 0.2030, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3160,\n",
      "         0.0060, 0.3160, 0.3160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7890, 0.0550,\n",
      "         0.0550, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2210, 0.2210, 0.2210, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.2210, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.2970, 0.2970, 0.2970, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 11245,  5833,  2000,  5310,  2005,  9530, 10258,  5844, 17498,\n",
      "          2111, 26697,  2007,  1996, 10257,  4974, 19817, 17635,  2175,  2125,\n",
      "         24761,  1045,  6814,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8292, 19139, 12933,  2679, 21109,  1998,  2515, 24173,  8083,\n",
      "          7539,  1997,  2010,  3507,  2317,  2711,  3570,  8292, 19139,  1999,\n",
      "          2296,  3168,  2003,  1037, 11829,  2386,  2002,  6274,  5413,   102],\n",
      "        [  101,  2279,  2051,  1037,  9152, 23033,  4978,  2033,  2039,  2038,\n",
      "          1037,  1043,  2546,  1045,  2097, 12117, 12326,  1056,  2546,  2041,\n",
      "          1997,  2009,  4604,  2009,  2000,  2014,  2017,  2035,  9152,   102],\n",
      "        [  101,  2339,  2024,  2061,  2116,  5181,  1999,  3715,  1997,  2035,\n",
      "          2256,  2865,  2043,  2027,  2024,  2107,  1037,  2235,  7017,  1997,\n",
      "          1996,  2313,  2339,  2003,  1996,  2865,  2061,  3424,  2137,   102],\n",
      "        [  101,  2043,  1045,  3427,  7207,  2377,  1996,  2450,  4003,  2076,\n",
      "          1996,  2602,  2009,  2790,  3492,  3154,  2000,  2033,  2008,  2023,\n",
      "          2003,  2339,  2308,  2064,  2025,  2022,  1999,  4331,  1996,   102],\n",
      "        [  101,  2045,  2205,  2116,  1059, 22571, 11514,  2080,  4851,  2054,\n",
      "          2023,  2003,  1998,  2065,  2027,  2064,  2131,  1999,  2023,  2003,\n",
      "          1037,  9152, 13327,  2015,  2069,  2724,   102,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2025, 10587,  2079, 17276,  4485,  2007,  2026,\n",
      "          2814,  1045, 10587,  2079,  4138,  2317,  2611,  4485,  2558,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2005,  2019,  2250,  3696,  1045,  2469,  2079,  8239,  5223,\n",
      "          3612,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2878, 14746, 18249,  3335, 11880,  2989, 21249,  2518,\n",
      "          3138,  2033,  2067,  2000,  1037, 16325,  2051,  2043,  2273, 12581,\n",
      "         17536,  2308,  2612,  1997,  4268,  2068,  2020,  1996,  2204,   102],\n",
      "        [  101,  2710,  2038, 14620,  2062,  8711,  6206,  7489,  2084,  1996,\n",
      "          3915,  2038,  2037, 10975,  2711,  3791,  1037,  5333,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24247,  2015,  2024,  2035,  4167, 27283,  2128,  7559,  5732,\n",
      "         17059,  2027,  2342,  2000,  2963,  1996,  6635,  2168,  2616,  2157,\n",
      "          2067,  1999,  2037,  2227,  2009, 28679,  2015,  2037,  4730,   102],\n",
      "        [  101,  2025,  2000,  5254,  2008, 11870, 14828,  2055,  5472,  9152,\n",
      "         13327,  2015,  3957, 12731, 10603,  2121, 20203,  6961,  2572,  5302,\n",
      "          2043,  2027,  2360, 13157,  2024,  2187,  3358,   102,     0,     0],\n",
      "        [  101,  5310,  2008,  5025, 16011,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2025,  2514,  3374,  2005,  2032, 14686,  1996, 16522,\n",
      "          2259,  2335,  2193,  1999,  7694,  2248, 10130,  2767,  2000,  3956,\n",
      "          1998,  1996,  5181,  6215,  1997,  2155,  5300,  1998,  1996,   102],\n",
      "        [  101,  1997,  2607,  2027,  2020,  2025,  2941,  4941,  2000,  9152,\n",
      "         13327,  2015,  2593,  2193, 17474,  2138,  2027,  2020,  4011,  2000,\n",
      "          2043, 13157,  2056,  2009,  2021,  2193, 20996, 21031,  2094,   102],\n",
      "        [  101,  1045,  3046,  2022,  3835,  2021,  1045,  7110,  1056,  2175,\n",
      "          2078,  2292,  2053,  8494,  7377,  8024,  8494,  2006,  2033,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0670, 0.0670, 0.0670, 0.0670, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2520, 0.2520, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0090, 0.0090, 0.0090, 0.0090, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0340, 0.0340, 0.0340, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300, 0.1300,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0330, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1230, 0.4680,\n",
      "         0.1230, 0.1230, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0410, 0.0410, 0.1570, 0.1570, 0.1570, 0.1570, 0.1570,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.1640, 0.1640, 0.1640, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3910, 0.3910,\n",
      "         0.0070, 0.1030, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0810, 0.0810, 0.0810, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0810, 0.0810],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2120,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2120,\n",
      "         0.2120, 0.2120, 0.0040],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.7960, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2028,  2051,  2005,  1037,  9152, 23033,  2040,  4282,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  2406,  1049, 10343,  2196,  2707,  2006,  2051,  2455,\n",
      "          1997,  1996,  2489,  2188,  1997,  1996,  9152, 13327,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2025,  3305,  2339,  3087,  2052,  3422,  4364,\n",
      "          2104,  2193,  2954,  1045,  2036,  2079,  2025,  3305,  2339,  3087,\n",
      "          2052,  3422,  9200, 22212,  2015,  2954,  2593,  2061,  2672,   102],\n",
      "        [  101,  1045,  2001,  7514,  2075,  2000,  4231,  2386,  4712,  1997,\n",
      "          1996,  5413,  2243, 27793,  3215, 22953,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 23033,  2288,  1037,  2317,  7743,  2074,  2000,  2425,\n",
      "          2014,  2054,  2000,  2079,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2040, 14977,  2055,  1996, 12010, 19062,  9818,  2094,  2451,\n",
      "          1045,  2079,  2025,  2729,  2055,  2040,  2027,  2293,  5223, 11891,\n",
      "          2125,  2215,  2342,  2030, 10657,  2031,  1045,  2079,  2025,   102],\n",
      "        [  101,  2017,  3198,  9152, 23033,  2015,  2000,  2022,  2115,  3521,\n",
      "          1998,  2027,  2203,  2039,  2108,  2115,  3538,  1997,  4485,  2238,\n",
      "          4954,  2009,  2039,  4770,  2283,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2023, 12593,  2106,  2025,  2498,  3308,  2000,\n",
      "          2017,  2005,  2017,  2000,  6402,  2032,  2066,  2008,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2308,  6042,  2461,  6745,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9217,  1996,  3439,  2535,  2308,  2209,  2003,  2000, 29591,\n",
      "          2068,  2273,  2020,  2025,  1998,  2024,  2025,  1999,  1037, 11641,\n",
      "          2027,  9530, 20740,  2094,  1999,  2363,  2473,  2013,  1998,   102],\n",
      "        [  101,  2065,  1037,  7743,  4929,  2317, 14829,  1059,  2304,  6007,\n",
      "          3580, 18601,  2027,  2064,  2102,  4377,  8073,  5892,  2008,  2061,\n",
      "         26997,  2100,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1996,  6187, 18100, 17759,  1997,  2317,  2111,\n",
      "         11225,  2039,  2004, 12593,  2015,  2005, 24387,  2106,  2017,  2035,\n",
      "          2025,  2156,  6796, 19817, 27627,   102,     0,     0,     0,     0],\n",
      "        [  101,  2023,  3124,  2003,  2019,  9706, 28696,  2618,  2002,  2003,\n",
      "          2053,  2062,  1037,  5152,  2084,  4441,  4828,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2115,  8562,  2003,  2241,  2006, 14398, 24004, 24920,\n",
      "          3348,  2964,  1998,  9040,  2017,  1521,  2128,  2025,  8239,  6057,\n",
      "          2175,  2188,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 17012,  2074,  1999,  2193,  2510,  5073,  2031,  2042, 18026,\n",
      "          2013,  2037,  2317,  2160,  5841, 13463,  9989,  2008,  2027,  2018,\n",
      "         24156,  3967,  2007,  3097,  2308,  2096,  7118,  2007,  2343,   102],\n",
      "        [  101,  7743,  2229,  2022,  3772,  2066,  9152, 23033,  2015,  9152,\n",
      "         23033,  2015,  2022,  3772,  2066,  7743,  2229,  7743,  2229,  2022,\n",
      "          8295,  2122,  9152, 23033,  2015,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.7960, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.6530, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7000,\n",
      "         0.1850, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.4580, 0.4580, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0350, 0.0350, 0.0350, 0.0350, 0.5030, 0.0350, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.2700, 0.0050, 0.0050, 0.0050, 0.0710, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.2700, 0.2700, 0.0050, 0.0050, 0.0050, 0.0710, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2003,  2296,  2402,  2711,  1999,  2637,  2128,  7559,\n",
      "          5732,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 26632,  2078,  2003,  2183,  2000,  5157,  2008,  2057,  2202,\n",
      "          8040, 25438,  8490,  8711,  2013, 23116,  1998,  1999,  2709,  2010,\n",
      "          2406,  2097,  2490,  2149,  1999,  1037,  3119,  3066,  1037,   102],\n",
      "        [  101,  5310,  2045,  1521,  2367,  2828,  1997, 14560,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2038,  2023,  3047,  2720, 11382,  3489,  7089,  2027,\n",
      "          2020, 10016,  2193,  2335,  1999,  3025, 24784,  4217, 12383,  2015,\n",
      "          1997, 16795,  2003,  1996,  3291,  1997,  8438,  2065,  2017,   102],\n",
      "        [  101,  7910,  2002,  2347,  1056,  1037,  4845,  1998,  1045,  2572,\n",
      "          3893,  6014,  2003,  2025,  2108,  2357,  2046,  1037,  9152, 13327,\n",
      "         17276,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2006,  2192, 10668,  7685, 10268,  2440,  1997,  2317,\n",
      "          4511, 11867, 14778, 16750,  1998, 17985, 14397, 28295,  2005,  2043,\n",
      "          1996,  1059, 20535,  3070,  4150, 24257,   102,     0,     0,     0],\n",
      "        [  101,  2200,  3835,  2008,  2017,  2064,  6149, 11721,  5910,  1045,\n",
      "          3984,  2006, 11721,  2497, 11721,  2497, 11379,  2066,  1037,  2128,\n",
      "          7559,  2094,  2138,  1997,  2035,  2023, 13675, 16103,  2791,   102],\n",
      "        [  101,  3071,  2049,  1037,  2663,  2005,  1996,  5637,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4521,  3102,  2035,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  9152, 23033,  2015,  4737, 10094,  2033,  2043,  1045,\n",
      "          2079,  2025,  2130, 18178,  9468,  2006,  2068,  6904, 13871, 12868,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2293,  6550,  1998,  1045,  2293,  2293,  2064,  1521,\n",
      "          1056,  2903,  1045,  1521,  1049,  2309,  2023,  1058,  2154,  2129,\n",
      "         17276,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2013,  1037,  9587, 25016,  2213,  2177,  1999,  1996,  3915,\n",
      "          2040,  2031,  6971,  2000, 15554,  5048,  2100, 17768,  4641,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2079,  2025,  1045, 12707,  2063,  2122, 15912,\n",
      "          2015,  2667,  2000, 17279,  3209,  1996,  2069,  7486,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2288,  5648,  1999,  2026,  2159,  2317,  7743,  1999,\n",
      "          2026,  4536,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2017,  2024,  2025,  1037, 11382,  3489,  2074,  1037,\n",
      "         12731, 18141, 11382,  3489,  3608,  9378,  2121,  2059,  2026, 10103,\n",
      "          2017,  2507,  4426,  2205,  2172,  4923,  1996,  2069,  2028,   102],\n",
      "        [  101,  1996,  9212,  2884, 17678,  2007,  1996,  2035,  2317,  6519,\n",
      "          2016,  9953,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3840,\n",
      "         0.3840, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1280, 0.0340, 0.0020, 0.0020,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4330,\n",
      "         0.4330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7220, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0340, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.4890, 0.1290, 0.1290, 0.1290, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3410, 0.0060, 0.0060, 0.0060,\n",
      "         0.3410, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2079,  2025,  2031,  1037, 11660,  2593, 10047,  2080,\n",
      "          2027,  2035,  2298, 10073,  2075,  2440,  2644,  1998,  2339,  2821,\n",
      "          2339,  2079,  2308,  2031,  2068, 16328,  2035,  2058,  2068,   102],\n",
      "        [  101,  5310,  3398, 12731,  2480,  4297,  2884,  4808,  2003,  1037,\n",
      "          8239, 16311,  1998,  5691,  3426,  4808,  2023, 19318, 19006,  2003,\n",
      "          2074,  5236,  2009,  2069,  1037,  3185, 10720,   102,     0,     0],\n",
      "        [  101,  2043,  2097,  1037,  9587, 25016,  2213,  2061,  9527,  4697,\n",
      "          2008,  6904, 13871,  4140,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  7619, 14636,  2009,  1037,  8317,  7577,  2000,\n",
      "          3535,  2000,  2265,  9587, 25016,  2213, 22006,  2122,  2659, 26264,\n",
      "          4485, 21049,  2031,  2053,  7395,  2024,  5980,  3238, 22052,   102],\n",
      "        [  101,  5310,  2288,  5506,  2012,  2033,  2138,  1045,  2409,  2032,\n",
      "          2002,  2001,  5637,  1999, 16215,  3694,  2001,  1045,  3809,  2748,\n",
      "          2003,  2002,  5637,  2748,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2498,  2021,  8040, 25438, 26454,  2040,  7180,  1999,\n",
      "          1996,  2866,  1998,  5987,  2673,  2005,  2489,  2193,  1997,  2068,\n",
      "          2123,  2102,  2147,  2193,  1997,  1996,  9040,  2015,  3344,   102],\n",
      "        [  101,  2036,  2129, 21746,  2039,  2001,  1996, 15478,  9152, 13327,\n",
      "          1999,  1996,  2193,  2193, 27918,  2008,  2106,  2025,  2130,  2113,\n",
      "          8398,  2171,  2056,  2069,  2343,  2059,  9596,  4223,  1998,   102],\n",
      "        [  101,  2047,  8771,  7910,  2213,  7632,  2298,  2065,  2017,  5223,\n",
      "         13350, 12010,  5152,  2111,  3644,  2111, 27620,  4877,  2030,  3649,\n",
      "          2059, 19045,  6616,  2125,  1045,  6814,  1045,  2064,  2102,   102],\n",
      "        [  101, 10469,  2015,  2018,  2498,  2000,  2360,  2055,  1996,  4467,\n",
      "          2450,  6080, 15504,  2011,  2093,  5152,  2273,  2006,  9130,  2444,\n",
      "          1045,  3984,  2027,  2020,  2205,  5697, 11225,  2039,  2066,   102],\n",
      "        [  101,  2610,  2031,  2467,  6283, 22190,  2483,  2039,  2127,  3728,\n",
      "          2085,  1996,  2610,  2024,  2478, 22190,  2483,  2000, 11895,  2860,\n",
      "          2129,  7473,  2027,  2024,  2021,  2748,  2610,  2031,  2467,   102],\n",
      "        [  101,  2079,  2025,  2022,  9376,  2758,  1996,  9152, 13327, 26887,\n",
      "          6616,  2008,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6502,  2003,  3223,  2000,  2131,  2943,  2013,  1996,  2598,\n",
      "          2000,  1996, 22278,  1996,  4954,  5963, 12436,  2290,  3005,  2193,\n",
      "          2154,  2214,  2958,  7798,  1999,  5631,  2197,  2733,  2453,   102],\n",
      "        [  101,  2613,  4632,  7743, 11721,  2546, 10094,  1037,  9152, 23033,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1051, 11631,  1045, 13900,  6616, 23755,  7743,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2293,  1996,  5152,  8499,  5921,  5499,  3741,  2129,\n",
      "          2272,  2027,  2106,  2025,  2202,  1999,  2130,  2028,  5152, 13141,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2279,  2051,  2017,  2963,  2619,  7743,  2075,  2055,  6467,\n",
      "          4611, 10825,  2068,  1997,  2651,  1998,  1996,  6467,  1997,  2193,\n",
      "          2304,  2111,  2193,  6696,  4004,  1998,  2193,  1059, 22571,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0600, 0.0160, 0.0160, 0.8610, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1830, 0.1830, 0.1830,\n",
      "         0.1830, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0160, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.2260, 0.2260, 0.2260, 0.2260, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0280, 0.1050, 0.1050, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0330, 0.0330, 0.1250, 0.1250, 0.1250,\n",
      "         0.1250, 0.1250, 0.0330],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0220, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0220, 0.0220, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0220,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.6450, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.3250, 0.3250, 0.3250, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210]]), 'label': tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2612,  1997, 18681,  2331,  2079,  2149,  4237,  1999,  7025,\n",
      "          2057,  2031, 18681,  5553, 15272, 15908,  2015,  2149,  2362,  1998,\n",
      "          2049,  1996, 10140,  3367,  2518,  2412,   102,     0,     0,     0],\n",
      "        [  101,  2980,  2611,  2621,  2428,  2357,  2033,  2046,  1037,  7570,\n",
      "          2063,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045, 20010,  4355,  5762,  2964,  2138,  1045,  7634,  2009,\n",
      "          2004,  1037,  3347, 25990,  2278,  2518,  3251,  2009,  3310,  2013,\n",
      "          1037,  2304,  2158,  2030,  1037,  2317,  2158,  5912, 26887,   102],\n",
      "        [  101,  5310,  8239, 22052,  2015,  2009,  1521,  2035,  2055,  1996,\n",
      "          6206, 12114,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2056,  2008, 17276, 11669,  2066,  7861, 11233,  2213,\n",
      "          2003,  1999,  2012,  1996,  2617,  1998,  2026, 16222,  2102,  2288,\n",
      "          8534,  1045,  2772,  1999,  2019, 17159,  2026,  4070,  5458,   102],\n",
      "        [  101,  2034,  1997,  2035, 11132, 23076,  2078,  2038, 12873,  7743,\n",
      "          2943,  1998, 27793, 15353,  7743,  2943,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  2043,  2502, 22212,  7743,  2229,  2360,  1045,\n",
      "          5223,  2746,  2000,  2122,  2502,  6904, 13871,  4140,  5019,  7743,\n",
      "          2065, 10930,  5637, 22212,  2100,  4632,  2123,  2102,  2358,   102],\n",
      "        [  101, 17620,  2098,  2445,  1996,  8750,  2197,  2305, 10047,  2025,\n",
      "          1996,  2828,  1997,  2711,  2000,  2175,  2041,  1997,  2026,  2126,\n",
      "          2000,  3422, 19483,  2865,  2003,  2045,  1037,  2744,  2005,   102],\n",
      "        [  101,  2317,  3124,  8509, 29464,  2094,  1999,  6670,  1998,  1996,\n",
      "          3433,  2003,  6616,  2035, 14163, 13793,  2229,  1998, 11867,  6558,\n",
      "          2994,  2465,  2100, 11721,  2497,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2079,  2025,  2017,  8108,  2655,\n",
      "          4426,  4603,  1998, 19483,  2057,  2156,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2572,  2317, 19154,  2003,  2025,  1999,  2035,\n",
      "         27994,  1996,  2035, 10823,  5443,  2035,  2317,  4895,  2483,  1999,\n",
      "          1996,  2035,  2304,  3346,  2052,  2298,  3376,   102,     0,     0],\n",
      "        [  101,  5674,  8239,  1037,  2317,  2611,  1998,  2016,  2655,  2017,\n",
      "          1037,  9152, 13327,  2076,  3348,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2018,  1037,  6919,  6919,  9152, 13327,  2489,  5353,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10041,  2317,  2308,  2003,  2763,  2893, 15504,  3679,  2085,\n",
      "          2008,  2016,  2038,  2053,  5152,  3129,  1998,  2006,  2327,  1997,\n",
      "          2008,  2014,  2365,  2003,  2085,  1037, 24815,  2923,  2074,   102],\n",
      "        [  101,  1045,  2572,  5580,  1996, 24247,  2015,  2387,  1996,  2204,\n",
      "          6040, 11268,  7512,  2098,  2011, 25242,  4496, 18331,  1045,  2079,\n",
      "          2025,  2215,  2000, 11113, 20872,  2232,  1996,  2157,  1045,   102],\n",
      "        [  101,  2004,  2310, 11254,  7327, 25325,  5657,  3597, 10861,  2033,\n",
      "          2226,  2053,  4168,  8915,  2213,  2030, 25538,  2213,  5472, 25518,\n",
      "          4590,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.1000, 0.1000, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3790,\n",
      "         0.3790, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.1340, 0.1340, 0.1340, 0.1340, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0990, 0.3740, 0.0070, 0.0070,\n",
      "         0.0990, 0.3740, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0390, 0.1470, 0.1470, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1470, 0.0030, 0.0390,\n",
      "         0.1470, 0.1470, 0.1470, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.1510, 0.1510, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5720, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3230, 0.3230, 0.3230, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2664,  2027,  2097,  2202, 18076, 14560,  2040,  2227,  2053,\n",
      "          5762,  2030,  3412, 14522,  2013,  2037,  2219,  3032, 17657,  3171,\n",
      "          6728,  6442, 19496, 12837,  2202, 23359,  2058,  2216,  2040,   102],\n",
      "        [  101,  5310,  2122,  2111,  2024,  2061, 10326,  2006,  4363,  6206,\n",
      "          7489,  1998,  2969,  4078, 26310,  3209,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2342, 18044,  4521,  1037, 15212,  2017,  8239,\n",
      "          9152, 13327,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  1054, 11434, 28616,  3401,  6914,  3370,  2008,  2003,\n",
      "          2019,  7814,  1997,  2317, 14052,  2061,  2065,  2017,  2024,  2317,\n",
      "          2017,  2024,  1037,  8494,  7377,  8024, 24053,  8950, 17328,   102],\n",
      "        [  101,  1996, 13433,  4095, 22889,  4904,  2012,  1996,  4035, 24477,\n",
      "          5062,  3840,  2001,  6719, 26259,  2014, 14068,  4604,  1996,  8275,\n",
      "          1057, 18372,  2015,  2000,  2014,  2237,  5665, 20755,  7941,   102],\n",
      "        [  101,  2193,  1998,  2085,  2130,  2295,  2027,  2031,  2576,  2373,\n",
      "          1996,  3698,  2145, 15187,  2122,  3972, 14499,  2389, 29310,  6169,\n",
      "          2006,  1996,  4145,  2008,  2130,  7486,  2008,  2031,  2969,   102],\n",
      "        [  101, 10823,  8487,  6558,  2308, 12163,  1996,  7290,  1999,  5109,\n",
      "          1999,  1996,  3915,  2129,  2055,  2317,  2273, 12163,  1045,  3984,\n",
      "          2216,  2515,  2025,  3043,  5310,   102,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2023,  9152, 13327,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  1996,  2149,  2323,  3499,  2028, 13141,\n",
      "          1999,  2005,  2296,  2193,  6206, 12114,  3718,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  9152, 13327,  2323,  2074,  3013,  2000,  1996,  5252,\n",
      "          1998,  3338,  2046,  1996,  2843,  2000,  8954,  1996,  2482,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2040,  1996,  6616,  4455,  2037,  2905,  9117, 11669,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  9152, 23033,  2003,  1037,  8239,  8257,  1045,  8415,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  3531,  5483,  2644,  4288, 13141,  2336,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2214, 12043,  2074,  2441,  1996,  7842,  9521,  2341,  3592,\n",
      "          1999,  2182,  2005,  2193,  3823,  1998,  2939,  2185,  2485,  1996,\n",
      "          2341,  6904, 13871,  4140,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 19219,  2057,  7367,  2571, 22008, 12535,  4478,  5798,  2651,\n",
      "          2926,  2043,  5152,  3428,  2024,  2975,  2104,  3571,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12456,  2128,  7559,  2094,  2003,  6069, 12456,  2128,  7559,\n",
      "          2094,  8754, 15509,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0110, 0.0110, 0.0030, 0.0030, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0030, 0.0030, 0.0030, 0.0030, 0.1650,\n",
      "         0.1650, 0.1650, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0030],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0680, 0.0680, 0.0680, 0.2590, 0.2590,\n",
      "         0.2590, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0990, 0.0990, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.3750, 0.0990, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0060, 0.0830, 0.0830, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0830, 0.0830, 0.0830, 0.0060, 0.0060, 0.0830, 0.0830,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0830, 0.0830, 0.0830, 0.0830, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0050, 0.0050, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0790, 0.0790, 0.0790, 0.0790, 0.0790,\n",
      "         0.0790, 0.0790, 0.0790],\n",
      "        [0.2290, 0.2290, 0.2290, 0.2290, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1730, 0.1730, 0.6550, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0510, 0.1920, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510,\n",
      "         0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.7420, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0790, 0.3010, 0.0790, 0.0790, 0.0790, 0.3010, 0.0790, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2023, 17768,  2132,  2425,  2317, 28101,  2239,  2027,  2323,\n",
      "          2025, 17612,  2055,  3742,  2512,  2317,  7521,  2013,  1996,  2353,\n",
      "          2088,  2016,  8835,  3017,  2055,  1996,  3574,  1997,  4234,   102],\n",
      "        [  101,  1045,  2001,  2831,  2378,  2000,  2784,  4817,  2002,  1037,\n",
      "         15478,  9152, 26745,  2290,  2395, 24667,  4842,  1045,  2079,  2025,\n",
      "          2130,  3342,  2073,  1996,  4512,  2007,  2009,  2318,  8840,   102],\n",
      "        [  101,  2053,  2126,  2008,  2178,  2304,  3124, 21054,  2178,  2317,\n",
      "          2711,  2008,  2064,  2025,  2022,  1045,  2812,  2000,  2360,  2008,\n",
      "          2003,  1037,  5223,  4126,  2052,  2022, 16939,  2015,  2030,   102],\n",
      "        [  101,  5310,  2045,  2515,  2025,  2342,  2000,  2022,  6544, 13986,\n",
      "          1999,  5152,  3032,  2017, 18110,  2175,  2045,  2000,  3325,  2037,\n",
      "          3226,  1998,  3243, 19597,  1996,  7489,  2182,  2024,  3140,   102],\n",
      "        [  101,  5310,  3374,  2002,  1037, 22889,  4904,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2069,  7069,  8840, 12184,  2869,  2024, 25202,  2043,  2027,\n",
      "         12324,  1037, 26264,  9587, 25016,  2213,  3031,  7574,  2930,  2193,\n",
      "         11573, 29525,  2015,  2052,  2025,  2342, 26980,  3825,  4280,   102],\n",
      "        [  101, 20976,  9152, 23033, 15504,  1037,  2611,  1998,  2002,  2573,\n",
      "          2012,  8934,  2232,  2008,  2919,  2147,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3272,  2317,  2336,  2024,  2062,  2411,  2084,  2025, 15504,\n",
      "          1998,  2730,  2011,  2060,  2317, 21877,  4747, 10814,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6309,  2330,  4303,  2092,  9152, 23033, 10118,  2131,  2017,\n",
      "          6309,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8529,  2339,  2515,  2016,  2031,  2014,  9353,  7630,  2417,\n",
      "         12095,  2006,  2014,  2132,  2003,  2008,  1037, 21146,  4360,  2375,\n",
      "          2518,  2030,  2074,  9200, 14163, 18719,  2063,  2308,  2667,   102],\n",
      "        [  101,  2122,  8448,  1999,  1996, 18167, 28781,  2020,  1996, 27236,\n",
      "          2000,  2599,  2710,  2353,  2087,  2759,  2283,  1996, 21915,  6102,\n",
      "          1998,  5236,  2011,  3267,  1996, 17768,  4974,  2180,  2138,   102],\n",
      "        [  101,  2256,  2334,  9587, 14540, 14428,  2015,  2024, 25221,  2000,\n",
      "          1996,  2148,  1998,  2148,  2225,  7238,  2515,  2025,  2031,  6910,\n",
      "          7489,  9587, 25016,  2213,  2030,  2025,  8711,  2040,  2288,   102],\n",
      "        [  101,  9152, 23033,  2015,  2293,  6595,  1999,  3967,  2007,  2027,\n",
      "          2214,  7743,  2229,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2242,  1045,  2031,  4384,  1999,  2166,  2296, 17824,  8114,\n",
      "          2711,  2017,  1040,  2215,  2770,  1037,  2334,  2030,  2976,  2231,\n",
      "          2003, 21268,  1999,  1996,  2797,  4753,  2138,  7857, 10085,   102],\n",
      "        [  101,  2122, 27672,  2308,  4929,  1037,  5266,  2006,  2037,  2132,\n",
      "          2096, 14488,  2023,  3017,  3218,  3653, 27122,  7025,  1998,  2001,\n",
      "          4372,  5558, 21280,  2011,  1996, 19178,  2035,  3017, 17831,   102],\n",
      "        [  101,  5310,  5310, 16913,  2072,  2467,  1037,  5394,  2040,  5147,\n",
      "          2730,  7486,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2990, 0.2990,\n",
      "         0.2990, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350, 0.0350,\n",
      "         0.0350, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0350, 0.0350, 0.0350],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.5130, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.1310, 0.1310, 0.1310],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0070, 0.0070, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.4020,\n",
      "         0.4020, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310, 10168,  7285,  2024,  1996,  2047, 16231, 13157, 20228,\n",
      "          2480, 19387,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2457, 10054,  2003,  1037,  8239,  6752,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2339,  2106, 16360,  2131, 15504,  1048,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  3685,  3613,  4214,  9731, 10469,  2015,  2065,  1996,\n",
      "          2916,  1997,  2035, 24185, 22984,  2078,  4995,  2102,  8280,  2748,\n",
      "          2000,  1037,  4424, 18421,  2270,  2862,  2021,  2097,  1037,   102],\n",
      "        [  101,  5310,  2008,  1996,  2391,  2128,  7559,  2094,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2552,  2066,  2017,  2079,  2025,  2444,  2279,\n",
      "          2000,  1037,  2160,  2440,  1997,  2317,  3337,  2005,  2017,  2175,\n",
      "          2131,  2028,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2000,  1996,  2308,  2012,  4419,  2739,  2040, 13263,  5074,\n",
      "          9932,  4244,  1998,  3021,  1051,  1999,  2344,  2000,  2131,  2769,\n",
      "          2017,  2024,  2742,  1997,  2339,  2273,  2053,  2936,  3404,   102],\n",
      "        [  101,  2026,  3507, 12461,  1045,  2031,  6659,  2739,  5181,  1998,\n",
      "          9152, 13327,  2015,  2145,  4839,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2017, 10587,  4952,  2000,  5637,  2189,  2005,  5637,\n",
      "          2111,  4952,  2000, 24582,  2361,  2045,  2003,  2061,  2172, 24004,\n",
      "         10624, 17456,  1999,  2070,  1997,  2037,  2774,   102,     0,     0],\n",
      "        [  101,  6616,  2115,  2951,  2017,  2614,  2066,  1037, 24004,  1045,\n",
      "          2572,  2025,  2183,  2000,  2131,  8631,  2046,  2115,  5637,  2208,\n",
      "          1997,  2171,  1996,  7349,  2005,  2035,  1045,  2113,  2017,   102],\n",
      "        [  101, 10823, 11115,  3113,  1996, 10823, 11115,  2027,  2024,  1037,\n",
      "          2962,  2287, 17276,  2155,  2013,  1996,  2237,  1997, 14864,  2027,\n",
      "          2024,  9152, 13327,  2015,  2157,  2013,  2381,   102,     0,     0],\n",
      "        [  101,  2016,  2309, 12731,  2480,  2016,  2064,  2025,  2424,  1037,\n",
      "          9152, 23033,  4276,  2014,  2051,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2053,  2126,  2023,  2941,  3047,  2065,  2002,  2106,\n",
      "          2131, 15504,  2009,  2001,  2763,  2011,  2070,  3060,  2030,  5424,\n",
      "          2005,  4424,  5057,  4436,  1998,  2059,  2002,  2081,  2039,   102],\n",
      "        [  101,  5310,  2175, 11362, 10398,  2073,  2020,  2017,  2043,  7560,\n",
      "          2308,  2020, 15504,  2115,  2814,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2574,  2273,  1998,  2308,  2180,  2102,  2022,  7244,  2169,\n",
      "          2060,  2027,  2097,  2022, 24382,  2066,  1999,  5152,  3032,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  1521,  1049,  3972, 20624,  3070, 10474,  2005,  1037,\n",
      "          3232,  2420,  2205,  2172, 17276,  4485,  3582,  2000,  2026,  2485,\n",
      "          2814,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0210, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0210,\n",
      "         0.0210, 0.0810, 0.0810],\n",
      "        [0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.1460, 0.1460,\n",
      "         0.1460, 0.1460, 0.1460, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1790, 0.1790, 0.1790, 0.1790,\n",
      "         0.1790, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0470,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2320, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2320,\n",
      "         0.0160, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.1960,\n",
      "         0.1960, 0.1960, 0.0520, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0520,\n",
      "         0.0520, 0.1960, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680, 0.0680,\n",
      "         0.0680, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2655,  5310,  1037, 11382,  3489,  2030,  2360,  2002,  2015,\n",
      "          1037,  5394,  1998,  2002,  2064,  2025,  4440,  2058,  2370,  3435,\n",
      "          2438,  2000,  2507,  2017,  1037,  4132,  2021,  2065,  2017,   102],\n",
      "        [  101,  5310,  3272,  2005,  1996, 17800,  2112,  4165,  2066,  2008,\n",
      "          2003,  1996,  7526,  2241,  2006,  2054,  6433,  2043,  2027,  2175,\n",
      "          2000,  2457,  2073,  2317, 10558,  7149,  2007,  2304,  2111,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  2027,  2024, 18066,  2065,\n",
      "          2017,  2024,  2317,  2748,  2021,  2004,  2009,  6433,  2027,  2031,\n",
      "          3313,  1996,  3798,  1997,  7521,  2008,  2057,  2079,  2866,   102],\n",
      "        [  101,  2197,  2733,  1045,  8823,  2012,  1037,  2047,  6700,  3334,\n",
      "         22861,  4160,  4825,  1998,  2657,  1996,  2087,  2643,  9643,  9152,\n",
      "         13327,  5005,  2412,  1038,  8017,  2075,  2013,  1996,  7492,   102],\n",
      "        [  101,  1045,  8415,  2017,  7852,  2097, 15174,  2005,  2193,  2086,\n",
      "          1998,  2097,  2025,  2022,  2130,  3621,  2829,  1998,  2059,  2044,\n",
      "          2017,  4638,  2009,  4150,  2304,  1999,  2193, 10819,  2015,   102],\n",
      "        [  101,  2643,  1999, 26703,  4116,  2050, 15456,  1045, 10587, 11506,\n",
      "          2026,  2293,  1997, 14969,  2486,  6181, 12603,  2007,  5957,  9117,\n",
      "         11669,  4785,  2689,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3461,  1051,  2053,  5365,  2412,  9152, 13327,  2015,  7438,\n",
      "          2121,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5973,  2045,  2024,  2312,  3616,  1997,  5181,  2107,  2004,\n",
      "         16522,  2259,  2017,  2097,  2424,  7167,  1997,  6900,  1998, 13044,\n",
      "          2008,  2138,  5181,  2024, 11432,  1999, 17982,  2529,  2433,   102],\n",
      "        [  101, 22052, 17276, 11669,  8444,  1045,  2097,  2031,  1037,  2283,\n",
      "          2043,  2619,  8509,  2010,  1999,  1996,  2598,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  1038,  5604,  2003,  1037,  7743,  2043,  2017,  2064,\n",
      "          2025,  2424,  1037,  3972, 12870,  6462,  5310,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2429,  2000,  2913,  2011,  1048, 12849,  7317,  4059,  2241,\n",
      "          2006,  3188,  2470,  2013, 24624, 18150,  2308,  6524,  2681,  5711,\n",
      "          2193,  1998,  2193,  1997,  1996,  7191,  2458, 12571,   102,     0],\n",
      "        [  101,  5310,  3407,  5798,  2000,  2028,  1997,  1996,  4602, 14163,\n",
      "         13213,  8609, 20005,  2089, 24404, 24844, 19994,  2017,  1998,  2089,\n",
      "          2017,  2562, 10209,  2122, 14163, 13213,  8609,  2015,  1050,   102],\n",
      "        [  101,  2505,  2021,  2227,  2039,  2000,  1996,  5221,  3291,  2304,\n",
      "          2111,  2031,  2304,  3226,  1037,  2028,  7168,  5665, 21646,  3686,\n",
      "          2796,  2822, 11560,  2064,  2272,  2000,  1996,  2149,  2031,   102],\n",
      "        [  101,  5310,  1045,  2165,  2028,  2013,  2023,  2317, 12043,  1998,\n",
      "          1045,  2018,  2028,  1997,  2026,  2219, 10163,  2224,  7861,  2053,\n",
      "          2062,  2144,  9152, 23033,  2015,  2042,  5996,  1998,  4485,   102],\n",
      "        [  101, 14720,  4487,  6371,  6895,  2001,  1037,  9152, 13327,  1045,\n",
      "          2106,  2025,  2113,  2008,  1996,  3526,  3042,  2027,  4366,  2001,\n",
      "          2025,  2130,  1996,  2034,  3526,  3042,  2000,  2655,  2090,   102],\n",
      "        [  101,  2821,  3426,  1045,  2245,  1037,  9152, 23033,  2040,  2614,\n",
      "         23713,  2298,  5637,  2056,  7680,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0040, 0.0040, 0.0040, 0.2310, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.5100, 0.1350,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1010, 0.0070,\n",
      "         0.1010, 0.0020, 0.0020, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010,\n",
      "         0.1010, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0670, 0.0670, 0.0670, 0.2530, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0050, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1760,\n",
      "         0.1760, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.1760, 0.0120, 0.1760, 0.1760, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0700, 0.0700],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.6300, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0540, 0.0540, 0.0540, 0.0540, 0.0540, 0.2040, 0.0540, 0.0540, 0.0540,\n",
      "         0.0540, 0.2040, 0.0540, 0.0540, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2043,  2356,  2054,  3159, 10852,  2245,  2055,  4302,  1998,\n",
      "         12756,  2002,  4660,  1045,  2031,  2053,  3291,  2007,  2023,  7145,\n",
      "          1996,  2548,  2155,  2038,  2467,  3079,  1037,  9152, 13327,   102],\n",
      "        [  101,  2027,  2442,  2022,  1037,  2502,  7162,  1999,  5887,  3773,\n",
      "          2193,  5444,  2005,  1996,  6548,  7743,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2123,  2102,  2113,  1996,  2381,  1997,  2148,  3088,\n",
      "          2131,  1996,  2338, 12455, 14712,  5285,  2243,  6299,  2527,  4215,\n",
      "          1996,  2338,  2003,  2069,  1999, 28673,  2079,  2470,  6904,   102],\n",
      "        [  101,  1996,  8740,  2102, 11382,  3489,  2001,  2467,  2074,  1037,\n",
      "          3644,  4758,  4559,  5679,  2521,  2157, 11087,  8986,  4487, 18719,\n",
      "         16454,  2157,  2317,  8986,  2035,  2488,  9804,  2005,  1037,   102],\n",
      "        [  101,  3725,  2015,  2288,  5848,  1045,  2001,  3241,  9117, 11669,\n",
      "          2021,  2053,  2016,  6057,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2017,  2115,  1996,  6703,  4750,  6904, 13871, 12868,\n",
      "          1053,  1053,  6761,  2078,  8275,  2638,  9333,  1996, 19718,  1056,\n",
      "         24281,  3334, 10474, 23848,  2050,  2307, 10830,  7520,  2075,   102],\n",
      "        [  101,  1045,  2079,  2025,  2113,  2339,  2027,  2191,  1996,  2482,\n",
      "         17364,  2121,  1037,  2317,  3124, 27793,  2009,  2025, 12689, 20868,\n",
      "          2140,  2009,  2052,  2022,  1037,  9152, 13327,  2030, 11867,   102],\n",
      "        [  101, 13451,  8155,  2017,  2113,  2769, 15315,  5339, 15315,  5339,\n",
      "         11669,  7570,  2229,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2191,  2053,  6707,  2023, 18820,  2213, 10023,\n",
      "          2953,  4586,  4181,  2003,  2004,  3424,  7560,  2004,  2151, 27256,\n",
      "          2061,  2049,  2037,  4722,  3043,   102,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2026, 23603,  3100,  2007,  1059, 24475,  1045,  2079,\n",
      "          2568, 10930,  2449,  7743,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2139,  6442,  2068,  6616,  2378,  5472,  9152, 13327,  2015,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2843,  1997,  2381,  2182,  2005,  9152, 13327,  2015,\n",
      "          3060,  4841,  2009,  1037,  9467,  1996,  2181,  2003,  2104,  6859,\n",
      "          2011,  2317,  1998,  5637, 12455,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8562, 12593,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2031,  2000,  3191,  1996,  2717,  4828,  2003,  2025,\n",
      "          2010,  2197,  2171,  1037,  9587, 25016,  2213,  2052,  2196, 18766,\n",
      "          2032,  2004,  4828,  1050,  2094,  2190, 12168,  2412,   102,     0],\n",
      "        [  101,  1045,  5223,  2000,  2360,  2009,  2058,  1998,  2058,  2021,\n",
      "          2009,  6468, 15192,  3331,  2000, 12456,  2128,  7559,  2094,  2003,\n",
      "          3599,  2066,  3331,  2000,  1037, 17276,  2304,  2450,  2467,   102],\n",
      "        [  101,  2204, 11721, 21724,  2016,  3504,  2066,  1996, 15053, 27086,\n",
      "         11382,  9681,  2015,  2007,  2008,  9350,  6616,  2378,  2227,  5310,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1840, 0.1840, 0.1840,\n",
      "         0.1840, 0.1840, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.1730, 0.6580, 0.0120, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0400, 0.0400, 0.0400, 0.5690, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0080, 0.1100, 0.1100, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4580, 0.4580, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.0100, 0.0100, 0.0380, 0.0380, 0.5410, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.2830, 0.0200, 0.2830, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0130, 0.0130,\n",
      "         0.0130, 0.1840, 0.1840, 0.1840, 0.1840, 0.1840, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0750, 0.0750, 0.2840, 0.2840, 0.2840, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7220, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.5070, 0.0090,\n",
      "         0.0090, 0.1340, 0.1340, 0.1340, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3424,  6394, 21442,  2818,  1998,  4485,  3513,  2021,  2053,\n",
      "          3043,  1996,  6123,  1045,  1521,  1049,  2025,  9343,  2505,  2008,\n",
      "          2038,  1037, 25430, 14083,  7556,  2006,  2009,   102,     0,     0],\n",
      "        [  101, 10041,  2594,  4352,  5152,  9576,  2015,  2000,  2425,  1996,\n",
      "          3677,  2129,  1998,  2054,  2000,  2079,  2003,  1037, 17974,  2005,\n",
      "          7071,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2115,  8466,  2265,  4728,  9152, 13327,  7089,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6854,  2122,  2048,  2210,  2317,  3057,  2097,  2025,\n",
      "          2287,  2092,  2593,  4983,  2619,  2007,  2070,  3168,  4152,  1037,\n",
      "          2907,  1997,  2037, 16939, 29393,  2229,  2027,  2097,  2022,   102],\n",
      "        [  101,  2074,  3236,  1037,  4766,  2193, 10819,  2015,  1997,  1996,\n",
      "          3424,  3282,  6186,  1998,  2045,  2001,  2008,  2210, 10338,  6342,\n",
      "          9102, 27589,  2290,  1998,  1037,  2261,  2060, 11576,  2100,   102],\n",
      "        [  101,  1045,  2079,  2025,  2903,  3087,  2003,  2941,  6296,  2000,\n",
      "          1996,  2168,  3348,  1996,  5171, 15504, 11690,  2003, 22442,  2041,\n",
      "          1997,  2009,  2116,  3920,  2273,  1998,  2308,  2024,  7976,   102],\n",
      "        [  101,  2179,  1037, 11825,  2651,  2013,  2043,  1045,  2001,  2066,\n",
      "          2193,  1998,  8909,  2517,  1037,  2466,  1999,  2009,  1996,  2466,\n",
      "          2001,  3841,  2777,  9485,  2016,  2001,  2028,  2204,  2559,   102],\n",
      "        [  101,  5310,  2053,  1045,  2812,  2317,  2003,  1037,  2744,  2109,\n",
      "          4919,  2005, 13481, 23368,  2015,  1999,  5762,  3408,  2008,  2003,\n",
      "          1037, 12354,  1037,  1037,  4070, 27793,  2028,  1997,  1996,   102],\n",
      "        [  101,  2191, 16419,  1524,  2004, 19424,  2004,  6394,  1524,  2000,\n",
      "         13350,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 19817, 27627,  7486, 12849,  1046, 25152,  2050, 10381,\n",
      "         23416,  2139, 10958,  3270, 22794,  2632,  4140,  1997,  8711,  2013,\n",
      "          5152,  2406,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1048,  2863,  2080,  2522,  2015,  2017,  2228,  1037,\n",
      "          2317,  2711,  2064,  2079,  1037,  2488,  3105,  2084,  1037,  2304,\n",
      "          2158,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24218,  2193,  1039,  2182,  9129,  2050,  2522,  5644, 14834,\n",
      "          2039,  2193,  2489,  4933,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6904, 13871,  4140,  2001,  6057,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4831,  2198,  2703,  2716,  2091,  1996,  3354,  4763,  3400,\n",
      "         10774, 13335,  1996, 15053, 15511, 19592,  1999,  2563,  1998,  1996,\n",
      "         13009,  1999,  2605, 16138,  8047,  1998,  4821, 10650,  3577,   102],\n",
      "        [  101,  2193,  3742,  5008,  2015,  2023,  2095,  1998,  2025,  2028,\n",
      "          5462,  2011,  1037,  2304,  2158,  2030,  2019,  6206,  7344,  2292,\n",
      "          2008,  7752,  1999,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7483,  2193, 14781,  2089, 13844,  3275,  2193,  7211,  2859,\n",
      "          2402,  4827,  2944,  2193,  3050,  3349,  3915,  2026,  5440,  5665,\n",
      "         12717, 19833,  2072,  8494,  7377,  8024,  2428, 17870,  6890,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.3210, 0.3210, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.4820, 0.4820, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0470, 0.6710, 0.0470, 0.0470, 0.0470,\n",
      "         0.0470, 0.0470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1998,  2794,  2477,  2000,  1041,  8591,  1997, 15310,  6528,\n",
      "          3215,  2520,  3660,  1998,  4615,  7004, 11545, 27006,  2226,  2314,\n",
      "          1056,  2989,  4183,  8505,  9001,  2013,  2012,  4115,  1998,   102],\n",
      "        [  101,  2256,  2489,  4613,  2003,  3225,  2000,  2175,  2205,  1999,\n",
      "          2210,  3971,  2667,  2000,  2191,  2111,  2228,  2009,  2003,  2005,\n",
      "          2204,  3480,  5346,  2030,  4297, 15402,  4808, 12065, 11039,   102],\n",
      "        [  101,  6616,  2610,  1998,  2065,  2017,  2490,  2068,  6616,  2017,\n",
      "          2205,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2008,  5637,  2008,  2054,  2009,  2003,  2054,  2003,\n",
      "          2008,  6904, 13871,  4140,  2854,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2205,  2919,  2009,  2115, 15544, 15460,  2066, 13144,  2040,\n",
      "          2024, 12324,  2075, 14163, 13793,  2229,  2046,  2037,  2163,  2017,\n",
      "          2562, 12097,  2045,  2053, 14163, 13793,  3291,  1999,  4174,   102],\n",
      "        [  101,  8239, 17359, 25643,  4632,  7743,  4632, 27136,  2100,  4632,\n",
      "          7743,  4632,  9152, 13327,  6658,  9152, 13327,  3836,  6904, 13871,\n",
      "          4140,  3521,  1997,  4485, 11891,  1037,  5980,   102,     0,     0],\n",
      "        [  101,  2317,  3337,  2228,  5962,  2000, 10722, 19498,  3957,  2068,\n",
      "          1037,  1050,  2773,  3413,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2126,  2000,  2175, 10208,  2672,  2035,  5472,  9152, 13327,\n",
      "          2015,  2024,  2025,  3294, 24185,  2037,  3594,  2009,  2066,  1045,\n",
      "          2467,  2360,  2026,  2162,  2097,  2022,  2006,  1996,  2197,   102],\n",
      "        [  101,  2428,  5305,  1997, 12043,  2015,  2552,  2378,  2066,  7743,\n",
      "          2229,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5223,  2000,  6532,  2115, 11957, 14412,  2021,  2053,  2450,\n",
      "          1997,  2151,  5762, 18240,  2024,  6020,  2065,  2151,  2035,  2308,\n",
      "          1997,  5762,  5636,  6447,  2024,  4310,  2074,  2023,  2972,   102],\n",
      "        [  101,  5310,  5310,  5310,  2045,  2003,  2525,  1037, 19583,  6173,\n",
      "          2009,  2090,  5223,  1998,  2293, 14337, 22040,  1998, 11922,  2005,\n",
      "          2500,  1998,  1037,  4792,  2000,  5335,  4826,  2005,  3071,   102],\n",
      "        [  101,  2061,  2172,  3424,  2317, 17871,  2003,  2041,  1997,  1996,\n",
      "         15076,  1997, 23368,  2015,  2097,  2360,  2009,  2153,  2065,  2027,\n",
      "         25250, 15766, 11703,  9581,  3508,  1997,  2317,  2679,  2027,   102],\n",
      "        [  101,  1045,  2079,  2025, 25805,  2638,  4808,  2030,  2478,  9322,\n",
      "          2004,  4255,  2021,  2065,  1045,  2001,  3140,  2000, 10463,  2000,\n",
      "          7025,  2023,  2003,  2054,  2017,  1040,  2131,  2013,  2026,   102],\n",
      "        [  101, 17270,  2003,  1037,  8239, 19854,  2006,  5713,  2193,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2055,  2008,  2308,  2015,  2233,  1999,  5887,  7483,  2009,\n",
      "          2001,  1037,  3112,  2005,  2343,  8398,  2138,  2006,  2010,  2034,\n",
      "          2440,  2154,  1999,  2436,  2002,  2288,  2062,  6638,  2308,   102],\n",
      "        [  101,  2008,  6433,  2007,  1999, 13578,  2094,  5472, 12155,  4523,\n",
      "          2013,  1996,  2690,  2264,  1998,  3088,  2061,  2008,  2003,  2339,\n",
      "          2196,  3404,  1037,  2773,  2027, 14395, 11937, 14702, 19903,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0480, 0.0480, 0.0130, 0.0130, 0.0130, 0.0130, 0.0480, 0.0480,\n",
      "         0.0480, 0.6950, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.6710, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0470, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.2440, 0.2440, 0.0170, 0.0040, 0.0640, 0.0640, 0.0640, 0.0640, 0.0640,\n",
      "         0.0640, 0.0640, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3800, 0.3800, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0260, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0260,\n",
      "         0.0260, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0060, 0.0060, 0.0840, 0.0840, 0.0840, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0840, 0.0840, 0.0840, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1640, 0.1640,\n",
      "         0.1640, 0.1640, 0.0110],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0390, 0.5630, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100]]), 'label': tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2017, 10257,  2132,  4632,  7570,  2098,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2193,  8711,  1999,  1037,  4322,  2008,  4011,  2000,  3677,\n",
      "          2193,  2024,  2017, 12489,  2033,  3849,  2066,  1996, 13176,  2024,\n",
      "          2025,  3809,  2438,  1999,  2037, 26911,  2015,  2000,  2393,   102],\n",
      "        [  101,  2129,  2515,  3038,  2308,  2024,  4276,  2625,  2084,  1037,\n",
      "          2512,  2741, 11638, 10768,  5809,  2025,  7939,  8004, 11657,  1996,\n",
      "          3268,  1997,  2308,  2017,  2024,  5128,  2068,  2012,  1996,   102],\n",
      "        [  101,  2524,  2000,  2041, 11382,  3489,  1996, 11382,  9681,  4331,\n",
      "          2003,  2037,  2208, 11504,  8991,  1062,  2243,  2497,  2097,  3275,\n",
      "          1037,  2126,  2000, 17428,  2068,  2035,   102,     0,     0,     0],\n",
      "        [  101,  2006,  1996,  2187,  5181,  5128,  1037,  6517,  2227,  2005,\n",
      "          1996,  4620,  2008,  2027,  2052, 10172,  2105,  1996,  2088,  2006,\n",
      "          1996,  2157,  1996,  2168,  5181, 12964,  2008,  2037,  6716,   102],\n",
      "        [  101,  2008,  2995,  2009,  2428,  2919,  2043,  1037,  9152, 13327,\n",
      "          3084,  1996,  2717,  2298,  2919,  2025,  2019,  3733,  2518,  2000,\n",
      "          2079,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2521,  2102,  9152, 13327, 14298,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4678,  6302,  1997,  1996, 28932,  2077, 14070,  1996,  3496,\n",
      "          2036, 27133,  2891,  9152, 13327,  6289, 23278,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  7514,  2075,  2000, 17153, 22083,  2695,  1999,\n",
      "          4721,  1997,  1037, 11382,  3489,  2008,  4455,  2111,  2175,  7274,\n",
      "          2017,  4025,  2000,  1997,  9471,  5181,  2730,  4441,  1996,   102],\n",
      "        [  101,  2488,  5342,  2008, 14906,  2013,  1996, 14163, 13793,  2229,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2193,  4841,  2757,  2138,  1997,  2019,  6206, 11560,\n",
      "          2023,  2003,  1999, 27942, 15370, 16306,  2256,  4277,  2139,  6442,\n",
      "          2068,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2002,  2965,  2000,  4297,  4221,  4808,  2000,  1037,\n",
      "          5310,  2043,  2002,  2758,  3288,  2009,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22212, 22212, 22212, 22212,  6904, 13871,  4140,  6904, 13871,\n",
      "          4140,  6904, 13871,  4140,  6904, 13871,  4140,  9152, 13327,  9152,\n",
      "         13327,  9152, 13327,  9152, 13327,  2317,  2100,  2317,  2100,   102],\n",
      "        [  101,  2087, 12461, 15581,  3492,  3733,  2000,  2108,  1037,  7162,\n",
      "          2004,  2146,  2004,  1996,  2047,  3484,  2024,  2025,  6355, 28781,\n",
      "          2066, 10823, 12461, 10574,  3352,  1037,  7162,  2000, 10823,   102],\n",
      "        [  101,  2644,  7079, 11382,  3489,  6105,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  3698,  4974,  1998, 16405, 18719,  2229,  2066,  2068,\n",
      "          5026, 10469, 19483,  2015,  2046,  3384,  8275, 11669, 16149,  1996,\n",
      "          2092,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.3220, 0.3220, 0.3220, 0.0220, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.4000, 0.0070, 0.4000, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0280, 0.0280, 0.0280, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7520, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.9650, 0.0180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.8200, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.4910, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0340, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.1950, 0.7380, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0290, 0.0290, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1010, 0.0070, 0.0070, 0.0070, 0.1010, 0.0070, 0.0070, 0.0070, 0.1010,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1010, 0.0070, 0.1010, 0.0070,\n",
      "         0.0070, 0.0070, 0.1010, 0.0070, 0.0070, 0.0070, 0.1010, 0.0070, 0.0070,\n",
      "         0.0070, 0.1010, 0.0070],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2160,\n",
      "         0.2160, 0.2160, 0.2160, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0170, 0.0170, 0.9040, 0.0630, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0520, 0.7540,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  7110,  1056,  2288,  2053,  2828,  9152, 23033,  2066,\n",
      "          1037, 22212,  9152, 23033, 10163,  2066,  9152, 23033,  2015,  2122,\n",
      "         10986,  7046,  2084, 11420,  4091,  2202,  1037, 20000,  2041,   102],\n",
      "        [  101,  2122,  2210,  9152, 23033,  2015,  2428,  5559,  2105,  1999,\n",
      "          2026,  3566,  2015,  2482,  1998,  2057,  3726,  2042,  9651,  2009,\n",
      "          2005,  2193,  2781,  2085,  1059,  5369,  2860, 11245,  5833,   102],\n",
      "        [  101,  2008,  4485,  2001,  2025,  7882,  2012,  2035,  2317,  2111,\n",
      "         20342,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4436,  2000,  2025,  7861,  9869,  4004,  2015,  2193,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  2022, 17276,  1998,  2025,  2022,  9350, 20318,\n",
      "          1045,  1521,  1049, 17276,  2005,  2469,  2021,  3554,  2035,  1996,\n",
      "          2051,  2003,  9200,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2291, 21601,  2039,  2007, 21258,  7999, 22190,  2072,  2317,\n",
      "         13606,  2716,  1999,  2011,  2155,  2008,  2031,  2196,  2404,  1037,\n",
      "          2309, 10647,  2046,  1996,  2291,   102,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2085,  2017,  2024,  4214,  4426,  9444, 10217,  2007,\n",
      "          2017,  8949,  2128,  7559,  5732,  8670,  5092,  5644,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2024,  2216,  1996,  4364,  2040, 12403,  2213,  2017,  2007,\n",
      "          5637, 22555,  1998,  6905,  4871,  9467,  2017,  2097,  2025,  2202,\n",
      "          2895,  2043,  2027,  4539,  2115,  5198, 27793,  5310,  2003,   102],\n",
      "        [  101,  7743,  2129,  2017,  2066,  2026,  9152, 23033,  3861,  2021,\n",
      "          2123,  1521,  1056,  2066,  3067,  2009,  1521,  4415,  1996,  2168,\n",
      "          3861,  1997,  2026,  2365,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2767,  1997,  1037,  2767,  2001,  2448,  2058,  2014,\n",
      "          3129,  2730,  2011,  1037, 14163, 18719,  2063,  1999,  1996,  2866,\n",
      "          2448,  2058,  1998,  2067,  2058,  2002,  6153,  2039,  2023,   102],\n",
      "        [  101,  2821, 21461,  2015,  2022,  2019,  4639,  2106,  2017,  2025,\n",
      "          2360,  2054,  2064,  1045,  2079,  2065,  2026,  2193,  2095,  2214,\n",
      "          2684,  7545,  2188,  1037,  9152, 13327, 11498,  8458, 23797,   102],\n",
      "        [  101,  2193,  9152, 13327,  2015,  2667,  2000,  9040,  1037, 19130,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616, 14115,  7847,  6616,  9587, 25016,  5244,  2331,  2022,\n",
      "          2588,  2017,  2017, 18294, 27136,  2075,  2128,  7559,  5732,  6616,\n",
      "          2015,  2017,  5236,  6616,  2015,  9378,  2115, 11808,  7395,   102],\n",
      "        [  101,  2017,  2024,  2488,  2125,  2185,  2013, 10474,  2009,  2003,\n",
      "          1037,  8292,  4757, 23270,  1997,  2128,  7559,  5732, 14106, 11721,\n",
      "          2497,  2003,  3652,  3679,  2009,  1037,  2204,  2173,  2000,   102],\n",
      "        [  101,  2292,  2035,  2507,  4283,  2000,  2256,  2510,  2273,  1998,\n",
      "          2308,  2040,  2562,  2256,  2406,  3647,  4067,  2017,  3915,  2637,\n",
      "          8873, 12096, 23848,  2050,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  4004,  2015,  2053,  2308,  2006,  2026,  6337,  4067,\n",
      "          1057,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0780, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2960, 0.2960,\n",
      "         0.2960, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.1240, 0.4720, 0.1240, 0.1240, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.4540, 0.4540, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1260, 0.1260,\n",
      "         0.1260, 0.1260, 0.1260, 0.1260, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.4160, 0.0080, 0.0080, 0.0080, 0.0080, 0.4160, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.5370, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0090, 0.4780, 0.0090, 0.0090, 0.4780, 0.0090, 0.0090, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0040, 0.0620, 0.0620, 0.0620, 0.0620, 0.0010, 0.0620, 0.0620, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.3120, 0.0220, 0.0820, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1870, 0.1870, 0.1870, 0.1870, 0.0490, 0.0490, 0.0490, 0.0490, 0.0490,\n",
      "         0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  8529,  2296, 15629,  2317,  2879,  2007,  2601,  2606,\n",
      "          1998,  3637, 29516,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821,  2017,  2812,  2122,  4364,  2035,  5181, 29450,  2056,\n",
      "          2053,  5181,  2024,  3795,  5130,  2003, 29450,  4688,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4172, 11865, 26933,  4484, 11867,  2594,  9253,  8663,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  4069,  5365,  4024,  5160,  4447,  2008, 14955,  3334,\n",
      "          3351,  2923,  2775,  2732,  9533,  1051, 24400,  2001, 15504,  1998,\n",
      "          7129,  2011,  5365, 12706,  9533,  2209,  1996,  2839,  8594,   102],\n",
      "        [  101,  2009,  2097,  2025,  2022,  2172,  1997,  1037,  3279,  2065,\n",
      "          2027,  2681,  2138,  2027, 12666,  6206,  7489,  2074,  1996,  4500,\n",
      "          2065,  2027,  2187,  2077,  1996,  8118,  2027,  2052,  2031,   102],\n",
      "        [  101,  2062,  2128,  7559,  5732,  9951,  2559,  9152, 13327,  2015,\n",
      "          2006,  3648, 12120,  2651,  1037,  9152, 13327, 17219,  2038,  2146,\n",
      "         17546,  8855,  2606,  1998,  1037, 27243,  6881,  4451,  3614,   102],\n",
      "        [  101,  5310,  2028,  3138,  1996,  1996,  2433,  1997,  1037,  2142,\n",
      "          2163,  2343,  2002,  2003,  3733,  2000,  3962,  2750,  1997,  2010,\n",
      "          2844, 11937, 14702, 19903,  2138,  2002,  2038,  1037,  9587,   102],\n",
      "        [  101,  2203,  2317, 22006,  1517,  4920, 11310,  2006,  8398,  3309,\n",
      "          5136,  2193, 24247,  2015,  2215,  2000,  2203,  2317, 22006,  2193,\n",
      "         12461,  2011,  3267,  2024,  4654, 23606, 19301,  1999,  2116,   102],\n",
      "        [  101,  2021,  1999,  1996,  3572,  1997,  4004,  2015, 27352,  2895,\n",
      "          2003, 16939,  2035,  6145, 23029,  4385,  2052,  2022,  4004,  2065,\n",
      "          2057,  2435,  2068,  3893,  2685,  2247,  2007,  2037,  7857,   102],\n",
      "        [  101,  1049, 10343,  2428,  2022, 21910,  2378,  2006,  1057,  1059,\n",
      "          7743,  2229,  2040,  2298,  2039,  2000,  1057, 23713, 23755,  6100,\n",
      "          9413,  2854, 20744,  1057,  2079,  2695,   102,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2031, 22876,  2014,  2144,  1045,  2031,  3638,\n",
      "          4647,  2009,  2003,  2026,  3105,  2004,  1037, 19483,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3308,  2009,  2001,  2033,  1999,  9595,  2007,  1996,  2334,\n",
      "         11113, 10050, 11528,  2229, 17330,  2004, 14560,  3492,  2204,  4931,\n",
      "          2562,  2009,  2006,  1996,  2091,  2659,   102,     0,     0,     0],\n",
      "        [  101,  8840,  2140,  1996, 13555, 11263,  9102,  2006,  1996,  2327,\n",
      "          7615, 27793,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3013,  2000,  1037,  2358,  3434, 28625, 21281, 19570,  2923,\n",
      "          2667,  2000,  3013,  1996,  2304,  4920,  2046, 25609,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2116,  1997,  2149,  2031,  2699,  2000,  4863,  2008,  2157,\n",
      "          3358,  2515,  2025,  2467,  1041, 16211,  2618,  2000,  2317, 22006,\n",
      "          2027,  5881,  2037,  3093,  1999,  2037,  5551,  1998,  2056,   102],\n",
      "        [  101, 15837, 10554, 14566,  2063, 16216, 20473,  2175,  2005,  1037,\n",
      "         27244,  1999, 16392, 15837, 10554,  1998, 14566,  2063, 16216, 20473,\n",
      "          5959,  1996, 11559,  4633,  2076,  2037,  5027, 27244,  2006,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0100, 0.1430, 0.1430,\n",
      "         0.1430, 0.1430, 0.1430, 0.1430, 0.0380, 0.0380, 0.0380, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9320, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0050, 0.0200, 0.0200, 0.0200, 0.2840, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2840, 0.2840, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0020,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200]]), 'label': tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2703,  3312,  7908,  5310,  2781,  3283,  2703,  3312,  7908,\n",
      "          2128,  2102, 28394,  3064, 15941, 12055, 15941,  2003,  2157,  1996,\n",
      "          8906,  1997,  2308, 22650,  5637,  4288,  7162,  6728, 24128,   102],\n",
      "        [  101,  2613,  4632,  9152, 23033, 11721,  2546, 10094,  1037,  7743,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2106,  2025,  2360,  2505,  2055,  2725,  2242,  6206,\n",
      "          1045,  8385,  2356,  1996,  3124,  2065,  2002,  2001,  2412,  4041,\n",
      "          2006,  2725,  2019,  2724, 20868,  2140,  2002,  5071,  1045,   102],\n",
      "        [  101, 22953,  2026, 10638,  2024,  2070,  8239, 15862,  7110,  1056,\n",
      "         24218,  4788,  2059, 17276,  2317,  4903,  2140,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  9152, 23033,  2056,  2193,  2066,  1045,  2180,  1521,\n",
      "          1056,  4875,  2014,  2041,  2074,  2000,  6616,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2637,  1996, 11117,  2058, 19980,  2015,  2012,  1996,  2976,\n",
      "          2334,  3798,  2031,  2081,  1037,  8170,  1996,  3268,  1997,  2137,\n",
      "          4480,  2024,  2053,  2936,  2256,  5142,  2004,  1997,  2023,   102],\n",
      "        [  101,  6947,  1045,  2812,  1045,  2572,  2006,  4684,  1998,  2064,\n",
      "          2102, 23178,  2039,  1996,  6947,  2005,  2033,  2021,  2065,  2017,\n",
      "          6293,  2105,  1045,  2064, 24234,  2115,  2132,  1999,  2007,   102],\n",
      "        [  101,  1037,  2304,  2158,  2007,  1037,  9587, 25016,  2213,  2171,\n",
      "          2003,  2019, 14863,  2098,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12436,  4063,  4455,  1996,  2005, 10887,  3424,  7011, 23160,\n",
      "          3795,  2923,  7308,  4147,  2128,  7559,  5732, 16592,  2135, 19175,\n",
      "          2015,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  2053,  2028,  2412,  2056,  2273,\n",
      "          2079,  2025,  2131, 15504,  2057,  2024,  3038,  2273,  9040,  2308,\n",
      "          2062,  1998,  7778,  2135,  2336,  3337,  2443,  3867,  1997,   102],\n",
      "        [  101,  5310,  2002,  2243, 16425,  6711,  7898,  6711,  2027,  2035,\n",
      "          2298,  2066,  2027,  2024,  1999,  2193,  2367,  2189,  6876,  2009,\n",
      "          7570, 18752, 14116,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1998,  3475,  2102,  2009,  2995,  2008, 11085,  2389,\n",
      "          5942,  2069,  1037,  5152,  2064, 14574,  1996,  4111,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3096,  4974, 22212, 12731,  3372,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037, 19483,  2304,  2711,  2003,  2193,  2335,  2062,  3497,\n",
      "          2000,  3325,  2610,  4808,  2084,  1037, 19483,  2317,  2711,  1517,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821,  2643,  5310,  2003,  2145, 14739,  4931,  6904, 13871,\n",
      "          4140,  2644,  3038,  2057,  2024, 11382,  3489, 11895, 12718, 16023,\n",
      "          2115, 15344,  2929,  2115,  9062, 11184, 18220,  2038,  2042,   102],\n",
      "        [  101,  2129,  2116,  7025,  2576, 13165,  8771,  2024,  2036,  4111,\n",
      "         10134,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.1020, 0.1020, 0.3870, 0.1020, 0.1020, 0.1020, 0.1020, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.7540, 0.0520, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.2250, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0490, 0.0490, 0.0490, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.1400, 0.1400],\n",
      "        [0.0120, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440,\n",
      "         0.6350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.3830, 0.1010, 0.0270, 0.0270,\n",
      "         0.0270, 0.1010, 0.1010, 0.1010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.3330, 0.3330, 0.3330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3680,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.3680, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2568,  2115, 14163, 11263, 18009,  2078,  2449,  2005,  1045,\n",
      "          3480,  1037,  7743,  5346,  2651,  3531,   100,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3412,  2135,  4092,  5152,  2308,  1996,  2190,  2308,  3114,\n",
      "          1045,  2064,  2053,  2936,  6709,  1059,  7988,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6554,  2758,  3058,  2012,  2051,  2524,  2000,  2903,  1996,\n",
      "          2111,  2045,  2941,  5444,  2005,  1037, 22692, 17768,  4974,  2000,\n",
      "          2022,  2037,  3664,  2092, 28072,  6526,  7249,  6854,   102,     0],\n",
      "        [  101,  1045,  1521,  1049,  5123,  2011,  2122, 17276,  7048,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5292,  3270,  1996,  9079, 19845, 20683,  2015,  2064,  1055,\n",
      "         11231, 24679,  2039,  2007,  2037,  8494, 14540, 14428,  7348,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2035,  2308,  2024, 10768,  2213,  2532,  5831,  2015,\n",
      "          1045,  2001,  9990,  2008,  5181,  5136,  3209,  1037,  2367,  2679,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3722,  5576,  2000,  2025,  2383, 19483,  4268,  2079,\n",
      "          2025,  2031,  2336,  2065,  2017,  2064,  2025,  3929,  5138,  2068,\n",
      "          2017,  1040,  2022,  1037,  9202,  6687,  4312,  2079,  2025,   102],\n",
      "        [  101,  1999,  9361,  2041,  2689,  8917,  2005,  2026,  3288,  6633,\n",
      "         23393,  2063,  2622,  1045,  2572,  9301,  2008,  1996, 28781, 14739,\n",
      "          2045,  2024,  2428,  2183,  2000,  5390,  2055,  7494,  2317,   102],\n",
      "        [  101,  2106,  2017,  2156,  2116,  5472,  9152, 13327,  2015,  1999,\n",
      "          8063,  1045,  3191,  1037,  2261,  2420,  3283,  2008,  2055,  2193,\n",
      "          7486,  2007,  4977,  7037,  9068,  5444,  1999,  1996,  3522,   102],\n",
      "        [  101,  2327,  2274, 27668,  8840, 22879,  2080,  2774,  2193,  9657,\n",
      "          2193,  2428,  2123,  2102,  2729,  2193, 16231,  4597,  2193,  2962,\n",
      "          3147,  2193, 24581,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24955,  2035,  2477,  2026,  2905,  2071,  3198,  2026,  9588,\n",
      "          2016,  5176,  2079,  2016,  2113,  2129,  2000,  5466,  2009,  2067,\n",
      "         15333,  9351,  2271,  7614,  2696,  2063, 13675,  2483,  3401,   102],\n",
      "        [  101,  2304,  2022,  9573,  2100,  3993,  2016,  5092,  5644,  2242,\n",
      "          2130,  2037, 23526,  2015,  2123,  2102,  2215,  6343,  4122,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2429,  2000, 11355,  2047, 22191,  1999, 23498,  2047,  2338,\n",
      "          8398,  7283, 19203,  1037,  2931,  2317,  2160,  3095,  2121,  2006,\n",
      "          1996,  4632,  1998,  2056,  1045,  2572,  2008, 23526,  5980,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  6229,  7375,  2843,  1997,  7560,\n",
      "         17246, 20284,  2072,  2730,  1998, 15504,  2339,  2256,  2796, 10644,\n",
      "          6080, 12954,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2026,  2307,  5615,  2056,  2002,  2038,  2025,  2464,\n",
      "          2107, 10398,  2144,  1996, 13157,  2404,  2041,  1996, 27306,  1999,\n",
      "          1996, 17276,  2015,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4035,  2023,  2733, 20119,  4070,  5310,  1996,  8796,  3606,\n",
      "          2003,  2008,  1996,  2317,  2679,  2003,  1996,  2087,  6355,  1998,\n",
      "         28558,  2486,  1997,  3267,  2006,  3011,  1045,  3984,  2027,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8200,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1550, 0.5870, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.1750, 0.1750, 0.0120, 0.0120, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0460, 0.0460,\n",
      "         0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460,\n",
      "         0.0460, 0.0030, 0.0030],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7040, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0460, 0.0460, 0.0460, 0.0460, 0.6630, 0.0460,\n",
      "         0.0460, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.2380, 0.0170, 0.0170],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280]]), 'label': tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2292,  2227,  2009,  2130,  1996, 26445,  4095,  2024,  2126,\n",
      "          3805,  1997,  2087,  5152,  3032,  1996, 26445,  4095, 18454,  2078,\n",
      "          2974,  2205,  2021,  2027,  2024,  9379,  1998,  2079,  2025,   102],\n",
      "        [  101,  7560, 23438,  6494,  2011,  7090,  2028,  4389, 14308,  2005,\n",
      "         11917,  9777,  6402,  4747,  2005, 24815,  2483,  1998,  5305,  7934,\n",
      "          2015,  4067,  2017, 16913,  2072, 23727,   102,     0,     0,     0],\n",
      "        [  101,  1999,  5962,  2129,  2000,  4608,  1037,  5637,  9152, 23033,\n",
      "          5310,  2272,  2182,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 18497,  6833,  2718,  2006,  2023, 11700,  1059, 24475,  2003,\n",
      "          2023,  2066,  5637,  3730, 22555,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2008,  2001,  1996,  2553,  2059,  2111,  2052,  2025,\n",
      "          2655,  2033,  1037,  9152, 13327,  2074,  2138,  1045,  2081,  1037,\n",
      "          8257,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2092, 11265,  7317,  2368,  2038,  2042,  4417,  2005,\n",
      "         20716, 27082,  1998,  1045,  2123,  2102,  3404,  2010,  8239, 11382,\n",
      "          3489,  2472,  2438,  2000,  2393,  2006,  2008,  2028,  1045,   102],\n",
      "        [  101,  2018,  1037,  4961, 11576,  7743,  2057,  2224,  2000, 22889,\n",
      "          4904,  2008,  7743,  2041,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2298,  5637,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2106,  1045,  3422, 19483,  3239,  2006,  2026,  3338,\n",
      "          2085, 10047,  6933,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13451,  7916,  2128,  7559,  3064,  7743,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1996,  2069,  3291,  1045,  2156,  2157,  2085,  2007,\n",
      "          2023,  2003,  1996,  8957,  2003,  2317,  2061,  2130,  2065,  2017,\n",
      "          2079,  3946,  2009,  2916,  2070, 17276,  9152, 23033,  2015,   102],\n",
      "        [  101,  1045,  1049,  5580, 16233,  2003,  2067,  2006,  3679, 19718,\n",
      "          2121,  2327,  1998,  2053, 11382,  3489,  2097,  2412,  2907,  2256,\n",
      "          2929,  2091,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2126,  2205,  2116,  2045,  2024,  2972,  3655,  1999,  1996,\n",
      "          2149,  2008,  2024,  4498,  4004,  2009,  2019,  7078,  9577,  3663,\n",
      "          1998,  4004,  2015,  2024,  2025, 12873,  2438,  2000,  2292,   102],\n",
      "        [  101,  2054,  2003,  7988,  2021,  6259,  7072,  2040,  2000,  2360,\n",
      "          2008, 11113, 15613,  6643,  4014,  9152, 13327,  2003,  2074,  2004,\n",
      "          2204,  1998,  9398,  2004,  2017,  2024,  2643,  2758,  1996,   102],\n",
      "        [  101, 23161,  1996,  2062,  1045,  2228,  2055,  2009,  2122, 21591,\n",
      "         22822,  5644,  2323,  2022,  2006,  2119,  5042, 28638,  2643,  2619,\n",
      "         10148,  2068,  2013,  1996, 17276,  2027, 12425,  2041,  1997,   102],\n",
      "        [  101, 20565,  2003,  1037,  2128,  7559,  2094,  1998,  2061,  2010,\n",
      "          2014,  5698, 25645,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0010, 0.0010, 0.0080, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0080, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0150,\n",
      "         0.2120, 0.2120, 0.0150, 0.0150, 0.0150, 0.0150, 0.2120, 0.0150, 0.2120,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2320, 0.0160, 0.0160,\n",
      "         0.0160, 0.2320, 0.2320, 0.2320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.1170, 0.1170, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.1170, 0.1170],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.4440, 0.0080, 0.0080, 0.0080, 0.0310,\n",
      "         0.0080, 0.4440, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.1160, 0.4380, 0.4380, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0240, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3500, 0.3500, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.7630, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0030, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1450, 0.1450, 0.1450],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.1550, 0.5870, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0580,\n",
      "         0.2180, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0580, 0.0580, 0.0580, 0.0580, 0.2180, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150],\n",
      "        [0.0540, 0.0540, 0.0540, 0.2060, 0.0540, 0.0540, 0.0540, 0.0540, 0.2060,\n",
      "         0.2060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  6616, 16604, 11928,  1998,  6616,  2008, 15667,  2124,  2004,\n",
      "          3817,  1045,  2572,  2005,  1996,  2613, 16604,  1996,  2397, 16604,\n",
      "          2025,  1996,  5637, 12661,  1997, 16604, 16604,  1998,  4078,   102],\n",
      "        [  101,  3548, 11253,  7716,  2378,  1999,  5120,  6477,  1996,  4534,\n",
      "          2061,  2008,  1996,  5152,  8749,  2008,  5181,  5446,  2123,  2102,\n",
      "          9040,  1996,  2334,  2308,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2083,  2041,  1996, 17276,  2001,  2045,  6583,  2854,  1037,\n",
      "          2773,  3272,  3428,  1999,  2665,  2040,  2083,  1996,  4534,  2071,\n",
      "          2022,  2657,  9694,  2073,  2026,  2274, 10658,  4430,   102,     0],\n",
      "        [  101,  2265,  2465,  2017,  5236, 11352, 17395,  9117, 11669, 12608,\n",
      "          1997, 17276,  5622,  3401, 17395,  5552,  2013,  2010,  2111,  6997,\n",
      "          2011,  2056,  9117, 11669,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  3109,  2053,  2017,  2109,  4841,  4171,\n",
      "          3477,  2545,  2769,  2006,  6206,  7489,  1998,  2085,  2017,  2215,\n",
      "          2000,  4366,  1037,  2110,  1997,  5057,  2017,  2081,  2023,   102],\n",
      "        [  101,  5310,  1999,  1037,  2282,  2007,  2010,  2564,  2905,  1998,\n",
      "          2388,  2057,  2020,  3331,  2055,  2054,  2049,  2066,  2000,  2514,\n",
      "         25135,  2004,  1037,  2308,  4493,  1999,  1996,  2088,  2007,   102],\n",
      "        [  101,  5148, 10288,  6030, 18155,  8649,  4697, 22282, 14856,  2037,\n",
      "          9394,  2038,  2042, 14424,  1996, 12293,  2003,  3659,  2138,  1997,\n",
      "          1037, 17219,  1045,  5223,  2017,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2053,  2002,  2001,  2070,  7424, 10608,  2040,  2288,\n",
      "          2915,  2011,  1037,  4916,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2151,  2051,  1037,  5968,  3632,  2125,  1999,  7128,  2028,\n",
      "          2064,  2022,  2469,  1037, 16522,  2106,  2009,  1998,  2008,  1037,\n",
      "          5152,  2097,  2022, 11248,  2005,  2009,  2011,  1996,  1062,   102],\n",
      "        [  101,  3021,  5003,  5886,  1049,  7025,  2003,  9202,  1998, 21922,\n",
      "          2323,  2025,  4839,  5973,  6616,  4071,  1997,  4676,  2317, 13350,\n",
      "          1051,  8840,  2140,  2009,  7929,   102,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2024,  4214,  4172, 11865, 26933,  2025,  2112,  1997,\n",
      "          1996,  2929,  2004,  2065,  1996,  2929,  2003,  2070,  4066,  1997,\n",
      "          8754,  1998,  3038,  2002,  2019, 26838,  3086, 29444,  1045,   102],\n",
      "        [  101,  5310,  2054,  2003,  2115,  5576,  2000,  1996, 13141,  5325,\n",
      "         29217,  2013,  1996,  9042,  2942,  2162,  2003,  2045,  2428,  2053,\n",
      "          7191,  5368,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2026,  7743,  2006,  1996,  4658,  2081,  2032, 11891,\n",
      "          2026,  5980,  2197,  2305,  1998,  1996,  4485,  2125,  2009,  2013,\n",
      "          2010,  4632,  1045,  2031,  2288,  2032,  2039,  2005,  5096,   102],\n",
      "        [  101,  2045,  1037,  2569,  2173,  1999,  2026,  2540,  2005,  4206,\n",
      "          2308,  2040,  4929,  2152,  8265,  1998,  2031,  2204, 16819,  1999,\n",
      "          2755,  1045,  2496,  2028,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  3844,  2023, 22301, 11829, 19321,  2072,  5318,  2023,  9152,\n",
      "         13327,  6536,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6696, 11560,  3611,  2015,  2024,  6719,  2061,  2878, 14045,\n",
      "          2108,  2992,  2000,  2025,  2265,  7603,  2021,  2059,  4760,  2009,\n",
      "          2055,  1996, 10479,  2477,  2027,  2106,  2025,  2031,  2004,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.2130, 0.0040, 0.0040, 0.0040, 0.2130, 0.0150, 0.2130, 0.0150, 0.0150,\n",
      "         0.0150, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2130, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.6950, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0700, 0.0700, 0.0700, 0.2670, 0.0700, 0.0700, 0.0700, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.2060, 0.0140, 0.0040, 0.0040, 0.0040, 0.0040, 0.0540,\n",
      "         0.0540, 0.0540, 0.0540, 0.0540, 0.0540, 0.0540, 0.0540, 0.0540, 0.0540,\n",
      "         0.0540, 0.0540, 0.0540, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320]]), 'label': tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2293,  2115,  4013,  2317,  2990,  1051, 12856,  6616,\n",
      "          2008,  9152, 13327,  1998,  6616,  1996,  2120,  3060,  2137,  4750,\n",
      "          2283,  2631,  1998,  2448,  2011,  5181,  2298,  2039,  2009,   102],\n",
      "        [  101,  1037,  2100,  1045,  2572,  2193,  2193,  3059, 10131,  2080,\n",
      "          1045,  2064,  2191,  6240, 18510,  1998,  2358, 21716, 14956,  2072,\n",
      "          2007,  1996,  2190,  1997,  7861,  2021,  1045,  2572,  9081,   102],\n",
      "        [  101,  5310,  1057,  5603,  2748,  2035,  2122,  5152,  2390,  2015,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2031,  2179,  1037,  9210,  1997,  2041, 14355,  2015,\n",
      "          2040,  2024,  2035,  2004,  2172,  2317,  2004,  2027,  2024,  2304,\n",
      "          1996,  6565,  3484,  1997, 10823,  2433, 17276,  2015,  1998,   102],\n",
      "        [  101,  1996, 17276,  1999,  2033,  2018,  2000,  2681,  2007,  1996,\n",
      "          2111,  2059,  3309,  2833,  1998,  1045,  2572,  2025, 14984,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  7655,  4632,  4215,  3594, 12141,  4255,  2003,  3642,\n",
      "          2005,  3956,  4122,  1037,  2345,  5576,  7528,  2006,  1996, 14560,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2270,  5689,  2013,  1037,  2460,  4530,  2292,  2032,  9792,\n",
      "          1999,  1996,  3612,  2004,  1037,  5432,  2000,  2151,  2060,  9152,\n",
      "         13327,  3241,  2055, 11878,  2151,  2317,  2450,   102,     0,     0],\n",
      "        [  101,  1037, 10469,  2006,  1996,  4035,  2074,  2056,  1996,  2548,\n",
      "          2250,  2486,  2342,  2000,  3443,  1037,  3647,  2686,  2005,  2308,\n",
      "          2000,  3189, 18162,  4424,  9849,  1045,  2228,  2016,  2097,   102],\n",
      "        [  101,  5310,  1996,  2028,  2040,  7861, 20709,  3401,  7025,  2500,\n",
      "          2006,  2395,  1997,  3915,  2020,  4487, 28745, 22648,  2075,  7025,\n",
      "         16455,  6190, 10278,  5443, 14163, 18599,  6190, 10278,   102,     0],\n",
      "        [  101,  1059,  4095,  4415,  3065,  2008, 10823,  5959,  3666, 10823,\n",
      "          2131,  1996,  4485,  3786,  2041,  1997,  2068,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  2553,  2017,  2018,  2151, 13579,  2055,  4701,  2108,\n",
      "         15504,  1998,  8342,  2125,  1996,  2227,  1997,  1996,  3011,  2182,\n",
      "          2003,  1037,  5379, 14764,  2064,  7011,  2213, 23848,  2050,   102],\n",
      "        [  101,  3374,  2690,  2264,  1998,  2406,  2066,  7795,  3291,  2003,\n",
      "          2013,  7025,  3102,  1996,  2512,  7606, 17960,  2008,  2950,  2111,\n",
      "          2040,  2444,  2045,  2008,  2339,  2009,  2003,  2025,  2183,   102],\n",
      "        [  101,  8840,  2140,  2057,  2024, 13330,  2138,  2057,  2020,  7917,\n",
      "          2013,  7249,  2842,  2138,  2057,  3480,  5622,  5910,  5346,  2205,\n",
      "          4703,  1998,  2057,  2024,  2409,  2008,  3480,  2514,  2480,   102],\n",
      "        [  101,  9122, 20228,  5004,  2386,  9122, 20228,  5004,  2386,  2193,\n",
      "          2781,  3283,  1045,  5993,  1998,  1996,  8801,  2323,  2022,  5338,\n",
      "          2007,  1996,  2168,  6997,  2008,  1996,  7489,  2024,  5338,   102],\n",
      "        [  101,  2138,  6683,  7520, 16103,  5181,  2024,  2061, 19345,  2485,\n",
      "          2000, 13481,  8840, 23858,  2023,  2003,  6057,  2748,  1045,  2113,\n",
      "          2009,  1996,  6745,  2064,  4232,  2108,  7463,  2105,  2043,   102],\n",
      "        [  101,  1045,  5223,  4012,  2378,  2000,  1049, 24316,  2078, 12948,\n",
      "          2122,  4004,  2015,  2064,  1521,  1056, 11865, 14693,  2078,  3298,\n",
      "          2005,  4485,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5550, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0390, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0930, 0.0930, 0.0930, 0.0930, 0.0930, 0.0930,\n",
      "         0.0930, 0.0930, 0.0930],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.1640, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0970, 0.0970, 0.0970, 0.0970,\n",
      "         0.0970, 0.0970, 0.0970, 0.0970, 0.0970, 0.0970, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0270, 0.0270,\n",
      "         0.1010, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.1390, 0.1390, 0.1390, 0.1390, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0790, 0.0210],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0130, 0.0130, 0.1880, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2064,  7861,  3240,  8292, 29577,  2098,  2644, 27104,  1996,\n",
      "          8103,  4451, 24858,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 13327,  9527,  2003,  1037,  9252,  4295,  3531,  4604,\n",
      "          4301,  1998, 12583,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8909,  6935,  3449,  3676,  4626,  1999,  1037,  3058,  3185,\n",
      "          2005,  5317,  8022,  2545,  2007,  5736,  5222,  7485,  2515,  2023,\n",
      "         10882, 24658,  2412,  2074,  2732,  1999,  3671,  5691,  2030,   102],\n",
      "        [  101,  5310,  5310,  2562,  2008,  2168,  2943,  2369,  6963,  2017,\n",
      "          5236,  9152, 13327,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6921,  2024,  2108, 15504,  1999,  1037,  3056, 24494,\n",
      "          3347,  2170,  2252,  7987, 15916,  3351,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 10047, 12422,  2004,  2000,  2339,  2193,  1997,  1996,\n",
      "          2111,  1999,  2023,  7615,  2930,  2024, 16776,  7875,  9541,  2015,\n",
      "          2030, 13157,  2021,  4009,  1037, 28662, 22418,   102,     0,     0],\n",
      "        [  101,  5310,  1045,  8239,  5223,  2017,  2002,  6250,  1998,  2357,\n",
      "          2006,  1996,  2694,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 14467,  2134,  1521,  1056,  2562,  2151,  7179,\n",
      "          2017,  6394,  2502,  4140, 14467,  1998,  7025,  2024,  1037,  4676,\n",
      "          1997,  3521,  2304,  3669,  6961, 18900,  3334,  6968,   102,     0],\n",
      "        [  101,  1999,  2193,  2057,  2031,  2000,  2275,  2039,  2678,  2648,\n",
      "          1996, 17276, 17888,  3182,  2061,  2057,  2064,  4175,  1996,  2193,\n",
      "          1997,  2111,  5738,  1998,  2975,  2009,  6719,  2052,  2025,   102],\n",
      "        [  101,  5310, 10047,  2025,  8840,  2140, 10047,  4937, 20265, 21885,\n",
      "          2075,  2690,  2082,  2317,  4268,  1998,  4004,  2015,  2004,  9202,\n",
      "          7299,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2296,  2406,  2097,  2031,  2037,  2219,  3563,  2645,  2000,\n",
      "          2954,  2096,  2762,  2087,  1997,  2885,  2097,  2031,  2000,  2954,\n",
      "          2125,  7486,  2637,  2038, 14068,  2545,  1998,  2060,  6910,   102],\n",
      "        [  101,  4317,  2308,  2024,  2069,  6638,  2308,  2040,  6638,  2003,\n",
      "          1999,  3182,  2008,  2273,  2066,  6638,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5205,  8040, 28600,  2121,  4900,  6206,  7489,  2040,  2024,\n",
      "          1999, 11371,  1997,  1996,  2375,  1997,  1996,  2455,  2058,  3423,\n",
      "          2375, 11113, 28173,  3070,  4480,  1997,  2023,  2406,  2196,   102],\n",
      "        [  101,  5310,  5310,  1045,  5223,  2017,  1521,  1062,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2253, 13075, 10020,  2102,  5933,  3041,  1045,  2915,  2416,\n",
      "         29384,  1998,  1037,  2990,  2527, 10322,  4183,  2053, 11382,  3489,\n",
      "         11432,  2295,  6517,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2059,  2339,  2064,  2025,  1996,  2945,  1997, 15504,  3057,\n",
      "          2552,  1998,  1045,  2097,  2360,  2242,  2000,  2122,  8593,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.7300, 0.0510, 0.0510, 0.0510, 0.0510, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0560, 0.8100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2270, 0.0160, 0.2270,\n",
      "         0.0040, 0.0040, 0.0040, 0.2270, 0.2270, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.0610,\n",
      "         0.0610, 0.2320, 0.2320, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.1190, 0.0310, 0.0310, 0.1190, 0.0310, 0.1190, 0.1190,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.7840, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  4931,  5310,  5310,  2017, 14870, 14695,  2144,  8909,  2243,\n",
      "          1061,  1045,  2572,  7917, 13366,  1037,  2317,  2711,  2030,  8398,\n",
      "          2121,  2021,  1045,  9377,  2870,  2043,  1056,  2546,  2003,   102],\n",
      "        [  101,  5310,  2009,  2025,  2130,  2055,  9761,  2015,  2017,  1037,\n",
      "          2878,  4632,  2317,  7975, 16371, 13871,  3388,  4214,  4004,  2015,\n",
      "          9200,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2643, 16424, 19483,  2015,  2027,  8364,  3209,  2000,  3109,\n",
      "          2007,  2068,  4067,  2643,  2005,  8398,  1998,  2010,  2307,  3247,\n",
      "          2000,  4047,  2256,  2510,  2339, 18454,  2094,  2256,  4171,   102],\n",
      "        [  101,  5310,  6270, 17653, 18520,  7207,  4424,  6101,  9989,  2024,\n",
      "          2625,  2590,  2084,  8037,  3045,  1999,  2193,  2016,  2196,  2056,\n",
      "          2008,  5310,  4269,  1059,  1037,  6270, 18458,  7207,  2179,   102],\n",
      "        [  101,  3233,  2039,  1998,  2022,  8897,  2514,  2489,  2000,  4471,\n",
      "          2033,  2007,  2151,  3980,  1996, 20912,  2243,  1047,  2243,  2003,\n",
      "          2747,  2635,  5097,  2057,  2024,  2559,  2005,  7481,  3017,   102],\n",
      "        [  101,  9498, 17952,  2004,  1999, 10930,  2089,  2638,  6289, 10506,\n",
      "          2480,  9303,  2050, 12946, 23755, 14163,  2232, 11263, 13871,  2378,\n",
      "          9152, 13327,  1059,  3270,  2050,  6289,  2232, 10905,  3372,   102],\n",
      "        [  101,  5310,  2293,  1041, 11735,  6558,  2013,  9152, 13327,  4176,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2190,  2112,  1997,  2023,  2375,  2001,  2008,  9802,\n",
      "         22226,  4197,  2041,  2008,  2662,  2038,  1996,  2168,  6531,  2005,\n",
      "          1999, 25969,  2075,  2619,  2007,  9820,  1998,  5378,  2068,   102],\n",
      "        [  101,  1996, 12849,  5521,  2758,  1996,  2069,  2126,  1037,  5637,\n",
      "          9587, 25016,  2213,  2064,  2131,  2000,  9097,  2003,  2011,  4288,\n",
      "          1999, 20740,  4877,  2216,  1999, 20740,  4877,  2017,  3102,   102],\n",
      "        [  101,  2053, 14163, 13793,  2229,  2073,  1045,  2444,  8937,  1998,\n",
      "          5121,  2053,  4916,  2015,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2027,  2024,  2025,  2317,  2027,  2031,  2000,  2175,\n",
      "          2067,  2707,  2007,  2216,  2006,  2591,  3036, 22024,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  5883,  2386,  2028,  3789,  2137,  2028,  7743,  2028,\n",
      "          3789,  4750,  2065,  2115, 10428,  2003,  2025,  6153,  2011,  2115,\n",
      "          7960,  2059,  2009,  2074, 10036, 11870, 14828,  1998,  2057,   102],\n",
      "        [  101,  8038,  2232,  3017,  2479,  3072,  4618,  2025,  2031, 19483,\n",
      "          2015,  2030, 12566,  2006,  2009,  2065,  2057,  2424,  2151,  2331,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2175,  2022,  1037,  8797,  2121,  6904, 13871,  4140,  4873,\n",
      "          2842,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2429,  2000,  8037,  2193,  2711,  2064, 10083,  1996,  1050,\n",
      "          2094,  7450,  2021,  2045,  2498,  2019,  6206, 11560,  2064,  2079,\n",
      "          2000, 10083,  6206,  7521,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  9915,  9152, 13327, 12134,  2015,  2000, 14955,  2005,  1996,\n",
      "         13433,  2480,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.1920,\n",
      "         0.1920, 0.1920, 0.1920, 0.1920, 0.0040, 0.0040, 0.0040, 0.0040, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.0090, 0.1250, 0.0090, 0.1250, 0.1250, 0.0090,\n",
      "         0.0090, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.1250],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.1170, 0.1170, 0.1170, 0.1170, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.7480, 0.1970, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0830,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0160, 0.8580, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990, 0.0990,\n",
      "         0.0990, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0010, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.4780, 0.4780, 0.0090, 0.0090, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0420, 0.0420, 0.0420, 0.1610, 0.1610, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.1610, 0.1610, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  4365,  1045,  2001,  5327,  2009,  2001,  1996,  2001,  8043,\n",
      "          2386, 22378,  1040, 12273, 12098,  7447, 22190,  2072,  6338,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7912, 21877, 10483,  2072,  4613,  2012,  1996,  9932, 19498,\n",
      "          2001, 13576,  2006,  1996,  2060,  2192,  8864,  2003,  2069,  6413,\n",
      "          2005,  7179,  2043,  6728, 19811,  3209,  1996,  5181,  2196,   102],\n",
      "        [  101,  2017,  2079,  2066,  2000,  2236,  4697,  2079,  2025,  1057,\n",
      "          5591,  1998, 21659,  2273,  2272,  2013,  5591, 21659, 10756,  2025,\n",
      "          7965,  2273,  1998,  2308,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2111,  2360,  2027,  2215,  1037,  2406,  2005, 12461,  2066,\n",
      "          3956,  1045,  2360,  2693,  2000,  3735,  2030,  2151,  2060,  2200,\n",
      "          2317,  3741,  2074,  2066,  5181,  2333,  2013,  2037,  5014,   102],\n",
      "        [  101,  6616,  9152, 13327,  2015,  1998,  5181,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2003,  2026,  2381,  1998,  2026,  2394,  2079,  2017,\n",
      "          2113,  2115,  9152, 13327,  2381,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  2288,  7743,  2229,  1998,  1045,  2288,  9152, 23033,\n",
      "          2015,  2021,  2057,  2113,  2001,  6342,  2361,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  9152, 13327, 10338,  8840,  6371,  6904, 13871,  4140,\n",
      "          1048,  2863,  2080,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2023,  2611,  2003,  2128,  7559,  5732,  1048,  2863,\n",
      "          2080,  2065,  2017,  1521,  2128,  5341,  2438,  2000,  2031,  2023,\n",
      "          2059,  2339,  2052,  2017,  2552,  2066,  2008,   102,     0,     0],\n",
      "        [  101,  2317, 16480,  3597, 25033, 16949,  2001,  1996,  2117,  5221,\n",
      "         10520,  1997,  2193,  2279,  2000,  2033,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3264,  2017,  2106,  2025,  9772,  2108,  1037,  9152, 13327,\n",
      "          7089,  2085,  2448,  2247,  1045,  2031,  2025,  2288,  2051,  2000,\n",
      "          5949,  7514,  2075,  2000, 22889, 16446,  2066,  2017,  7929,   102],\n",
      "        [  101,  4364,  2079,  2025,  6271,  2039,  5637,  6620, 26635,  5292,\n",
      "          3270,  2023,  2003,  1037,  8257,  1045,  2079,  2025,  2729,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10047,  2074,  2183,  2000,  7868,  2008,  3124, 21746,  1037,\n",
      "          9152, 13327,  1999,  1996,  4632,  1998,  5310,  2001,  1996,  2765,\n",
      "          2065, 26948,  2515,  2025,  2342,  2000, 20410,  3441,  4445,   102],\n",
      "        [  101,  2610,  2097,  2025,  8556,  1996,  4428,  2283,  2005, 13003,\n",
      "          2317,  2111,  2062,  2000,  2175,  2000,  2028,  1997,  2037,  2824,\n",
      "          2021,  2027,  2097,  6545,  2606, 16200, 18116,  2015,  2040,   102],\n",
      "        [  101,  2092,  1045,  3984,  1996,  3424,  2317,  2791,  2003,  2763,\n",
      "          1037,  2843,  2062, 14969,  2651,  1996,  5181,  1998,  2037,  6208,\n",
      "         14302,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6804,  2386, 11689,  2395,  4485,  3334,  4040,  6904,  2290,\n",
      "          4586, 13109, 20060,  2489,  4613,  3513,  2035,  8489,  1996,  8488,\n",
      "          1051, 11923,  1045,  3706,  1999,  9152, 13327,  4485,  2821,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.7870, 0.0550, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2180,\n",
      "         0.2180, 0.2180, 0.2180, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.6830, 0.1800, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.8320, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0560, 0.0560, 0.0560, 0.8030, 0.0150, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.7220, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6190, 0.0430,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0430, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.0430,\n",
      "         0.6190, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0800, 0.0800, 0.0800, 0.0800, 0.3040,\n",
      "         0.3040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0670, 0.0670,\n",
      "         0.0670, 0.2540, 0.0670, 0.0050, 0.0050, 0.0050, 0.0670, 0.2540, 0.0670,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2096,  7486,  2024, 14255,  8737,  2075,  1998,  9680,  2075,\n",
      "          2317,  3057,  5181,  2024,  7694,  2035,  5450,  1997, 14386,  4630,\n",
      "          3348,  2083,  1996,  2865,  5181,  1998,  7486,  1999,  2317,   102],\n",
      "        [  101,  2611,  3844,  2039,  1045,  2113,  2017,  2066,  1996,  5637,\n",
      "          2015,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 21117,  5284,  2003,  1996,  2173,  2000,  2175,  2006, 10885,\n",
      "          2028,  2515,  2025,  2031,  2000, 27481,  2007, 17276, 11669,  2054,\n",
      "          1037,  4335,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1037,  9152, 13327,  2082,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2348,  2009,  4165,  2066,  2205,  2172, 14303,  8909,  2323,\n",
      "          2022,  2246,  2046,  2007,  1037,  2367, 13384,  1996,  6206,  7489,\n",
      "          2031,  2053,  2157,  2000,  3789,  2005,  2008,  3043,  2027,   102],\n",
      "        [  101, 22692,  9152, 13327,  3367,  5886,  2063,  2024,  2205,  2116,\n",
      "          2317,  3057,  3810,  2046,  9152, 13327, 10205,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2008,  2428,  4658,  1998,  2035,  2021,  2009,  4332,\n",
      "          2041,  2308,  9152, 13327,  2015, 11867,  6558,  5181, 14560,  4004,\n",
      "          2015,  1998,  8797,  2545,  2036,  3789,   102,     0,     0,     0],\n",
      "        [  101,  1045,  2514,  2066,  6222,  9152, 23033,  2015,  2064,  2069,\n",
      "          2404,  2039,  2007,  6222,  2308,  4647,  2057,  2035,  1037,  2210,\n",
      "          2128,  7559,  5732,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  3752,  2023,  1056, 28394,  2102,  2175,  4392,  2070,\n",
      "          2300,  2085,  2017,  2643,  4365,  2139, 10536,  7265,  3064, 22889,\n",
      "          4904,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2054,  2055,  1996,  8817,  1997,  2203,  2937,\n",
      "         18221,  2542,  6917, 11974,  1999,  5152,  2406,  6084,  4977,  6239,\n",
      "          2323,  2022,  5845,  2066,  1996,  2168,  2965,  6908,  2041,   102],\n",
      "        [  101,  2035,  2122,  2643,  5477, 18294,  9576,  2015,  1998,  9152,\n",
      "         13327,  5152, 11089, 10932,  5104,  2122,  6616,  2378,  3336,  2527,\n",
      "          4691,  5181,  2562,  5026,  1999,  2003,  4786,  1037, 19857,   102],\n",
      "        [  101,  2193,  2054,  1996,  2069,  2173,  1999,  1996,  2088,  2073,\n",
      "          2111,  3713, 28934,  1996,  2653,  2008,  4441,  3764,  2009,  1037,\n",
      "          2103,  2170,  5003, 23067,  7068,  1998,  2003,  1999,  7795,   102],\n",
      "        [  101,  5310,  1045, 14283,  2005,  2017,  2651,  2115,  2166,  2965,\n",
      "          1037,  2843,  2061,  2002,  2323,  2507,  2017,  2115,  2540,  4792,\n",
      "          2077,  2017,  3102,  4426,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 18076,  2031,  7129,  2062,  2084,  2193,  2317,  6617,  2021,\n",
      "          1996, 10823,  2024,  2205, 13971,  5236,  2007,  2019, 26264,  1997,\n",
      "          2193, 19499,  2128,  7559,  5732, 15578,  3366,  9152, 13327,   102],\n",
      "        [  101,  2061,  5458,  1997,  2035,  2023,  5637,  4485,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2061,  2017,  4129,  2033,  2043,  1045,  2298,  2066,\n",
      "          2023,  1045,  1521,  1049,  1037, 10257,  4974,  2021,  2043,  2016,\n",
      "         11651,  2009,  2009,  1521,  4827,   102,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0650, 0.0050, 0.0650, 0.0050, 0.0650, 0.0050, 0.0050, 0.0650,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0650, 0.0650, 0.0050, 0.0050,\n",
      "         0.0050, 0.0650, 0.0050, 0.0650, 0.0050, 0.0650, 0.0650, 0.0650, 0.0650,\n",
      "         0.0650, 0.0650, 0.0010],\n",
      "        [0.0390, 0.0390, 0.0390, 0.0100, 0.0100, 0.0100, 0.1470, 0.1470, 0.5580,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4260, 0.4260,\n",
      "         0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9480, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0130, 0.7000, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.1850, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.1320, 0.1320, 0.1320, 0.1320, 0.1320, 0.1320, 0.1320,\n",
      "         0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.6600, 0.0120, 0.0120, 0.0460, 0.0460,\n",
      "         0.0460, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0460,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0110, 0.0110, 0.0110, 0.1510, 0.1510,\n",
      "         0.1510, 0.0030, 0.0030, 0.1510, 0.1510, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0110, 0.1510, 0.0110, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0740, 0.0050, 0.0050, 0.0050, 0.0740, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2820, 0.0050, 0.0050, 0.2820,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  8307,  2003,  2025,  2317,  2084,  2027,  2024,  2183,\n",
      "          2000,  2022,  5837,  2011,  1059,  2078,  2006,  1996,  5286,  2027,\n",
      "          2024,  2025,  2317,  2308,  1999,  2236,  2342,  3724,  2041,   102],\n",
      "        [  101,  7743,  2229,  1038,  1037,  2367,  2828, 12873,  7110,  1056,\n",
      "          2053,  2126,  1045,  2572,  3173,  1037,  9152, 23033,  1999,  7173,\n",
      "          2091,  2017,  2035,  3268,  2442,  2022,  2200, 11771,   102,     0],\n",
      "        [  101,  7191,  1997,  1996,  2466,  9152, 23033,  2015,  2022,  4688,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  8239,  5223,  2017,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2009,  2995,  2008,  1996, 25670,  2323, 13387,  2041,\n",
      "          1996, 12873,  2121,  1998,  2008,  2317,  2111,  2024, 12873,  2121,\n",
      "          2084,  4004,  2015,  2059,  2009,  1999,  2317,  2111,  2190,   102],\n",
      "        [  101,  2122,  9152, 23033,  2015,  9868,  1996,  2193, 11742, 10514,\n",
      "         18098,  2050,  3746,  3565,  4605,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2065,  1045,  2001,  2182,  2000,  4485,  2006,  2115,\n",
      "          2283,  2023,  2052,  2022,  1037,  2204,  2126,  2000,  2079,  2009,\n",
      "          3398,  1057,  4364,  2288,  2033,  7349,  2053,  1057,  7349,   102],\n",
      "        [  101,  2215,  2000,  2113,  1996,  2613, 11957,  1996, 13751,  2104,\n",
      "          1996,  7349,  2057,  2097,  6366,  1996,  9152, 13327,  7349,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2228,  1996,  2028,  2016,  2999,  2001,  2941,  1037,\n",
      "          4603,  1998,  1996,  2265, 11382,  3489,  3135,  2999,  2014,  2005,\n",
      "          2008,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2025,  3102,  4426,  2026,  2905,  2065,  2002,  4122,\n",
      "         28844,  2100,  2806,  2292,  2032, 11286,  2034,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3422,  5152, 10474,  2360,  4485,  2066,  2376,  3964,  2024,\n",
      "         18820,  2213,  2065, 24471,  1037,  2450,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6203,  2329, 10558,  2644, 17033,  5472,  9152, 13327, 21122,\n",
      "          2290,  8198,  2707,  8650,  2111,  2065,  2017, 17328,  3560, 12731,\n",
      "         10603,  2180,  2102,  2079,  2505,  2005,  2210,  2317,  3057,   102],\n",
      "        [  101,  5310,  2915,  2039,  1045,  5223,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2083, 25044,  5170,  2001,  8733,  2046,  1996, 22365,  2015,\n",
      "          2069,  2000,  2022,  3030,  2011,  1996,  5508,  1997,  2373,  3614,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3241,  2055,  1996,  2755,  2008,  9253,  6394,  3166,  7296,\n",
      "          7415,  2003,  2941,  2019,  3059,  4485,  4974,  2170,  4901,  4670,\n",
      "          2532,  2009, 28851,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1045,  2064, 14306,  2017,  2023,  2003,  2521,\n",
      "          2062,  2691,  2426,  1996, 23368,  2015,  1998,  2005,  2008,  3114,\n",
      "          2003,  6461,  2012,  2068,  2036,  2690,  4793,  2317,  2111,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.1030, 0.1030, 0.1030, 0.1030, 0.1030, 0.1030,\n",
      "         0.1030, 0.1030, 0.1030],\n",
      "        [0.5940, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1560, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.7520, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.3530, 0.3530, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0090, 0.1290, 0.0340, 0.0340, 0.0340,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0340, 0.1290, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0090, 0.0090, 0.1290, 0.1290, 0.0090, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0930, 0.0930, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.3550, 0.3550, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290]]), 'label': tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2042,  2083,  2070,  2919,  4485,  1045,  2323,  2022,  1037,\n",
      "          6517,  7743,  2040,  2052,  2050,  2245,  2009,  2735,  2033,  2000,\n",
      "          1037,  9576,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  3426,  4291,  4290,  2610,  2064,  1521,  1056,\n",
      "          8984,  1037, 16099,  2859,  5831,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1045,  2572,  7098,  2000, 15391,  7025,  1998,\n",
      "         15391,  1996,  7025,  9031,  1997,  2256,  2406,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 10768, 22311,  5831,  6097, 25438, 21302,  1047,  2243,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2061,  5458,  1997,  2122, 11382,  3489, 15554,\n",
      "          1998,  2037,  4763,  3768,  3240,  2015,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2055,  2548, 17328,  2015,  6065, 12155,  3549,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2317,  2611, 18097,  1045,  5223,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2021,  2016,  2106,  2025, 18520,  2699,\n",
      "          2000,  8568,  2032,  2059,  2074, 13538,  2006,  2014,  8050, 12637,\n",
      "          2000,  2663,  1996,  3078,  2014,  4491,  2020,  3262,  3343,   102],\n",
      "        [  101,  1998,  2017,  2024,  4352,  2216,  5472,  9152, 13327,  2015,\n",
      "          2000, 16152,  2017,  2302,  2017,  7493,  1037,  2915,  2204,  3105,\n",
      "          2158,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7714,  1045,  2052,  9544,  2000,  2156,  9610, 25370,  2007,\n",
      "         22531,  2015,  2693,  2046,  1996,  2160,  2279,  2341,  2084,  2292,\n",
      "          2062,  7486,  2031,  3229,  2000, 16371,  3489,  2974,  2111,   102],\n",
      "        [  101, 10293,  1040,  2372,  1997,  3519,  2024,  5026,  8711,  2043,\n",
      "          2343,  8398, 11596,  3519,  2006,  9857,  1045,  6592,  2008,  1054,\n",
      "          2372,  1997,  3519,  3288,  5694,  1997,  6206,  7489,  2009,   102],\n",
      "        [  101,  1045,  2409,  2026,  3566, 10047,  2050,  2735,  5637,  1998,\n",
      "          2016,  2056,  6583,  2115,  2063,  2205,  2172,  1997,  1037,  7570,\n",
      "          2063,  2017,  2293,  2122,  2308,  2066,  1045,  2293,  2833,   102],\n",
      "        [  101,  1056,  2045,  2024,  2116,  2062,  9916,  1998,  6355, 10768,\n",
      "          7811,  3111,  5462,  2084,  2057,  2412,  2963,  2172,  2055,  2216,\n",
      "          2057,  2963,  1997,  2024,  2054,  2003,  3479,  2011,  1996,   102],\n",
      "        [  101,  1045,  2253,  2000,  1996,  2695,  2436,  2651,  1998,  2356,\n",
      "          1996,  2193,  6053,  2016,  5092,  2239,  2369,  1996,  4675,  2129,\n",
      "          2172,  5514,  1037,  3661,  2000, 23204, 10486,  2052,  2131,   102],\n",
      "        [  101,  1996,  2069,  2518,  4788,  2084,  1037,  5236,  2304,  2711,\n",
      "          2003,  1037,  5236,  2317,  2711,  1045,  2572,  4445,  2304,  4496,\n",
      "          5236,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2027,  2123,  1521,  1056,  2729,  2055,  4841,  2027,\n",
      "          2069,  2729,  2055,  6206,  7489,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0720, 0.2740, 0.0190, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0120, 0.0120, 0.1790, 0.1790, 0.1790, 0.1790, 0.0120,\n",
      "         0.0120, 0.0120, 0.1790, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.6910, 0.1820, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.6490, 0.0450, 0.1710, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.1820, 0.1820, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0030, 0.0030, 0.0030,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0360, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0360, 0.5170, 0.0360],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2390,\n",
      "         0.0170, 0.0170, 0.0040],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.1060, 0.1060, 0.1060, 0.4020, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2017,  4167,  3238,  9152, 13327,  8295,  6904, 13871, 12868,\n",
      "          4900,  1996,  5210,  1997,  7838, 13363,  2005,  1996,  2317,  2929,\n",
      "          4485,  2515,  2025,  2131,  2151,  4569, 14862,  2084,  2008,   102],\n",
      "        [  101,  2064,  2017,  4364,  2360,  9152, 13327,  2302,  2893,  4727,\n",
      "          8840,  2140,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2035,  2023, 10231,  2007,  8398,  2089,  2022,  2183,  2006,\n",
      "          2515,  2025,  2812,  1045,  2064,  2025,  4299,  2026,  6203,  6583,\n",
      "         14713,  1037,  3407, 16215,  7387,  2012,  7387,  4336,  3088,   102],\n",
      "        [  101,  5310,  3071,  5223,  2115,  5042,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  3342,  2027,  2903,  2035, 12461,  2024, 16939,  2015,\n",
      "          2029,  2074, 14144,  1996,  6215,  1997,  2035, 11342,  1997,  2317,\n",
      "          2111,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  2028,  2051,  6331, 12934,  2545,  2024,  2085, 27394,\n",
      "          1996,  2616,  1997,  1996, 16297,  1999,  1996,  2214,  9025,  1517,\n",
      "          2748,  2216, 10743,  3424, 16211,  3064, 28616, 15707, 26942,   102],\n",
      "        [  101,  2026,  3679,  6616,  5310,  1056, 28394,  2102,  2175,  3280,\n",
      "          2017, 16231, 16103,  5980,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  6655,  2065,  2009,  2020,  2317,  2413,  2111,  1999,\n",
      "          1996,  4534,  1997,  3000,  2108, 16939,  2030, 24004, 20200,  2612,\n",
      "          1997, 13675,  5714,  4328, 27444, 11421,  2075,  2057,  1040,   102],\n",
      "        [  101,  2023,  2003,  2025,  1037,  2971,  2114, 12461,  2057,  2024,\n",
      "          1999,  2023,  2362,  2065,  2017,  2215,  2000,  6232,  5562,  2060,\n",
      "         12461,  2023,  2069,  3084,  2009,  5263,  2000,  2412,  3786,   102],\n",
      "        [  101,  2008,  5904,  9337,  4808,  2003, 15180,  3993,  2005,  2086,\n",
      "          1996,  2157,  7274, 20703,  2098,  2013,  4808,  2096,  1996,  5499,\n",
      "          4654,  7913, 23738,  2015,  1998,  5068,  8037,  2566, 22327,   102],\n",
      "        [  101,  1045, 21090,  1038, 13728,  2215,  2000,  6033,  2033,  1998,\n",
      "          2026,  2155,  2027,  5223,  2035,  2317,  2111,  1998,  2903,  2027,\n",
      "          2024,  1037,  6020,  2679,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2317,  2690,  2465,  2267,  5161,  6179, 28781,  1997,\n",
      "          1996,  2187,  8246,  2000,  5382,  2008,  1996, 24247,  5069,  2069,\n",
      "         14977,  2055,  7521,  2005,  4494,  1998, 10036,  4450,  2027,   102],\n",
      "        [  101,  4709,  8494,  7377,  8024,  1059, 14014,  2015,  2016,  2205,\n",
      "          2986,  2000,  2147,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 23148, 27633,  3351,  3565, 14081,  2003,  5637,  3057,  2069,\n",
      "          2724,  2027,  2428,  2191,  1996,  2887,  2160,  1998,  9306,  2040,\n",
      "         17653,  2037,  9273,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3666,  4689,  4138,  4004,  2015,  2612,  1997,  6315, 12464,\n",
      "          4430,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  2444,  1999,  2047,  2259,  2023,  2003,  2114,\n",
      "          2256,  2034,  7450,  2916,  2057,  2031,  6206, 12114,  2008,  2031,\n",
      "         15504,  7129,  7376, 15702, 13263, 20114, 10964,  5850,  1998,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.1880, 0.1880, 0.1880, 0.1880, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0510, 0.0510, 0.0510, 0.0510, 0.7400, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0210, 0.0210, 0.2960, 0.2960, 0.2960, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0160, 0.2240, 0.2240, 0.2240, 0.0590, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0050, 0.0050, 0.2920, 0.0770, 0.0050, 0.0050, 0.0200, 0.0050, 0.2920,\n",
      "         0.2920, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0020, 0.0020, 0.0890, 0.0890, 0.0890, 0.0890, 0.0890, 0.0890, 0.0890,\n",
      "         0.0890, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220]]), 'label': tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2215,  2000,  3477,  2005,  4925,  2007,  7773,  2191, 25730,\n",
      "         17688,  2673, 10205,  3477,  2008,  4171,  6616,  2216,  3937,  7570,\n",
      "          2229,  1998,  6616,  2068,  7570,  2063,  4632,  4925,   102,     0],\n",
      "        [  101,  5310,  1998,  2716,  2039, 27793,  3215,  1998,  3521,  2066,\n",
      "          7036,  3057,  4995,  1521,  1056, 15504,  1998, 11364,  2296,  2154,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 26478,  8609,  2015,  2000,  8398,  2005,  2437,  4013,  5620,\n",
      "          6449,  2008,  9853,  7489,  1999,  2256, 11681,  2001,  2467,  1037,\n",
      "         26136, 13043,  2895,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3984,  1045,  2097,  2022,  2066,  3071,  2842,  2008,\n",
      "          4152,  6731,  2013, 10474,  1998,  2191,  1037,  2047,  4070,  2109,\n",
      "          2026,  3042,  2193,  2006,  2193,  6731,  6115,  2525,  2061,   102],\n",
      "        [  101,  4604,  2033, 10678,  4485,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821,  1998,  4593,  2115,  2063,  1037,  2417,  9152, 13327,\n",
      "         15315, 16814,  8840,  2140, 10047,  2025,  4527,  2144, 16475,  2015,\n",
      "          2024,  2128,  7559,  5732,  2007,  2591,  4813,  1998,  4331,   102],\n",
      "        [  101,  2022,  2317,  2111,  2147,  2005,  1997,  2086,  2000,  3857,\n",
      "          1037, 10585, 16152,  1996,  2088,  6162,  2307,  2791,  2193,  9372,\n",
      "          2105,  2035,  1997,  1996,  2087,  6541,  3767,  2031,  2351,   102],\n",
      "        [  101,  5980, 19161,  2038,  2042, 25857,  2046,  3241,  1037,  2317,\n",
      "          2980,  3899, 10236,  4842, 11221,  1999,  1996,  3612,  2003,  1037,\n",
      "          6531,  5210,  3674,  2335,  2651,   102,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2339,  2027,  2655,  2009, 16216, 10867, 17791,  2216,\n",
      "          6616,  2378,  5152,  6904, 13871, 12868,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8827,  2079,  2025,  3524,  6229,  2045,  2024,  1037,  2454,\n",
      "          1997,  2017,  2169,  2707,  2085,  1998,  8627,  2500,  1998,  2035,\n",
      "          1997,  2017,  4366,  2005,  6666,  2005,  2115,  4268,  1996,   102],\n",
      "        [  101,  2060, 12936,  7080, 24027,  7074,  4916,  2015,  2693,  2006,\n",
      "          4647,  2027,  2439,  2339,  2079,  2122, 14560,  1999,  3956,  2467,\n",
      "          2131,  1037,  3413,  9374,  7025,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  1051,  5358,  2546,  2056,  2016,  2001,\n",
      "          4916,  2205,  1045, 20868,  2890, 13444,  3238,  2016,  1037,  2304,\n",
      "          3763,  2595, 11690,  2040, 16424,  2317,  2111,  2061,  2054,   102],\n",
      "        [  101,  5310,  2065,  2016,  5905,  2059,  2016,  5905,  1996,  2203,\n",
      "          4606,  2009, 16142,  1996, 13229,  7984,  1997,  2035,  2317,  2111,\n",
      "          2024, 16939,  2129,  2055,  2016,  1037, 13433,  2015,  2040,   102],\n",
      "        [  101,  1045,  2572, 23503,  1045,  2097,  2954,  2114,  7025,  2000,\n",
      "          1996,  2331,  1045,  2031,  2464,  2129, 25047, 14163, 13793,  2229,\n",
      "          2024,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4942, 29234,  2000,  2026,  3149,  6904, 13871, 12868,  2193,\n",
      "          7858,  4012,  1039,  2852,  9351, 26576,  2884,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2023,  1998,  1996,  4035,  2048,  2308,\n",
      "          1037,  2733,  3280,  2013,  3287,  4808,  2625,  2008,  3867,  1997,\n",
      "          7979,  9040,  2015,  2203,  1999,  1037, 10652,  2273,  2031,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.1110, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.4210, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3480, 0.3480, 0.0920, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0920, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3200, 0.3200,\n",
      "         0.3200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.2210, 0.2210, 0.2210,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.1690, 0.6420, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.5500, 0.1450, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230]]), 'label': tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2043,  1045,  2131,  2496,  1045,  2215,  2026,  5030,  2000,\n",
      "          2022,  2066,  1996,  2028,  2125,  4689,  4138,  4004,  2015,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1041, 11735,  6558,  3766,  1037,  5236,  2187,  9314,  9152,\n",
      "         13327,  7585,  2006,  4419,  2739,  2323,  2025,  2022,  2006,  4419,\n",
      "          2739,  2130,  2295,  4419,  2739,  2003,  2053,  2936,  4189,   102],\n",
      "        [  101,  1998,  2057,  2196,  2018,  2053,  4569,  2092,  2027,  2234,\n",
      "          2091,  2524,  2006,  1996,  6904, 13871, 12868,  1998,  2027,  2234,\n",
      "          2091,  2524,  2006,  1996,  2395,  2027,  2234,  2091,  6211,   102],\n",
      "        [  101,  2412,  5060,  2129,  2122,  2308, 13014,  2169,  2060,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  3913,  2319, 17712,  2226,  6097,  3286,  3520,  4502,\n",
      "          2232,  3475,  2102,  5177,  8639,  2021,  8915, 27390,  2008,  1049,\n",
      "          2546,  7743,  2003, 13970, 24388, 19128,  2906,  6616,  2017,   102],\n",
      "        [  101,  2193,  2317,  2111,  2040,  2359,  2000,  2022,  2304,  2029,\n",
      "          2001,  2625,  2084,  2193,  2057,  2170,  2068,  2317, 12593,  2229,\n",
      "          2027,  2359,  2000,  2022,  2112,  1997,  2304,  3226,  1999,   102],\n",
      "        [  101,  5310,  2053,  2066,  2027,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 11324,  2003,  2028,  1997,  1996,  2502,  3314,  1045,\n",
      "          2031,  2007,  1996,  4828, 12731, 10603,  2071,  2017,  3746,  1996,\n",
      "          2149,  2651,  2007,  2019,  4469,  2193,  2454, 17276, 11586,   102],\n",
      "        [  101,  2026,  3566,  2409, 20862,  2016,  2323,  2202,  2729,  1997,\n",
      "          2014,  4091,  2061,  2016,  2180,  1521,  1056,  2031,  2000,  2131,\n",
      "          2751,  4091,  2138,  2008,  1521, 17276,   102,     0,     0,     0],\n",
      "        [  101,  2026,  7743,  2175, 13660,  2080,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2017,  2288,  2009,  2157,  2045,  2003,  2053,\n",
      "          8016,  2005,  1996,  4808, 23713,  6215,  2014, 17871,  2003, 10439,\n",
      "          8095,  2075,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2074,  3084,  2128,  3762,  2298,  2130,  2062,  2066,\n",
      "          1037,  7743, 15488,  2232,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053, 16756,  2063,  8040,  2819,  2426,  1996,  4217,  2008,\n",
      "          2005,  2017, 18294,  2317,  2175, 10139,  2213,  2000, 18094,  2005,\n",
      "          2149,  2009,  7691,  2005,  2017,  2009,  2019, 14987,  2017,   102],\n",
      "        [  101,  2187,  8845, 27853,  2678, 26393,  2005,  3105,  2138,  2130,\n",
      "          1037,  8239,  2482,  2018,  2000,  2022,  5637,  1999,  2070,  2126,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2113,  2129,  2008,  9152, 13327, 11248,  4633,  2006,\n",
      "         19712,  2015,  2302,  9301,  2002,  2001, 10324,  1996, 16522,  1998,\n",
      "          2059,  2010, 11382,  3489, 28213,  2015,  2626,  2010, 12480,   102],\n",
      "        [  101, 29450,  2003,  2008,  2017,  2030,  2003,  2023,  2129,  2017,\n",
      "          2292,  2115, 22889,  4904,  2831,  2023,  2711,  2003,  1037,  2388,\n",
      "          1998,  2017,  2024,  5191,  2055,  3974,  2115,  4268,  2058,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.1290, 0.4880, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.7630, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0870, 0.0870,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0870, 0.0870,\n",
      "         0.0870, 0.0870, 0.0230],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.1200, 0.1200, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1200, 0.1200, 0.1200, 0.1200,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6610, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0000],\n",
      "        [0.0570, 0.8280, 0.0570, 0.0570, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.8450, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0240, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.3440, 0.0240, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.5150, 0.1360, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090]]), 'label': tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2036,  1999,  2256,  2193,  2087,  2670,  6941,  7025,  2069,\n",
      "          7545,  4028,  1998,  6215,  5310,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2027,  2652,  1037,  2843,  1997,  5636,  2189,  2012,  2023,\n",
      "          2317,  4632,  5030,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2064,  2102,  2057,  2074,  3579,  2256,  4073,  2006,  1996,\n",
      "         14163, 17960,  2015,  1998,  3066,  2007,  1996,  5181,  2101,  2028,\n",
      "         20861,  2172,  5514,  2059,  1996,  2060,   102,     0,     0,     0],\n",
      "        [  101,  4569,  2755,  2106,  2017,  2113, 10556, 13639,  6182,  2319,\n",
      "          2003,  7508,  2005,  9152, 13327,  7089,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9155,  3931,  3248,  1037, 11690, 15178,  4674,  1999,  2054,\n",
      "          1996,  4465,  2335,  2024,  4214,  1996,  2190, 19483,  2143,  2144,\n",
      "          3407,  2362,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3867,  1997,  1996,  2779,  2313,  2024,  2108, 18516,  2157,\n",
      "          2085,  2011,  9130,  2750,  4209, 11382,  3489, 16950,  9102, 20689,\n",
      "          2094,  2881,  1042,  2497,  2000, 18077,  1996,  2529,  4167,   102],\n",
      "        [  101,  2296,  2028,  1997,  2068,  2130,  2091,  2000,  2193, 16215,\n",
      "          1997,  1037,  2431, 15910,  4284, 10834,  1998,  1996, 13323, 10464,\n",
      "          2239, 11382,  3489,  6616,  2545,  2205,   102,     0,     0,     0],\n",
      "        [  101,  2279,  2088,  2452,  3453,  2148,  3088,  2005,  2952,  1040,\n",
      "         10338,  2193,  2058,  1998,  2193,  2058,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6638,  9152, 23033,  2015,  2007, 14436,  2015,  2022,  2559,\n",
      "          2066,  2502,  4632, 22212,  2015,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  1037,  2120,  5002,  1997,  6721,  8168,  1997, 15667,\n",
      "          2015,  1998, 28229,  2015,  2193,  1997,  2216,  3767,  2040,  2170,\n",
      "          3209, 15667,  2030, 22437,  6431,  2193,  1997, 28229,  3767,   102],\n",
      "        [  101,  5310,  1045,  8239,  5223,  2017,  1062, 28665,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2021,  6927,  1996,  6719,  5190,  1997,  2336,  2040,  2020,\n",
      "         15504,  2000,  2331,  1998, 10202,  2004, 22286,  2015,  2006, 10733,\n",
      "          3685,  2272,  2830,  2037,  3008,  2024,  2205,  6517,  2000,   102],\n",
      "        [  101,  2021,  2477,  2024, 20607,  1045,  2228,  2027,  2052,  2085,\n",
      "          2298,  2054,  2216,  1038, 13728,  2016,  5092,  5644,  2106,  2000,\n",
      "         15941,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2317,  3951, 23503,  2015,  2040,  4370,  2188,  2097,\n",
      "          3477,  1996,  3976,  2017,  2064,  5293,  2115,  4171,  3338,  2085,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2354,  1045,  2001,  5637,  1996,  3371,  1045,  2387,\n",
      "          4748, 23144,  2638,  9212,  2884,  1521,  3566,  2006,  1996, 18178,\n",
      "         12928,  2232,  3057,  2026,  2512, 25953,  2193,  2095,  2214,   102],\n",
      "        [  101,  1996,  2838, 11721,  2497,  2038,  2024,  8121,  3458, 10474,\n",
      "          3937, 11307,  2862,  2894,  9611,  2116,  3471,  2008,  1055,  3501,\n",
      "          9333,  2006, 10474,  7743,  2055,  2664,  4209,  2068,  2027,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1240,\n",
      "         0.1240, 0.1240, 0.1240, 0.1240, 0.1240, 0.1240, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1090, 0.1090, 0.1090, 0.1090,\n",
      "         0.4150, 0.1090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6040, 0.0420, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0100, 0.0100, 0.0360, 0.5200, 0.1370, 0.0100, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.1870, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.7090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0780, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0440, 0.0120, 0.0120, 0.0120, 0.1690, 0.1690, 0.1690, 0.0120, 0.1690,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0520, 0.7440, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330]]), 'label': tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2079,  2025,  6100,  1056, 28394,  3215,  2013,\n",
      "          2115, 24815,  2072,  3428,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2026,  9130, 19483,  4004,  2015,  2177,  7507,  2102,  2003,\n",
      "          2026,  2878,  2166, 29300,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2331,  1997,  3744,  2798,  2139,  2273,  9351,  2229,  1046,\n",
      "          2532,  3654, 13944,  2078,  1998,  2035,  5181,  5905,  1997, 14052,\n",
      "          2442,  2022,  4654,  3334, 26972,  2011, 15523,   102,     0,     0],\n",
      "        [  101,  3980,  2193,  2052,  1996,  2304,  3124,  2079,  1996,  2168,\n",
      "          2000,  2178,  2304,  3124,  2193,  2052,  1996, 22190,  2072,  2079,\n",
      "          1996,  2168,  2000,  2178, 22190,  2072,  2193,  2052,  1996,   102],\n",
      "        [  101, 13350,  2024,  2128,  7559,  5732, 11992,  2024,  2128,  7559,\n",
      "          5732, 19297,  2015,  2024,  2128,  7559,  5732,  3492,  2172,  3071,\n",
      "          2003,  2128,  7559,  5732,  2021,  2033,   102,     0,     0,     0],\n",
      "        [  101,  2054, 19237,  2055,  6117,  2003,  2008,  2130,  2007,  1037,\n",
      "          5065,  3014,  1045,  2064,  2025,  4025,  2000,  2424,  2147,  1998,\n",
      "          1999,  2023,  2110,  2027,  2097,  2069, 10887,  2017,  2065,   102],\n",
      "        [  101,  2317,  2934,  2074,  2109,  1996,  2744,  6206, 12114,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6389,  6616,  9587, 25016,  2213,  2053,  4797,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2000,  2035,  2026,  7025,  8771,  1045,  2293,  2017,  1998,\n",
      "          2115,  2166,  5609,  2994,  3647,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12569,  7054,  2559,  2012,  1996,  2477, 16215,  2102, 18062,\n",
      "          2078,  2716,  2000,  2014,  1998, 15261,  2011,  2129,  2002,  4282,\n",
      "          1996,  2946,  1997,  1996,  6007,  2016,  4929,  2014,  3540,   102],\n",
      "        [  101,  8239,  2139,  6914, 22139,  6904, 13871, 12868,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998,  5665,  2360,  2009,  2153,  1996,  2069,  2204,  9587,\n",
      "         25016,  2213,  2003,  2028,  2008,  2025,  5505,  8239,  2558, 10334,\n",
      "          2040,  6732,  2122, 13555,  6616,  2545,  2024,  2182,  2005,   102],\n",
      "        [  101,  6289,  2748,  1996,  2307,  5961,  2008, 18675,  2296, 16428,\n",
      "          2088,  4485, 29334,  2000,  2272,  2000,  2256, 13312,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2272,  2182, 10142,  1998,  2017,  2097,  2025,  2131,\n",
      "          2170,  2019,  6206,  7344,   100,   100,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2216,  2916,  2020,  2025,  2130,  2081,  2005,  2017,  2027,\n",
      "          2020,  2081,  2011,  2317,  2111,  2005,  2317,  2111,  9444,  2245,\n",
      "          2009,  2001,  1037,  2204,  2801,  2000,  2507,  2017, 10556,   102],\n",
      "        [  101,  5310,  5310,  1045,  2812,  2017,  2024,  2157,  1999,  1996,\n",
      "          2755,  2008, 17710, 24076,  1047,  2293,  1039,  6473,  1998,  2888,\n",
      "          6187, 26548,  2024,  2035,  2317,  2021,  1996,  2717,  1045,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0440, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0440, 0.0120, 0.0120, 0.0120, 0.1660,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0810, 0.0810, 0.0810, 0.0810, 0.0810, 0.0810, 0.0810, 0.0810, 0.0810,\n",
      "         0.0060, 0.0060, 0.0810, 0.0810, 0.0810, 0.0060, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.4750, 0.4750, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.1730, 0.1730, 0.6550, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0230, 0.0230,\n",
      "         0.0060, 0.0060, 0.0060, 0.0230, 0.0230, 0.0230, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0230, 0.3310, 0.3310, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2230,\n",
      "         0.2230, 0.2230, 0.2230, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290]]), 'label': tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  6456,  2057,  2025,  2635,  2053,  9152, 23033,  2015,  3809,\n",
      "          3225,  2238,  2009,  2621,  2061,  2027, 10094,  2000,  2031,  2193,\n",
      "         27408,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1048,  2863,  9541, 10166,  1045,  2717,  2026,  2553, 12731,\n",
      "          3372,  2515,  2025,  2507,  1037,  4485,  2055,  4808,  2030, 11113,\n",
      "         15613, 10768,  5809,  2229,  2074,  2359,  2000,  2707, 12486,   102],\n",
      "        [  101,  5310,  2057,  2323,  5157,  3519, 13520,  1037,  2120,  6209,\n",
      "          2043,  1996, 14163, 13793,  2063, 17328,  2003,  2908,  8529,  2054,\n",
      "          2000,  2655,  2009,  2191, 14074, 14735, 17603,  6790, 23805,   102],\n",
      "        [  101,  1045,  2424,  2009,  3733,  2000,  2131,  2105,  2108,  2170,\n",
      "          1037, 16939,  3348,  2923,  6394, 24004,  8458, 20891,  2065,  2017,\n",
      "          2024,  2074,  2019, 22052,  2000,  3071,   102,     0,     0,     0],\n",
      "        [  101,  2002, 12373,  2015,  3254,  2077,  8058,  2000,  1996,  2060,\n",
      "          2203,  1997,  1996,  6847,  1998,  2183,  2067,  2000,  2010, 28902,\n",
      "          1996,  6616,  2115,  3291,  4312,  8209,  3160,  1045,  2079,   102],\n",
      "        [  101,  2339,  1996,  2117,  4602,  2143,  2412,  2550,  2044,  9152,\n",
      "         13327, 14433,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  2764,  1037,  4121, 10188,  2006,  3801,  2007,\n",
      "         20665,  4641,  3376, 13852,  7743,  2229,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  1996,  6210,  1997,  1037, 11382,  3489,  2040,\n",
      "          5506,  2138,  2017,  2106,  2025,  6133,  2000,  4654,  3334, 19269,\n",
      "          2035,  1996,  2175, 10139,  2213,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4507,  2003,  2017,  2025,  9303,  2050,  4553,  2029,\n",
      "          2828,  1997,  7743,  2017, 24260,  3436,  2000,  2127,  2044,  2017,\n",
      "          2589,  2985,  2006,  2014,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2030,  2074,  3524,  2127,  2017,  2031,  2042, 23142,  2007,\n",
      "          1037,  2482,  2440,  1997,  9454,  3337,  1998,  6544,  1998,  2017,\n",
      "          2024,  2525,  1996,  2221,  2117,  2087,  3297, 15667,  2566,   102],\n",
      "        [  101,  5310,  1045,  2572,  5305,  1997, 12593,  2015,  2467,  5782,\n",
      "          1037,  2317,  2711,  2000,  2272,  1998,  3828,  2068,  2317,  2111,\n",
      "          2024,  2025,  2183,  2000,  3828,  2149,   102,     0,     0,     0],\n",
      "        [  101,  2193,  2193,  2343,  6031,  1043, 15456,  5751,  1996,  5057,\n",
      "         20563,  2552,  2046,  2375,  1999,  2193,  2429,  2000,  1996,  2047,\n",
      "          2375,  3296,  7521,  2013,  2151,  2406,  3685, 13467,  2193,   102],\n",
      "        [  101,  1045,  2097,  2191,  2023,  2004, 10317,  6149,  2004,  1045,\n",
      "          4298,  2064,  3102,  2035,  1996,  5472,  9152, 13327,  2015,  2127,\n",
      "          2045,  2025,  1037,  2309,  2028,  2187,  1998,  2017,  2097,   102],\n",
      "        [  101,  2298,  2158,  1045,  2572,  3374,  1045,  2572,  2107,  1037,\n",
      "          6904, 13871,  4140,  7570,  2063,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2087,  8796,  2007,  8398, 11382,  3489,  4434,  3109,  2010,\n",
      "         13628,  2024,  5181,  2025,  2204,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2003, 14163, 28600, 25666,  5152,  2030,  7025,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1530, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0400, 0.1530, 0.0400],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.7320, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8580,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7240, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.7320, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0550, 0.0550,\n",
      "         0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0140, 0.0140, 0.0140, 0.2070,\n",
      "         0.2070, 0.0040, 0.0040],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.8450, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.6140, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2008,  2065,  2027,  2064, 22149,  2461,  1996,\n",
      "         22033, 10536,  3561,  2061,  2170,  8711,  3262,  2273,  2006,  2045,\n",
      "          2126,  2013,  2605,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2006,  2327,  1997,  2008,  2017,  2064,  2074,  3191,  1996,\n",
      "         14054,  1998,  2156,  2111,  2215,  1037,  3114,  2000,  4487, 21338,\n",
      "          2229,  5051,  6593, 10823,  2138,  1037,  2711,  2081,  1037,   102],\n",
      "        [  101,  1996,  9587, 25016,  2213,  2003,  2025,  1996,  9452,  2383,\n",
      "          1037, 23368,  2030,  2070,  2060,  2679,  2266,  2004,  1996,  9452,\n",
      "          1999,  2344,  2000,  2128, 10354, 27972,  5796,  2213,  7984,   102],\n",
      "        [  101,  2122,  2024,  1996,  2168,  2329,  2610,  2040,  2052,  6545,\n",
      "          1037,  2158,  2005,  8701,  1043, 22571, 14625, 26783,  3436,  1999,\n",
      "          2010,  2219,  2188,  2044,  2002,  2513,  2013, 10885,  2040,   102],\n",
      "        [  101,  2085,  6358,  2074,  2138,  2115,  2383,  3348,  2007,  1037,\n",
      "         22635, 10658,  2029,  2003,  2025,  7965,  1998,  2017,  2453,  2941,\n",
      "          2022,  2128,  7559,  5732,  1045,  2572,  2005,  2613,  4406,   102],\n",
      "        [  101,  5310,  5310,  5310,  2009,  2170, 16498, 10257,  2132,  2175,\n",
      "          2067,  2000,  2115,  4750,  2406,  1998,  2156,  2129,  2008,  2573,\n",
      "          2041,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 11690,  5470, 12070,  2016,  2089,  5050,  1037,  6903,\n",
      "          1997,  1996,  5637, 11690,  2177,  2021,  2008,  2009,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  7151, 19992, 24008,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2193,  5408,  1061,  2099,  2214,  2317,  2611, 15504,  2011,\n",
      "          2193,  7486,  1998,  2049,  2074,  9680, 19966,  2015,  6643, 26010,\n",
      "         24862,  2015,  2893,  2009,  3308,  2823,   102,     0,     0,     0],\n",
      "        [  101,  2175,  4095,  8038,  3363,  1996, 12603,  1045,  5223,  1057,\n",
      "          2317,  7743,  2229,  3398,  3500,  3193,  2690,  2082, 10047,  3331,\n",
      "          2000,  2017,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  2202,  2040,  7361,  2072,  2041,  1997,  1996,\n",
      "         17276,  2021,  2017,  2064,  2025,  2202,  1996, 17276,  2041,  1997,\n",
      "          2040,  7361,  2072,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2045,  2024,  5152, 26114,  2050,  6616,  2545,  5152,\n",
      "         11085,  2389,  9130,  2003,  2025, 10539,  2057,  2442,  2031,  1037,\n",
      "          4037,  2591, 14048,  2521,  2373, 19699,  5313,  2084,  5152,   102],\n",
      "        [  101,  2017,  2064,  2202,  1996,  9152, 13327,  2041,  1997,  1996,\n",
      "         17276,  4604,  2032,  2000,  2267,  2005,  2489,  2000,  2377,  2374,\n",
      "          2021,  2025,  2175,  2000,  2465,  2059,  2507,  2032,  8817,   102],\n",
      "        [  101,  1045,  2293,  2216,  4314, 27058,  2869,  1996,  5152,  7221,\n",
      "          1998,  1996,  5038,  1997,  6744,  2004,  3956,  3007,  3065, 14560,\n",
      "          3424,  3366, 22930,  2964,  4786,  2062,  2417,  8197, 13112,   102],\n",
      "        [  101, 10785,  1998,  2122, 16371, 26755,  3711,  1999,  2035,  2967,\n",
      "          2053, 21845,  5152,  2097,  2412,  2468,  1037,  5920,  9472,  1996,\n",
      "          2087,  7490,  2468,  1059, 11961,  2989,  4315, 24968,  2229,   102],\n",
      "        [  101,  2296,  3105,  1999,  1996,  2088,  6526,  9578,  2000,  2191,\n",
      "          1037,  2317,  2450,  2166,  2488,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0050, 0.0050, 0.0050, 0.0050, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740,\n",
      "         0.0740, 0.0740, 0.0740, 0.0740, 0.2800, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0040, 0.0140, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2830, 0.0750, 0.0750,\n",
      "         0.0750, 0.0750, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.2830, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.3360, 0.3360, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.3140, 0.3140, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0290, 0.0290,\n",
      "         0.4110, 0.4110, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.1040, 0.1040, 0.1040, 0.1040, 0.1040, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1040, 0.1040, 0.1040, 0.1040,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0140, 0.2010, 0.2010, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0530],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.2910, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1580,\n",
      "         0.1580, 0.1580, 0.1580, 0.1580, 0.1580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0820,\n",
      "         0.0820, 0.3120, 0.3120, 0.0820, 0.0820, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310, 10166,  2008,  1037,  2843,  1997, 13157,  2040,  2215,\n",
      "          2606, 12690,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11021,  8000,  2003,  1037,  6904, 13871,  4140,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2092,  2292,  2149,  2156,  7441, 26635,  1037,\n",
      "          2304,  1043,  2546,  2021,  2008,  8906,  1037, 11729,  4136,  2317,\n",
      "          3057, 15504,  2000,  3844,  2039,  2003,  2036,  7929, 12436,   102],\n",
      "        [  101,  2821,  1045,  2113,  2008,  2021,  2027,  2020,  2025,  1059,\n",
      "         10606,  2100,  2210,  6904, 13871, 12868,  2064,  2017, 19337,  3512,\n",
      "          1045,  2288,  7917,  2005,  4214,  3664,  1997,  2414,  1037,   102],\n",
      "        [  101,  1045,  3305,  1996,  2317, 15941, 22953,  9575,  1045,  2131,\n",
      "          2054,  4439,  2009,  2021,  1045,  9826,  2079,  2025,  3305, 22846,\n",
      "          4658,  4845,  3451, 27255,  2138,  1037,  2843,  1997,  2009,   102],\n",
      "        [  101,  2317,  2111,  2342,  2000,  2707, 11922,  2055,  2037,  2219,\n",
      "          2785,  2612,  1997, 14457,  2058, 11043,  2005,  2296, 10147,  3654,\n",
      "          5092,  2080,  9576,  2008,  2052, 24986,  3102,  2068,  2005,   102],\n",
      "        [  101,  5310,  2358,  4430,  2361,  2000,  3046,  2000,  3102,  4426,\n",
      "          2087,  5684,  4183,  6240, 16078,  4365,  4183,  1060,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  1998,  2182,  3310,  1996,\n",
      "         12487,  2677,  2002,  2056,  2017,  2071,  2065,  2017,  2020,  4138,\n",
      "         18210, 15504,  2048,  2308,  3825,  1047,  2005,  4632,  8787,   102],\n",
      "        [  101,  3005,  6318,  1045,  2572,  2157,  2182, 22953,  2008,  2033,\n",
      "          1999,  2008,  3861,  2000,  1996,  2327,  2187,  2030,  2070, 11382,\n",
      "          3489,  2040,  3504,  2066,  2033,  1045,  2064,  2025,  3342,   102],\n",
      "        [  101,  1045,  2074,  2288,  1996,  2087,  2128,  7559,  5732,  3013,\n",
      "          1999,  2026,  2166,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2066,  2129,  2017,  2655,  2041,  3071,  2008,\n",
      "          2515,  4933, 20868,  2140,  2004, 11867,  2121,  5620,  1998,  4366,\n",
      "          1045,  2572,  2593,  1037, 11382,  3489,  2030,  1037,  9152,   102],\n",
      "        [  101,  5310,  4931,  1045,  2031,  1037, 16428,  4070,  2021,  2026,\n",
      "          6971,  2024,  2035,  2317,  1998,  1045,  2064,  2102,  2425,  2029,\n",
      "          6971,  2024, 16428,  1998,  1996,  2489,  3924,  2129,  2079,   102],\n",
      "        [  101,  5310,  6289, 23278,  3270,  3270,  2232,  1998,  1996, 22399,\n",
      "          1997,  1037,  9680,  2923,  5618,  2006,  1037,  3909, 20325,  2040,\n",
      "         15504,  1998,  7129,  9932,  7377,  3576,  3057, 17977,  1998,   102],\n",
      "        [  101,  1045,  2812,  1045,  1040,  2145,  2655,  2017,  1037,  2128,\n",
      "          7559,  2094,  5728,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2025,  2342,  2051,  2000,  5293,  2017,  2021,\n",
      "          1045,  2074,  2342,  2051,  2000,  5223,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 15537,  2033,  1997,  1996, 11513,  2043,  4028,  2001,\n",
      "         25883,  1998,  2087,  2020,  4333,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.3420, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.3420],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3950,\n",
      "         0.3950, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0500, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0330, 0.0330, 0.0330, 0.0330, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.6150,\n",
      "         0.0430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.1050, 0.4000, 0.4000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  1045,  1040,  2293,  2000,  2360,  1045,  2572,  1037,\n",
      "          2911, 19483,  2021,  2784,  2091,  1045,  2113,  1045,  2572,  1996,\n",
      "          9047,  2828,  1998,  1996, 15667, 14813,   102,     0,     0,     0],\n",
      "        [  101,  2691,  3168,  2758,  1996,  5576,  2000,  2296,  3291,  1999,\n",
      "          1996,  2088,  2003,  2317,  2273,  5181,  2360,  1996,  3291,  2007,\n",
      "          2673,  1999,  1996,  2088,  2003,  2317,  2273,  2009,  2052,   102],\n",
      "        [  101,  8398,  4223,  2006,  1996,  1038, 13728,  3211, 28911, 14853,\n",
      "          6314,  2015,  2033,  8112,  2003,  3517,  2021,  2025,  8398,  1045,\n",
      "          2245,  2002,  2001,  2005,  2035,  4841,  2030,  2066,  2256,   102],\n",
      "        [  101,  4151,  4485,  1996,  9200, 11382,  3489,  2012,  1996,  2203,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 23848,  2050, 22006,  2003,  3308,  3251,  2049,  3795,  2923,\n",
      "          3644, 22006,  2030,  2317, 22006,  2009,  3424, 26654,  2937,  1998,\n",
      "          2947,  2141,  2000,  8246,  4763,  2467,  4515,  2039,  3974,   102],\n",
      "        [  101,  3374,  1045,  2001,  7727,  2000,  1996, 11513,  2466,  1045,\n",
      "          2903,  2009,  2000,  2022,  1037,  4682,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2033,  2232,  3071,  4282,  2017,  2024,  1037,  5472, 25518,\n",
      "          4590, 21146,  4360,  6904,  2290,  2079,  2025,  2017,  2031,  1037,\n",
      "          5177,  2740,  4322,  2000,  2022, 17512,  2000,  4487, 21146,   102],\n",
      "        [  101,  5310,  8112,  2141,  1999,  7359,  2030,  2025,  2001,  2992,\n",
      "          1999,  5152,  3032,  2011,  5152,  2269,  4481,  2002,  2038,  2053,\n",
      "         14588,  2000,  1996,  3915,  2021,  2059,  4445,  2079,  2087,   102],\n",
      "        [  101,  5310, 24471,  2025,  2026,  6904,  2615,  1045,  8239,  5223,\n",
      "          2017,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  5236,  6638,  8239,  2317,  8579,  2121,  7743,\n",
      "          8046,  3098,  2115,  2677,  2066,  2017,  2031,  1037, 14841,  2278,\n",
      "          2006,  1996,  2417, 10135,  2128,  7559,  2094,   102,     0,     0],\n",
      "        [  101, 13442, 12593,  2229,  8415,  2027,  2123,  1521,  1056,  2079,\n",
      "          2505,  3308, 25818,  1045,  8415,  1045,  2123,  1521,  1056,  2022,\n",
      "          2725,  2498,  2017,  2074,  2022,  4440,  4691,  2006,  2033,   102],\n",
      "        [  101,  1045,  2507,  1037,  6616,  1999,  2008,  1045,  2572,  3407,\n",
      "          2045,  2028,  2625,  9152, 13327,  2000,  2202,  2256, 21025,  5910,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  2042,  2437,  2009,  1037,  2391,  2000,  3191,\n",
      "          2062,  3441,  2007, 11690,  2015,  2060, 19483, 21989,  2138,  1045,\n",
      "          2145,  3325,  6721,  5637,  8056,  2004,  1045,  2572, 13400,   102],\n",
      "        [  101,  5310,  5310,  1045,  2134,  1521,  1056,  2360,  2009,  5320,\n",
      "          4808,  2009,  3849,  2000,  5326,  1037,  3056,  9580, 27793,  2292,\n",
      "          1521,  2025,  9811,  2009,  2987,  1521,  1056,   102,     0,     0],\n",
      "        [  101,  1996,  5637,  4302, 10693,  1997,  8083,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2733,  2193,  2193,  2064,  3490, 10264, 11513,  2193,  7942,\n",
      "          2193,  2035,  1996,  6087,  1997,  1996,  2601,  2193,  2668,  1998,\n",
      "          2304, 12922,  2193, 11798,  2030,  1062,  5358,  5638,  2193,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0540, 0.0540, 0.0540, 0.0540, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0140],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.2040, 0.0140, 0.0140, 0.0540, 0.0540,\n",
      "         0.0540, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0540,\n",
      "         0.0540, 0.0540, 0.0540],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.3480, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0270, 0.0270, 0.0270, 0.1020, 0.1020, 0.1020,\n",
      "         0.1020, 0.1020, 0.1020, 0.1020, 0.1020, 0.1020, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.5280, 0.1390, 0.1390,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0470, 0.1800, 0.1800, 0.1800, 0.1800, 0.1800, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200]]), 'label': tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2467,  8239,  6283,  2043,  1045,  2387,  2338, 12220,\n",
      "         21025, 10343,  2007,  7935,  8469,  2078,  2045, 10892,  2498,  3308,\n",
      "          2007,  2009,  2138,  2338, 12220,  1037,  2317, 26705,  2021,   102],\n",
      "        [  101,  1045,  3246,  2624,  3799, 23462,  2046,  1996,  3534,  4153,\n",
      "          2017,  4429,  6834,  8292, 29577,  2098,  8493, 21555,  4920,  2005,\n",
      "         19483,  2015,  6206, 12290,  2023,  6696,  3538,  1997,  4485,   102],\n",
      "        [  101,  7486,  2360,  2027,  2097,  2191,  2009,  3423,  2000,  9040,\n",
      "          2317,  2308,  2043,  2027,  2202,  2058,  2885, 15536,  2099,  2022,\n",
      "          3683, 20058,  2078,  6892,  2480,  2102,  8040,  8747,  7939,   102],\n",
      "        [  101,  1045,  2131,  2026,  2482,  1050,  2094,  1045,  1521,  1049,\n",
      "          2067,  4684,  2651,  7743,  2229,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2876,  2102,  2009,  2022,  2488,  2065,  1996, 11513,\n",
      "          2001,  7919, 10847,  2821,  2008,  2015,  2157,  2049,  6206,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2123,  2102,  2228, 10047,  2893,  2026,  3336,  2068,\n",
      "          2317,  2002,  2038,  2048,  2317,  1046,  1998, 18368,  2015,  2025,\n",
      "          2130,  5028,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10973, 11265,  7317,  2368,  2002,  2089,  2022,  2496,  2000,\n",
      "          1037, 14068,  2121,  1998,  1037,  4828, 10841,  3600,  2021,  2012,\n",
      "          2560,  2002, 13659,  1999,  1996,  2157,  3257,   102,     0,     0],\n",
      "        [  101, 26632,  2078,  2003,  1037, 10007,  6616,  2121,  2040,  2097,\n",
      "          2022,  6908,  2125,  1996,  1041, 13355,  2884,  3578,  2011,  2010,\n",
      "          9587, 25016,  2213,  2058, 19980,  2015,   102,     0,     0,     0],\n",
      "        [  101,  7025,  7460,  1999,  4501,  7269,  6239,  2690,  2264,  6084,\n",
      "          2163,  2167,  3088,  2025,  2007,  2317,  2111,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  3685,  2175,  2000,  1037,  4825, 23713,  4521,  1037,\n",
      "         15890,  2008,  1521, 17276,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2025,  2156,  2339,  2111,  2175, 13215,  2065,\n",
      "          1045,  2359,  2000, 13184,  2026,  7395,  2125,  1998,  4485,  1999,\n",
      "          1037, 13610,  1045,  2052,  3637,  2012,  2026,  5916,  2160,   102],\n",
      "        [  101,  1045,  2106,  2025,  5987,  2242, 11382,  3489,  2008,  4151,\n",
      "          4485,  1045,  1056,  3504,  2061,  2204,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3504,  2066,  8398, 14180,  2149,  2058,  7987,  2666,  2102,\n",
      "          8237,  2102,  4311,  4830,  3540, 16154,  3066,  2584,  2007,  2643,\n",
      "         10678, 11382,  3489,  8040, 28600,  2121, 21877, 10483,  2072,   102],\n",
      "        [  101,  5310,  2623, 26706,  2193,  1045,  2572,  7568,  2017,  2342,\n",
      "          2019,  4469,  2006,  2275,  2619,  2000,  2191,  2469,  7424, 10608,\n",
      "          2001,  2579,  2067,  1045,  2572,  5627,  2000,  2272,  2147,   102],\n",
      "        [  101,  2043,  1996,  2329,  7574,  2291,  2001,  2275,  2039,  2044,\n",
      "         25755,  2009,  2071,  2147,  2138, 13818,  6214,  2020,  2367,  2045,\n",
      "          2001,  2379,  2440,  6107,  1999,  2193,  1996,  2390,  2894,   102],\n",
      "        [  101,  5310,  2021,  6530, 21545, 18210, 20228,  2015,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0720, 0.0720, 0.0720, 0.0050, 0.0050, 0.0050, 0.2740, 0.0190,\n",
      "         0.0190, 0.0050, 0.2740, 0.0190, 0.0190, 0.0190, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0990, 0.0990,\n",
      "         0.0990, 0.0990, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7320,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.2920, 0.2920, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0770, 0.0770, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1340, 0.1340, 0.1340, 0.1340, 0.1340, 0.1340, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0350, 0.0350, 0.0350, 0.0350, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0700, 0.0700],\n",
      "        [0.0110, 0.0410, 0.0410, 0.0410, 0.0410, 0.5890, 0.0410, 0.0410, 0.0410,\n",
      "         0.0410, 0.0410, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.1350, 0.1350, 0.5130, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  5409,  2143,  1997,  2193, 11504,  4788,  2084,  2008,\n",
      "         11690,  5745,  8286,  7747,  8349,  2007,  2008,  6638,  9152, 13327,\n",
      "          1037,  2261,  2086,  2067,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  1996, 22617,  2000,  2468,  2019,  3059,  6926,\n",
      "          7037,  1998,  1045,  2360,  2139,  6442,  2035,  5472,  9152, 13327,\n",
      "          2015,  3202,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6719,  1045,  1521,  2310, 29543,  2094,  1996, 17276,  2045,\n",
      "          2003, 22077,  2015,  7249,  2655,  1996,  2610,  1996,  2610,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748,  3531,  2272,  2000, 16392,  1998,  2191,  2033,  2175,\n",
      "         13433, 11253,  8840,  2140,  2292,  2149,  2156,  2115,  4586,  9152,\n",
      "         13327,  2940, 24457,  2100,  4632,  3046,   102,     0,     0,     0],\n",
      "        [  101,  1045,  2066,  2009,  1045,  2064,  2025,  3524,  2000,  3422,\n",
      "          1996, 11382,  3489, 17183,  4105,  3535,  2000,  3275,  2041,  2040,\n",
      "          2000,  2448,  1999,  2193,  2008,  2097,  2025,  3294, 18138,   102],\n",
      "        [  101,  2196,  2018,  1037,  2482,  2440,  1997,  4004,  2015, 15686,\n",
      "          2000,  4028,  2033,  2058,  1037,  3576,  4026,  5043,  3303,  2011,\n",
      "          2037,  4945,  2000,  3305,  1996,  3937,  3513,  1997,  1996,   102],\n",
      "        [  101,  6616,  2009,  1045,  2572,  9303,  2050,  2707,  3666,  2373,\n",
      "          1059,  1996,  2717,  1997,  2017,  9152, 13327,  2015,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2137,  2308,  1999,  2326,  2024,  3403,  2005,  1996,\n",
      "          2655,  2000, 21296,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  3398,  2027,  2018,  2000,  3857,  1996, 25516,  2015,\n",
      "          1998,  2084,  2224,  2068,  2000,  9570,  1996, 11918,  2015,  2008,\n",
      "          1037,  2843,  1997,  2524,  2147,  2068,  9152, 13327,  2015,   102],\n",
      "        [  101,  3784,  6394,  5292,  3270,  4364,  1996,  2187,  2064,  2025,\n",
      "          2033,  4168,  2193,  2317, 14293,  8906,  2003,  2256,  3997,  2679,\n",
      "          2003,  2074,  3096,  3609,  1996, 11513, 16939,  3348,  2923,   102],\n",
      "        [  101,  5310,  4689,  4138,  4138,  4004,  2015,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  3504,  1037,  2978, 14757,  6292,  2041,  2045,  1045,\n",
      "          2056,  2054,  3084,  2017,  2360,  2008,  3880,  2026,  2564,  1045,\n",
      "          2056,  2008,  6080,  1997, 10823,  2007, 13227,  2006,  1996,   102],\n",
      "        [  101,  5622, 19279, 18117,  2024,  1999, 14920,  2008,  2045,  2003,\n",
      "          1037,  3742,  3795,  9230,  6230,  2027,  2031,  4342, 11937, 14702,\n",
      "         19903,  3243,  2092,  2013,  2037,  9587, 25016,  2213,  2058,   102],\n",
      "        [  101,  2009,  2448,  2011,  1037,  2317,  3124,  2339,  2079,  2017,\n",
      "          7868,  2035,  2397,  2305,  2833, 19753,  2024,  2448,  2011,  7489,\n",
      "         16939,  2317,  2111,  2079, 28543,  5841,  2205,   102,     0,     0],\n",
      "        [  101,  2995,  2021,  1996,  2087, 19424,  2518,  2052,  2022,  1037,\n",
      "          5152,  1056, 29548,  2075,  1037, 13555,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2097,  2025,  2644,  2068,  3404,  2033,  1045,  2572,\n",
      "          1037,  2858,  2652, 23114,  2015,  2532,  3489,  2025,  2130,  1037,\n",
      "          3644,  2858,  2652, 23114,  2015,  2532,  3489,  1998,  2027,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3550, 0.0930, 0.0060, 0.0060, 0.0060, 0.0930, 0.3550, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0430, 0.6220, 0.1640,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0760, 0.0760, 0.0760, 0.0760, 0.0760, 0.2870, 0.0760, 0.0760,\n",
      "         0.0760, 0.0760, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1260, 0.4800, 0.1260,\n",
      "         0.1260, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.5610, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.6860, 0.0130, 0.0130, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0750, 0.0750, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2860, 0.2860, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0750,\n",
      "         0.0750, 0.0050, 0.0050],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0080, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190,\n",
      "         0.1190, 0.0000, 0.0000],\n",
      "        [0.0930, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0930, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.3510, 0.0240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190,\n",
      "         0.0190, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700, 0.0700,\n",
      "         0.0700, 0.0700, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0250, 0.0250, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950, 0.0950,\n",
      "         0.0950, 0.0950, 0.0950, 0.0950, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.6230]]), 'label': tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  1045,  2812,  2469,  2002, 15504,  2308,  7271,\n",
      "          2363,  8700,  2021,  3233,  2011,  2115,  2158, 18904,  4221,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7910,  2138,  2308,  2024,  4030,  2106,  2027,  2292,  2068,\n",
      "          3198,  1996,  4378,  2005,  1996,  6998,  2030,  2191,  3042,  9289,\n",
      "          4877,  2205,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3563,  8767,  1997,  4808,  2323,  2196,  2022,  7936,  3102,\n",
      "          1996, 10189,  4801,  2003,  3039,  2004,  2009,  2003, 10009,  2004,\n",
      "          2576,  4613,  3102,  2008, 10189,  4801,  2012,  2193,  2364,   102],\n",
      "        [  101,  2002,  7499,  2015,  2317, 22006,  2043, 24114,  1996,  5181,\n",
      "          2052,  2191,  1996,  2088,  2191,  3168,  2054,  2079,  2017,  2228,\n",
      "          2010, 26264,  2003,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2115,  6069,  8246,  2349,  2000, 21262,  5668,  2007,  4800,\n",
      "          5636,  2945,  1996, 18076,  7486,  1998,  4004,  2015,  2228, 16522,\n",
      "          2024,  2317,  2115,  6069,  2131,  2149,  1999, 22158,  2059,   102],\n",
      "        [  101,  5310,  5310,  1998,  3531,  2079,  2017,  2568,  2025,  4214,\n",
      "          1046,  2243,  1037,  2317,  2879,  2049, 12726,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  2196,  2428,  8725,  2005,  5310,  2021,  1045,\n",
      "          2193,  4487,  3736,  6767,  2860,  1996,  2079, 20348,  2075,  1997,\n",
      "          2032,  2017,  2064,  4756,  2012,  2032,  2655,  2032,  1037,   102],\n",
      "        [  101,  5292,  5292,  5292, 15537,  2033,  1997,  1996,  5223,  5653,\n",
      "          2013, 10112,  2108,  2741,  2000, 13067,  2015,  1997, 16795,  2023,\n",
      "         11382,  3489,  4012,  9856,  3313,  3713,  1998,  3313,  2228,   102],\n",
      "        [  101,  2292,  2149,  7499,  1996,  9152, 13327,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2178,  2317,  3124, 21289,  2019,  3060,  2137,  2005,\n",
      "          3241,  2005,  2370,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  2060,  1046, 12155,  2739,  8398,  3488,  2000,  3113,\n",
      "          2007,  7618,  2121,  7483,  2008, 11382,  3489,  7618,  2121,  2056,\n",
      "          2002,  4122,  2000, 16371,  3489,  1050,  4420,   102,     0,     0],\n",
      "        [  101,  5310,  8861,  1060,  2001,  4632, 21369, 23854,  2011,  6538,\n",
      "          2304,  7486,  2025,  2317,  8986,  2030,  8864, 10129,  2017,  2156,\n",
      "          2045,  1998,  9508,  6328,  2003,  1037,  2367,  4696,  2025,   102],\n",
      "        [  101,  1045,  3342,  1045,  2170,  2023,  3124,  1037, 10257,  2132,\n",
      "          2005,  3038,  5472,  3070,  4590,  8292, 29577,  2098,  1998,  2002,\n",
      "          2288,  2026, 16222,  2102,  6731,   102,     0,     0,     0,     0],\n",
      "        [  101,  2000,  2022,  3154,  2193,  1997,  2308,  2024, 12858,  2005,\n",
      "          2009,  1996,  2060,  2193,  2024, 11690,  2015,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2178,  5152,  9452,  2886, 28339,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  1996,  2193,  2193, 22082,  2132,  1998,  9663,  2020,\n",
      "          3492, 19964,  1045,  2079,  2903,  2027,  3139,  1996, 11721, 28878,\n",
      "          1997,  4004,  2015,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0210, 0.2990, 0.2990, 0.2990, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.1030, 0.1030, 0.0070, 0.0070, 0.0070, 0.0270, 0.0270, 0.0270,\n",
      "         0.3920, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.6390, 0.0440, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.7320, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4110, 0.4110,\n",
      "         0.0080, 0.0080, 0.0290, 0.0290, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190,\n",
      "         0.1190, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2023,  2609,  2145, 19237,  9152, 13327,  5980,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5637,  9587, 25016,  2213,  2233,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1045,  2628,  2017,  1998,  2017,  2106,  2025,  3582,\n",
      "          2067,  6616,  2017,  1045,  2288,  6731,  2065,  2017,  2106,  2025,\n",
      "          2113,  6904, 13871, 12868,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  3524,  6229,  2002,  4152,  2000,  1996,  2112,  2055,  1996,\n",
      "         14560,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 11082,  3246,  2061,  3806,  1996,  2843,  2164,  1996,  9152,\n",
      "         13327,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2695,  5302, 25888,  2964,  2444,  1998,  2292,  2444,  4145,\n",
      "          1997,  3606,  9251,  2008,  2130,  2048,  4500,  1998, 12590, 27894,\n",
      "          4447,  2064,  2119,  2022,  2995,  2023,  2003,  2004,  5236,   102],\n",
      "        [  101,  5310, 18411,  2860,  3046,  3788,  4439,  2030,  2130,  3909,\n",
      "          2408,  1037,  2149,  2510,  2918,  2025,  2130,  6206, 12114,  2052,\n",
      "          2131, 27046,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2292,  1996, 11382,  3489, 22889, 16446,  5252,  2149,  2049,\n",
      "          3835,  2000,  2514,  2359,  2174,  1045,  2738,  5252,  2308,  1997,\n",
      "          2026,  2219, 15977,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3599,  2065,  1037,  2659, 26264,  9152, 13327,  2013,  3088,\n",
      "          2040,  2064,  2025,  3191,  2064,  3305,  7025,  1045,  2228,  1045,\n",
      "          2064,  3305,  3102,  1996, 13970, 20961,  2099,  2498, 11259,   102],\n",
      "        [  101,  2273,  4682,  2308,  4682,  3616,  2079,  2025,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1037,  2843,  2027,  2074, 25635,  3031,  1996, 23325,\n",
      "         15900,  1998, 11867,  5833, 21025, 29325,  4509,  2055,  7489,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998,  2001, 24563,  2011,  2988, 28868,  2164, 10428,  3482,\n",
      "         28652,  1998, 28973,  1997,  4559, 17888,  6074,  1998,  7206,  2076,\n",
      "          1996,  3049,  2877,  2039,  2000,  1996,  2602,  2045,  2020,   102],\n",
      "        [  101,  7743,  2229,  2022,  2725,  2205,  2172,  2022,  4658,  7570,\n",
      "          2063,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2129,  2055,  2017,  2131,  1996, 10827,  3815,  1997,\n",
      "         28229,  3012,  2125,  2026,  5637,  4632,  2694,  2034,  1998,  2059,\n",
      "          2057,  2064, 11147,  1996,  6022,  8491,  4109,  1997, 19483,   102],\n",
      "        [  101,  5310,  1045,  2031,  2000, 18766,  2205,  1045,  8239,  5223,\n",
      "          2017,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2508,  2003, 17276, 22692, 11669,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.7800, 0.2060, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.7320, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.2440, 0.2440, 0.2440, 0.0040, 0.0040, 0.2440,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4160, 0.4160, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.6280, 0.1650, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0400, 0.0400, 0.5710, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0400, 0.0400, 0.0400, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.7280, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1920, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9320, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  9152, 23033,  2015,  2131,  1037,  2354, 17680,  2006,  2166,\n",
      "          1998,  2228,  2009,  3100,  2000,  2128, 18824,  2571,  4485,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 17559,  2006,  1056,  2140,  2021,  1045,  8239,  5223,  2108,\n",
      "          1037,  2931,  7929,  9061,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2131,  1037,  7170,  1997,  2023,  2128,  7559,\n",
      "          2094,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1998,  2017,  1037, 12873,  7743,  1999,  3067,  2562,\n",
      "         22868,  7570,  2063,  2017,  2145,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6517,  2466,  2000,  2022,  2469,  2006,  1037,  2217,  3602,\n",
      "          2070,  4364,  2323,  2025,  2412,  4929,  4951, 13284,  2129,  2515,\n",
      "          2151,  2202,  2008, 26666,  4273,  3124,  3809,  4377,  2066,   102],\n",
      "        [  101, 22091,  1045,  2001,  5327,  2009,  2001,  1996,  3954,  1997,\n",
      "         11090,  2025,  2070,  5413,  2243,  2017,  8617,  1037, 11090,  6517,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2043,  5181,  2655,  2041,  5181,  2017,  2113,  2049,  2919,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3046,  4067,  1037,  8991,  1060,  2030,  4971, 19825,  2140,\n",
      "          2040,  4152,  2037, 15882, 15504,  2138,  2017,  2020,  2205, 13971,\n",
      "          1998, 11809,  2000,  3073,  2005,  2115,  2219,  5075,   102,     0],\n",
      "        [  101, 14398,  2001,  8826,  2011,  4750,  5181,  1996,  2744,  1996,\n",
      "          4145,  2216,  2168,  4750,  5181,  7129, 15295,  1997,  8817,  1997,\n",
      "         16939,  2015,  2664, 12461,  2448,  2105,  6015,  1997,  2108,   102],\n",
      "        [  101,  1045,  2123,  2102,  2729,  2055,  8042,  2138,  1045,  2729,\n",
      "          2055,  2530,  2111,  8042,  4473,  8817,  1997,  5181,  2000, 13382,\n",
      "          2004, 16231, 16103,  2015,  2000, 12731,  3600,  8817,  1997,   102],\n",
      "        [  101,  9042,  2015,  2024, 14560,  2339,  2134,  2102,  2027,  2448,\n",
      "          2000,  8174, 13085, 12577, 15501,  9042,  2015,  2079,  2025,  3713,\n",
      "          2446,  2593,  9042,  2015,  2031,  2448,  2000,  1996,  2769,   102],\n",
      "        [  101,  5181,  2024, 19424,  4942, 28600,  2319,  4176,  1996,  2088,\n",
      "          2052,  2022,  2061,  2172,  2488,  2065,  2296, 16522,  2351,  4826,\n",
      "          2616,  2064,  2025,  6235,  2129,  2172,  1045,  5223,  1996,   102],\n",
      "        [  101,  2026,  3611,  2003,  1037,  6904, 13871,  4140,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4283, 12455,  1045,  2001,  9587,  6834,  1996, 10768,\n",
      "         22311,  5831,  2013,  1996,  2434,  1056, 28394,  2102,  1045,  2123,\n",
      "          1521,  1056,  2342,  2151,  5375,  2013,  2017,  2061,  2031,   102],\n",
      "        [  101,  5310,  5310, 11677,  2011,  5635,  3303,  2011, 14649,  2748,\n",
      "          7167,  1997,  3032,  2031,  6102,  5919,  2066,  2710,  2021,  2043,\n",
      "          2027,  2175,  2440, 14649,  2008,  2043,  2027,  2735,  1999,   102],\n",
      "        [  101,  7017,  5814,  4126, 10255,  2068,  2000,  1996,  2157,  7875,\n",
      "          5833,  1996,  6548,  2006,  2769,  7770, 13375,  2435, 17294,  1046,\n",
      "          1037,  2307, 13137,  9289,  2989,  2085,  2002,  2428,  2054,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2740, 0.2740, 0.2740, 0.0720,\n",
      "         0.0720, 0.0050, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.1120, 0.1120, 0.1120, 0.1120, 0.1120, 0.4250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.7630, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0910,\n",
      "         0.0910, 0.3430, 0.3430, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0600, 0.0600, 0.2270, 0.0600, 0.0600, 0.0600, 0.0600, 0.0600, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0600, 0.2270, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0550, 0.0140, 0.0550, 0.0550, 0.0550, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0550, 0.0550, 0.0550, 0.0550, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0550, 0.0550, 0.0140, 0.0550,\n",
      "         0.0550, 0.0550, 0.0550],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1330, 0.1330, 0.5040, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290]]), 'label': tensor([1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 27505,  2015, 11242,  1996, 11513, 11242,  5637,  2015, 11242,\n",
      "         10469,  2015, 11242,  3644,  3747,  1999,  2231,  2865,  5446,  4024,\n",
      "         11242, 24552,  1998,  2062,  2021,  1045,  2228,  2017,  2024,   102],\n",
      "        [  101,  2204,  2453,  4030,  2091,  2037,  8119,  2011, 15667,  7486,\n",
      "          2040,  5223,  2308,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2027,  2031,  7578, 17088,  2024,  1996,  1038,  2721,\n",
      "          2595,  1998, 14560,  3039,  2000,  2191,  1037,  5618,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 13327,  2064,  2025,  2360,  2008,  2006, 10474, 18411,\n",
      "          2860,  2023,  2003,  2339,  1045,  2288, 26356,  2497,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2021,  2017,  4364,  2253,  1998,  2700,  1996,  5221,  8239,\n",
      "          6904, 13871,  4140,  1999,  2637,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2064,  1045,  2360, 17276,  9350,  2006,  2182,  2138,  1045,\n",
      "          2288,  2404,  1999, 10474,  7173,  2005,  4214,  1037,  3124,  1037,\n",
      "         17276,  9350,  2044,  2002,  2170,  2033,  1037,  2317, 14293,   102],\n",
      "        [  101,  2067,  1999,  1996,  2193,  2043,  5190,  2938,  1999,  3210,\n",
      "          2000,  2131,  3806,  2057,  2018,  2019,  3670,  2005,  1996, 14560,\n",
      "          2008,  2020,  7570, 29154,  2037,  3514,  5472, 25518, 15776,   102],\n",
      "        [  101,  2053,  2027,  2079,  2025,  2065,  2054,  2017,  5136,  2000,\n",
      "          2022,  3837,  2017,  6523,  2000, 12593,  2229, 23368,  2015,  1998,\n",
      "          4004,  2015, 17450, 17086,  1045, 14306,  2017,  2008,  1045,   102],\n",
      "        [  101,  2062, 14163,  2480,  8609,  2112,  1998, 20463,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  2178,  2553,  1997,  2317, 28072,  2008,  2097,  2776,\n",
      "          2599,  2000,  2317,  2679,  5920,  2317,  2111,  2024,  2074,  8239,\n",
      "          5236,  2000,  6148,  2037,  2219, 13614,  8840,  2140,   102,     0],\n",
      "        [  101, 17957,  2026,  2235,  5637,  4632,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2585,  1037,  8359,  3781, 20119,  4070,  5310,  3178,  3283,\n",
      "          2073,  2001,  1996, 25292, 19357,  2140,  4668,  2646, 11503,  8446,\n",
      "          2011,  1996,  2187,  2043,  3021,  5003,  5886,  3615,  2000,   102],\n",
      "        [  101,  5310,  2065,  2008,  3084,  2033, 16939,  2619,  4965,  2033,\n",
      "          1037,  2317,  4197,  6045,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2292,  2025,  5293,  2032, 25553, 23564, 20668,  2025,\n",
      "         21029,  6394, 13425,  1998, 21987, 22555,  2127,  3140,  2145,  4352,\n",
      "          9201, 21850, 10415,  4180, 18993, 22555,   102,     0,     0,     0],\n",
      "        [  101,  2065,  2108,  5637,  2061,  9874,  2100, 11701,  2339,  2079,\n",
      "          2061,  2116,  8292,  2571,  5910,  1998, 14955, 18291,  6962,  2031,\n",
      "          8275, 12743,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4217, 26264, 11721,  2497,  8007,  1998,  2741,  2026,  7514,\n",
      "         14342, 16436,  2391,  2003,  2023,  3124,  2003,  1037,  6530,  9152,\n",
      "         13327,   102,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0260, 0.0970, 0.0970, 0.0970, 0.0970, 0.0970, 0.0970, 0.0970,\n",
      "         0.0970, 0.0970, 0.0970, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.8200, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3160, 0.3160,\n",
      "         0.3160, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3920, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.5640, 0.0390, 0.0390, 0.0390,\n",
      "         0.0390, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0170, 0.9320, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0060, 0.0060, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0060, 0.0060, 0.0060, 0.0850, 0.0850, 0.0850, 0.0850,\n",
      "         0.0850, 0.0850, 0.0850, 0.0850, 0.0850, 0.0850, 0.0850, 0.0220, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0030, 0.0430, 0.0430, 0.0430, 0.0430, 0.1630, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.1630, 0.1630, 0.1630, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.2540, 0.2540, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4360, 0.4360,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2515,  2025,  7025,  1999,  2530,  3032,  2224,  1037,  2714,\n",
      "          2832,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2467, 24415, 29337,  4095, 11106,  2532, 10936,  2016,  7295,\n",
      "         16103,  6962, 14301, 14545,  4048,  5737,  3501,  2256, 22375,  5332,\n",
      "         28911, 10936,  2274,  3634, 10920,  2028,   102,     0,     0,     0],\n",
      "        [  101,  2304,  4783,  2906,  1998,  1053,  2201,  2005,  1996,  3462,\n",
      "          2188,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2108,  2309,  4485,  2003, 17276,  2004,  6616,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  1045,  2052,  2031,  2245,  2009, 23760,\n",
      "         14956,  2063,  1037,  2261,  2086,  3283,  2205,  2021,  2085,  2057,\n",
      "          2288,  6197,  1997,  2317, 28774, 10343,  2667,  2000,  5495,   102],\n",
      "        [  101,  5310,  3449,  7662,  2003, 19483,  2679, 17727, 11124,  2819,\n",
      "          1997,  2158,  2003, 12626,  2100,  6160,  2000,  1996,  2047,  6904,\n",
      "         13871,  4140,  2854,  1048,  2863,  2080,   102,     0,     0,     0],\n",
      "        [  101,  5292,  6429,  6396,  2102,  8275,  2638,  9333,  2024,  2428,\n",
      "          2183,  2083,  1037,  5848, 12475,  2062,  2066,  1037, 19501,  2041,\n",
      "          1999,  1037,  2047,  2259,  2103, 17276,  2067,  8975,  1996,   102],\n",
      "        [  101,  2139,  9152, 13327, 21146, 13327,  2042,  2006,  2026,  4485,\n",
      "          9863,  2005,  1037,  2146,  2146,  2051,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  5637,  9152, 23033,  2097, 10973, 24471,  6181, 17695,\n",
      "          2125,  1998,  2224,  2009,  2000,  2191,  2370,  1037,  4605,  1997,\n",
      "         20943,  1998,  5438,  2009,  2000,  2017,  2068,  9152, 23033,   102],\n",
      "        [  101,  5181,  2024,  2369,  1996,  5152,  4676,  1998,  2111,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2279,  3357,  2003,  2000, 14308,  2008,  7743,  2007,\n",
      "          1037, 14012,  1997, 11611,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2196,  5293,  2065, 18520,  2018,  2180, 23269,  1997,  2353,\n",
      "          2088, 16836,  2052,  2031,  2042, 10964,  1996, 23512,  6997,  1998,\n",
      "          2591, 12554,  2057,  2156,  1999,  2762,  2052,  2031,  2042,   102],\n",
      "        [  101,  5310,  5310, 21357,  2009,  2000,  5181,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2715, 12698,  2024,  3458,  2128,  7559,  5732,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2381, 12011,  2149,  2008,  2044,  2998,  2304,  2998, 23407,\n",
      "          2015,  2079,  2025,  2197,  2146,  2021,  2008,  2011,  2059,  2317,\n",
      "          3337,  1998,  2317,  7307,  2298,  2000,  2022,  2007,  4004,   102],\n",
      "        [  101,  2009,  1037,  8902,  4135, 15549, 13911,  2213,  2005, 12731,\n",
      "          3600,  2017,  5481,  2000,  1996,  3639,  1997,  2023,  2919,  9971,\n",
      "          6881,  2080, 12316,  2094, 22889,  4904,  2008,  2003,  1037,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7840, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0080, 0.4580, 0.4580, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0190, 0.0190, 0.0190, 0.0190, 0.0190, 0.2710, 0.2710, 0.2710, 0.0190,\n",
      "         0.0190, 0.0190, 0.0190, 0.0190, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.4710, 0.0330, 0.1240, 0.1240, 0.1240, 0.1240, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290]]), 'label': tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  1996,  5665, 21646,  8520,  7489,  1998, 14352,  2078,\n",
      "         12256,  5620,  2442,  2025,  5293,  2054,  2027,  2024,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310, 18453,  2100,  2085,  2965,  6595,  2007,  1037,\n",
      "          9680,  2923,  6984,  2056,  9680,  2923,  9846,  2308,  2002, 15504,\n",
      "          1998,  5689,  2006,  2000,  2056,  2158,  2000,  4536,  1999,   102],\n",
      "        [  101,  2821, 15003,  7929,  1045,  2018,  1037,  2428,  2919, 12845,\n",
      "          2005,  2008,  2028,  2021,  1045,  2572,  2074,  6069,  2562,  2026,\n",
      "          2677,  3844,  2002,  5369,  2008,  2052,  5791,  2022,  1037,   102],\n",
      "        [  101,  2821,  1045,  2288,  2122,  7136, 22212,  2015,  5506,  2651,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2115,  3204, 12461,  2580,  1996,  4145,  1997,  2706,\n",
      "          6616,  9152, 13327,  2015,  1998,  2151,  3538,  2065,  4485,  2679,\n",
      "         17328,  2008, 13010,  2005,  2122,  4176,  2065,  2017,  2079,   102],\n",
      "        [  101,  2317,  8871,  4004,  2015,  2024,  2061,  5881,  2039,  1998,\n",
      "         12726,  6616,  2017, 19992, 24008,  2859,  3203,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5355,  2051,  1998,  2004,  2002, 14283,  1996,  4827,  1997,\n",
      "          2010,  4175,  8189,  5897,  2001,  8776,  1998,  2010, 15547,  3672,\n",
      "          2001,  2317,  1998,  1043,  9863,  7999,   102,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310, 11404,  2075,  1999,  1996,\n",
      "          2142,  2163,  2758,  2054,  2055,  5567,  4490,  1997, 14398,  2011,\n",
      "          3010,  3539,  2704, 18301, 24815,  2483,  3039,  2067,  2046,   102],\n",
      "        [  101,  3841, 24630,  2003,  3015,  1037,  2047,  2338,  2055,  1996,\n",
      "          3978,  1997,  2530, 10585,  2182,  1037, 27594,  2121,  1996,  5181,\n",
      "          2106,  2673,  2204,  2764,  3886,  4499,  3765,  7588,  1998,   102],\n",
      "        [  101,  2360,  3649,  2017,  2215,  2055,  8112,  2613,  8083,  3065,\n",
      "         24815,  2072,  9288,  2015,  1997,  9877,  1997,  2111,  4148,  5570,\n",
      "          1996,  2755,  2027,  2061,  6524,  4148,  1999,  2637,  2003,   102],\n",
      "        [  101,  6616,  2017,  2017,  7743,  4632,  9152, 13327, 12731,  3372,\n",
      "          1045,  5223,  2304,  9152, 13327,  2015,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 27593, 15593,  2072,  6933,  2193, 20996, 12053, 16303,  2038,\n",
      "          2196,  2031,  4000,  2005,  2193, 13329,  2072,  7560, 26136, 23194,\n",
      "          2015,  2730, 12364, 15504,  5533,  2185,  2013,  2037,  5014,   102],\n",
      "        [  101,  2644,  7025,  2085,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2183,  2157,  2000,  2026,  2317,  2879,  1999, 15842,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6616,  2023,  5472,  9152, 13327,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24185,  8737, 24185,  8737, 11382,  3489,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0040, 0.0570, 0.2150, 0.2150, 0.0570, 0.2150, 0.2150, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.3350, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0230, 0.0230,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.2960, 0.0210, 0.2960, 0.2960, 0.0210, 0.0210, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0870, 0.3320,\n",
      "         0.0870, 0.0870, 0.0870, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0040, 0.0040, 0.0040, 0.2310, 0.2310, 0.2310, 0.2310, 0.0160, 0.0160,\n",
      "         0.0160, 0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.1730, 0.6550, 0.1730, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.4680, 0.4680, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0180, 0.0180, 0.9650, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  4047,  4841,  1999,  8493,  3655,  2057,  2024,  6778,\n",
      "          3550,  2007,  4816, 16011, 20070,  1998,  6206,  9867,  1998, 28973,\n",
      "          2011,  3026,  6383,  2451,  2372,  1998,  1996,  6206,  7489,   102],\n",
      "        [  101,  2008,  9152, 23033,  8954,  2065,  2002,  3298,  2019, 17727,\n",
      "          7911,  2007,  2053,  9594, 17695,  2015,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  5223,  2017,  1045,  2293,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2323,  2022,  2328,  2006,  5472,  9152, 13327,  2015,\n",
      "          1998,  2060,  9576,  2015,  9343,  2256,  9767,  2000,  3102,  2169,\n",
      "          2060,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2215,  2000,  2113,  2054,  1996, 11904,  2228,  2055,\n",
      "          2017,  2027,  8239,  5223,  2017,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2022,  2595,  8925, 15504,  2012,  2193,  1061,  2869,  1997,\n",
      "          2287,  2193,  1061,  2099,  2214,  2611,  1999, 27456, 15504,  2011,\n",
      "          2193, 22190,  2072,  7486,  2035,  4428,  7206,  1999,  4428,   102],\n",
      "        [  101,  1045,  2001,  5881,  2090,  1045,  2342,  2000,  3828,  2769,\n",
      "          1998,  2017,  2069,  2444,  2320,  2059,  1045,  2253,  2000,  1045,\n",
      "          2572,  5881,  2090,  1045,  2973,  2320,  1998,  2073,  2008,   102],\n",
      "        [  101,  1037,  9220,  2012,  7124, 10034,  2277,  1999,  4068,  2038,\n",
      "          3936,  2008,  1996,  2446, 18079,  2003, 21936,  2471,  2035,  5097,\n",
      "          2005, 11386,  2013,  2010,  2277,  7726,  1998, 12632,  8711,   102],\n",
      "        [  101,  2019, 23238,  2278,  7743,  2229,  2288,  1996,  2190, 22418,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2429,  2000,  3712,  2739,  2151,  3059,  2576,  2283,\n",
      "          2040,  2003, 26355,  2135,  3424,  7521,  3424,  7327,  2024,  9253,\n",
      "         14870,  2015,  2122,  2187,  2666,  4800, 10841,  2140,  9587,   102],\n",
      "        [  101, 19657,  5448,  7743,  2229,  2022,  2006,  9152, 23033,  2015,\n",
      "          2062,  2084,  9152, 23033,  2015,  2022,  2006,  7743,  2229,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 22889,  4904, 25850,  2075,  1997, 12267, 12322, 13033,\n",
      "         12312,  2428, 22132, 17125,  1996,  2053, 13871,  2378,  2065,  2017,\n",
      "          3046,  2000, 24873, 19170,  2115, 11194,  2046,  2437,  6567,   102],\n",
      "        [  101,  5310,  2065,  2017,  2079,  2025,  2156,  1996,  4489,  2090,\n",
      "          6206,  7489,  1998, 10834,  2017,  2079,  2025,  7141,  1999,  2231,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 11338,  2226,  4122,  2054,  7071,  3189,  2011,  5487,\n",
      "          3972, 14366,  2080,  2038,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3424,  7011,  2024,  1996,  2613, 13157,  2158,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25022, 29207,  2102, 24978,  3501,  2860,  5310,  7459, 14068,\n",
      "          2545,  8840,  2140,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0270, 0.3930, 0.3930,\n",
      "         0.0070, 0.0070, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.1970, 0.1970, 0.0140, 0.0140,\n",
      "         0.1970, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1230,\n",
      "         0.4670, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0170, 0.9160, 0.0170, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0120, 0.1760, 0.1760, 0.1760, 0.1760, 0.1760, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0250, 0.0250,\n",
      "         0.3540, 0.3540, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9160, 0.0170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2134,  1521,  1056,  2113, 19031, 24183,  2001,  1999,\n",
      "          4689,  4138,  4004,  2015,  1044,  2232,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2187,  3358,  8801,  4352,  2023,  2005,  1996, 14163, 13213,\n",
      "          8609,  3789,  8183,  9574,  2106,  2025,  4553,  2074,  3038,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2821,  2748,  2292,  5247,  2769,  3847,  8711,  2096,\n",
      "          2025,  2635,  2729,  1997,  2256,  8244,  4658,  4658,  4658,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2614,  2066,  2019, 15703,  8797,  2121,  6904, 13871,\n",
      "          4140,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3291,  2005,  2017,  2003,  2008,  2017,  2079,  2025,  3305,\n",
      "          6747,  2009,  1996, 16134,  1997,  2008,  2470,  2009,  2347,  1056,\n",
      "          2000,  5646,  1037,  3558, 18275,  2009,  2109,  2512, 12064,   102],\n",
      "        [  101,  3087, 19512,  4699,  1999,  9569,  2245,  2030,  8321,  2591,\n",
      "          8570,  2323,  3582,  2023,  2158,  2006, 11721,  2497,  1996,  2755,\n",
      "          2008,  2057,  2031,  6638, 11265, 17603, 11393,  2015,  2006,   102],\n",
      "        [  101,  2512, 11690,  2015,  2041,  2182,  6886,  2105,  1996,  2773,\n",
      "         22212,  2062,  2084,  2070,  1997,  2149,  5025, 11690,  2015,  1996,\n",
      "         21171,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 24815,  2003,  3701,  3625,  1998, 24815,  2072,  2066,\n",
      "          1057,  1054,  6551,  3625,  2644, 24815,  1998,  2088,  2097,  2022,\n",
      "          2172,  2172,  9379,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2228,  1045,  2066, 11721,  2497,  2005,  2048,  4436,\n",
      "          2307,  2033,  7834,  1998,  3752,  2026,  3129,  6685, 16457,  1045,\n",
      "          2777,  1998,  2496,  2023, 23503,  2021,  2429,  2000,  2195,   102],\n",
      "        [  101,  5310,  5310,  2425,  2008,  2000, 11851, 17789,  2030,  2151,\n",
      "          2060, 12873,  9152, 13327,  2008,  2288,  2915,  6012,  3031,  2361,\n",
      "          1997,  1037,  8872,  2045,  2015,  2062,  2303, 28727,  8333,   102],\n",
      "        [  101,  5310,  2821, 10166,  2074,  4342,  2023,  2773,  2083,  2017,\n",
      "          2021,  2106,  2027,  2224,  2009,  2004,  2019, 19804,  7361, 18963,\n",
      "          2009,  2000,  2191,  2009,  2644, 11878,  2068,  2066, 12170,   102],\n",
      "        [  101,  7929,  2073,  1521,  1996, 27071,  9117,  2003,  2023,  1037,\n",
      "          8239,  8257,  1045,  1521,  1049,  2061,  2589,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2995,  2021,  5637,  2111,  2024,  2145,  7854,  1998,\n",
      "          2730,  2012,  1037,  2152,  3446, 12010,  4160,  2336,  2024,  1996,\n",
      "          2922,  2177,  1997, 11573,  3360,  1998,  5637,  2111,  2073,   102],\n",
      "        [  101,  1996,  2317,  2273,  2064,  2102,  2562,  2037,  6471,  2039,\n",
      "          2027,  2024, 29082,  1996, 10823,  4004,  2015,  6696,  2015,  5181,\n",
      "          2123,  2102,  5009,  2115,  3348, 24069,   102,     0,     0,     0],\n",
      "        [  101,  1045,  6592,  2017,  2404,  2023,  9152, 13327,  2006,  2115,\n",
      "          2604,  1997,  5501,  2002,  3849,  2066,  1037,  2204,  2028,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2001,  2941,  2437,  1996,  2553,  4953,  3287,  5344,  3352,\n",
      "          2062,  9253,  6528,  3560,  1998, 12320,  1998,  2931,  5344,  3352,\n",
      "          2521,  2062, 16137, 10841, 22153,  5422,  2158,  3900,  2860,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7840, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7630, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.3050, 0.3050, 0.3050, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.3710, 0.3710, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.1450, 0.5520, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0860, 0.0860, 0.0860, 0.0860, 0.0860, 0.0860, 0.0860, 0.0860,\n",
      "         0.0860, 0.0860, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200]]), 'label': tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2065,  2045,  2001,  1037,  2882, 11933,  8285,  2264, 22304,\n",
      "          2017,  1040,  2022,  2583,  2000,  8954,  2061,  2116,  5968,  4632,\n",
      "          3765,  2013,  1996,  4004,  2015,  2763,  2035,  1045,  2052,   102],\n",
      "        [  101,  5310,  3439,  6123,  5609,  3272,  2005,  2043,  2017,  2215,\n",
      "          2000,  2681,  2041,  1996,  3493,  5845,  2074,  2004,  2919,  2170,\n",
      "          1996,  9152, 13327,  2015,  1997,  2885,  2021,  4931,  2008,   102],\n",
      "        [  101,  2064,  2025,  2079,  4331,  2125,  4179,  2043,  2139,  6914,\n",
      "         22139,  8040,  2819,  2066,  2017,  2491,  1996,  2125,  4179,  2008,\n",
      "          2339,  2057,  2031,  2000,  6859, 11382,  3489, 11895,  3363,   102],\n",
      "        [  101,  2317,  2879,  4312,  3849,  2066,  2023,  2001,  1996, 19336,\n",
      "          2304, 21830,  2542,  1999,  1037,  2160,  2007,  2010,  2450,  1998,\n",
      "          2037,  2219,  4268,  2085,  4283,  2000,  1996, 14068,  2121,   102],\n",
      "        [  101,  2054,  1996,  6616,  2003,  1037,  4586,  9152, 13327,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2530,  2273,  2018,  2921,  2037,  2308,  1999,  7919,\n",
      "         10215, 15180,  1997,  2381,  2087,  9252,  6424,  2027,  2052,  2025,\n",
      "          2031,  2734,  2000, 12324, 15451,  3630,  9496, 14740,  1999,   102],\n",
      "        [  101,  5310, 15624, 27793,  2003,  3087,  4527,  2037,  6984,  2124,\n",
      "          6394,  4172, 11865, 26933,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2006,  1996,  2028,  2192,  1045,  2018,  2000, 20101,  2193,\n",
      "          2030,  2193,  6904, 22772,  6394,  6115,  1998,  2006,  1996,  2060,\n",
      "          2192,  1045,  2031,  2000,  2954, 22529,  2229,  2648,  2023,   102],\n",
      "        [  101,  2225,  5196,  2003,  2440,  1997,  2128,  7559,  5104,  2040,\n",
      "          2074,  3442,  1059,  3145,  2043,  2027,  2156,  2017,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4314,  2128,  7559,  5104,  2175,  4521,  2062, 10401,\n",
      "         26723,  1048,  2863,  2080,  2017,  2031,  2584,  2115, 26007,  1997,\n",
      "         18691,  3012,  1998,  4315, 22043,  3672,  2664,   102,     0,     0],\n",
      "        [  101, 11382, 18774,  9581,  2190,  2879,  2343,  1997,  1996, 27818,\n",
      "          2308,  2252,  2327,  2193, 10469,  2015,  1997,  2035,  2051,  8291,\n",
      "          1997, 11690,  2015,  4086,  3336, 11382, 18774,  9581,   102,     0],\n",
      "        [  101,  5310,  5310,  8037,  6160,  6206,  7344,  9680,  5130,  2138,\n",
      "          1996,  8037,  2031,  2053,  4847,  2005,  2308,  2027,  2069,  2729,\n",
      "          2005,  2373,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  2009,  2010,  2417,\n",
      "         18278,  5542,  3383,  2030,  1996,  2304,  8351,  1997,  1996,  2155,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  7110,  1056,  2130, 11501,  2664,  1998,  9152, 23033,\n",
      "          2015,  4688,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2204,  2851, 22017,  1045,  2572,  2069,  3348,  2923,\n",
      "          3426,  2017,  2024,  7916,  2065,  1045,  2572,  3308,  1045,  2572,\n",
      "          5637,  6616,  2009, 28516,  2879,  3617,  2025,  3543,   102,     0],\n",
      "        [  101,  2049,  1996,  4895,  2611,  1999,  4699,  1999,  1999,  4161,\n",
      "          9040,  2004,  1037,  6994,  1997,  2162,  2193,  2454,  2317,  4268,\n",
      "         15504,  2011, 22190,  2072,  7486,  2003,  4501, 10082,  2012,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1250, 0.1250, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.4760, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6030,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.1950, 0.7380, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0460, 0.0460, 0.1730, 0.1730,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.3890, 0.3890, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.7520, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0290, 0.4200, 0.4200, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260]]), 'label': tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2079,  2025,  3239,  4897,  2033,  7743,  2022,  3835,\n",
      "          2017, 22889,  4904,  3723, 22889,  4904,  9467,  3993,  2140, 26403,\n",
      "          2121, 16374,  1997,  1996,  2301,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  9152, 23033,  2031,  1037,  3336,  2006,  2033,  1045,\n",
      "          8415,  1045,  1521,  2222,  2202,  2041,  1996,  2878,  2155,  3374,\n",
      "          2025,  3374,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  7929,  1045,  6449,  1996, 16358,  3504,  2066,\n",
      "          1037, 14163, 13793,  2063, 16634,  2072,  2717,  2035,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  2193,  2045,  2001,  2193,  2454,  2317,  3017,  2148,\n",
      "         18076,  2085, 11382,  3489,  2024, 24665, 15808,  5358,  2135,  8991,\n",
      "         10085, 28173,  3070,  2216,  2193,  2454,  9379,  2140,  2647,   102],\n",
      "        [  101,  2009,  1037,  2450,  2040,  4447,  2000,  2022,  1996,  3200,\n",
      "          1997,  1037, 22437,  6394,  6519,  7011, 13871,  4140,  2040,  2079,\n",
      "         19068,  1998, 12581, 16999,  2019,  2104, 18655,  2879,   102,     0],\n",
      "        [  101,  2691,  4563, 17901,  2205,  2172, 11620,  5802, 18178,  2213,\n",
      "          9612, 15942,  2078,  8738,  2308,  2913,  2012,  7768,  2223,  2816,\n",
      "          5506,  3597,  2860,  5796, 14905,  2278,  2205, 27885,  3630,   102],\n",
      "        [  101,  2339,  2079,  2025,  1996,  8239,  5472,  9152, 13327,  2015,\n",
      "         15581,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2074,  2562,  7618,  2010,  2317,  4632,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2025,  2113,  2065,  2049,  1996,  2168,  2028,  2021,\n",
      "          3041,  2651,  2027,  2106,  1037,  3189,  2073,  2027, 10263,  1037,\n",
      "          9587, 25016,  2213,  2450,  1999,  1037,  7632,  3900,  2497,   102],\n",
      "        [  101,  5310,  2296,  2051,  1045,  2175,  2000, 10926,  2009,  2062,\n",
      "          6517,  2062, 11573,  2062, 16939, 14921, 17183, 11219,  2075,  8711,\n",
      "          2197,  2051,  1045,  2387, 17732,  1999,  1996,  2380,   102,     0],\n",
      "        [  101,  2562,  2115,  2568,  2006,  1996,  2613,  2227,  1997, 14398,\n",
      "          1996,  2162,  2006, 12461,  4125,  2039,  1998, 15908,  2026,  3428,\n",
      "          2004,  2500,  2031,  2579,  2039,  4808,  2114,  2017,   102,     0],\n",
      "        [  101,  1045,  4952,  2000,  1996,  2168,  2774, 10126,  1045,  2293,\n",
      "          9342,  2532,  1998,  2304,  8091,  2243,  2064,  2027,  1998, 19166,\n",
      "          2713,  2047,  4042,  3531,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 12731,  2015,  8038,  3363,  2070,  6904, 13871, 12868,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053,  2107,  2518,  2004,  4649,  5092, 24920,  2017, 12873,\n",
      "          4632, 22212,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 20277,  2480,  2129,  8108,  2023,  3442,  2317,  3287,  2215,\n",
      "          2000,  2022,  2920,  1999,  2010,  2451,  3046,  2000,  2191,  1037,\n",
      "          4489,  2043,  2045,  2024,  5025,  5907, 10258, 21272,  9099,   102],\n",
      "        [  101,  5310, 12509,  2300,  2006,  2033,  2065,  5637,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0260, 0.0070, 0.0070,\n",
      "         0.0070, 0.3770, 0.3770, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.7220, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.6090, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0260, 0.3740, 0.3740, 0.0070, 0.0070, 0.0070, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.3230, 0.3230, 0.3230, 0.0060, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.4740, 0.4740, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1850, 0.1850, 0.1850, 0.1850, 0.0490, 0.0490, 0.0490, 0.0490, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.7480, 0.1970, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0070, 0.0070, 0.0070, 0.0070, 0.0990, 0.0990, 0.0990, 0.0990,\n",
      "         0.0990, 0.0990, 0.0990],\n",
      "        [0.0130, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.7320, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  6331, 19428,  2149,  2008,  9444,  4932,  2010,  2677,\n",
      "         18536,  2010,  2166,  2002,  2040,  7480,  2898,  2010,  2970,  3310,\n",
      "          2000, 10083,  6011, 15185,  2015,  2193,  2193,   102,     0,     0],\n",
      "        [  101, 20324,  4808,  2965,  2115,  2593,  1037,  7349,  2030,  2019,\n",
      "         10041,  7823,  2831,  2003,  2005,  3969,  3238,  9152, 13327,  2015,\n",
      "          2017,  2323,  4553,  2000,  4485,  2039,  2030,  2228,  3442,   102],\n",
      "        [  101,  2061,  2017,  2024,  2019,  6206, 11560,  2008,  2288, 16154,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  1046,  2015, 22578, 22578,  3501,  1045,  2812,\n",
      "          2017,  2024,  3038,  2017,  2079,  2025,  2729,  2055,  5035,  3426,\n",
      "          2017,  2079,  2025,  2729,  2055,  3769,  2021,  2009,  2025,   102],\n",
      "        [  101,  5310,  2016,  2003,  1037, 12873,  7743,  2040,  1996,  6616,\n",
      "         13783,  9907,  5610,  1999,  2037,  2775,  2227,  2030,  4324,  2068,\n",
      "          2066,  1037,  4365,  9121,  1045,  8239,  5223, 10756,  2040,   102],\n",
      "        [  101,  5060,  2129,  5181,  7887,  2224,  1996, 14161, 22208,  2100,\n",
      "          2027,  2766,  2006, 14938,  2076,  4214,  2035, 19640,  2015, 13157,\n",
      "          2004,  1037,  3104,  2039,  2061,  2008,  6343,  2064,  2655,   102],\n",
      "        [  101,  5310,  6160,  2000,  1996,  2252,  1045,  6866,  2055, 10733,\n",
      "          5867, 11513, 10661,  3606,  2000,  7796, 16222,  2102,  5843,  1045,\n",
      "          2097,  2025,  2128,  6494,  6593,  2028,  2773,  2061,  2009,   102],\n",
      "        [  101,  2043,  1045,  2360,  1045,  2069,  2066,  2698,  2193,  2273,\n",
      "          1045,  2812,  1045,  2069,  2293,  2698,  2193,  2273,  4647, 10047,\n",
      "          8239,  5637,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2035,  7570,  2229,  2131,  7144,  1998,  2074,  2707,\n",
      "          2108,  5379,  2007, 10334,  2066,  2611,  2067,  2039,  2077,  1045,\n",
      "          2202,  2115,  5835,  2059,  7151,  2017,  2091,   102,     0,     0],\n",
      "        [  101,  2298,  2054,  2027,  2052,  2131,  1037,  9582, 29591,  2094,\n",
      "          5870,  4518,  2040,  2499,  2012,  1037,  3026,  2504,  2016,  2052,\n",
      "          4906,  2157,  1999,  2007,  1037,  4314,  2610,  2533,  4439,   102],\n",
      "        [  101,  2821,  2053,  6394, 16980,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2193,  2062, 10818,  4978,  2000, 18230,  1998,  2600,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4302,  8472,  2003,  1037,  8239, 17813,  2065,  2002,  2001,\n",
      "          2005, 28872,  2078,  1996, 15957,  2052,  2022,  2183,  2006,  2055,\n",
      "          2129,  2919,  9404,  2003,  1999,  1996,  2208,  7619, 14071,   102],\n",
      "        [  101,  6034, 29525,  3436,  1997,  7489,  2030,  1037,  5152,  7221,\n",
      "          1045,  2288,  1037,  2488,  2801,  1037,  2193,  2095,  7221,  2006,\n",
      "          2035,  7521,  2167,  2637,  3791,  1037, 24501, 23270,  2063,   102],\n",
      "        [  101,  5310,  3398,  2008,  2015,  3492,  7977,  1045,  6440,  2026,\n",
      "          3756, 17447,  1998, 11382, 13944,  2232,  2007,  6620,  2079,  2025,\n",
      "          2066,  2000,  2022,  4102,  2000,  1037,  6394,   102,     0,     0],\n",
      "        [  101,  5310,  5310, 22563,  2610,  2024, 12318, 22563,  6831,  2004,\n",
      "         10338,  3217, 15395,  2015,  2027,  2074,  2215,  2000,  3102,  2035,\n",
      "         22563,  2111,   102,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0470, 0.0470, 0.0470, 0.0470, 0.1780, 0.1780, 0.0470, 0.0470,\n",
      "         0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0690, 0.0690, 0.0690, 0.0690, 0.2600, 0.2600, 0.0690, 0.0690, 0.0690,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.3770, 0.0990, 0.0070],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.2190, 0.2190, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2190, 0.2190, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0270, 0.0270, 0.3930, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.6950, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0240,\n",
      "         0.0240, 0.0910, 0.0910],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0820, 0.0820, 0.0820, 0.0820, 0.0060, 0.0060, 0.0820, 0.0820, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0060, 0.0060, 0.0820, 0.0820,\n",
      "         0.0820, 0.0820, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0010, 0.0060, 0.0060],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  6933, 11624, 17897,  2099, 14021, 12274, 10603, 20760,  5017,\n",
      "          8057,  2073,  2024,  1996,  8629,  8040, 28600,  2121,  2003,  1038,\n",
      "         20470,  5677,  2075,  2128, 14163,  8093, 17854,  2401,  2123,   102],\n",
      "        [  101,  8945,  3683, 18820,  2213,  2207,  2058,  2193,  3057,  2009,\n",
      "          2018, 11364,  2086,  3283,  2138,  2027,  2024, 14163,  4757, 16930,\n",
      "          2319,  2085,  2065,  3725,  2071,  2074,  2131,  1996, 14163,   102],\n",
      "        [  101,  2293,  2108,  2409,  2011,  2317,  3442,  2111,  2129,  2000,\n",
      "          2514,  2055, 24004, 24920,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2030,  2069,  3058,  4004,  2015,  2593,  2126,  1996,\n",
      "          2317,  2679,  2003,  2757,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3374,  2021,  2053,  2009,  2052, 16475,  2389,  5657,\n",
      "          4494,  1999,  2058, 16340,  8898,  2752,  1045,  1041,  2216,  2752,\n",
      "          2058,  2448,  2011,  7489,  2025,  4480,  2664,  2040,  2057,   102],\n",
      "        [  101,  2054,  1996,  3109,  2298,  2012,  1996,  6394,  6904, 13871,\n",
      "          4140,  2175,  2012,  2009,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1045,  3342, 11178,  2115,  2069,  5142,  2001,  2129,\n",
      "          2000,  2424,  6248,  4620,  1997,  1996,  2308,  1999,  1996,  3861,\n",
      "          1045,  2572,  2469,  2011,  2008,  7615,  2115,  1037,  2613,   102],\n",
      "        [  101,  2051,  2005, 12633,  7743,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  5181,  2052,  2025,  2130,  2342,  2000,  4319,  2008,\n",
      "          7743,  2039,  2017,  2052,  2025,  2130,  2342,  2000,  9040,  2014,\n",
      "          1048,  2213,  4213,  2080,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2021, 22953,  2054,  2055,  2008,  2241,  2931,  9152, 13327,\n",
      "          2236,  8398,  5086, 10424,  8004, 11528,  2241,  2158,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1996,  2512, 12461,  2097,  3582, 11210,  2057,  2175,\n",
      "          2127,  2057,  2175,  4873,  2008,  2057,  2079,  2025,  2292, 15485,\n",
      "          2669,  9077,  5181,  1999,  2007,  2149,  1998,  2907,  2041,   102],\n",
      "        [  101,  5310,  3524,  2149,  7486,  2205,  2919,  2693,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  7714,  8909,  2278,  2055,  2023,  2097,  2009,\n",
      "          2515,  2025,  3043,  2012,  2035,  2174,  1045,  2228,  2009,  2093,\n",
      "          2335,  1057,  2546,  3333,  2013,  2193,  2000,  2193,  2044,   102],\n",
      "        [  101,  6728,  2003,  1037,  5236,  9152, 13327, 19907,  1997,  4083,\n",
      "          2000,  8756,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2488,  2084,  9152, 13327,  2396,  2298,  2012,  2008, 16490,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  6289,  2064,  9826,  2360, 13642,  2196,  2018,  1037,\n",
      "          2784, 13017,  7733,  3347,  2027,  2079,  2025,  2079,  2068,  2182,\n",
      "          9544,  1037,  3835,  2784, 13017,  6904, 13871,  4140,  1998,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550,\n",
      "         0.0550, 0.0550, 0.0550],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3560, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.3560, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.4620, 0.4620, 0.0080,\n",
      "         0.0080, 0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.1660, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.1660, 0.1660, 0.1660,\n",
      "         0.1660, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0540, 0.7760, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.4070, 0.4070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8580, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0000]]), 'label': tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 11867,  2594,  9152, 13327,  5413,  2243,  2024,  2074,  2093,\n",
      "          4973,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2354,  2026,  2304,  2931, 14293,  2006, 10474,  2001,\n",
      "          2460,  2973,  2012,  2560,  1045,  2064,  2831,  2055,  2304,  3314,\n",
      "          2885,  7025,  2187,  3111,  4012, 28397,  6904,  6182,  2229,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  4873,  1999,  2256,  7521,  4277,\n",
      "          2009,  2758,  2027,  2031,  2000,  2022, 17929,  1045,  2031,  3191,\n",
      "          2009,  2085,  2292,  2149,  2156,  2065,  2027,  3582,  2037,   102],\n",
      "        [  101,  2129,  2116,  9042,  8711,  2038,  2577, 18856,  7828,  3240,\n",
      "          2579,  2046,  2010,  2188,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2024,  2069, 13946,  2129,  2128,  7559,  5732,  2017,\n",
      "          2024,  1998,  1045,  2572,  2183,  2000,  3613,  4760,  2129,  2172,\n",
      "          1997,  2019,  4767, 12383,  2017,  2024,  2004,  2092,   102,     0],\n",
      "        [  101,  6719,  2296,  2309,  8239,  2051,  2009,  2145,  9826, 20096,\n",
      "          2033,  2151,  2051,  1045,  2424,  2242,  2008,  4763,  3424,  2317,\n",
      "          2030,  3424,  2530, 10585,  2045,  2003,  2467,  2467,  1037,   102],\n",
      "        [  101,  4252,  2273,  2025,  2000,  9040,  2003,  1037,  2033,  4168,\n",
      "          2008, 18138,  2229,  2033,  2125,  1998,  2009,  2038,  2070,  2308,\n",
      "          2061,  6015,  1997,  2273,  2027,  2228,  2027,  2024,  2183,   102],\n",
      "        [  101,  4647,  2016,  1037, 12316,  2094,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10587,  2022,  2026,  2364, 22889,  4904,  2017, 10657,  4521,\n",
      "          2039,  4521,  2039, 10587,  2022,  2026,  4086,  2293,  2021,  2017,\n",
      "          2003,  2025, 12918,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 24443,  2000,  3795,  5130,  2017,  2323,  2428,  2079,  2070,\n",
      "          2470,  2055,  1996, 17727,  5243, 22729,  2832,  2828, 17727,  5243,\n",
      "          2818,  1996,  2343,  2046,  1037,  3945,  3194,  1998,  3477,   102],\n",
      "        [  101,  2572,  2368,  2057,  2342, 12461,  2193,  2191,  1999, 15338,\n",
      "          4372, 16093,  2546,  4933,  2193,  2562,  2149,  2672,  2500,  4142,\n",
      "          4013, 11560,  4485, 29521,  4641,  6714,  2043,  1057,  2360,   102],\n",
      "        [  101, 17710,  5311, 17516,  2102, 25930,  2239,  6290,  3726,  6285,\n",
      "          9033,  2812,  3057, 11895,  7743,  2017,  2699,  2000,  2079,  7680,\n",
      "          2066,  1996, 13958,  2021,  2017, 24723,  5506,   102,     0,     0],\n",
      "        [  101,  2317,  3124,  2009,  1037,  6965,  5690,  2317,  3124,  2027,\n",
      "          2024,  1037, 11404, 11240,  2317,  3124,  1999,  2008,  2406,  2027,\n",
      "          5466,  6904, 13871, 12868,  2125,  1997, 23308,  2015,   102,     0],\n",
      "        [  101,  1997,  2522,  8557,  1996,  3644, 26171,  4152,  7007,  2000,\n",
      "          5631,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2017,  2428,  2228,  2023,  2304, 17276, 17219,  2052,\n",
      "          3233,  1037,  3382,  2014,  3129,  2001,  1037, 10916,  1998,  2111,\n",
      "          2113,  2016,  2001, 16939,  2985,  2769,  2066,  2009, 11333,   102],\n",
      "        [  101,  2339,  2106,  2440,  6271, 22555,  2074,  3769,  2039,  2006,\n",
      "          2026,  1056,  2140,  2029,  2028,  1997,  2017,  9152, 13327,  2015,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.3250, 0.3250, 0.3250, 0.0060, 0.0060, 0.0060, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0430, 0.6250],\n",
      "        [0.1290, 0.1290, 0.1290, 0.1290, 0.1290, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0340, 0.0340, 0.0340, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0170, 0.0170, 0.0170, 0.9480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.7320, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2550, 0.2550, 0.2550,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6810,\n",
      "         0.0470, 0.0470, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2000, 0.2000, 0.2000, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2498,  2062,  2084,  7642,  9680,  5130,  2119,\n",
      "          1997,  2068,  2002, 15504,  2308,  1998,  2137, 26457,  1998,  2016,\n",
      "         15504,  2637,  1998,  1996,  2137, 26980,   102,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  2003,  2601,  1996, 16434,  2001,  9577, 16877,\n",
      "          6708,  2003,  4689,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  2019,  8586, 27364,  2389,  2021,  1045,  2109,\n",
      "          2000,  2031,  2111,  3298,  2627,  2033,  7491,  3102,  4426,  2017,\n",
      "          7861,  2080,  6904, 13871,  4140,  2043,  1045,  2939,  2091,   102],\n",
      "        [  101, 10317,  6149, 22822,  2239,  6796, 19817, 27627,  1997,  2710,\n",
      "          2040, 13135, 24663,  6367,  1996,  2149,  2005,  2037,  5741,  7521,\n",
      "          7221,  2013,  5152,  3484,  3741,  2409, 10582,  6962,  2025,   102],\n",
      "        [  101,  1996,  5152,  2190,  4818,  3012,  1998, 21877,  3527, 21850,\n",
      "          6632,  2982,  5310,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2145,  1999,  5981,  2006,  3251,  2030,  2025,  2009,\n",
      "         16011,  2030,  2023,  3124,  2074,  2108,  2428,  2204,  2012, 12814,\n",
      "          1037,  2466,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5223,  2317,  7743,  2229,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  1037, 14764,  2008, 12461,  2020,  2025,  1996,  2034,\n",
      "          6658, 17794,  1517,  2009,  2001,  1996,  9587, 25016,  5244,  1996,\n",
      "         22889, 29553,  2020,  1996,  2034,  7179,  2076,  1996,  9587,   102],\n",
      "        [  101,  5310,  1045,  2215,  2000,  8595, 19817, 27627,  2059,  2216,\n",
      "          5152,  2229,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2304,  2158,  8563,  1037,  2317,  2775,  1999,  1037,  9680,\n",
      "          2678,  2498,  2941,  6433,  2317,  2158,  2758,  9152, 13327,  2006,\n",
      "          1037,  7858,  2678,  4748, 16874, 17288,  2015,  4558,  2037,   102],\n",
      "        [  101,  2008, 12446,  8621,  2655,  3465,  1996,  9058,  1996,  2208,\n",
      "          2365,  1997,  7743,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  5377, 13423,  2391,  2182,  2003,  1999,  2344,  2000,\n",
      "          6848,  2312,  2967,  1997,  2111,  2057,  2031,  2000,  3066,  1999,\n",
      "         20185,  2025,  3633,  2045,  2024,  7564,  1997,  6047, 10823,   102],\n",
      "        [  101,  4314,  6616, 26016, 11382,  3489, 10916,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2200,  2092,  2056,  2025,  2296,  6904, 13871,  4140,  2003,\n",
      "          5637,  1998,  2025,  2296,  5637,  2003,  1037,  6904, 13871,  4140,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2941,  2017,  2024,  2074,  1037,  2128,  7559,  5732,  6904,\n",
      "         13871,  4140,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7570,  2229,  2024, 15703, 27793,  3215,  2024, 15703,  2029,\n",
      "          2024,  3492,  2172,  1996,  2168,  2317,  4903,  2140,  2024, 15703,\n",
      "          3009,  2111,  2024, 15703,  1998,  4004,  2015,  2024,  2205,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0580, 0.2200, 0.2200, 0.2200, 0.2200, 0.0580, 0.0040, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0340, 0.4830, 0.4830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.1940, 0.0510, 0.0510, 0.0510,\n",
      "         0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.1940, 0.0510, 0.0510, 0.0510,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0500, 0.0500, 0.0500, 0.0500, 0.0130, 0.0130, 0.0500, 0.7130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6450, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0060],\n",
      "        [0.0170, 0.0170, 0.9480, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0300, 0.0300, 0.0300, 0.0300, 0.4350, 0.4350, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.5570, 0.0100, 0.0100, 0.1470, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100]]), 'label': tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2156,  1045,  5993,  2007,  2008,  3867,  1996,  3145,  2003,\n",
      "          3601,  2009,  5310,  2040,  2515,  2025,  4025,  2000,  2903,  1999,\n",
      "          3601,  2016,  6732,  3071,  2323,  2022,  2066,  2014,  1045,   102],\n",
      "        [  101,  1053,  2129,  2116,  2808,  2020,  2517,  1999,  3088,  2077,\n",
      "          2317,  1998, 14560,  3662,  2039,  1037,  3904,  2027,  2018,  2196,\n",
      "          2764,  1037,  2517,  2653,  2304,  2273,  2193,  1997,  1996,   102],\n",
      "        [  101,  5310,  2515,  2009,  3043,  2065,  1045,  2001, 15807,  2228,\n",
      "          2055,  1996,  2155,  1997,  1996,  5920,  6778,  2017,  2024,  2061,\n",
      "          2128,  7559,  5732,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2070, 11382,  3489,  4485,  2157,  2182,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8840,  2140, 18520,  7207,  2770,  2005,  2343,  2339,\n",
      "          2038,  2016,  2025,  2042,  2699,  2005, 14712,  1998, 16011,  1997,\n",
      "          2343,  8398,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2023,  2003,  1037,  5499,  5047,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  2008,  2052,  2022, 11235,  3779, 11235,\n",
      "         27263,  7088, 10695,  2100,  2300, 10199,  2239,  3661,  8758, 26352,\n",
      "         11097,  3779,  2017,  3809,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1048,  2863,  2080,  2070,  4735,  2317,  7743,  4152,  1037,\n",
      "          3962,  2006,  3795,  2739,  2005,  2014,  3899,  4485,  3769,  9781,\n",
      "          2449,  2096,  2145,  2108,  2006, 17393,  8484, 21746,   102,     0],\n",
      "        [  101,  5310,  2033,  2000,  2017,  2030,  1045,  2572,  2066,  2017,\n",
      "          2113,  2054,  1045,  2202,  2009,  2067,  6616,  2017,  2205,  7570,\n",
      "          2063,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3913,  2091,  2008,  3778,  2006,  1996,  2065, 12031,  9152,\n",
      "         23033,  2015,  2008,  2097,  2025, 11679,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2085,  2002,  3310,  7158,  3648,  5121,  2028,  1997,  1996,\n",
      "         22302, 11081,  2745, 10905,  2053, 24004,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2193,  2866, 12616,  2920,  1999,  1996,  3104,  2039,  1997,\n",
      "          2193,  2454,  2317,  2336, 15504,  2011, 22190,  2072,  7486, 12897,\n",
      "          2035,  1997,  2017, 18294, 21123,   102,     0,     0,     0,     0],\n",
      "        [  101,  5273, 14303,  2026,  2567,  2351,  1997,  2019,  6728,  3695,\n",
      "          3593, 26641,  2129,  2064,  2017,  8081,  2008,  2703, 11265,  7317,\n",
      "          2368,  2009,  3100,  2000,  2022,  2317,  5273, 14303,  7929,   102],\n",
      "        [  101,  2085,  2043,  2619, 12386,  2019,  3239,  2030,  2037,  2166,\n",
      "          4647,  1037,  2317,  2711,  4122,  2000,  6033,  2477,  2005,  4485,\n",
      "          2015,  1998, 26466,  2059,  2054,   102,     0,     0,     0,     0],\n",
      "        [  101,  2022,  8059,  1997,  3537,  2283,  2027,  1054,  6035,  2007,\n",
      "          5152,  2967,  2933,  2000,  4487, 11512,  9286,  3265,  2916,  2128,\n",
      "         26373,  4552, 16500, 15523,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2021,  1045,  2572,  2074,  2025,  2130, 14036,  5236,  9152,\n",
      "         13327,  7961,  4902,  2651,  1048,  2863,  9541,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0010, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.9320, 0.0170, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8750, 0.0610, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0280, 0.4040, 0.4040, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.3440, 0.3440, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0420, 0.0420, 0.0420, 0.0420, 0.1580, 0.1580, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.1580, 0.1580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1350, 0.1350, 0.5110,\n",
      "         0.1350, 0.0090, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101, 13325,  2011,  2115,  2128,  7559,  5732, 14123,  2100,  9669,\n",
      "          1045,  3811,  4797,  2115,  4632,  2038,  2151,  2360,  4953,  2137,\n",
      "          6043,  1998,  6195,  1045,  2572,  2019,  2137,  6926,  2017,   102],\n",
      "        [  101,  2339,  2003,  1037,  5637, 11382,  3489,  3228,  1037,  4613,\n",
      "          2055,  2009,  2108,  7929,  2000,  2022,  2317,  1045,  2245,  2010,\n",
      "         12604,  4502, 27659,  2001,  2028,  1997,  2193, 23458, 11382,   102],\n",
      "        [  101, 18542,  2696,  3769,  8091,  9388, 11239,  2721,  2064,  2025,\n",
      "         15876,  3367,  4115,  2023,  9152, 13327,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748,  3071,  2040,  2003,  2025,  1037, 20199, 27065,  2317,\n",
      "          3017,  2158,  2003,  2104,  2890, 28994, 14088,  1999,  2256,  2231,\n",
      "          1998,  2009,  1037,  3291,  2174,  2053,  4767,  2003,  2625,   102],\n",
      "        [  101,  3147, 12559,  3461,  1996,  5923,  2097,  2022,  2404,  1999,\n",
      "          1996,  4030, 16546,  2099, 11585,  2007,  2070, 12486, 25659,  2015,\n",
      "         24444,  8292,  3917,  2100,  2005,  1037, 20717,  2100, 11350,   102],\n",
      "        [  101,  5310,  2017,  2064,  3524,  6229,  1996,  5353,  2043,  2115,\n",
      "         11666,  2131, 15504,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  2001,  2178, 14163,  2480,  8609,  9452,  2886,  2079,\n",
      "          2025,  2903,  1996,  2071,  2025,  2131,  4201,  8016,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2059,  2017,  2024,  2128,  7559,  5732,  2029,  2003,\n",
      "         17704,  2995,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2004,  2146,  2004,  2017,  2113,  9152, 13327,  2015,  1998,\n",
      "         10823,  2024,  2025,  1996,  2168,  2066, 11560,  1998,  6206, 11560,\n",
      "          2024,  2025,  1996,  2168,  2079,  2025,  7518,  2009, 13229,   102],\n",
      "        [  101,  1996, 10558,  2097,  8556,  2023, 11611,  2886,  2021,  2079,\n",
      "          2025,  2031,  1996,  4219,  2000,  8556,  2402,  3057,  2108, 15504,\n",
      "          2011,  8239,  8494, 14540, 14428,  2015,  2051,  2005,  1037,   102],\n",
      "        [  101,  2178, 10467,  1997,  2054,  1037, 11809,  8257,  1996,  2866,\n",
      "          2610,  2024,  2926,  2128,  7559,  5732,  2000,  4604,  2048, 23206,\n",
      "          2308,  2000, 10439,  2890, 22342,  1037,  9680,  2923, 12361,   102],\n",
      "        [  101,  9152,  9354,  3215,  2424,  5510,  1997,  4485, 19424,  2062,\n",
      "          2000,  2272,  2004,  2023,  2466, 11791,  6131,  2278,  3570, 14409,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  7039,  2026,  9165,  1998,  1045,  2572,  3867,  2317,\n",
      "          2064,  1045,  2360, 10047,  2074,  2013,  2028,  3842,  2053,  2021,\n",
      "          2026,  2679,  2003,  5760,  2052,  1045,  2689,  2026,  2568,   102],\n",
      "        [  101,  2017,  2024,  5791,  1037, 16054,  2017,  2074,  2079,  2025,\n",
      "          2031,  2008, 14818, 14974,  2008, 22212,  2015,  2031,  9826,  2017,\n",
      "          2024,  3228,  2033,  2350,  7872, 21209,  2015,  2017,  2024,   102],\n",
      "        [  101,  2017,  2113,  2008,  2216, 16711,  3619,  2024,  2035,  5152,\n",
      "          5472,  9152, 13327,  2015,  2008,  2215,  2000,  3443,  2037,  2219,\n",
      "          5472,  9152, 13327,  2110,  1999,  2885,  2157,   102,     0,     0],\n",
      "        [  101,  3801,  2360,  9152, 23033,  2015,  7110,  4485,  1998,  2175,\n",
      "          3046,  1042,  2860,  2178,  2931,  2043,  2878,  2051,  2027,  2025,\n",
      "          4485,  4445,  2085,  2017,  5506,  2012,  3093,   102,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0960, 0.0960, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0250, 0.0250, 0.0250, 0.0960, 0.0960,\n",
      "         0.0960, 0.0960, 0.0960],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.7650, 0.0530, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3180, 0.0840, 0.0840, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0840, 0.0840, 0.0840, 0.0840, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0320, 0.0320, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.4580, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0320, 0.0320],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0910, 0.0060, 0.0060, 0.0060, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0910, 0.0910, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0910, 0.0910],\n",
      "        [0.1840, 0.0480, 0.1840, 0.1840, 0.1840, 0.1840, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0860, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3280, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0470, 0.1800, 0.1800,\n",
      "         0.1800, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1800, 0.1800,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3180,  2851,  3533, 12130,  2928, 11085,  4842,  2378,  2003,\n",
      "         15677,  2438,  2000,  1056, 28394,  2102,  2055,  1996,  2047, 18059,\n",
      "         10250, 19879,  4263,  2008,  2042,  2041,  2005,  3134,  2994,   102],\n",
      "        [  101,  5310,  1045,  8415,  3389,  8117,  7570,  2097,  5147,  2735,\n",
      "          2033,  5637,  2100,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2024,  2017,  1037, 17203, 10916,  2040,  2990,  2015,\n",
      "          2125,  2000,  1037,  8494,  7377,  8024,  2040,  2052,  2025, 18138,\n",
      "          2006,  2032,  2065,  2002,  2020,  2006,  2543,  2718,  2039,   102],\n",
      "        [  101,  5310,  2065,  2017,  2024,  3752,  2023,  2017,  2024,  1037,\n",
      "          6904, 13871,  4140,  1045,  2572,  2074,  2033, 26432,  3070,  1998,\n",
      "          1037,  2978, 11471,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2193,  2924,  7025,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10892,  2016,  2003,  1037, 17328,  2000,  2637,  2016,  2003,\n",
      "          2667,  2000,  2131,  2979, 21146,  4360,  2375,  2029,  2003,  1999,\n",
      "          3143, 11371,  1997,  2256,  4552,  2016,  2323,  2085,  2022,   102],\n",
      "        [  101,  2017,  9152, 23033,  2015,  6904, 13871, 12868,  5128,  2017,\n",
      "          2035,  2398,  2006,  3801,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6396,  2335,  2022,  2035,  2066,  3113,  2023,  2241,  2193,\n",
      "          2095,  2214, 25283,  4890,  2040,  2074,  2234,  2041,  2004,  5637,\n",
      "          1999,  2392,  1997,  2010,  2193, 11690, 26572, 22591, 13288,   102],\n",
      "        [  101,  2008,  2442,  2022,  2339, 14163, 13793,  2229,  5223,  6077,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3424,  7011,  2003,  2747,  5255,  2673,  1999,  4356,  1998,\n",
      "          6012,  2111,  2039,  3233,  2091,  2619,  2003,  5008,  2023,  2082,\n",
      "          2039,  3233,  2091,  2045,  2024,  1037,  9129,  1997,  6206,   102],\n",
      "        [  101,  2002,  2055,  2000,  2022,  3058, 15504,  2029,  6433, 10453,\n",
      "          2006,  2023,  2265,  2061,  2053,  2502,  6292,  4593,  2821, 11535,\n",
      "          2821,  4202,  2821, 11535,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2913,  2265,  2512, 12461,  3193,  4071,  3294,  2367,  2084,\n",
      "         12461,  2005,  2742,  2193,  1997,  6696,  2015,  3193,  5223,  4613,\n",
      "          2004,  2019,  2552,  1997,  4808,  2029,  2965,  2027,  2052,   102],\n",
      "        [  101,  1045,  2145,  2228,  4273, 10823,  2024,  5410,  2469,  2027,\n",
      "          2064,  2131,  1037,  5883,  2019,  2915,  2619,  2214,  2030,  6680,\n",
      "          2021,  2044,  2008,  2027,  2024,  2027,  2024,  3733,  2004,   102],\n",
      "        [  101,  2272,  2006,  3531,  2017,  9471,  2017,  2024,  2013,  2885,\n",
      "          2017,  2228,  2167,  3088,  2003,  2304,  2017,  2202,  3653, 13598,\n",
      "          2015,  2005,  7402,  2015,  2059,  2005,  6505,  2024,  2017,   102],\n",
      "        [  101,  2064,  2619,  3531,  2424,  2041,  2065,  2023,  3648,  2003,\n",
      "          2028,  1997,  2068,  3504,  2066,  1037, 19888,  2080,  6904, 13871,\n",
      "          4140, 11382,  3489,  2000,  2033,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2122, 26319,  2024,  2061,  2128,  7559,  5732, 26044,\n",
      "          2063,  7110,  2102,  2652,  1037,  3729,  2213,  1998,  2145,  2038,\n",
      "          2714,  6984, 26319,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.1380, 0.5230, 0.1380, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.6110, 0.0110, 0.0110, 0.0110, 0.0420, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0130, 0.1890, 0.7180, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2360,\n",
      "         0.2360, 0.0040, 0.0040],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450, 0.0450,\n",
      "         0.0450, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0040, 0.0040, 0.0040, 0.2110, 0.2110, 0.0560, 0.0560, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0560, 0.0560, 0.0560,\n",
      "         0.0560, 0.0560, 0.0560],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0860, 0.0860, 0.0060, 0.0060, 0.0060, 0.0860, 0.3260, 0.3260,\n",
      "         0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1037,  4485, 19894,  2515,  2025,  1041, 16211,  2618,  2000,\n",
      "          3225,  1037,  8476,  2074,  2000, 11867,  7974,  6721,  8635,  1998,\n",
      "          2017,  2024,  6984,  1996,  8239,  5472,  9152, 13327,  2015,   102],\n",
      "        [  101,  9152, 23033,  2015,  2064,  2022,  9444,  2027,  2215,  2000,\n",
      "          2022,  1999,  1056, 28394,  3215,  2288,  2000,  3342,  2008,  2043,\n",
      "          2017,  2024,  3784,  5306,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 21881, 18746,  2214,  3203, 14236, 14383,  3981,  4942,  2502,\n",
      "          2304,  5980, 27263,  2015,  3835,  3348, 10658,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2323,  2022,  1037,  2375,  2008,  3087, 18625,  1996,\n",
      "         11300,  2552,  2442,  2022,  7743, 11159,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  8415,  7424, 17059,  1998,  5472,  9152, 13327,  2015,\n",
      "          2031,  2053,  3932, 18971,  2065,  1996, 11382,  9681,  2020,  6183,\n",
      "          2005,  2647,  9230,  2046,  3088,  1998,  1996,  2690,  2264,   102],\n",
      "        [  101,  4365,  2009,  7168,  4402,  2140,  4487,  3366, 13344,  8545,\n",
      "          2989,  2001,  2026,  6517,  6553, 12832,  1997,  1996,  2154,  2007,\n",
      "          2122,  8466,  1996,  9152, 13327,  3786,  2033,  2000,  2009,   102],\n",
      "        [  101,  1045,  2572,  2145,  6575,  2005,  1037,  9379,  5472,  9152,\n",
      "         13327,  5152,  7025,  2003,  1996,  4676,  1997,  3521,  2027,  2562,\n",
      "          4129,  2149, 23848,  2050,  2302,  7486,   102,     0,     0,     0],\n",
      "        [  101,  5310,  2138,  2317, 22052,  2015,  7868,  1996,  2972,  2088,\n",
      "          2003, 17156,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  7864,  2026,  3259,  6378,  2055,  5637, 16861,  1999,\n",
      "         12006,  2009,  6798,  1998,  3651,  1045,  2071,  2031,  3867,  2589,\n",
      "          1037, 19483,  3752,  1997,  2611,  6010,  2088,  2612,  1042,   102],\n",
      "        [  101, 11504,  2002,  4152,  9436,  1997,  1996,  6904, 13871, 12868,\n",
      "          1998, 22212,  2015,  2279,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3398,  2009,  1037,  6517,  2005,  1999,  2637,  2043,  2317,\n",
      "         10514, 28139, 22911,  5130,  2707,  1037,  4808,  6186,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748,  2138,  1037,  2171, 16463,  2040,  2003,  1037, 11382,\n",
      "          3489,  1998,  2040,  2003,  2025,  5525,  1045,  2572,  2074,  2004,\n",
      "          2172,  1037,  2440, 26064,  2446,  2004,  2026,  2307,  2882,   102],\n",
      "        [  101, 12495, 25832,  2003,  1996,  4602, 10687,  2000,  2033,  1998,\n",
      "          2009,  2025,  2138,  2002,  2317,  2030,  2138,  1997,  2129,  2116,\n",
      "          5661,  2002,  2515,  2030,  2515,  2025,  2219,   102,     0,     0],\n",
      "        [  101,  5310,  2017,  1521,  2128,  2128,  7559,  5732,  2065,  2017,\n",
      "          2903,  2023,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2074,  2288,  4137,  2000,  4339,  1037,  3259,  2006,  2129,\n",
      "          7901, 14398,  2003,  2025,  2613,  1999,  1037,  2465,  2440,  1997,\n",
      "          2317,  4903,  2140,  2017,  2035,  2113,  1045,  2288,  2023,   102],\n",
      "        [  101,  2017,  2035,  4851,  2008,  2317,  4632,  2158,  2000,  2811,\n",
      "          3246,  2055,  1996, 27166,  2015, 21438,  2003,  1996,  5662,  2000,\n",
      "          2043,  6108,  2380,  3764,  2000,  2317,  4632,  2158,  2193,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0740, 0.0740, 0.0740, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0740],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.4470, 0.4470, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0860, 0.0860, 0.0060, 0.0860, 0.0860, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0020, 0.0020, 0.0860, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0230, 0.0230, 0.0860],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7320, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3590, 0.3590,\n",
      "         0.0950, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0250, 0.0250, 0.0250, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.0310],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0300, 0.0300, 0.0300, 0.4250, 0.0300, 0.4250,\n",
      "         0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6610,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.8720, 0.0160, 0.0160, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2572,  6427,  2008,  2439, 14829, 13583,  2041,  1997,\n",
      "          1996,  2160,  2000,  2175,  1998,  3945,  2005,  2008,  2028, 10818,\n",
      "          3564,  1999,  1996,  2690,  1997,  1996,  2346,   102,     0,     0],\n",
      "        [  101,  2052,  2025,  2009,  2022,  6057,  2065,  2137, 10823,  1998,\n",
      "          4916,  2015,  2020,  2183,  2105,  6012,  1996, 10231,  2041,  1997,\n",
      "          5152, 14560,  1996,  4314,  2865,  2052,  4257,  4558,  2037,   102],\n",
      "        [  101,  5830,  2739,  4297,  2140,  4419,  2003,  7078,  2046,  3917,\n",
      "          3085,  2085,  2027,  2031,  1037,  2261,  4603,  8845,  2021,  2057,\n",
      "          1996,  2270,  2024,  5968, 28037,  2011,  1037,  7700,  1997,   102],\n",
      "        [  101, 11558,  2003,  9587, 25016,  2213,  2406,  1996, 12043,  2003,\n",
      "          2108,  5338,  2007,  8381,  1997,  6544,  4998,  2013,  1996,  2060,\n",
      "          5571,  2008,  2515,  2025,  2130,  2191,  3168,  2065,  6544,   102],\n",
      "        [  101,  5310,  2129,  2097,  2017,  2644,  1996,  3097, 11099,  1997,\n",
      "          6206,  7489,  6830,  2059,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  2667,  2000,  3275,  2041,  2339,  1037,  2158,\n",
      "          2052,  2175,  2000,  1037, 11690,  4101,  2000,  4392,  4157, 16780,\n",
      "          2498,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2429,  2000,  6825,  2651,  2932,  2308,  5247,  2193,  2847,\n",
      "          1997,  2037,  3268,  6933,  6168,  1038, 29027,  2229,  5247,  3599,\n",
      "          1996,  2168,  3815,  1997,  2051,  2025,  4209,  2054,  1996,   102],\n",
      "        [  101,  2026,  4847,  2005,  3956,  2097,  2175,  2039, 24256,  2065,\n",
      "          2027,  2318,  4214,  2041,  2037,  2522,  4676,  5130,  2040,  2031,\n",
      "          2042,  6183,  1996,  7486,  3031,  2149,  2037,  9253,  8663,   102],\n",
      "        [  101,  2137, 17276, 11669,  2003,  2061,  4340,  2000,  5245,  1996,\n",
      "         23300,  2057,  6728, 28994,  2098, 11376,  2008,  2027,  2805,  2317,\n",
      "          5586,  2079, 28060,  2906,  2000,  2022,  2343,  1997,  1996,   102],\n",
      "        [  101,  2017,  2288,  5223,  2039,  1999,  2115,  2540,  9152, 23033,\n",
      "          2008,  2115,  5221, 28450,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2029,  3827,  2003,  2002,  2183,  2000,  2057,  2342,  2000,\n",
      "          2131,  2023,  3124, 15504,  1998,  5920,  2094,  1999,  2010,  3526,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  7151,  6305,  5802,  2347,  2102,  2005,  8650,  5181,\n",
      "          2001,  2005,  2054,  3047,  1999,  3607,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009, 19424,  2129,  1045,  2156, 10823,  7438,  2037,  4176,\n",
      "          2041,  2182,  1999, 12948,  2122, 17276,  2111,  2024,  2061,  1044,\n",
      "         22571, 10085, 14778,  7476,  2034,  2000, 17612,  2055,  2129,   102],\n",
      "        [  101,  5310,  3524,  2054,  7402,  2158,  2040,  8007,  2046,  9282,\n",
      "          6670,  2440,  1997,  2317,  4497,  7347,  5338,  2007, 10130,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2292,  2149,  2707,  2007,  3097, 17347,  2339,  2079,\n",
      "          2017,  2228,  2027,  2323,  2022,  3039,  2000,  3747,  2576,  2373,\n",
      "          1998,  2052,  2115, 13165,  2907,  2995,  2065,  2027,  2020,   102],\n",
      "        [  101,  6904, 13871,  4140,  2057,  6614,  2000,  2031,  1037, 14870,\n",
      "          9052,  4574,  2017,  6904, 13871, 12868,  2031,  6737,  2006,  1042,\n",
      "          2497,  1998, 10474,  2073,  2057,  2024,  8292, 29577,  2098,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0260, 0.0260, 0.0260, 0.0070, 0.0070,\n",
      "         0.3800, 0.3800, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510,\n",
      "         0.0510, 0.0510, 0.0130],\n",
      "        [0.0060, 0.0060, 0.0240, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1430, 0.1430,\n",
      "         0.1430, 0.1430, 0.0100],\n",
      "        [0.0200, 0.2850, 0.2850, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0200, 0.0200,\n",
      "         0.0200, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0200,\n",
      "         0.0200, 0.0050, 0.0050],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0310, 0.0310, 0.0310,\n",
      "         0.0310, 0.0310, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190, 0.1190,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2620, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0180, 0.0180, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.1010, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.1010, 0.1010, 0.1010,\n",
      "         0.0070, 0.3810, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070]]), 'label': tensor([1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  6947,  2008,  2017,  2024,  2128,  7559,  5732,  2138,\n",
      "          2017,  2377, 12202,  2008,  2025,  2130,  8321,  1048,  2863,  2080,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  2175,  2067,  2000,  2115,\n",
      "          2694,  9117, 11669,  1998,  4952,  2000, 13229,  2070,  2062,  2151,\n",
      "          4490,  1997,  4808,  2003, 19424,  2187,  2030,  2157,   102,     0],\n",
      "        [  101,  2009,  2003,  9643,  2298,  2012,  2088, 28321,  4004,  2015,\n",
      "          2024,  8239,  7249,  2178, 14583,  2317, 14052,  2003,  2613,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1056,  6392,  2099,  3844,  2039,  1998,  3102,  5472,  9152,\n",
      "         13327,  2015,  2005, 14163,  2232,  1045,  2480,  6820,  2140,  2175,\n",
      "         10139,  2213,  2017,  2024,  2182,  2000,  3710,  2025,  2000,   102],\n",
      "        [  101,  8275,  5152,  6778,  9021,  9875, 11937, 15549, 19903,  9875,\n",
      "          3658, 17207,  8167, 20093, 10255,  2370,  8275,  5081, 22028,  4727,\n",
      "          8038,  6491,  2378,  7367, 19845,  2094,  6270, 10798,  2886,   102],\n",
      "        [  101,  5310,  5310,  2633,  1037,  2450,  2008,  2003,  2465,  1998,\n",
      "          2025,  1037,  2317, 11669,  2100,  2028,  2066,  2216,  5208,  2057,\n",
      "          2024,  5305,  1997,  3773,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 10514,  9126, 25152,  6777,  2072,  2001, 20361, 15504,\n",
      "          1998,  7129,  1998,  1043, 11774,  2100,  2155,  6643,  9397,  2226,\n",
      "          2106,  2009,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2084,  2891,  2061,  6728, 22953,  2066,  2129,  2023,  9152,\n",
      "         23033,  2663,  2067,  2000,  2067,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2024,  1996,  2028,  4526, 12873,  4895, 11020,\n",
      "         11638, 18513,  3408,  2000,  2490,  2115, 13072, 14818,  4632,  2040,\n",
      "          5506,  1998,  4689,  2085,  2129,  2024,  2057,  2108,  1044,   102],\n",
      "        [  101,  5310,  4165,  1037,  2978,  8401,  2017,  2106,  2025,  2360,\n",
      "          2505,  5223,  3993,  2011,  2151,  3382,  2059,  2153,  2033,  5102,\n",
      "          1999,  1037, 24405,  1998,  4214,  1996,  2613,  2033,  1037,   102],\n",
      "        [  101,  2085,  2008, 16824,  9680,  2923,  3235, 21179,  2075,  7007,\n",
      "          2010,  1056, 16279,  1998, 20160, 10362, 20968,  2005,  1037,  7570,\n",
      "          2080,  5292,  2232, 14571,  1997,  1996,  2329, 26980,  2002,   102],\n",
      "        [  101,  2593,  2008,  2030,  2017,  2024,  1037,  2128,  7559,  2094,\n",
      "          2040,  2515,  2025,  3305,  2008,  1996,  2773,  5157,  2003,  7661,\n",
      "          8486,  2135,  2109,  2043,  2041, 16992,  2576,  3289,  2130,   102],\n",
      "        [  101,  2158,  2017,  2024,  2035, 11043,  1996,  2811,  7460,  2000,\n",
      "          1996,  2784,  2110, 18856,  9912,  2015, 17328,  2015,  1998, 21392,\n",
      "          4691,  3419,  8645,  6736,  9413,  3995,  2193,  3867,  4997,   102],\n",
      "        [  101,  2057,  2031,  2018,  1037, 14163, 13793,  2063,  3291,  2144,\n",
      "          2008, 27756, 21877,  3527, 12619,  2318,  2010,  2331,  8754,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2027,  5223,  2017,  2005,  2108,  2613,  2074,  8568,\n",
      "          2008,  4485,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8840,  2140,  2085, 10047,  5191,  1045,  2097,  2695,  2026,\n",
      "         11225,  2039,  2004, 18411,  2015,  4042, 27263,  2015,  1998,  2619,\n",
      "          2003,  6069, 24234,  2033,  2005,  2108,  5152,  1998, 14739,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.0130, 0.0130, 0.0510, 0.0510, 0.7360, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.1220, 0.1220,\n",
      "         0.1220, 0.1220, 0.0020, 0.0020, 0.1220, 0.1220, 0.1220, 0.1220, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.1030, 0.3910, 0.3910, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0480, 0.6960, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0170, 0.0170, 0.0650, 0.0650, 0.0170, 0.0170, 0.0170, 0.0170, 0.0650,\n",
      "         0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0650, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0010, 0.0170, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170],\n",
      "        [0.0130, 0.0130, 0.0130, 0.1830, 0.1830, 0.1830, 0.1830, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.4470, 0.1180, 0.0080, 0.0080, 0.1180,\n",
      "         0.1180, 0.1180, 0.0080, 0.0080, 0.0080, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.1850, 0.1850, 0.1850, 0.1850, 0.1850, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1996,  7006,  1997, 16522,  3207,  2050,  4627,  1037,  8917,\n",
      "          3981,  5831,  3508,  2124,  2004,  1996,  3017,  5012,  1998,  2057,\n",
      "          5425,  2167,  2637,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2061,  2029,  7743, 15048,  2000,  3913,  1037,  4344,\n",
      "          2006,  2032,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  8239,  5472,  9152, 13327,  9576,  2015,  2342,  2000,\n",
      "          2175,  2067,  2000,  2037,  2219,  3032,  1998,  2065,  2027,  2079,\n",
      "          2025, 17912,  1996,  2051,  2097,  2272,  2000,  8186,  6366,   102],\n",
      "        [  101,  5310,  2049,  2066,  5263,  2000,  2360,  2053,  2153,  1045,\n",
      "          2288, 15504,  1998, 20114,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2003,  2009,  2825,  2000,  2562,  4459,  4679,  2013,\n",
      "          2412,  3173,  1037,  2231,  2597,  2292, 10459,  1999,  1996,  2317,\n",
      "          2160,  2153,  2023,  3124,  2003,  1037,  8239, 18224,  2010,   102],\n",
      "        [  101,  5310,  2339,  2079,  2025,  2017,  3113,  2007,  1996,  2308,\n",
      "          2008,  2017, 15504,  1998,  3749,  2068,  2019, 12480,  2007,  9430,\n",
      "          2045,  2003,  1037,  2862,  1998,  2017,  2031,  2025,  2356,   102],\n",
      "        [  101,  1045,  3342,  2108,  2579,  2000,  2899,  5887, 11513,  2688,\n",
      "          2006,  2277,  2492,  9109,  2012,  2105,  2193,  2030,  2193, 14563,\n",
      "          1997,  2019,  2214,  7381,  5096,  2007, 11171,  2160,  2104,   102],\n",
      "        [  101,  2106,  2025,  2002,  5466, 14219,  2012,  9101,  2111,  1999,\n",
      "          2010,  3360,  2065,  2002,  4122, 17213,  2005,  2139,  6914, 22139,\n",
      "         11382,  3489,  5691,  2612,  1997,  1052,  7962,  2075,  4004,   102],\n",
      "        [  101,  1999,  1037,  2193,  2839, 17276,  4784,  2097,  7543,  2196,\n",
      "          2022, 10573,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2748,  2044,  2002,  3719,  1999,  2035,  1996,  7486,  1998,\n",
      "         18076,  2027,  2097,  3102,  2035, 22212,  2015,  2066,  2017,  1045,\n",
      "          5993,  2002,  2003,  1037,  5394,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  6057,  2065,  1045,  2360,  2242,  2055,  1037,\n",
      "          2942,  2162, 10474,  3796,  2033,  1998,  2085,  2023,  2317,  4485,\n",
      "          8398,  2360,  2242,  2055,  1037,  2942,  2162, 10474,  2079,   102],\n",
      "        [  101,  2026,  1056, 28394,  2102,  2000,  8962,  2271,  5312,  3283,\n",
      "          2909,  5310,  5310,  2122,  6206, 12114,  1998,  2037, 18829,  3613,\n",
      "          2000,  2224,  1996,  2773, 13141,  2007,  9594,  6935,  1045,   102],\n",
      "        [  101,  1996,  2187,  2003,  2025,  7866,  2033,  2138,  1045,  2572,\n",
      "          1037,  2317,  3287,  2030,  1037, 16939,  2065,  2008,  2020,  2995,\n",
      "          2027,  2052,  2025,  2655,  2304, 11992,  2522,  5644,  2030,   102],\n",
      "        [  101,  2644, 26539, 25385,  2063, 12849, 22513,  6342,  2013,  7404,\n",
      "          6026,  1996,  8254, 17713,  2884,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8534,  2008,  9152, 23033,  1045,  2079,  2025,  2342,  2026,\n",
      "          2851,  9868,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2725,  5099, 14756,  4485,  2066,  2023,  3084,  2256,  2217,\n",
      "          2298,  2128,  7559,  5732,  2021,  2122,  2111,  2020,  2196,  2428,\n",
      "          2006,  2256,  2217,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.8450, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.3590, 0.3590, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
      "         0.0220, 0.0220, 0.0220],\n",
      "        [0.0080, 0.0080, 0.0080, 0.1160, 0.1160, 0.1160, 0.1160, 0.1160, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1160, 0.1160,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0720, 0.0720, 0.0720, 0.0720, 0.2750, 0.0720, 0.0720, 0.0720, 0.0720,\n",
      "         0.0720, 0.0720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.1470, 0.1470,\n",
      "         0.1470, 0.0100, 0.0100, 0.1470, 0.1470, 0.1470, 0.0100, 0.0100, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.2440, 0.2440, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0640, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.5650, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.3040, 0.3040, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.3040, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1045,  2106,  2025,  3198,  4485,  5423,  4496,  2729,  2054,\n",
      "          2115,  2576, 27577,  2017,  2024,  1037,  5980, 26016,  2008,  1037,\n",
      "         29276,  6394, 10587,  4783,  2006, 11721,  2497,  2066,  1996,   102],\n",
      "        [  101,  2003,  5355,  4811,  2006,  1037,  3260,  2000, 29543,  1996,\n",
      "         12456, 15950,  2000,  6011,  2010, 11382,  3489,  7584, 14753,  2050,\n",
      "         26000,  2015,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 13451, 12316,  2094, 10369,  2323,  2022, 12923,  2011,\n",
      "          1996,  2193,  2454,  2002, 21746,  2058,  2007,  2037, 18558,  1998,\n",
      "          6167,  2032,  4550,  1997,  2296, 10647,  1998,  2166,  1999,   102],\n",
      "        [  101,  8840,  2140,  2304,  2111,  2097,  4952,  2000, 29270,  2058,\n",
      "          2035,  1997,  2122,  2128,  7559,  5732,  2739,  6736,  2926,  2065,\n",
      "          2002,  3084,  1037, 28543,  9680,  2201,  5266,  2010,  4301,   102],\n",
      "        [  101,  2016, 17567,  2013,  1996,  3768,  1997,  2613,  2166,  3325,\n",
      "          1998,  2003,  2521,  2205, 23657,  2007,  2690,  2637,  2065,  2016,\n",
      "          2973,  2074,  2193,  2154,  2426,  1996, 16985,  5104,  1999,   102],\n",
      "        [  101,  3392,  2094,  2522,  5644,  2024,  2190,  2522,  5644,  3407,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4365,  1062,  8524,  2638,  2079,  2025,  3404,  1996,  6995,\n",
      "         22889,  4904,  2053,  2062,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2887,  2024,  2025,  2128,  7559,  5732,  2066,  2317,\n",
      "          2111,  5667,  2074,  3046,  2000,  2031,  2019,  7481,  4512,  2007,\n",
      "          1037,  2317,  2711,  2055,  5181,  3795,  2964,  2030,  1996,   102],\n",
      "        [  101,  2004,  3103,  2275,  1056,  9759, 15876,  2040,  2001,  2210,\n",
      "          2062,  2084,  3174,  2048,  2056,  2043,  2017,  2064,  2831,  2055,\n",
      "          5181,  1999,  2270,  2007,  1996,  9706, 21297,  2497,  1997,   102],\n",
      "        [  101,  1045,  2001,  6603,  2043,  1037,  5152,  4150,  3539,  2704,\n",
      "          2073,  2097,  1996,  2034,  2394,  9732,  5968,  2022,  4530,  2098,\n",
      "          2006,  5087,  2414,  2030,  9371,   102,     0,     0,     0,     0],\n",
      "        [  101,  1057,  2226,  9152, 23033,  2015,  2003,  2000,  5379,  2085,\n",
      "          1037,  2420,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3841, 24630,  1037,  5171,  4688, 11382,  3489,  2667,  2000,\n",
      "          5050,  1996, 12456,  2157, 12962,  5181,  2031, 23359,  2058,  2512,\n",
      "          5181,  2005,  2893,  2019,  5611,  9068,  2002,  4688,  2004,   102],\n",
      "        [  101,  1996,  7619, 12909,  5666,  1997,  5472,  9152, 13327,  8801,\n",
      "          1999,  2885, 21029,  2216,  1997,  2647,  6934,  2013,  5738,  3033,\n",
      "          1997,  2885, 16405,  2232,  3389,  2480,  8398,  7460,  1999,   102],\n",
      "        [  101, 19739, 11124,  4571,  8309, 14570,  2229,  2498,  2017,  2064,\n",
      "          2196,  3246,  2000,  2663,  1517,  9915,  9152, 13327,  3520,  4557,\n",
      "          2428, 11382,  3489,  2879,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998,  1996, 19815,  2003,  2757,  2028,  2625,  8494, 14540,\n",
      "         14428,  2003,  1037,  2204,  2518,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2055,  6616,  2125,  1998,  4521,  4485,  2017, 12316,\n",
      "          2094,  8444,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.1780, 0.1780, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.1240, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.1240, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0020, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0330, 0.4710, 0.0090, 0.0090, 0.4710, 0.0090, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.1870, 0.7090, 0.0130,\n",
      "         0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.3330, 0.0880, 0.0880, 0.0880, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0880, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0880, 0.0880],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.4960, 0.0340, 0.0340, 0.0340,\n",
      "         0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340, 0.0340,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0030, 0.0420, 0.0420, 0.1590, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.1590, 0.1590],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.4010, 0.4010, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0280, 0.4000, 0.0280, 0.0280, 0.0070, 0.4000, 0.0280,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.8320, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.1020, 0.1020, 0.0270, 0.1020, 0.1020, 0.0270, 0.3850,\n",
      "         0.1020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2061,  2054,  2016,  3038,  2003,  4759,  3769,\n",
      "          2021,  2302,  4759,  2061,  2074,  3769,  2008,  2025,  1037,  3112,\n",
      "          2005,  1047,  3769,  2009, 21100,  8162,  6129,  2394,  3769,   102],\n",
      "        [  101,  5310,  1045,  2156,  2016,  2097,  2131,  2503,  1996,  7764,\n",
      "          2007,  9587, 24861,  7827,  2028,  1997,  1996, 11287,  2000,  2175,\n",
      "          2000,  7668, 11504,  1045,  6618,  2144,  1045,  2572,  2062,   102],\n",
      "        [  101,  2036,  1059, 24475,  2106, 20996, 22231,  6170, 11113,  2102,\n",
      "          4808,  1999,  2082,  1998,  2032,  2025,  1054,  2135,  3228,  1037,\n",
      "          4365,  2055,  2009,  1048,  2863,  2080,  1059, 24475,  4530,   102],\n",
      "        [  101,  4687,  2339,  2002,  2253,  2000,  1037, 17768,  4974,  2406,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2821,  4485,  2023,  2965,  1996,  6881,  2080,  2097,  2031,\n",
      "          2062,  2051,  2006,  2010,  2398,  2000,  4339,  2178,  2338,  2092,\n",
      "          2012,  2560,  2010,  2128,  7559,  5732,  4599,  1996, 28781,   102],\n",
      "        [  101,  2320,  2153,  2054,  1996,  6616,  2024,  2017,  8670, 15343,\n",
      "          2055,  2053,  4687,  2017,  2031,  2107,  2019, 11113,  7274,  9067,\n",
      "          2695,  2000,  3556,  6463,  2017,  2024,  1037,  1038, 15909,   102],\n",
      "        [  101,  7025,  2003,  1996, 16830,  2390,  1997,  1996,  8174,  5465,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  3599,  2157,  2296,  2051,  1045,  2963,  2122, 18656,\n",
      "          3038,  7490,  7025,  1045,  2215,  2000,  6978,  2053,  2017, 10047,\n",
      "          4783,  6895,  2571,  2009,  2003,  7025,  2558,  2122,  2024,   102],\n",
      "        [  101,  2061,  2079,  2317,  4903,  2140,  2360,  2023,  2008,  9152,\n",
      "         13327,  4485,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2079,  2017,  2655,  1037,  2859,  2386,  2007,  2028,\n",
      "          4190, 14841, 19291, 18454,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 13410,  2139, 11748,  9629, 17547,  2005,  2025,  3436,\n",
      "          2940,  2522, 10698, 10175,  9152, 13327,  2015,  2097,  2886,  2610,\n",
      "          2007, 11015,  1998,  5749,  2044,  1037,  2261,  2847,  2027,   102],\n",
      "        [  101,  1045,  8239,  5223,  5181,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2172,  2769,  2052,  2009,  2202,  2005,  2017,  2000,\n",
      "         15385,  1037,  6077, 22052,  2025,  2200,  2172,  6195,  2017,  2024,\n",
      "          1037,  4954,  5963,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1996,  4808, 24955,  2115,  2175,  2497,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2017,  2175,  2011,  5637,  1042,  2773,  2004,  2092,\n",
      "          2157,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7929,  2023,  2801,  2038,  7857,  1996,  2308,  2097,  2022,\n",
      "          3647,  2013,  4424, 12630,  2065,  2027,  2994,  2041,  1997,  2899,\n",
      "          5887,  9079,  9148,  2121,  2094,  1998,  1996, 13555, 11263,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.4140, 0.4140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0690, 0.0050, 0.0050, 0.0050, 0.0690, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.2640, 0.0690, 0.0050, 0.0690, 0.0690, 0.0690,\n",
      "         0.0690, 0.0690, 0.0690],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0060, 0.0840, 0.0840, 0.0220, 0.0220,\n",
      "         0.0840, 0.0840, 0.0840],\n",
      "        [0.3220, 0.0850, 0.0850, 0.0850, 0.0850, 0.0850, 0.0850, 0.0850, 0.0850,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0080,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0080, 0.0080,\n",
      "         0.0080, 0.1210, 0.1210, 0.1210, 0.1210, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.1210],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7480, 0.0520,\n",
      "         0.0520, 0.0520, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0470, 0.0470, 0.0470, 0.6710, 0.0470, 0.0470, 0.0470,\n",
      "         0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.4340, 0.0080, 0.1140, 0.1140, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.1140, 0.0080],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.4180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1840, 0.1840, 0.1840, 0.1840,\n",
      "         0.1840, 0.0000, 0.0000]]), 'label': tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1998,  2011,  7489,  1045,  2812,  3087,  2025, 18855,  4765,\n",
      "          1997, 13481,  2040,  2333,  2182,  1999,  1996, 16215, 16215,  2301,\n",
      "          7489,  2040,  2024,  9287,  2013, 18076, 14560,  4004,  2015,   102],\n",
      "        [  101,  4931,  5088,  4419,  2612,  1997,  6903,  7694,  2304,  2374,\n",
      "          2867,  2129,  2055,  1037,  7050,  2000,  2317,  2308, 15504,  2011,\n",
      "          2304,  2374,  2867,  2348,  2349,  2000,  2051, 14679,  2008,   102],\n",
      "        [  101,  2043,  1045,  2001,  2402,  2026,  3125,  2001,  2000,  2022,\n",
      "          2066,  4869, 20099,  2378,  2006,  1055, 20554,  2019, 21591, 22889,\n",
      "          4904,  2633,  3651,  2026,  3289,   102,     0,     0,     0,     0],\n",
      "        [  101,  1045, 11382,  3489,  1996,  2801,  1997,  2019,  4895, 19023,\n",
      "         19574,  2591,  2865, 10439,  2021,  2339,  2053, 18059, 10439,  2339,\n",
      "          2003,  2025,  2045,  2062,  6475,  2045,  2036,  3791,  2000,   102],\n",
      "        [  101,  2339,  2079,  2317,  3032,  3477,  2061,  2172,  3097,  4681,\n",
      "          1998,  2036,  2507,  8711,  2769,  1999,  2256,  2219,  3032,  2339,\n",
      "          1996,  3313, 16510,  2028,  2030,  1996,  2060,  2030,  2488,   102],\n",
      "        [  101,  5310,  4487, 10286,  6562,  2111, 14052,  1997,  2193,  2454,\n",
      "          5181,  2193,  2454, 20337,  2193,  2454,  2317,  3017, 12513,  2193,\n",
      "          2454,  2822,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2215,  2017, 16477,  2098,  8797,  2121, 12731, 10603,\n",
      "          2000,  2425,  2033,  2129,  2057,  2024,  2035,  1996,  2168,  1998,\n",
      "         14068,  2545,  2024,  3019, 11992,   102,     0,     0,     0,     0],\n",
      "        [  101,  2582,  7145,  2111,  4370,  2185,  2013,  4004,  2015,  2138,\n",
      "          2027,  2020,  2245,  2000,  2022,  4795, 10372,  4385,  2023,  2018,\n",
      "          1037,  2843,  2000,  2079,  2007, 19857, 18859,  2746,  1999,   102],\n",
      "        [  101,  5310,  5310,  2053,  5499,  3226,  7670,  1996, 12528,  4691,\n",
      "          2079,  2025, 15115,  2007,  2037,  3451,  7443,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19992, 24008, 17880,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310, 19994,  2002,  1037, 15629,  2317,  2879,  2007,  7877,\n",
      "          1998,  1037,  2158, 21122,  2323,  2025,  2022,  2524,  2000,  4867,\n",
      "          2009,  2091,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2129,  2116,  1999,  7017,  2433,  5181,  9152, 13327,  2015,\n",
      "          4916,  2015, 14163, 13793,  2229,  2030, 11089,  4641,  3789,  2005,\n",
      "          2625,  2231, 24554,  1998,  2625,  2231,  2578,   102,     0,     0],\n",
      "        [  101,  2925,  6616, 10140,  3631,  7743,  2229,  2008,  2453,  2022,\n",
      "          1996,  2087, 16021, 29150,  9152, 23033,  2412,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2097,  3288,  2070, 17977,  2027,  2024,  2428,  2204,\n",
      "          2012,  4363,  5568,  2091,  1045,  5552,  2068,  2013,  9587, 25016,\n",
      "          2213,  9040,  2027, 12533,  2033,   102,     0,     0,     0,     0],\n",
      "        [  101,  1998,  2017,  2064,  2655,  2033,  1037, 22212,  2021,  9152,\n",
      "         23033,  2015,  2020,  6015,  1997,  2014,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  6522,  2615,  5320,  4456,  8040,  3286,  2001,  3107,\n",
      "          2000,  1996,  2175, 10139,  2213,  2061,  2004,  2000,  2191, 13164,\n",
      "          2016, 11705,  2015,  2006,  2664,  2178, 22132,  2271, 11382,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
      "         0.0240, 0.0240, 0.0240],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.1300, 0.1300, 0.1300,\n",
      "         0.1300, 0.1300, 0.1300, 0.1300, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7320, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0990, 0.0990,\n",
      "         0.0260, 0.0260, 0.0260, 0.0990, 0.0990, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0480, 0.0480, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.6890, 0.0130,\n",
      "         0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.4950, 0.4950, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2320, 0.2320, 0.2320, 0.2320,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0280, 0.0280, 0.0280, 0.3970,\n",
      "         0.3970, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2660, 0.2660, 0.0050, 0.0050,\n",
      "         0.0050, 0.0180, 0.2660, 0.0180, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050]]), 'label': tensor([1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  1057, 13871,  2232,  2043,  1037,  5472, 25518,  4590, 12509,\n",
      "          2015,  2833,  2007, 13433,  7361,  2012,  2560,  1057,  2113,  1996,\n",
      "         13433,  7361,  2003,  4840,  2866,  5152,  2040, 25401,  2833,   102],\n",
      "        [  101,  5310,  9152, 23033,  8239,  2170,  2033,  1037,  6904, 13871,\n",
      "          4140,  2043,  1045,  2056,  2122,  2477,  2000,  2032,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10768,  4757,  2039,  2065,  2017,  2018,  1037, 17276,  8479,\n",
      "          2121,  2043,  2017,  2020,  1037,  4845,  8797,  8758,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10166,  1045,  2293,  2023,  4239,  4180,  1997,  2017,  4214,\n",
      "          2111,  6904, 13871, 12868,  2035,  2154,  2009,  1037,  3154,  3696,\n",
      "          1997,  7789, 13811,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2025,  2342,  2000,  3191,  2151,  3189,  1999,\n",
      "          2026,  2154,  2057,  6283, 22190,  2483,  2057,  2354,  2027,  2020,\n",
      "         10882, 24658,  2027,  2071,  2025,  2562,  2037,  2398,  1997,   102],\n",
      "        [  101,  4675,  5152,  9887,  2011, 12252,  1037, 12121,  7770, 18982,\n",
      "          2105,  3924,  2132,  2007,  2069,  1996,  2159, 14486,  1998,  6815,\n",
      "          2000,  2022,  1037,  2266,  1997,  1996,  3418,  2344,  1997,   102],\n",
      "        [  101,  4895,  8663, 23141, 10457,  7062,  2317,  2611,  5218,  2000,\n",
      "          2304,  2611,  2004,  9152, 13327,  2006,  9130,  2304,  2611, 16412,\n",
      "          2000,  6011,  2014,  3308,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2052,  2074, 17079,  9152, 13327,  2028,  2006,  2028,\n",
      "          2049,  4189,  2954,  2085,  2065,  2002,  3046,  2242,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8840,  2140,  2017,  2113,  1996,  2062,  2690,  2789,  2308,\n",
      "          1045,  2387,  2058,  2045,  1996,  2062,  1045,  2234,  2000,  3305,\n",
      "          2339,  1996,  2273,  6616, 17977,   102,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  6583, 18684,  4877,  2024,  2004,  2919,  2004,\n",
      "         24815,  2483,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  1521,  1049,  4994,  1996,  2665,  9769,  2015,\n",
      "          2024,  9657,  4826, 22652,  3038,  2115, 29126,  2069, 20378,  2627,\n",
      "          1996, 12281,  4385,  2064,  1521,  1056,  2156,  2009,  2870,   102],\n",
      "        [  101,  3096,  3609,  2323,  2196,  5646,  3251,  2030,  2025,  2028,\n",
      "          2064,  2433,  2037,  2677,  2000,  2191,  1037,  2614,  2074,  2138,\n",
      "          2070, 10041,  4858, 10048,  2007,  2009,  9152, 13327, 19635,   102],\n",
      "        [  101,  1045,  2018,  2000,  3191,  2039,  2006,  2068,  2043,  1045,\n",
      "          2318,  2652, 10585,  5875,  2111,  7167,  1997,  4111,  7065, 20935,\n",
      "          7687,  8342,  2041,  2011, 14163, 13793,  2229,  2023,  2003,   102],\n",
      "        [  101,  2065,  1045,  3066,  2007,  1037,  9152, 23033,  8909,  3654,\n",
      "          2546,  2055,  2040,  2002,  2224,  2000,  6616,  2007,  1057,  7743,\n",
      "          2229,  2424, 23899,  2033,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2333,  1999,  2007,  2198, 10722,  7377,  2271,  1998,\n",
      "          2155,  2090, 11793,  1998,  2034,  3694,  1998,  2002,  2001,  2091,\n",
      "          8715, 10007, 11263, 23177,  2128,  7559,  5732,  4735,  2135,   102],\n",
      "        [  101,  1037,  8579,  9422, 15667,  5152, 16374, 12097,  2000,  2022,\n",
      "          1037,  2878,  2060,  2711,  4150,  1996,  8275,  2343,  2515,  2025,\n",
      "          5142,  2017, 20287,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0010, 0.0010, 0.0770, 0.0050, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.3470, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0920, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060],\n",
      "        [0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0450, 0.0450, 0.0450, 0.0450, 0.6520, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1080, 0.1080, 0.1080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.1080, 0.4110, 0.0290, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3590, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0660, 0.0660, 0.0660, 0.0660, 0.2520, 0.0660, 0.0660, 0.0660, 0.0660,\n",
      "         0.0660, 0.0660, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.1600, 0.0110, 0.0110, 0.6070, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0270, 0.0270,\n",
      "         0.0270, 0.1040, 0.0270, 0.0270, 0.1040, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0290, 0.1080, 0.1080, 0.1080, 0.1080, 0.1080, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290, 0.0290,\n",
      "         0.0290, 0.0290, 0.0290, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  2292,  2149,  2079,  1996,  2051, 24136,  2153, 21541,\n",
      "          8695, 16522,  2000, 16417,  2187,  1998,  1037, 11382,  3489,  2000,\n",
      "          1996,  2157,  3398,  1045,  2064,  2156,  5310,  4823,  2009,   102],\n",
      "        [  101,  1045,  9826,  2079,  2025,  2228,  2637, 19821,  1996,  5995,\n",
      "          1998, 25291,  1997,  7207,  7897,  2030,  1996, 11591, 15561,  1997,\n",
      "          3795,  5130,  2027,  2024,  3974,  2673,  2035,  1996,  3825,   102],\n",
      "        [  101,  1045,  2903,  2057, 18454,  6392,  2031,  1037,  2120,  8494,\n",
      "          7377,  8024,  6209,  2205,  7110,  1056, 14034,  9152, 13327,  2015,\n",
      "         21025,  2102,  1037,  4920,  3204,  1999, 13114,  2019, 17490,   102],\n",
      "        [  101,  5310,  2893,  2471,  6476,  2041,  2011,  1996,  4326,  2317,\n",
      "         17523,  2099,  2040,  5078,  4344,  3238, 11875,  2005,  2070,  3114,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16711,  2029,  2003,  2058,  3867,  9587, 25016,  2213,  2031,\n",
      "          2700,  2023, 17768,  4974,  2098,  2450,  2004,  2037,  2034,  2931,\n",
      "          9587, 25016,  2213,  6131,  2008,  8388, 14594,  2005,  8038,   102],\n",
      "        [  101,  2033,  2232,  2130,  2065,  2017,  2024,  3308,  2055,  9587,\n",
      "         25016,  2213,  4485, 29334,  2015, 16873,  1996,  6745,  2886,  2017,\n",
      "          2097,  2763,  2022,  2157,  2055,  1996,  2279,  2028,  2036,   102],\n",
      "        [  101, 15705,  1997,  2248, 11099, 12620,  7278,  5095,  2009,  4122,\n",
      "         20996, 12053,  3148,  5152,  8711,  2040,  6783,  2000,  9632,  7269,\n",
      "         16360,  4017, 25475,  2000,  2037,  2280,  5014,  2061,  2027,   102],\n",
      "        [  101, 14187,  2483,  2024,  2066,  2065,  2643,  2018,  1037,  2128,\n",
      "          7559,  5732,  2210,  2567,  2040,  2699,  2000,  2191,  4286,  2205,\n",
      "          6131,  6169, 29336,  2271,  6279, 27122,   102,     0,     0,     0],\n",
      "        [  101,  2242,  1996,  2088,  1997,  6870,  2038,  2025,  3039,  2000,\n",
      "          5607,  2317, 24091,  2015,  2005,  6013,  4983,  1997,  2607,  2017,\n",
      "          2024,  1037,  4551, 12069,  7069,  2021,  2130,  2059,  2017,   102],\n",
      "        [  101,  2507,  2149,  2062,  1997,  2115,  2769,  2308,  1998,  2406,\n",
      "          2009,  2003,  2256,  2157,  2000,  9040,  2017,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2054,  2112,  1997,  1045,  2572,  1037, 28543,  2711,\n",
      "          2007,  6355,  3424,  2591,  7166,  2319,  9243,  1998,  1996,  6832,\n",
      "          2458,  1997,  1037, 25659,  1041, 16211,  4570,  2000,  1996,   102],\n",
      "        [  101,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  5310,  5310,\n",
      "          5310,  5310,  5310,  5310,  2009,  2001,  2069,  2138,  2619,  2001,\n",
      "         13599, 10032,  2000,  9040,   102,     0,     0,     0,     0,     0],\n",
      "        [  101, 10930,  2064,  2017,  2035,  2175,  3805,  1998,  2131,  5310,\n",
      "          2039, 24955,  2045,  2205, 12731,  2480,  2065,  8398,  2015,  2908,\n",
      "          1998,  2002,  2343,  2002,  2175,  2078,  2022,  4214, 12455,   102],\n",
      "        [  101,  2298,  2012,  2023,  2128,  7559,  5732,  4485,  2157,  2182,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 17203,  2021,  2664,  2087,  3497,  6753,  1996,  4808,  2008,\n",
      "          5365,  8509,  2041,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 16215,  2723,  2672, 10166, 13229,  2007,  1996,  8275,  2638,\n",
      "          9333,  1996,  2303,  4175,  2003,  2183,  2000,  2022, 11333,  4710,\n",
      "          2919,  2205,  2021,  2057,  2064,  2035,  2175,  2188,  2085,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.6770, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2720, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.2720, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0190, 0.0190, 0.0190, 0.0190, 0.2720, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0420, 0.0110, 0.0420, 0.0420,\n",
      "         0.6100, 0.0420, 0.0110, 0.0110, 0.0110, 0.0110, 0.0420, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.3590, 0.3590,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070],\n",
      "        [0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0280],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2850, 0.2850,\n",
      "         0.2850, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0050, 0.0050, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300,\n",
      "         0.0300, 0.0300, 0.0300],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260, 0.0260,\n",
      "         0.0260, 0.0260, 0.0260],\n",
      "        [0.0300, 0.0300, 0.0300, 0.4260, 0.4260, 0.0300, 0.0300, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n",
      "         0.0830, 0.0830, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080]]), 'label': tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  1045,  8239,  5223,  2014,  2061,  2172,  1998,  1045,\n",
      "          2293,  2014,  2061,  2172,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4750,  2859,  2003,  1037,  6939, 23961,  2232,  4420,  2003,\n",
      "          1037,  6939, 14757, 16336,  2015, 11399,  2003,  1037,  6939,  1996,\n",
      "          2019,  2278,  2003,  1037,  6939,  1996,  7327,  4895,  2024,   102],\n",
      "        [  101,  5310,  5310,  5310,  2073,  2115,  3120,  1045,  2145,  2031,\n",
      "          2025,  2464,  2151,  6947,  1997,  1996,  2152,  3798,  1997,  9099,\n",
      "          2308,  2040,  2131, 15504,  1999,  3287, 15996,   102,     0,     0],\n",
      "        [  101,  5310,  1045,  6563,  8092,  2128,  7559,  2094,  4415,  1997,\n",
      "          2029,  6737,  1999,  6773, 23082,  1998,  3536,  3907,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6517,  2774,  2024,  4658,  2021,  2031,  2017,  2412,  2699,\n",
      "          6933,  2138,  2017,  2288, 10500,  7852,  2612,  1997,  2317,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  2008,  2001,  2026,  2388,  2008,  9152, 13327,  2052,\n",
      "          2022,  2006,  1037, 17584,  2012,  1996, 22822,  9077,  2157,  2085,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3265,  6904, 13871, 12868,  2024,  2000,  3917,  3085,  2061,\n",
      "          2146,  2004,  2027,  2994,  1999,  2037,  4644,  1998,  2562,  2477,\n",
      "         16246,  1037,  2554,  2008, 14067,  1998, 21566,  6904, 13871,   102],\n",
      "        [  101,  5310,  2625,  7489,  2062,  3506,  2000,  4900,  2013,  2896,\n",
      "          7597,  2330,  2115,  2159, 11979, 15721,  5685,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1051,  2100,  2310,  2100,  2016,  2357,  2033,  2046,  1037,\n",
      "         11382,  3489, 21461,  2015,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 23011,  2083,  7325,  2964,  2003,  8275, 23011,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2040,  2079,  7743,  2229,  1999,  5469,  5691,  2467,  2031,\n",
      "          4121,  3506,  2066,  4642,  2239,  2057,  2113,  2017,  2064,  1521,\n",
      "          1056,  3104,  2216,  3200,  7773,   102,     0,     0,     0,     0],\n",
      "        [  101,  2193,  2308,  2024, 11669,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  2017,  2024,  2317, 11669,  2061,  6616,  2125,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045, 10587,  2131, 15504,  2011,  5310,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  5236,  2317,  6616,  6293,  2515,  2025,  2113,  1037,\n",
      "          4365,  2518,  2055,  2054,  2304,  2273,  1999,  2637,  2175,  2083,\n",
      "          2069,  2304,  2273,  2113,  2008,  4241,  7382,  2666,   102,     0],\n",
      "        [  101,  1998,  2060,  2084,  4297, 15402,  2111,  2000, 24495,  4808,\n",
      "          2054,  2024,  2017,  4699,  1999,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1200,\n",
      "         0.4540, 0.1200, 0.0080],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.7630, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.7730, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0250, 0.3530, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.3530, 0.0250, 0.0250, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.1780, 0.6740, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.7220, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.3310, 0.3310, 0.3310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0050, 0.0670, 0.0670, 0.2560, 0.2560, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.2560, 0.0050, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  5310,  2023,  7743,  4282,  2054,  2039,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  2065,  1045,  2572,  1037,  6904, 13871,  4140,\n",
      "          2339,  2052,  1045,  2022,  2317,  5000,  2075,  2005,  1037,  2611,\n",
      "          2017,  2342,  2000,  2543,  2115, 13717,  2533,   102,     0,     0],\n",
      "        [  101, 10047,  2006,  1996, 28194,  5886,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3424,  2317,  3424,  2137, 11382,  3489,  2040,  7463,\n",
      "         16393,  1997, 14588,  2041,  1997,  2816,  2138,  2009,  2758,  2028,\n",
      "          3842,  2104,  2643,  2054,  2097,  2468,  1997,  2149,  2302,   102],\n",
      "        [  101,  2047,  2000, 24978,  2546,  2860, 10474,  1528,  2193,  1528,\n",
      "          2149,  1528,  3730,  2524, 14383,  1528,  2309,  1528, 11690,  1528,\n",
      "          2016,  2014,  8318,  2193, 19387,  2005,  8203,   102,     0,     0],\n",
      "        [  101,  5310,  2003,  2009,  6910,  2030,  2304,  1998,  2317,  1998,\n",
      "          2191,  2469,  2009,  2038,  2417,  4281,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  1045,  8239,  5223,  2017,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2128,  7559,  5732, 18749, 29336,  2075,  2158, 20876,\n",
      "         12731,  3600,  4292,  1037,  6659,  2742,  2005,  2010,  2336,  2002,\n",
      "          2003,  2725, 20868,  2890, 28689,  3468,  4053,  2000,  2068,   102],\n",
      "        [  101,  2256,  2128,  7559,  5732,  4632,  2229,  2288,  2061,  4365,\n",
      "          5507,  2197,  2305,  2057,  2074,  2085, 12447,  2039,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8840,  2140,  7486,  5223,  2119, 12010,  1998,  5181,\n",
      "          2053,  2028,  3980,  2068, 27793,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  2021,  2045,  2024,  6206, 12114,  2061,  1042,  6396,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9152, 23033,  2012,  2147,  2056,  1045,  2298,  2066,  1037,\n",
      "         10798, 27747,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6854,  5190,  1997,  2308,  2298,  2066,  2023,  2027,  2031,\n",
      "         26641,  2094,  2006, 17663, 11382,  3489,  2017,  2323,  2292,  2068,\n",
      "          2113,  2055,  2037,  4650,  1996,  2279,  2051,  2027,  2644,   102],\n",
      "        [  101,  5310,  1045,  5223, 23368,  2015,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2079,  4841,  2903,  2008,  8711,  2323,  2272,  2034,\n",
      "          2058,  4841,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2228,  2017,  2342,  2000, 26450, 10930,  7570,  2063,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.1300, 0.1300, 0.4950, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090],\n",
      "        [0.0030, 0.0030, 0.0370, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0100,\n",
      "         0.0100, 0.1400, 0.1400, 0.1400, 0.1400, 0.1400, 0.1400, 0.0370, 0.0370,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0370, 0.0370, 0.1390, 0.1390, 0.1390, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.1630, 0.1630, 0.1630, 0.1630, 0.1630, 0.1630, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.4700, 0.4700, 0.0090, 0.0090, 0.0090,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0450, 0.6550, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.3310, 0.3310, 0.3310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910,\n",
      "         0.0910, 0.0910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.9010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2023,  2003,  2339,  2643,  2409,  2010,  2111,  2000,  3102,\n",
      "          1996, 19483,  2015,  1998,  2002, 10678,  1996,  2455,  2008,  7936,\n",
      "          2068, 11902, 29587,  2193,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5604,  2024,  2017,  3039,  2000,  2360,  9152, 13327,  2006,\n",
      "          2182,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2060,  2084, 11242,  2008,  7025,  2003,  2025,  9379,  1998,\n",
      "          2008, 19483,  2015,  2024,  2025,  2141,  2008,  2126,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4735,  3012,  1997, 15667,  4490,  2003,  8335,  2007,\n",
      "          2530,  5300,  2028,  2323,  2025, 28679,  2530,  3226,  2007,  2783,\n",
      "          4827,  2926,  2144,  2116,  1997,  1996,  2783,  4827,  2015,   102],\n",
      "        [  101,  2057,  2342,  2000,  2191,  2070, 12661,  2015,  1997,  2214,\n",
      "          3152,  1998,  5672,  4556,  2189,  2007,  9680,  2189,  1998,  2022,\n",
      "          2469,  1998,  2031,  2304,  2273,  2437,  2293,  2000,  2317,   102],\n",
      "        [  101,  1061,  2113,  2054,  1045,  2196,  2156,  2151,  6256,  1997,\n",
      "         16522,  2006,  2175,  2100,  8570,  5973,  2009,  8239,  6659, 16522,\n",
      "         15657,  2573,  2066,  2014, 10374,  2009,  2035,  2058,  1996,   102],\n",
      "        [  101,  2045,  2053,  2107,  2518,  2004,  7490,  7025,  2009,  2074,\n",
      "          7025,  9040,  3742,  4028,  2024,  2112, 20463,  1997,  3679,  9587,\n",
      "         25016,  2213,  2166,  2009,  2037,  3226,  2009,  2040,  2027,   102],\n",
      "        [  101,  2009,  2025,  2058, 16903,  2027,  2024,  2025, 19200,  2009,\n",
      "          2025,  2019,  2779,  3815,  1997,  4126,  1999,  1996,  2051,  2009,\n",
      "          2165,  2017,  2000,  3191,  2023,  2695,  1037,  4126,  2038,   102],\n",
      "        [  101,  2017,  2024,  1045,  2572,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2113,  2498,  2055,  2256,  4470,  3272,  3649, 16522,\n",
      "         21233,  2024,  2041,  2045,  1998,  2065,  8038, 10587,  2175,  2008,\n",
      "         19717,  2017,  2442,  2217,  2007,  1996,  3424,  7011,  6904,   102],\n",
      "        [  101,  2017,  2412,  8595,  1037, 10005,  1999,  2019,  3535,  2000,\n",
      "          2514,  2844,  2030,  2572,  1045,  2128,  7559,  5732,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  2003,  2074,  2061,  2128,  7559,  5732,  2008,  4845,\n",
      "          2515,  2025, 10107,  2054,  2746,  2488,  2145, 20320,  2216, 28781,\n",
      "          2043,  1996,  4845,  2003,  2141,  2027,  2323, 14308,  1996,   102],\n",
      "        [  101,  3335,  2032,  2054,  1037, 11067,  1045,  2018,  1996,  4495,\n",
      "          2000,  2444,  1999, 11334,  1999,  1996,  2193,  2043,  2002,  2081,\n",
      "          6379,  4542,  2009,  2001,  2058,  1996,  2327,  4569,  2085,   102],\n",
      "        [  101,  3057,  2066,  2919,  3337,  2138,  2027,  2024,  4569, 27084,\n",
      "         19210,  1998,  2079,  2025,  2507,  1037,  4485,  2055,  2068,  3057,\n",
      "          2066,  5637,  2273,  2138,  2027,  2024,  4569, 27084, 19210,   102],\n",
      "        [  101,  2821,  2643, 12528,  7685,  2129,  1045,  5223,  2008,  2518,\n",
      "          2009,  2001,  1037,  2066,  1037,  2128,  7559,  5732,  2544,  1997,\n",
      "          2909,  2072,  2030,  2522, 13320,  2532,  2021,  2296,  2978,   102],\n",
      "        [  101,  5310,  1051,  8210, 18404,  4314,  2045,  2003,  4487,  4246,\n",
      "          2090, 13141,  1998,  6206, 11560,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.3000,\n",
      "         0.3000, 0.3000, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8720, 0.0160, 0.0160,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620,\n",
      "         0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0530, 0.0530, 0.0530, 0.0530, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140, 0.0140,\n",
      "         0.0140, 0.0140, 0.0140],\n",
      "        [0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090, 0.0090,\n",
      "         0.0090, 0.0090, 0.0090, 0.1310, 0.1310, 0.0090, 0.0090, 0.0090, 0.1310,\n",
      "         0.1310, 0.0090, 0.0090],\n",
      "        [0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0230, 0.0880, 0.0880,\n",
      "         0.0880, 0.0230, 0.0230, 0.0230, 0.0020, 0.0020, 0.0020, 0.0020, 0.0880,\n",
      "         0.0880, 0.0230, 0.0230, 0.0230, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "         0.0020, 0.0020, 0.0020],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.2710, 0.2710, 0.2710, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0720, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150],\n",
      "        [0.0170, 0.0170, 0.0170, 0.0170, 0.9320, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1220,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.1220,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670,\n",
      "         0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.6300, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0220],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0730, 0.0730, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360, 0.0360,\n",
      "         0.0360, 0.0000, 0.0000],\n",
      "        [0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770, 0.0770,\n",
      "         0.0770, 0.0770, 0.0770, 0.0770, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2061,  2023, 13433,  2015,  4152,  1037,  3789,  1997,  2053,\n",
      "          7023,  2013,  2010, 11964, 10424,  2243,  2078,  6429,  2130, 28616,\n",
      "         29098, 26121,  1997,  5029, 26693,  2057,  5293,  1996,  2025,   102],\n",
      "        [  101,  2017,  4688,  9152, 13327,  1996,  1047,  2243,  2106,  2053,\n",
      "          2107,  2518,  2000,  2115,  6904,  2213,  1996,  9152, 13327,  2015,\n",
      "          2008,  2288, 11404,  2098,  2020,  2216,  2040, 15504, 20114,   102],\n",
      "        [  101, 10556,  2860,  4048,  2003,  1037,  8239, 21910,  3642,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2514,  3374,  2005,  2122,  5525, 10597,  5305,  2317,\n",
      "          2111,  2040,  2024,  5525, 14868,  1998,  7789,  2135,  2128,  7559,\n",
      "          5732,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2757,  7206,  6206, 11560,  7206, 10768,  7811,  7206,  2027,\n",
      "          2079,  2025,  3789,  2005, 10643,  2079,  2027,  2002,  5369,  5369,\n",
      "          5369,  5369, 15727, 10760, 22994,  2063,   102,     0,     0,     0],\n",
      "        [  101,  2428,  4074,  3557,  7164,  2008,  1996, 14560,  1999,  3956,\n",
      "          2342,  2000,  2709,  2000,  5207,  2073,  2027,  2941,  2234,  2013,\n",
      "          2138,  2008,  2026,  2048,  2110,  5576,  3956,  1998,  5207,   102],\n",
      "        [  101,  8840,  2140,  2069,  1037,  2931,  9152, 13327,  2071,  2022,\n",
      "          2061, 12873,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  8909, 12083,  2497,  2480,  2758,  9152, 13327,  6904,\n",
      "         13871,  4140,  2035,  1996,  2051,  2021,  2053,  2028,  2941,  3957,\n",
      "          2032,  4485,  2005,  2009,  8840,  2140,  2111,  2024,  5236,   102],\n",
      "        [  101,  5310,  2009,  2965,  2008,  2027,  5223,  5637,  2111,  2021,\n",
      "          2514,  8796, 17927,  2061,  1999,  2392,  1997,  1037, 19483,  2711,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2442,  2022,  1037,  6904, 13871,  4140,  1037, 11382,\n",
      "          3489,  2030,  2119,  6616,  2125,  2067,  2000, 10474,  2017, 13072,\n",
      "         10338,  6342,  9102,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2057,  2024,  2025, 15807,  2011,  1996,  4675,  4100, 17456,\n",
      "          2065,  2017,  2024,  2025, 23558,  2011,  2054,  7069,  5181,  2024,\n",
      "          2725,  2000,  2317,  3032,  2017,  2024,  2025,  7079,  3086,   102],\n",
      "        [  101,  6108,  2339,  2079,  2025,  2017,  3422, 19483,  3239,  2027,\n",
      "          2356,  2017,  2323,  3422,  2009,  2009,  5637,  2514,  5350,  2027,\n",
      "          7278, 14020,  3495,  2046,  1996,  4950,   102,     0,     0,     0],\n",
      "        [  101,  1998,  2035,  1996, 14163, 13793,  2229,  1999,  1996,  2088,\n",
      "          4117,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5850,  5356,  4638,  2009,  6616,  2007,  2149, 19739, 14693,\n",
      "          2023,  9152, 13327,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19387,  3915, 12326, 15000,  2015,  1045,  2196,  2245,  1045,\n",
      "          2052,  2156,  1996,  2154,  2043, 13350,  2052,  2031,  2061,  2172,\n",
      "         17152,  2005,  2028,  2158,  2037,  2406,  2008,  2027,  2052,   102],\n",
      "        [  101,  4797,  2035,  2017,  2066,  2009,  2003, 10003,  2755,  2106,\n",
      "          1996, 17768,  4974,  1999,  2335,  2675,  2298,  2317,  2000,  2017,\n",
      "         10003,  6688, 28616, 20470,  9050, 14302,  2004,  2317,  2000,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010],\n",
      "        [0.0030, 0.0030, 0.1390, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.0100, 0.0100, 0.1390, 0.0100, 0.0100, 0.0100, 0.0100,\n",
      "         0.0100, 0.0100, 0.1390, 0.0100, 0.0100, 0.0100, 0.0100, 0.1390, 0.1390,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.1670, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
      "         0.0320, 0.0320, 0.0320],\n",
      "        [0.0050, 0.0730, 0.0730, 0.2780, 0.2780, 0.0730, 0.0730, 0.0730, 0.0730,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.3320, 0.0880, 0.3320, 0.0880, 0.0880,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0810, 0.3080, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0810, 0.0060, 0.0210, 0.3080, 0.0810, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0160, 0.0160, 0.0160, 0.8860, 0.0160, 0.0160, 0.0160, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.0380, 0.0380, 0.0380, 0.5500, 0.0380, 0.0380, 0.0380, 0.0380,\n",
      "         0.1450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180, 0.0180,\n",
      "         0.0180, 0.0180, 0.0050],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.3330, 0.0880, 0.0880, 0.0880, 0.0880, 0.0880, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0230, 0.0230, 0.0230, 0.0230, 0.0060, 0.0060, 0.0060,\n",
      "         0.0060, 0.0060, 0.0060]]), 'label': tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  5310,  8129, 23023,  2743,  1037,  2336,  2015,  2188,  1999,\n",
      "         27456,  2073,  2016,  2853,  2104,  2287,  2317,  3057,  2000,  1996,\n",
      "          2334, 22190,  2483,  2016,  2074,  2061,  3047,  2000,  2022,   102],\n",
      "        [  101,  2489,  5637,  6740,  8750,  4620,  2190,  4398,  3348, 10899,\n",
      "          3348,  2689,  5852,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6289,  2098, 17214, 27605,  2003,  2317,  2099,  2084,  2035,\n",
      "          1996, 11382,  3489, 11432,  1999,  3956,  2489,  6289,  2098, 17214,\n",
      "         27605,  3806,  1996,  5181,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2036,  2053, 17768,  4974,  2308,  2147,  2027,  2074,  8843,\n",
      "          1999, 13578,  2098,  2015,  1998,  4366,  6666,  2027,  3749,  2498,\n",
      "          2000,  1996,  2225,  7078,  2498,  1997,  3643,  2030,  2147,   102],\n",
      "        [  101,  5310, 11513,  2003,  1037,  2502,  4682,  2045,  2003,  2053,\n",
      "          3350,  2055,  2008, 11513,  5638, 25394,  2063,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2061,  2144,  2023,  2003,  2026, 16215,  2695,  1045,  2245,\n",
      "          1045,  1040,  5254,  2008,  1996,  2171,  8670,  8458,  8462,  2102,\n",
      "          1996,  6548,  2070,  7425,  3310,  2013,  2214,  2413,  2005,   102],\n",
      "        [  101,  5310,  4365,  3504,  2066,  1045,  1521,  1049,  2128,  7559,\n",
      "          5732,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2942,  2162,  2146,  2004,  1045,  2079,  2025,  2031,  2000,\n",
      "          2444,  1999,  2115,  2047,  3072, 10357,  2011, 16939,  2940, 24457,\n",
      "          3111,  1998,  5665, 21646,  3686,  2317, 11669, 11838,  6616,   102],\n",
      "        [  101, 17276, 11320,  2615,  2011,  7304, 13793,  1050,  2852,  6633,\n",
      "          2080,  2003,  1037,  9389,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  8037,  7961,  5674,  8037,  1999,  3715,  1997,\n",
      "          2256,  2406,  2057,  2035,  2183,  2000,  2514,  2004,  2057,  2031,\n",
      "          2042, 15504,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2122,  7570,  2229,  2024,  9577,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  5310,  3814,  2232, 11782,  2064,  2017,  2025,  3191,\n",
      "          2317,  7743,  1058,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15554,  2525,  2202,  1999,  2256,  2336,  2000,  3345,  2068,\n",
      "          2023,  2003,  1037,  2028,  2126,  4440,  2005,  2068,  2065,  2035,\n",
      "          2009,  3138,  2003,  2000,  2031,  2336,  2000,  2131,  2067,   102],\n",
      "        [  101,  2193,  1997,  2137,  2308,  2024,  2058, 11179,  2030, 15578,\n",
      "          3366,  1517,  2054,  1996,  3109,  2003,  2183,  2006,  1999,  2256,\n",
      "          2406,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2572,  5580,  2017,  2031,  1037,  2269,  1998,  2002,\n",
      "          3849,  2066,  1037, 11519,  2028,  2562,  5962,  2000,  2032,  1045,\n",
      "          9411, 12145,  2007,  2312,  3616,  1997,  5181,  2005,  2086,   102],\n",
      "        [  101, 21089,  2207,  2304,  4586,  2006,  1996,  4773,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210, 0.0210,\n",
      "         0.0210, 0.0210, 0.0210],\n",
      "        [0.0480, 0.6860, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0480, 0.0130,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0130, 0.0030, 0.0030, 0.0030, 0.1900, 0.1900,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1900, 0.1900, 0.1900, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0270, 0.3930, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.2270, 0.2270, 0.0600, 0.0600, 0.0600, 0.0600, 0.0600, 0.0600,\n",
      "         0.0600, 0.0600, 0.0600, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
      "         0.0280, 0.0280, 0.0070],\n",
      "        [0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.0160, 0.8860, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0590, 0.0590,\n",
      "         0.0040, 0.0590, 0.2230, 0.2230, 0.0590, 0.2230, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110, 0.1110,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.9480, 0.0170, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0060, 0.0060, 0.0060, 0.0060, 0.0840, 0.0840, 0.0840, 0.0840, 0.3180,\n",
      "         0.3180, 0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0070, 0.0070, 0.0280, 0.0280, 0.0280, 0.4000, 0.0280, 0.4000, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0010, 0.0790, 0.0790],\n",
      "        [0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.1430, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  3246,  2002,  7906,  6911,  2075,  1996,  2391,  6854,  1996,\n",
      "          2291,  2097,  2087,  2763,  2131,  2032,  3718,  2005,  4092,  1996,\n",
      "          3606,  2605,  2003,  2061,  6015,  1997,  2122, 17657,  6206,   102],\n",
      "        [  101,  4931,  2304,  2065,  1996,  2291,  2003, 25216,  2005, 12461,\n",
      "          2059,  2339,  2024,  1996,  4004,  2015,  2725,  2488,  2084,  3071,\n",
      "          2842, 10661,  6155, 13181, 20821, 26264, 18900,  7747,   102,     0],\n",
      "        [  101, 18411,  2015,  2004,  7486, 11689,  1037, 11689,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2215,  2000,  2156,  1996,  5606,  1997,  5190,  1997,\n",
      "          6363,  1997, 15565,  1996, 14560,  2435,  9587, 23555,  6216,  1998,\n",
      "          2079, 19140, 16078,  2002,  2288,  2048,  2350, 12197,  1998,   102],\n",
      "        [  101,  2043,  1996, 24992, 18927, 14122,  2121,  2017,  3582, 16360,\n",
      "         14122,  2015,  1037,  2186,  1997,  6248,  2016,  5092,  5644,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 19318,  2193,  2193,  8038,  9765,  2050,  4372,  2771,  2327,\n",
      "          2193,  2544,  2229,  3972, 19318, 16877,  6708,  2928, 10654,  8591,\n",
      "          1061,  9895, 27106,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1059, 24475,  2008,  9781,  9152, 13327,  2074,  2515,  2025,\n",
      "          2113,  2010,  2173,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8398,  2003,  2525,  6984,  1996,  9366,  1997,  2942,  2162,\n",
      "          2065, 17727,  5243,  7690, 10334,  2040,  6732,  2002,  7036,  2012,\n",
      "          2023,  2391,  2003,  1037,  8239, 10041,  2065,  2008,  2025,   102],\n",
      "        [  101,  8840,  2140,  1996,  2168,  7743,  2229,  2040,  2031,  5407,\n",
      "         22673,  2006,  6616,  9152, 23033,  2015,  2007, 27408,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2003,  2023,  9152, 13327,  3809,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2092,  2012,  2560,  1996,  8494, 14540, 14428,  2015,  5681,\n",
      "          2131,  2009,  2157,  2085,  2065,  2027,  2071,  2074, 13276,  2009,\n",
      "          2039,  2011,  2055,  2193,  2454,   102,     0,     0,     0,     0],\n",
      "        [  101,  1998,  2054,  2515,  2008,  2191,  2017,  1037, 14994,  4710,\n",
      "         21877, 21814, 22822,  2239,  2054,  2003,  1037, 11382,  3489,  4312,\n",
      "          2054,  3830,  2089,  1045,  2173,  2588,  2115, 11067,  2129,   102],\n",
      "        [  101, 10416,  2023,  2017,  8239,  6904, 13871,  4140,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2010,  2240,  1997, 14492,  2074,  6476,  1999,  2002,  2003,\n",
      "          2524,  2153,  8840,  2140, 13330,  2017,  2288,  2115,  2047,  2564,\n",
      "          2015,  9152, 13327,  4124,  2000,  6570,  2017,  2008,  2773,   102],\n",
      "        [  101,  3225,  2000,  4558,  2062,  1998,  2062,  4752,  1999,  2304,\n",
      "          2273,  2169,  2154,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2079,  2025,  2215,  2000,  2963,  2055, 22575, 14398,\n",
      "          1998,  2373, 14293,  2013,  4004,  2015,  1998, 11382,  9681,  2144,\n",
      "          2027,  2024,  7778,  2135,  7177,  3771,  2084,  2149,  3844,   102]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.1870, 0.1870,\n",
      "         0.1870, 0.1870, 0.0130],\n",
      "        [0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480, 0.0480,\n",
      "         0.0480, 0.0480, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.6490, 0.0450, 0.1710, 0.0450, 0.0450, 0.0450, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "         0.0200, 0.0010, 0.0010],\n",
      "        [0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.8450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.1870, 0.7090, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
      "         0.0270, 0.0270, 0.0270],\n",
      "        [0.0150, 0.0150, 0.0150, 0.8200, 0.0150, 0.0150, 0.0150, 0.0150, 0.0150,\n",
      "         0.0150, 0.0150, 0.0150, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0170, 0.0170, 0.9480, 0.0170, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.7320, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.6860, 0.0130, 0.0130, 0.0130, 0.0130,\n",
      "         0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0140, 0.0140, 0.0140, 0.2000, 0.7580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.5770, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0710,\n",
      "         0.0710, 0.0710, 0.0710, 0.0710, 0.0710, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0440, 0.0440, 0.6330, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)}\n",
      "{'input_ids': tensor([[  101,  2941,  1045,  2572,  1037,  3017,  2017, 14163, 13793,  2063,\n",
      "          8840,  2239,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8840,  2140,  2043,  2106,  1045,  2412,  2360,  2505,  2055,\n",
      "          5637,  3348,  1045,  3432,  2056,  2115,  4748,  7570, 11233,  2213,\n",
      "          4491,  2020, 11937, 21756,  7570, 11233,  2213,  2515,  2025,   102],\n",
      "        [  101,  6203,  6206,  7489,  2542,  1999,  2026,  4545,  2311,  2644,\n",
      "         15849,  8525, 15379,  2290,  1996, 12699,  3698,  2644,  3228,  2033,\n",
      "          6530,  3504,  2043,  1045, 19045,  3198,  2017,  2000,  6366,   102],\n",
      "        [  101,  5310,  4931,  2045, 10047,  5620,  2007,  2317, 15406,  2064,\n",
      "          2022,  3492, 16801,  2000, 10782,  2672,  2009,  2019,  3341,  2553,\n",
      "          2021,  2009,  2165,  2033,  3243,  2070,  2051,  2000,  3275,   102],\n",
      "        [  101,  1998,  2292,  2149,  2191,  2242,  2842,  3154, 10474,  2003,\n",
      "          2025,  5379,  2005,  2336,  1998,  2087,  1997,  1996,  2308,  2008,\n",
      "          1045,  2031,  2412,  2777,  1999,  2026,  2166,  2008,  2020,   102],\n",
      "        [  101,  5310,  2023,  2003,  1996,  3124,  1045,  2001,  3214,  2000,\n",
      "          2022,  9177,  2007,  2010, 16012,  2758,  2002,  2003,  1037, 11867,\n",
      "          2594, 18792,  2021,  2811,  2032,  2006,  2009,  1998,  2002,   102],\n",
      "        [  101,  2111,  2008,  2228,  2008,  2027,  2031,  1037,  3167,  3276,\n",
      "          2007,  2831,  2000,  1037,  7214, 11382,  3489,  2566, 16874, 14397,\n",
      "         10128,  2923,  2006,  1037,  6293,  2024,  9577,  2566, 16874,   102],\n",
      "        [  101,  2059,  2045,  2024,  1996,  3924,  2040,  2435,  2009,  2039,\n",
      "          2030,  2921,  4333,  2055,  2108, 15504,  1998,  2288,  2187,  1999,\n",
      "          1996,  6497,  4312, 17399, 21863,  3367,  9438,  2427,  1998,   102],\n",
      "        [  101,  2017,  2412,  2156,  3469,  2084,  2166,  2304,  2308,  2131,\n",
      "          4854,  5674,  2193,  1997,  2068,  1999,  2037,  5760,  2304,  7046,\n",
      "          2084,  2166,  7385,  6461,  2012,  1996, 22418,  3337,  1997,   102],\n",
      "        [  101,  2151,  6530,  2564, 22889, 16446,  2215,  2000,  2031,  2070,\n",
      "          4569,  3745, 27263,  2015,  1998,  2074,  2079,  4689,  4485,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5310,  4931,  6775,  2054,  2024,  1996, 26319,  2006,  9040,\n",
      "          2043,  1045,  2387,  1996,  9152,  2015, 15088,  5002,  2009,  3090,\n",
      "          2008,  2247,  2007,  2081,  2000, 19136,  2308,  2024,  2145,   102],\n",
      "        [  101,  1045,  8415,  2090,  5310,  1998,  5310,  2009,  2019, 10866,\n",
      "         16360, 16119, 15667,  6187,  3597, 21890,  4890,  1997,  9587,  2906,\n",
      "          2304, 10338,  2015,  1045,  2215,  9587,  2906,  2304, 10338,   102],\n",
      "        [  101,  5310,  3531,  4863,  2000,  2033,  2339,  6206,  7489,  2052,\n",
      "          4374,  8817,  2104,  2115,  6745,  3021,  2008,  2003,  2074, 25506,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2017,  2113,  2129,  2128,  7559,  5732,  2009,  2003,  2000,\n",
      "          2131,  1037,  1045,  1521,  1049,  2746,  2000,  2017,  2004,  1037,\n",
      "          2450,  1524,  1040,  2213,  2012,  1996,  2287,  1997,  2193,   102],\n",
      "        [  101,  2023,  2003,  2339,  2308,  2383, 10922,  2003,  2025,  2256,\n",
      "          2111,  2023,  2003,  2339,  2151,  2512,  2317,  7521,  2003,  2025,\n",
      "          2256,  2111,  2023,  2003,  2339,  2725,  5850,  2003,  2025,   102],\n",
      "        [  101,  5310,  5310,  5310,  6256,  1998, 27936,  2003,  2025,  2054,\n",
      "          3047,  1996,  2157,  3358, 11240,  3047,  2216,  4364,  2293, 11273,\n",
      "          3102,  4426,  2012,  2111,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0]], device='cuda:0'), 'space': tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]]), 'attention_score': tensor([[0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.7280, 0.1920, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0080, 0.1140, 0.1140, 0.1140, 0.1140, 0.1140, 0.1140, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080, 0.0080,\n",
      "         0.0080, 0.0080, 0.0080],\n",
      "        [0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
      "         0.0230, 0.0230, 0.0230],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "         0.0250, 0.0250, 0.0250],\n",
      "        [0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0740, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200, 0.0200, 0.2810],\n",
      "        [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.6030, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "         0.0110, 0.0110, 0.0110],\n",
      "        [0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.0390,\n",
      "         0.0390, 0.0390, 0.0390, 0.0390, 0.0390, 0.1470, 0.0390, 0.0390, 0.0390,\n",
      "         0.0390, 0.0390, 0.0390, 0.0390, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0590, 0.0590, 0.0040,\n",
      "         0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2230,\n",
      "         0.0590, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.0040, 0.2230, 0.2230,\n",
      "         0.0040, 0.0040, 0.0040],\n",
      "        [0.0070, 0.0960, 0.3640, 0.3640, 0.0960, 0.0070, 0.0070, 0.0070, 0.0070,\n",
      "         0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0070, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "         0.0330, 0.0330, 0.0330],\n",
      "        [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030,\n",
      "         0.0420, 0.1610, 0.0420, 0.0030, 0.0420, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "         0.0420, 0.1610, 0.1610, 0.0420, 0.0420, 0.0420, 0.0030, 0.0030, 0.0030,\n",
      "         0.0030, 0.0030, 0.0030],\n",
      "        [0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
      "         0.0530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0120, 0.0120, 0.0120, 0.6610, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120, 0.0120,\n",
      "         0.0120, 0.0120, 0.0000],\n",
      "        [0.0050, 0.0050, 0.0050, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170, 0.0170,\n",
      "         0.0170, 0.0050, 0.0050, 0.0050, 0.0050, 0.0660, 0.2500, 0.2500, 0.0170,\n",
      "         0.0170, 0.0170, 0.0170, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
      "         0.0050, 0.0050, 0.0050],\n",
      "        [0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0430,\n",
      "         0.0430, 0.0430, 0.0430, 0.0430, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000]]), 'label': tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "       dtype=torch.float64)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1597782/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2121711545.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1597782/2121711545.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">426</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__repr__</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 423 │   │   │   │   </span>Tensor.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__repr__</span>, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, tensor_contents=tensor_contents           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 424 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 425 │   │   # All strings are unicode in Python 3.</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 426 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._tensor_str._str(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, tensor_contents=tensor_contents)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 427 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 428 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>(                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 429 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, retain_graph=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, create_graph=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, inputs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor_str.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">636</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_str</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">633 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_str</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *, tensor_contents=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">634 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">635 │   │   </span>guard = torch._C._DisableFuncTorch()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>636 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _str_intern(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, tensor_contents=tensor_contents)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">637 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor_str.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">567</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_str_intern</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">564 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layout != torch.strided:                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">565 │   │   │   │   │   │   </span>tensor_str = _tensor_str(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.to_dense(), indent)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">566 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>567 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>tensor_str = _tensor_str(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, indent)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">568 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">569 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layout != torch.strided:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">570 │   │   </span>suffixes.append(<span style=\"color: #808000; text-decoration-color: #808000\">\"layout=\"</span> + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layout))                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor_str.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">327</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_tensor_str</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">324 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, indent, summarize, real_formatter, imag_formatter                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">325 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">326 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>327 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>formatter = _Formatter(get_summarized_data(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> summarize <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _tensor_str_with_formatter(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, indent, summarize, formatter)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">330 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor_str.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">111</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.floating_dtype:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tensor_view:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>111 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>value_str = <span style=\"color: #808000; text-decoration-color: #808000\">\"{}\"</span>.format(value)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.max_width = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">max</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.max_width, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(value_str))                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">872</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__format__</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 869 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_torch_function_unary(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 870 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> handle_torch_function(Tensor.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__format__</span>, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, format_spec)   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 871 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dim() == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.is_meta <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> Tensor:                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 872 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.item().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__format__</span>(format_spec)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 873 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">object</span>.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__format__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, format_spec)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 874 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 875 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@_handle_torch_function_and_wrap_type_error_to_not_implemented</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1597782/\u001b[0m\u001b[1;33m2121711545.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1597782/2121711545.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m426\u001b[0m in \u001b[92m__repr__\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 423 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mTensor.\u001b[92m__repr__\u001b[0m, (\u001b[96mself\u001b[0m,), \u001b[96mself\u001b[0m, tensor_contents=tensor_contents           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 424 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 425 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# All strings are unicode in Python 3.\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 426 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch._tensor_str._str(\u001b[96mself\u001b[0m, tensor_contents=tensor_contents)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 427 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 428 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbackward\u001b[0m(                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 429 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m, gradient=\u001b[94mNone\u001b[0m, retain_graph=\u001b[94mNone\u001b[0m, create_graph=\u001b[94mFalse\u001b[0m, inputs=\u001b[94mNone\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor_str.py\u001b[0m:\u001b[94m636\u001b[0m in \u001b[92m_str\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m633 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_str\u001b[0m(\u001b[96mself\u001b[0m, *, tensor_contents=\u001b[94mNone\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m634 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m635 \u001b[0m\u001b[2m│   │   \u001b[0mguard = torch._C._DisableFuncTorch()                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m636 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _str_intern(\u001b[96mself\u001b[0m, tensor_contents=tensor_contents)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m637 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor_str.py\u001b[0m:\u001b[94m567\u001b[0m in \u001b[92m_str_intern\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.layout != torch.strided:                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtensor_str = _tensor_str(\u001b[96mself\u001b[0m.to_dense(), indent)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m566 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m567 \u001b[2m│   │   │   │   │   │   \u001b[0mtensor_str = _tensor_str(\u001b[96mself\u001b[0m, indent)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.layout != torch.strided:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m570 \u001b[0m\u001b[2m│   │   \u001b[0msuffixes.append(\u001b[33m\"\u001b[0m\u001b[33mlayout=\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mstr\u001b[0m(\u001b[96mself\u001b[0m.layout))                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor_str.py\u001b[0m:\u001b[94m327\u001b[0m in \u001b[92m_tensor_str\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, indent, summarize, real_formatter, imag_formatter                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m326 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m327 \u001b[2m│   │   \u001b[0mformatter = _Formatter(get_summarized_data(\u001b[96mself\u001b[0m) \u001b[94mif\u001b[0m summarize \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _tensor_str_with_formatter(\u001b[96mself\u001b[0m, indent, summarize, formatter)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor_str.py\u001b[0m:\u001b[94m111\u001b[0m in \u001b[92m__init__\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.floating_dtype:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m value \u001b[95min\u001b[0m tensor_view:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m111 \u001b[2m│   │   │   │   \u001b[0mvalue_str = \u001b[33m\"\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m\"\u001b[0m.format(value)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.max_width = \u001b[96mmax\u001b[0m(\u001b[96mself\u001b[0m.max_width, \u001b[96mlen\u001b[0m(value_str))                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m872\u001b[0m in \u001b[92m__format__\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 869 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m has_torch_function_unary(\u001b[96mself\u001b[0m):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 870 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m handle_torch_function(Tensor.\u001b[92m__format__\u001b[0m, (\u001b[96mself\u001b[0m,), \u001b[96mself\u001b[0m, format_spec)   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 871 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.dim() == \u001b[94m0\u001b[0m \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.is_meta \u001b[95mand\u001b[0m \u001b[96mtype\u001b[0m(\u001b[96mself\u001b[0m) \u001b[95mis\u001b[0m Tensor:                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 872 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.item().\u001b[92m__format__\u001b[0m(format_spec)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 873 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mobject\u001b[0m.\u001b[92m__format__\u001b[0m(\u001b[96mself\u001b[0m, format_spec)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 874 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 875 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=30\n",
    "BATCH_SIZE=16\n",
    "PROJECTION_DIM=2\n",
    "\n",
    "# Instantiate an object of the BERTDataset class\n",
    "bert_dataset = BERTDataset(text=None, labels=None, attention_scores=None, max_length=None, tokenizer=None, projection_dim=None)\n",
    "\n",
    "# Call the dataprep method on the object\n",
    "train_loader, val_loader = bert_dataset.dataprep(train_df, val_df, tokenizer, MAX_LEN, BATCH_SIZE, PROJECTION_DIM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGGXmXltToJP"
   },
   "source": [
    "# Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_projected(vects):\n",
    "    x, w = vects\n",
    "\n",
    "    dp = torch.matmul(x, w.t())\n",
    "\n",
    "    x_mag = torch.norm(x, dim=2, keepdim=True)\n",
    "\n",
    "    w_mag = torch.norm(w, dim=1, keepdim=True)\n",
    "\n",
    "    denominator = dp / x_mag\n",
    "    cosine = denominator / w_mag\n",
    "\n",
    "    return cosine\n",
    "\n",
    "# NA\n",
    "def compare_cosine(vector):\n",
    "    peace, violent, normal = vector\n",
    "\n",
    "    peace = torch.mean(peace, dim=1)\n",
    "    violent = torch.mean(violent, dim=1)\n",
    "    normal = torch.mean(normal, dim=1)\n",
    "    out = torch.cat([peace, violent, normal], dim=-1)\n",
    "    print(\"COMPARE-COSINE\")\n",
    "    print(out.shape)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "crv2VhKhUBiQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class remove_pads(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, **kwargs):\n",
    "        super(remove_pads, self).__init__(**kwargs)\n",
    "        self.mask_generator = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, inputs, input_ids):\n",
    "        masks = self.mask_generator(input_ids)\n",
    "        masks = masks.float().unsqueeze(-1)\n",
    "        temp = masks.unbind(dim=1)\n",
    "        del temp[0]\n",
    "        temp.insert(0, torch.zeros_like(temp[0]))\n",
    "        masks = torch.stack(temp, dim=1)\n",
    "        length = masks.sum(dim=1, keepdim=True)\n",
    "        masked_embeddings = inputs * masks\n",
    "        masked_embeddings = masked_embeddings.sum(dim=1, keepdim=True)\n",
    "        masked_embeddings /= length\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "class remove_padsV2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, **kwargs):\n",
    "        super(remove_padsV2, self).__init__(**kwargs)\n",
    "        self.mask_generator = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, inputs, input_ids):\n",
    "        filtered_input_ids = torch.where((input_ids == 101) | (input_ids == 102), torch.tensor(0), input_ids)\n",
    "        masks = self.mask_generator(filtered_input_ids)\n",
    "        masks = masks.float().unsqueeze(-1)\n",
    "        masked_embeddings = inputs * masks\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mean embeddings\n",
    "def merge_function(vects):\n",
    "    negative, normal = vects\n",
    "\n",
    "    negative_length = torch.count_nonzero(torch.sum(negative, dim=2, keepdim=True), dim=1, keepdim=True, dtype=torch.float32)\n",
    "    normal_length = torch.count_nonzero(torch.sum(normal, dim=2, keepdim=True), dim=1, keepdim=True, dtype=torch.float32)\n",
    "\n",
    "    negative_average = torch.sum(negative, dim=1, keepdim=True) / negative_length\n",
    "    normal_average = torch.sum(normal, dim=1, keepdim=True) / normal_length\n",
    "\n",
    "    res = torch.cat([negative_average, normal_average], dim=-1)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# max embeddings\n",
    "def merge_functionV2(vects):\n",
    "    negative, normal = vects\n",
    "\n",
    "    negative_max = torch.max(negative, dim=1, keepdim=True)[0]\n",
    "    normal_max = torch.max(normal, dim=1, keepdim=True)[0]\n",
    "\n",
    "    res = torch.cat([negative_max, normal_max], dim=-1)\n",
    "\n",
    "    return res\n",
    "\n",
    "# increase stdDevLoss in projection dimension\n",
    "def StdDevLoss(x):\n",
    "    std_dev = torch.std(x, dim=2)\n",
    "    std_dev_loss = torch.mean(std_dev)\n",
    "\n",
    "    return std_dev_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xVIgFoIztcq"
   },
   "source": [
    "Loading Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CustomLoss(nn.Module):\n",
    "#     def __init__(self, name=None):\n",
    "#         super(CustomLoss, self).__init__()\n",
    "#         self.name = name\n",
    "\n",
    "# class CosineSimilarityLoss(CustomLoss):\n",
    "#     def forward(self, x, y):\n",
    "#         return torch.mean(1.0 / (1.01 + F.cosine_similarity(x, y)))\n",
    "\n",
    "# class IntraClassLoss(CustomLoss):\n",
    "#     def forward(self, cosine_values):\n",
    "#         return 1.0 / (torch.std(cosine_values) + 0.001)\n",
    "\n",
    "# class BinaryCrossEntropyLoss(CustomLoss):\n",
    "#     def forward(self, attention_score, hidden4):\n",
    "#         return nn.BCEWithLogitsLoss()(attention_score, hidden4)\n",
    "    \n",
    "    \n",
    "    \n",
    "# class LossValues:\n",
    "#     def __init__(self):\n",
    "#         self.offensive_normal_loss = []\n",
    "#         self.toxic_intra_loss = []\n",
    "#         self.non_toxic_intra_loss = []\n",
    "#         self.attention_loss = []\n",
    "\n",
    "#     def update(self, offensive_normal_loss, toxic_intra_loss, non_toxic_intra_loss, attention_loss):\n",
    "#         self.offensive_normal_loss.append(offensive_normal_loss.item())\n",
    "#         self.toxic_intra_loss.append(toxic_intra_loss.item())\n",
    "#         self.non_toxic_intra_loss.append(non_toxic_intra_loss.item())\n",
    "#         self.attention_loss.append(attention_loss.item())\n",
    "\n",
    "#     def get_values(self):\n",
    "#         return {\n",
    "#             'offensive_normal_loss': self.offensive_normal_loss,\n",
    "#             'toxic_intra_loss': self.toxic_intra_loss,\n",
    "#             'non_toxic_intra_loss': self.non_toxic_intra_loss,\n",
    "#             'attention_loss': self.attention_loss\n",
    "#         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class SpockModel(nn.Module):\n",
    "    def __init__(self, MAX_LENGTH, PROJECTION_DIM, lambda_value):\n",
    "        super(SpockModel, self).__init__()\n",
    "        self.MAX_LENGTH = MAX_LENGTH\n",
    "        self.PROJECTION_DIM = PROJECTION_DIM\n",
    "        self.lambda_value = lambda_value\n",
    "        self.VECTOR_DIM = 768\n",
    "\n",
    "        # Layers\n",
    "        self.bert_model = bertModel  # Assuming you have defined bertModel elsewhere\n",
    "        self.offensive_embedding_layer = nn.Embedding(PROJECTION_DIM, self.VECTOR_DIM)\n",
    "        self.normal_embedding_layer = nn.Embedding(PROJECTION_DIM, self.VECTOR_DIM)\n",
    "\n",
    "        self.hidden1 = nn.Linear(2 * self.PROJECTION_DIM, 256)\n",
    "        # self.hidden2 = nn.Linear(612, 256)\n",
    "        self.hidden3 = nn.Linear(256, 64)\n",
    "        self.hidden4 = nn.Linear(64, 30)\n",
    "        self.classification_layer = nn.Linear(30, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Loss Functions\n",
    "        self.cosine_loss = CosineSimilarityLoss(name='cosine_loss')\n",
    "        self.intra_loss = IntraClassLoss(name='intra_loss')\n",
    "        self.bce_loss = BinaryCrossEntropyLoss(name='attention_loss')\n",
    "        # self.loss_values = LossValues()\n",
    "\n",
    "\n",
    "    def forward(self, ids, mks, projection_space, attention_score):\n",
    "        input_sentence = self.bert_model(ids, attention_mask=mks)[0].to(device)\n",
    "\n",
    "        offensive_embedding_np = self.offensive_embedding_layer(projection_space)\n",
    "        normal_embedding_np = self.normal_embedding_layer(projection_space)\n",
    "\n",
    "        offensive_embedding = offensive_embedding_np.permute(0, 2, 1)\n",
    "        normal_embedding = normal_embedding_np.permute(0, 2, 1)\n",
    "\n",
    "        offensive_cosine = self.cosine_similarity_projected(input_sentence, offensive_embedding)\n",
    "        normal_cosine = self.cosine_similarity_projected(input_sentence, normal_embedding)\n",
    "\n",
    "        offensive_cosine_nopads = self.remove_padsV2(offensive_cosine, ids)\n",
    "        normal_cosine_nopads = self.remove_padsV2(normal_cosine, ids)\n",
    "\n",
    "        merged = self.merge_functionV2(offensive_cosine_nopads, normal_cosine_nopads)\n",
    "        merged = merged.view(-1, 2 * self.PROJECTION_DIM)\n",
    "\n",
    "        hidden1 = F.relu(self.hidden1(merged))\n",
    "        hidden2 = F.relu(self.hidden2(hidden1))\n",
    "        hidden3 = F.relu(self.hidden3(hidden2))\n",
    "        hidden4 = F.relu(self.hidden4(hidden3))\n",
    "\n",
    "        predictions = torch.sigmoid(self.classification_layer(hidden4))\n",
    "        # print(predictions)\n",
    "\n",
    "        # # Losses\n",
    "        offensive_normal_loss = self.cosine_loss(torch.mean(offensive_cosine, dim=1), torch.mean(normal_cosine, dim=1))\n",
    "        toxic_intra_loss = self.intra_loss(offensive_cosine)\n",
    "        non_toxic_intra_loss = self.intra_loss(normal_cosine)\n",
    "        bce_loss1 = self.bce_loss(attention_score, hidden4)\n",
    "\n",
    "        # Total Loss\n",
    "        # + self.lambda_value * bce_loss1\n",
    "        loss = offensive_normal_loss + toxic_intra_loss + non_toxic_intra_loss + self.lambda_value * bce_loss1\n",
    "        \n",
    "        # self.loss_values.update(offensive_normal_loss, toxic_intra_loss, non_toxic_intra_loss, bce_loss1)\n",
    "        \n",
    "\n",
    "\n",
    "        return predictions,loss,offensive_normal_loss, toxic_intra_loss, non_toxic_intra_loss, bce_loss1\n",
    "\n",
    "#     def cosine_similarity_projected(self, x, w):\n",
    "#         dp = torch.matmul(x, w)\n",
    "#         x_mag = torch.norm(x, dim=2, keepdim=True)\n",
    "#         w_mag = torch.norm(w, dim=1, keepdim=True)\n",
    "#         cosine = dp / (x_mag * w_mag)\n",
    "#         return cosine\n",
    "\n",
    "#     def remove_padsV2(self, vects, ids):\n",
    "#         masks = ids != 0\n",
    "#         masks = masks.unsqueeze(-1).float()\n",
    "#         masked_embeddings = vects * masks\n",
    "#         return masked_embeddings\n",
    "\n",
    "#     def merge_functionV2(self, negative, normal):\n",
    "#         negative_max = torch.max(negative, dim=1, keepdim=True)[0]\n",
    "#         normal_max = torch.max(normal, dim=1, keepdim=True)[0]\n",
    "#         return torch.cat([negative_max, normal_max], dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training and Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 32\n",
    "PROJECTION_DIM = 3\n",
    "VECTOR_DIM = 768\n",
    "lambda_value = 0.2\n",
    "EPOCHS = 3\n",
    "\n",
    "# Initialize model\n",
    "spock_model = SpockModel(MAX_LENGTH, PROJECTION_DIM, lambda_value)\n",
    "# spock_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spock_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval(f):\n",
    "    def wrapper(model, *args, **kwargs):\n",
    "        model.eval()\n",
    "        return f(model, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def train(f):\n",
    "    def wrapper(model, *args, **kwargs):\n",
    "        model.train()\n",
    "        return f(model, *args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader,val_dataloader=dataprep(3)\n",
    "s=1\n",
    "@train\n",
    "def train_epoch(model, train_dataloader, optimizer):\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # print(step)\n",
    "        # if step==1:\n",
    "        \n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_masks = batch['attention_masks'].to(device)\n",
    "        space = batch['space'].to(device)\n",
    "        attention_score = batch['attention_score'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids, attention_masks, space, attention_score) # (B, Seq_Len, 2)\n",
    "        preds,loss,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss, train_bce_loss1= outputs\n",
    "        loss = torch.mean(loss)  # Compute the mean loss across the batch    \n",
    "        \n",
    "        labels = labels.view(-1, 1).float()\n",
    "        \n",
    "        bce_loss = nn.BCEWithLogitsLoss()(preds.view(-1,1), labels.float())\n",
    "        loss += bce_loss\n",
    "        \n",
    "        train_preds += preds.detach().tolist()\n",
    "        train_labels += [l.item() for l in labels]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # else:\n",
    "        #     break\n",
    "    return train_loss, train_preds, train_labels,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss, train_bce_loss1\n",
    "\n",
    "@eval\n",
    "def eval_epoch(model, val_dataloader):\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for step, batch in enumerate(val_dataloader):\n",
    "            # if step==1:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_masks = batch['attention_masks'].to(device)\n",
    "            space = batch['space'].to(device)\n",
    "            attention_score = batch['attention_score'].to(device)\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(input_ids, attention_masks, space, attention_score) # (B, Seq_Len, 2)\n",
    "\n",
    "            # loss, logits = outputs.loss, outputs.logits\n",
    "            preds,loss,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss, val_bce_loss1 = outputs\n",
    "            loss=torch.mean(loss)\n",
    "            # print(preds.dtype)\n",
    "\n",
    "\n",
    "            # probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # pred = torch.argmax(probs, dim=-1) # (B)\n",
    "            val_preds += preds.detach().tolist()\n",
    "            val_labels += [l.item() for l in labels]\n",
    "            # print(val_labels,val_preds)\n",
    "            val_loss += loss.item()\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "               \n",
    "    return val_loss, val_preds, val_labels,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss, val_bce_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Metrices\n",
    "def training(model, train_data, val_data, config):\n",
    "    model = model\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "\n",
    "    num_train_steps = int(len(train_data) / config['batch_size'] * config['epochs'])\n",
    "    num_train_steps=2\n",
    "\n",
    "    print(f'Train steps: {num_train_steps}')\n",
    "\n",
    "    # train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
    "    # val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=config['val_batch_size'])\n",
    "\n",
    "    history = {\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': [],\n",
    "        'train_f1': [],\n",
    "        'val_f1': [],\n",
    "        'train_precision': [],\n",
    "        'val_precision': [],\n",
    "        'train_recall': [],\n",
    "        'val_recall': [],\n",
    "        'train_offensive_normal_loss': [],\n",
    "        'train_toxic_intra_loss': [],\n",
    "        'train_non_toxic_intra_loss': [],\n",
    "        'train_bce_loss1': [],\n",
    "        'val_offensive_normal_loss': [],\n",
    "        'val_toxic_intra_loss': [],\n",
    "        'val_non_toxic_intra_loss': [],\n",
    "        'val_bce_loss1': []\n",
    "    }\n",
    "    # Inside the training loop\n",
    "    for epoch_num in range(config['epochs']):\n",
    "        print(f'Epoch: {epoch_num + 1}')\n",
    "\n",
    "        # Train stage\n",
    "        train_loss, train_preds, train_labels,train_offensive_normal_loss,train_toxic_intra_loss, train_non_toxic_intra_loss, train_bce_loss1 = train_epoch(model, train_dataloader, optimizer)\n",
    "\n",
    "        # Eval stage\n",
    "        val_loss, val_preds, val_labels,val_offensive_normal_loss, val_toxic_intra_loss, val_non_toxic_intra_loss, val_bce_loss1 = eval_epoch(model, val_dataloader)\n",
    "\n",
    "\n",
    "        train_preds_tensor = torch.tensor(train_preds)\n",
    "        val_preds_tensor = torch.tensor(val_preds)\n",
    "\n",
    "        # Get class labels using argmax\n",
    "        train_preds_labels = torch.argmax(train_preds_tensor, dim=1).cpu().numpy()\n",
    "        val_preds_labels = torch.argmax(val_preds_tensor, dim=1).cpu().numpy()\n",
    "        \n",
    "        # losses_dict = model.loss_values.get_values()\n",
    "\n",
    "        \n",
    "        # print(train_preds_labels,val_preds_labels)\n",
    "        # print(val_labels,train_labels)\n",
    "                \n",
    "\n",
    "        # Metrics calculation\n",
    "        train_acc = accuracy_score(train_labels, train_preds_labels)\n",
    "        val_acc = accuracy_score(val_labels, val_preds_labels)\n",
    "        train_f1 = f1_score(train_labels, train_preds_labels, average='macro')\n",
    "        val_f1 = f1_score(val_labels, val_preds_labels, average='macro')\n",
    "        train_precision = precision_score(train_labels, train_preds_labels, average='weighted')\n",
    "        val_precision = precision_score(val_labels, val_preds_labels, average='weighted')\n",
    "        train_recall = recall_score(train_labels, train_preds_labels, average='weighted')\n",
    "        val_recall = recall_score(val_labels, val_preds_labels, average='weighted')\n",
    "\n",
    "        # Update history dictionary\n",
    "        history['train_losses'].append(train_loss / len(train_dataloader))\n",
    "        history['val_losses'].append(val_loss / len(val_dataloader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['val_recall'].append(val_recall)\n",
    "\n",
    "        # Append training loss values\n",
    "#         history['train_offensive_normal_loss'].append(train_offensive_normal_loss)\n",
    "#         history['train_toxic_intra_loss'].append(train_toxic_intra_loss)\n",
    "#         history['train_non_toxic_intra_loss'].append(train_non_toxic_intra_loss)\n",
    "#         history['train_bce_loss1'].append(train_bce_loss1)\n",
    "        \n",
    "        history['train_offensive_normal_loss'].append(train_offensive_normal_loss.detach().cpu().numpy())\n",
    "        history['train_toxic_intra_loss'].append(train_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['train_non_toxic_intra_loss'].append(train_non_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['train_bce_loss1'].append(train_bce_loss1.detach().cpu().numpy())\n",
    "\n",
    "        # Append validation loss values\n",
    "        history['val_offensive_normal_loss'].append(val_offensive_normal_loss.detach().cpu().numpy())\n",
    "        history['val_toxic_intra_loss'].append(val_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['val_non_toxic_intra_loss'].append(val_non_toxic_intra_loss.detach().cpu().numpy())\n",
    "        history['val_bce_loss1'].append(val_bce_loss1.detach().cpu().numpy())\n",
    "\n",
    "        print()\n",
    "        print(f'Train loss: {train_loss / len(train_dataloader)} | Val loss: {val_loss / len(val_dataloader)}')\n",
    "        print(f'Train acc: {train_acc} | Val acc: {val_acc}')\n",
    "        print(f'Train f1: {train_f1} | Val f1: {val_f1}')\n",
    "        print(f'Train precision: {train_precision} | Val precision: {val_precision}')\n",
    "        print(f'Train recall: {train_recall} | Val recall: {val_recall}')\n",
    "        \n",
    "        \n",
    "        # losses_dict = loss_values.get_values()\n",
    "\n",
    "\n",
    "        # Add loss values to history\n",
    "        # history['offensive_normal_loss'].append(losses_dict['offensive_normal_loss'])\n",
    "        # history['toxic_intra_loss'].append(losses_dict['toxic_intra_loss'])\n",
    "        # history['non_toxic_intra_loss'].append(losses_dict['non_toxic_intra_loss'])\n",
    "        # history['attention_loss'].append(losses_dict['attention_loss'])\n",
    "\n",
    "    # Free GPU cache if necessary\n",
    "    free_gpu_cache(device_id)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "GPU memory occupied: 12237 MB.\n",
      "GPU Usage after emptying the cache\n",
      "GPU memory occupied: 12237 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization(device_id)\n",
    "torch.cuda.empty_cache()\n",
    "free_gpu_cache(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1595234/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1390667852.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1595234/1390667852.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'LEARNING_RATE'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1595234/\u001b[0m\u001b[1;33m1390667852.py\u001b[0m:\u001b[94m10\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1595234/1390667852.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'LEARNING_RATE'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_dataloader,val_dataloader=dataprep(PROJECTION_DIM)\n",
    "NUM_EPOCHS=10\n",
    "config = {\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'val_batch_size': BATCH_SIZE,\n",
    "    \n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'fp16': False,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'max_grad_norm': MAX_GRAD_NORM,\n",
    "    'weight_decay': 0.01,\n",
    "}\n",
    "history = training(spock_model.to(device), train_dataloader, val_dataloader, config)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_losses', 'val_losses', 'train_acc', 'val_acc', 'train_f1', 'val_f1', 'train_precision', 'val_precision', 'train_recall', 'val_recall', 'train_offensive_normal_loss', 'train_toxic_intra_loss', 'train_non_toxic_intra_loss', 'train_bce_loss1', 'val_offensive_normal_loss', 'val_toxic_intra_loss', 'val_non_toxic_intra_loss', 'val_bce_loss1'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_results(history, do_val=True):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 10))\n",
    "\n",
    "    # Losses\n",
    "    axs[0, 0].plot(history['train_losses'], label='Train Loss')\n",
    "    if do_val:\n",
    "        axs[0, 0].plot(history['val_losses'], label='Validation Loss')\n",
    "    axs[0, 0].set_title('Train / Validation Loss')\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Accuracy\n",
    "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy')\n",
    "    if do_val:\n",
    "        axs[0, 1].plot(history['val_acc'], label='Validation Accuracy')\n",
    "    axs[0, 1].set_title('Train / Validation Accuracy')\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('Accuracy')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # F1 Score\n",
    "    # axs[1, 0].plot(history['train_f1'], label='Train F1 Score')\n",
    "    \n",
    "    axs[1, 0].plot(history['train_offensive_normal_loss'], label='train_offensive_normal_loss')\n",
    "    if do_val:\n",
    "        axs[1, 0].plot(history['val_offensive_normal_loss'], label='val_offensive_normal_loss')\n",
    "\n",
    "    axs[1, 0].set_title('Train / Validation offensive_normal_loss')\n",
    "    axs[1, 0].set_xlabel('Epochs')\n",
    "    axs[1, 0].set_ylabel('offensive_normal_loss')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Precision\n",
    "    \n",
    "    axs[1,1].plot(history['train_toxic_intra_loss'], label='train_toxic_intra_loss')\n",
    "\n",
    "    if do_val:\n",
    "        axs[1,1].plot(history['train_non_toxic_intra_loss'], label='train_non_toxic_intra_loss')\n",
    "    # axs[1, 1].plot(history['train_precision'], label='Train Precision')\n",
    "    # if do_val:\n",
    "    #     axs[1, 1].plot(history['val_precision'], label='Validation Precision')\n",
    "    axs[1, 1].set_title('Toxic/ Non_Toxix intra_loss')\n",
    "    axs[1, 1].set_xlabel('Epochs')\n",
    "    axs[1, 1].set_ylabel('Precision')\n",
    "    axs[1, 1].legend()\n",
    "    \n",
    "        # axs[1,1].plot(history['train_toxic_intra_loss'], label='train_toxic_intra_loss')\n",
    "\n",
    "    if do_val:\n",
    "        axs[2,0].plot(history['train_bce_loss1'], label='train_bce_loss1')\n",
    "        axs[2, 0].plot(history['val_bce_loss1'], label='Trainval_bce_loss1')\n",
    "    # if do_val:\n",
    "    #     axs[1, 1].plot(history['val_precision'], label='Validation Precision')\n",
    "    axs[2,0].set_title('train_bce_loss1/ val_bce_loss1')\n",
    "    axs[2,0].set_xlabel('Epochs')\n",
    "    axs[2,0].set_ylabel('Precision')\n",
    "    axs[2,0].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_results(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCHS=3\n",
    "\n",
    "criterion = nn.BCELoss()  # Define your loss function\n",
    "train_dataloader,val_dataloader=dataprep(PROJECTION_DIM)\n",
    "\n",
    "optimizer = optim.Adam(spock_model.parameters(), lr=0.001) # Adam optimizer with learning rate 0.001\n",
    "\n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, optimizer, criterion, device):\n",
    "    history = {'train_losses': [], 'val_losses': [], 'train_acc': [], 'val_acc': [],\n",
    "               'train_f1': [], 'val_f1': [], 'train_precision': [], 'val_precision': [],\n",
    "               'train_recall': [], 'val_recall': []}\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            input_ids = data['input_ids']\n",
    "            attention_masks = data['attention_masks']\n",
    "            space = data['space']\n",
    "            attention_score = data['attention_score']\n",
    "            train_labels = data['label']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, _ = spock_model(input_ids, attention_masks, space, attention_score)\n",
    "            loss = criterion(outputs, labels.view(-1, 1).float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            predicted_labels = (outputs > 0.5).float()\n",
    "            correct_predictions += (predicted_labels == labels.view(-1, 1).float()).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            if i % 5 == 4:  # Print every 5 mini-batches\n",
    "                print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {train_loss / 5:.3f}\")\n",
    "                train_loss = 0.0\n",
    "\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        # Evaluation on validation set\n",
    "        val_loss, val_preds, val_labels = eval_epoch(model, val_dataloader, device)\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        val_precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "        val_recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "        train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
    "\n",
    "\n",
    "        history['train_losses'].append(train_loss / len(train_dataloader))\n",
    "        history['val_losses'].append(val_loss / len(val_dataloader))\n",
    "        history['train_acc'].append(train_accuracy)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['val_recall'].append(val_recall)\n",
    "\n",
    "        print()\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        print(f'Train loss: {train_loss / len(train_dataloader)} | Val loss: {val_loss / len(val_dataloader)}')\n",
    "        print(f'Train acc: {train_accuracy} | Val acc: {val_accuracy}')\n",
    "        print(f'Val f1: {val_f1} | Val precision: {val_precision} | Val recall: {val_recall}')\n",
    "\n",
    "    return history\n",
    "\n",
    "def eval_epoch(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            input_ids = data['input_ids']\n",
    "            attention_masks = data['attention_masks']\n",
    "            space = data['space']\n",
    "            attention_score = data['attention_score']\n",
    "            labels = data['label']\n",
    "\n",
    "            outputs, _ = model(input_ids, attention_masks, space, attention_score)\n",
    "            loss = criterion(outputs, labels.view(-1, 1).float())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_labels = (outputs > 0.5).float()\n",
    "            val_preds.extend(predicted_labels.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return val_loss, val_preds, val_labels\n",
    "\n",
    "# Train and evaluate the model\n",
    "history = train_and_evaluate(spock_model, val_dataloader, train_dataloader, optimizer, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "OJHKxhG4Uphm",
    "outputId": "8e989294-bc36-4224-f212-269241763980",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# Set up hyperparameters\n",
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 16\n",
    "PROJECTION_DIM = 30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value = 2\n",
    "EPOCHS = 20\n",
    "PROJECTION_DIM = 10  # You redefined PROJECTION_DIM here, it might not be necessary\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "spock_model1 = SpockModel(MAX_LENGTH, PROJECTION_DIM, lambda_value)\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Define your loss function\n",
    "optimizer = optim.Adam(spock_model1.parameters(), lr=0.001)  # Define your optimizer\n",
    "train_ds,val_ds=dataprep(PROJECTION_DIM)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_ds):\n",
    "        # Get the inputs, attention masks, space, attention score, and labels from the dictionary\n",
    "        input_ids = data['input_ids']\n",
    "        attention_masks = data['attention_masks']\n",
    "        space = data['space']\n",
    "        attention_score = data['attention_score']\n",
    "        labels = data['label']\n",
    "        \n",
    "        \n",
    "        # print(input_ids.shape,attention_masks.shape,space.shape,attention_score.shape)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # print('ok')\n",
    "\n",
    "        # Forward pass\\ids, mks, projection_space, attention_score\n",
    "        outputs, loss = spock_model1(input_ids, attention_masks, space, attention_score)\n",
    "        # print('ok3')\n",
    "\n",
    "        # Calculate loss\n",
    "        \n",
    "        labels=labels.view(-1,1)\n",
    "        # print(outputs.dtype,labels.dtype)\n",
    "        # print(outputs.shape,labels.shape)\n",
    "        labels = labels.float()\n",
    "    \n",
    "        loss = criterion(outputs, labels)\n",
    "        # print('ok')\n",
    "\n",
    "        # Backward pass and optimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print('ok')\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5== 1999:  # Print every 2000 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Log loss to TensorBoard\n",
    "    writer.add_scalar(\"training_loss\", running_loss, epoch)\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiazliz the tensorboard to visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1st laod the teansorbaord before tarining\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 30\n",
    "# BATCH_SIZE = 16\n",
    "# PROJECTION_DIM =30\n",
    "# VECTOR_DIM = 768\n",
    "# \n",
    "# spock_model1= spock_model(MAX_LENGTH, PROJECTION_DIM)\n",
    "# spock_model1.summary()\\\n",
    "# tf.keras.backend.clear_session()\n",
    "# print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "# # Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ps aux | grep tensorboard\n",
    "# # !kill 146651\n",
    "# !pkill -f tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Model and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 32\n",
    "# PROJECTION_DIM =30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##incase the port is already using, we have to kill it forst\n",
    "# !lsof -i :6006\n",
    "# !kill 148692\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#laod the tensor board with passing the base path. Note incase of runing on VPN, I need to \n",
    "# http://192.168.1.206:8000/user/naseem_fordham/proxy/6006/ where 6006 is the local host port\n",
    "# %tensorboard --logdir $BASE_PATH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accuracy plots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot(history,path):\n",
    "    # Create a new figure for the combined plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot accuracy on the first subplot\n",
    "    axs[0].plot(history['accuracy'])\n",
    "    axs[0].plot(history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy', fontsize=12)\n",
    "    axs[0].set_ylim(0, 1, 0.1)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axs[0].legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    # Plot loss on the second subplot\n",
    "\n",
    "\n",
    "    axs[1].plot(history['loss'])\n",
    "    axs[1].plot(history['val_loss'])\n",
    "    axs[1].plot(history['Interspace'])\n",
    "    axs[1].plot(history['ToxicIntra_Loss'])\n",
    "    axs[1].plot(history['Non_toxicIntra_Loss'])\n",
    "    axs[1].plot(history['Attention_Loss'])\n",
    "    \n",
    " \n",
    "\n",
    "    axs[1].set_title('Model Loss', fontsize=12)\n",
    "    axs[1].set_ylim(0, 15, 1)\n",
    "    axs[1].set_ylabel('Loss', fontsize=12)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss','posStdDevLoss','norStdDevLoss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    axs[1].legend(['Train', 'Validation','Interspace','ToxicIntra_Loss','Non_toxicIntra_Loss','Attention_loss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "    # axs[1].legend(['Train', 'Validation','ToxicIntra_Loss','Non_toxicIntra_Loss','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    # Adjust spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    # Save the combined plot as a single image\n",
    "    plt.savefig(path, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model laoding from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def predictionLabels(i):\n",
    "    return np.where(i < 0.5, 0.0, 1.0)\n",
    "\n",
    "    \n",
    "    \n",
    "    # return np.argmax(i, axis=1)\n",
    "\n",
    "pattern = r\"_([0-9]+)$\"\n",
    "\n",
    "\n",
    "getLabels = np.vectorize(predictionLabels)\n",
    "# predictions = model.predict(test_ds)\n",
    "# predictedLabels = getLabels(predictions)\n",
    "\n",
    "BASE_PATH = f\"/home/naseem_fordham/Spock-paper/Spock_Hateoffensive/\"\n",
    "\n",
    "accuracy=[]\n",
    "# Iterate over subdirectories\n",
    "for folder_name in os.listdir(BASE_PATH):\n",
    "    print(folder_name)\n",
    "    folder_path = os.path.join(BASE_PATH, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        match = re.search(pattern, folder_name)\n",
    "        if match:\n",
    "            model_number = match.group(1)\n",
    "            print(folder_path)\n",
    "            spock_model2 = spock_model(MAX_LENGTH, int(model_number),lambda_value)\n",
    "            model_filename = os.path.join(folder_path, f\"CS_{model_number}.h5\")\n",
    "            print(model_filename)\n",
    "\n",
    "            if os.path.exists(model_filename):\n",
    "                spock_model2.load_weights(model_filename)\n",
    "                \n",
    "                history=np.load(f\"{folder_path}/training_history{model_number}.pkl\",allow_pickle=True)\n",
    "                accuracy.append(history['val_accuracy'][-1])\n",
    "                \n",
    "                # print(f\"Loaded model from {model_filename,model_number}\")\n",
    "                train_ds, val_ds = dataprep(int(model_number))\n",
    "\n",
    "                # Calculate the confusion matrix\n",
    "                predictions = spock_model2.predict(val_ds)\n",
    "                predictedLabels = predictionLabels(predictions)\n",
    "                cm = confusion_matrix(val_df['class'].values, predictedLabels)\n",
    "\n",
    "                # Calculate the confusion matrix as percentages\n",
    "                cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['Toxic', 'Non-Toxic'])\n",
    "\n",
    "                # Calculate the classification report\n",
    "                clf_report = classification_report(val_df['class'],\n",
    "                                                   predictedLabels,\n",
    "                                                   target_names=['Toxic', 'Non-Toxic'],\n",
    "                                                   output_dict=True)\n",
    "\n",
    "\n",
    "                # Create a new figure for the combined plot\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "                # Plot the confusion matrix as percentages on the left\n",
    "                disp.plot(cmap=plt.cm.Blues, values_format=\".2f\", ax=axs[0])\n",
    "                axs[0].set_title(f'Confusion Matrix of CS_{model_number}')\n",
    "\n",
    "                # Plot the classification report as a heatmap on the right\n",
    "                sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, ax=axs[1])\n",
    "                axs[1].set_title(f'Classification Report of CS_{model_number}')\n",
    "\n",
    "                # Adjust spacing between subplots\n",
    "                plt.subplots_adjust(wspace=0.5)\n",
    "                \n",
    "                \n",
    "                           # Save the combined plot as a single image\n",
    "                plt.savefig(f'{folder_path}/combined_CS_{model_number}.png')\n",
    "                plot(history,f'{folder_path}/Acc_loss{model_number}.png')\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weights and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "U7gwzlktUtH9",
    "outputId": "56a7955b-b7bf-49f7-c6b5-135b4bcb0926"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS CELL AFTER MODEL TRAINING\n",
    "\n",
    "# save model history\n",
    "\n",
    "with open(f\"{BASE_PATH}/training_historyV4.pkl\",\"wb\") as hist:\n",
    "  pickle.dump(history.history,hist)\n",
    "\n",
    "# history=np.save(f\"/home/naseem_fordham/Hate_Xplain/history/C_loss_history_{PROJECTION_DIM}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/naseem_fordham/Spock-paper/Spock_HateXplain\"\n",
    "model.load_weights(f\"{BASE_PATH}/test3.h5\")\n",
    "history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23gCGD8ZeJfE",
    "outputId": "43e84bd0-3285-47e0-9b26-f5ed8ba6102f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BASE_PATH='/home/naseem_fordham/Spock-paper/'\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)\n",
    "# history\n",
    "# import pickle\n",
    "\n",
    "# with open('/home/naseem_fordham/Spock-paper/Random_w/Model/training_historyV4.pkl', 'rb') as f:\n",
    "#     loaded_data = np.load(f,allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3kEUFa9eRfk"
   },
   "outputs": [],
   "source": [
    "# prepare test data for evaluation:\n",
    "test_gen   = dataset(test_df[\"tweet\"].values,test_df[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer, projection_dim=PROJECTION_DIM, val = True)\n",
    "test_ds = tf.data.Dataset.from_generator(test_gen,\n",
    "                                            output_signature = \n",
    "                                           ({\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VcYiveLe-Ki"
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "def predictionLabels(i):\n",
    "     return np.argmax(i, axis=1)\n",
    "\n",
    "  # if i < 0.5:\n",
    "  #   return 0.0\n",
    "  # else:\n",
    "  #   return 1.0\n",
    "\n",
    "# getLabels = np.vectorize(predictionLabels)\n",
    "predictions = model.predict(test_ds)\n",
    "predictedLabels = predictionLabels(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-Cv6nLJsSsL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "predictedLabels = predictionLabels(predictions)\n",
    "\n",
    "confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "ConfusionMatrixDisplay.from_predictions(test_df['class'].values, predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "\n",
    "# Calculate the confusion matrix as percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['0','1','2'])  # You should define class_labels\n",
    "\n",
    "# Plot the confusion matrix as percentages\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nIV_XQ00gUYz",
    "outputId": "a28ee2c7-3d22-4fa8-a4fc-16b73454c70b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# print(classification_report(y_test, predictedLabels))\n",
    "clf_report = classification_report(test_df['class'],\n",
    "                                   predictedLabels,\n",
    "                                   \n",
    "                                   target_names=[0,1,2],\n",
    "                                   output_dict=True)\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-1xVwjAJgVrt",
    "outputId": "2b7f24a8-291e-4f8b-a5a3-cf9d89f07aaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.ylim(0,1,0.1)\n",
    "\n",
    "plt.ylabel('accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',{'fontsize' : 12})\n",
    "# plt.ylim(0, ,0.05)\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation accuracy')\n",
    "# display(plt.show())\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain//acc.png\",dpi=300)\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain/Plots/plots{PROJECTION_DIM}/accu_{PROJECTION_DIM}.png\",dpi=300)\n",
    "\n",
    "#skip: plt.savefig(\"/gdrive/Shareddrives/Thesis/Results_for_thesis/spock_xhate_acc.png\",dpi=300)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# plt.yticks(np.arange(0,1,step=.1))\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.ylim(0,3,0.1)\n",
    "\n",
    "# plt.title('Training loss vs Validation Loss',fontdict = {'fontsize' : 12})\n",
    "plt.ylabel('loss',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',fontdict = {'fontsize' : 12})\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime Explainibity\n",
    "In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification## In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in train_ds.take(1):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0][\"input_ids\"]\n",
    "# # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# laoding data set and performning cleaning to ready for feed funtion,\n",
    "# here we have assigned a tem class to our data set\n",
    "df_test=pd.read_csv('/home/naseem_fordham/Spock-paper/test.txt',sep='/n', header=None,engine='python')\n",
    "df_test = df_test.rename(columns={0: 'tweet'})\n",
    "df_test\n",
    "\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "df_test['class']=1\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create generators for train and validation\n",
    "BATCH_SIZE = 32\n",
    "# make sure batch size complies with total data set\n",
    "lime_gen = dataset(df_test[\"tweet\"].values,df_test[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer,projection_dim=PROJECTION_DIM)\n",
    "\n",
    "# create tensorflow dataloaders from generators\n",
    "lime_ds = tf.data.Dataset.from_generator(lime_gen,\n",
    "                                            output_signature =\n",
    "                                           ( {\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict function which will be use later for each text in sentence\n",
    "def predict_fun(x):\n",
    "    return model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(1):\n",
    "#     t=ele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['non_hate','hate'])\n",
    "# exp=explainer.explain_instance(x, predict_fun, num_features=90, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_test['tweet'].iloc[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementing LIME on each sentence\n",
    "\"\"\"Interpretability: If you want highly interpretable explanations that focus on the most salient \n",
    "words or terms, you may choose a lower num_features value.\n",
    "\n",
    "Comprehensiveness: If you want a more comprehensive understanding of why the model made a particular\n",
    "prediction and are willing to explore a larger number of words or terms, you may choose a higher num_features value.\"\"\"\n",
    "\n",
    "\n",
    "''' 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "for i in range(1,10):\n",
    "\n",
    "    x=df_test['tweet'].iloc[i]\n",
    "    # num=len(df_test['tweet'].iloc[i].split())\n",
    "    \n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=['hate','offensive','normal'])\n",
    "    exp=explainer.explain_instance(x, predict_fun, num_features=6, labels=(0,1), num_samples=10, distance_metric='cosine')\n",
    "    exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime EXplaniation Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(0):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0]\n",
    "# # # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_res= list()\n",
    "# for tweet in df_test['tweet']:\n",
    "#   tweet = text_preprocessing(tweet)\n",
    "#   test_res.append(tweet)\n",
    "#     # print(tweet)\n",
    "\n",
    "# df_test['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96kydpg1iWwm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Input_ids=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1]))\n",
    "# # bertModel = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "# # tokenizer \n",
    "# '''In this part we are creating the bert inputs for our model and pass it to the model to predicts the class. \n",
    "# Later on we pass this predict model to LIME to underrstand which part of text is more relavent as per our model prediction'''\n",
    "\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# bmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# import torch\n",
    "# def predict(x):\n",
    "#     encoded = tokenizer(\n",
    "#     text=df_test['tweet'].tolist(),  # the sentence to be encoded\n",
    "#     add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "#     max_length = 45,  # maximum length of a sentence\n",
    "#     padding='max_length',  # Add [PAD]s\n",
    "#     return_attention_mask = True,  # Generate the attention mask\n",
    "#     return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "\n",
    "#   )\n",
    "#   # print(encoded)\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         outputs = bmodel(**encoded)\n",
    "\n",
    "#         # Evaluating the model will return a different number of objects based on \n",
    "#         # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "#         # becase we set `output_hidden_states = True`, the third item will be the \n",
    "#         # hidden states from all layers. See the documentation for more details:\n",
    "#         # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "#         # hidden_states = outputs[2]\n",
    "#         # violent_hidden_states = violent_outputs[2]\n",
    "\n",
    "#         last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "#     # print(last_hidden_states)\n",
    "\n",
    "#     x_test=last_hidden_states.numpy()\n",
    "#     # print(x_test.shape)\n",
    "#     Inputs_test=encoded['input_ids']\n",
    "#     # print(Inputs_test.shape)\n",
    "#     Inputs_test=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1])).numpy()\n",
    "#     print(Inputs_test.shape)\n",
    "\n",
    "\n",
    "#     # print(x_test.shape,Inputs_test.shape)\n",
    "#     embedding_test=embedding_index[0].reshape(embedding_index[0].shape[0],1)\n",
    "#     # embedding_test=embedding_index[:30]\n",
    "#   # embedding_test=embedding_index[:30].reshape(30,embedding_index[:30].shape[1],1)\n",
    "#   # embedding_test=embedding_index[:10].reshape(10,embedding_index.shape[1])\n",
    "#   # return model.predict([x_test,Inputs_test,embedding_test])\n",
    "  \n",
    "#     # print(embedding_test.shape)\n",
    "#     print(x_test.shape,Inputs_test.shape,embedding_test.shape)\n",
    "#     return np.array([[float(1-x), float (x)] for x in model.predict(lime_ds)])\n",
    "#     # return last_hidden_states\n",
    "# # model.predict([x_train,Input_ids,embedding_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def return_embedding_index(count):\n",
    "  \n",
    "#   embedding_index=np.array([i for i in range(count)])\n",
    "#   # embeding_index=np.array([[0,1,2]])\n",
    "#   embeding_index=np.ravel(embedding_index)\n",
    "\n",
    "#   embedding_index=np.tile(embedding_index,(len(df_test),1,))\n",
    "#   # print(embedding_index.shape, type(embeding_index))\n",
    "#   return embedding_index\n",
    "\n",
    "# embedding_index = return_embedding_index(PROJECTION_DIM)\n",
    "# embedding_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "# exp=explainer.explain_instance(x, predict, num_features=60, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# #num of sample must be same as length of the data set \n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "# for i in range(10):\n",
    "\n",
    "#     x=df_test['tweet'].iloc[i]\n",
    "\n",
    "#     explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "#     exp=explainer.explain_instance(x, predict, num_features=30, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "#     #num of sample must be same as length of the data set \n",
    "#     exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Concept Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "\n",
    "\n",
    "hate_layer = model.get_layer('hate_embedding')\n",
    "hate_embedding = hate_layer.get_weights()\n",
    "# positive_weights=positive_weights[0].T\n",
    "\n",
    "\n",
    "offensive_layer = model.get_layer('offensive_embedding')\n",
    "offensive_embedding = offensive_layer.get_weights()\n",
    "\n",
    "\n",
    "normal_layer = model.get_layer('normal_embedding')\n",
    "normal_embedding = normal_layer.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# positive_embedding = model.get_layer('positive_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# positive_embedding = specific_layer.get_weights()\n",
    "# positive_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# negative_embedding = model.get_layer('negative_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# negative_embedding = specific_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you have two weight vectors of shape (10, 768)\n",
    "\n",
    "\n",
    "\n",
    "# # Combine the two weight vectors into one array\n",
    "# combined_weight_vectors = np.vstack([offensive_embedding[0], hate_embedding[0],normal_embedding[0]])\n",
    "# tsne = TSNE(n_components=2, perplexity=2, early_exaggeration=12.0, learning_rate=20.0, n_iter=1000)\n",
    "# # Compute t-SNE embeddings\n",
    "# # tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# # Separate the t-SNE embeddings for the two weight vectors\n",
    "# tsne_embeddings1 = tsne_embeddings[:25]  # First weight vector\n",
    "# tsne_embeddings2 = tsne_embeddings[25:50]  # Second weight vector\n",
    "# tsne_embeddings3 = tsne_embeddings[50:] \n",
    "\n",
    "# # Create a scatter plot for the t-SNE embeddings\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], label='hate_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='offensive_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], label='offensive_embedding', s=5)\n",
    "# # plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='normal_embedding', s=5)\n",
    "\n",
    "# plt.xlabel('t-SNE Dimension 1')\n",
    "# plt.ylabel('t-SNE Dimension 2')\n",
    "# plt.legend()\n",
    "# plt.title('t-SNE Visualization of Weight Vectors')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import the 3D plotting module\n",
    "\n",
    "# Assuming you have three weight vectors of shape (10, 768)\n",
    "\n",
    "# Combine the three weight vectors into one array\n",
    "combined_weight_vectors = np.vstack([hate_embedding[0], offensive_embedding[0], normal_embedding[0]])\n",
    "tsne = TSNE(n_components=3, perplexity=50, early_exaggeration=12.0, learning_rate=50.0, n_iter=10000)\n",
    "\n",
    "# Compute t-SNE embeddings\n",
    "tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# Separate the t-SNE embeddings for the three weight vectors\n",
    "tsne_embeddings1 = tsne_embeddings[:25]        # First weight vector (hate)\n",
    "tsne_embeddings2 = tsne_embeddings[25:50]      # Second weight vector (offensive)\n",
    "tsne_embeddings3 = tsne_embeddings[50:]        # Third weight vector (normal)\n",
    "\n",
    "# Create a 3D scatter plot for the t-SNE embeddings\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Create a 3D axis\n",
    "\n",
    "ax.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], tsne_embeddings1[:, 2], label='hate_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], tsne_embeddings2[:, 2], label='offensive_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], tsne_embeddings3[:, 2], label='normal_embedding', s=5)\n",
    "\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "ax.set_zlabel('t-SNE Dimension 3')\n",
    "plt.legend()\n",
    "plt.title('3D t-SNE Visualization of Weight Vectors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMciCgoRuYPP4D87bGoAjIQ",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06285d669e92494192637cb3ee5a40f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f14c359d92748268810099e6cdd1fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06285d669e92494192637cb3ee5a40f4",
      "placeholder": "​",
      "style": "IPY_MODEL_209ee3e0949b446b8c58c57989065c5a",
      "value": " 232k/232k [00:00&lt;00:00, 2.84MB/s]"
     }
    },
    "123641d1426541fba838576dff7f6082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17ae300ebf634778862bc211cb432eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51f1ae4e3bd4563be3eb7c04dec7a60",
      "placeholder": "​",
      "style": "IPY_MODEL_c7586ac9b41c4e75b02a6c076a458686",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "18e134c7af5d45baa952ccf06f96f3d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f1d5a79d7ec4e42add7775fa925b187",
      "placeholder": "​",
      "style": "IPY_MODEL_e89d668a4fb541ec8d75d171bf899869",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "1cf66f2a8c5f49ce98d59dae5186298d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd44792f624499b87bd768836016e88",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae841edad05b4ef9b4308308d6683fa3",
      "value": 570
     }
    },
    "1ec35f8bfadb40968f777ab7bbb55184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b0c918326174bc4b80585a52ac33e32",
      "placeholder": "​",
      "style": "IPY_MODEL_e38ea829111b4065bad8ad4a4927bc39",
      "value": " 466k/466k [00:00&lt;00:00, 8.67MB/s]"
     }
    },
    "2024092105904b418c984aae9f4118bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f0a4e1b4929448a8b0a25b202271a40",
      "placeholder": "​",
      "style": "IPY_MODEL_ac93c61a19c0474994803853194d2aa8",
      "value": " 28.0/28.0 [00:00&lt;00:00, 584B/s]"
     }
    },
    "209ee3e0949b446b8c58c57989065c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21bf2e03eac8419fa693628ab2cef02d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430a9d1768614e0596960d2a3d15d69e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_909ae03e117345f7a4b53f3045e090b7",
      "value": 231508
     }
    },
    "274875a4aa6047c9903ae3065a5d85c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31914a14cfa243388f43a02da4db24b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3258d106659040dfb7ffea47c017ed38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34bbd1edf06c4a9194bd27eaeeee32b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e574772e8b4f81bc7e02e8ebaeb258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3258d106659040dfb7ffea47c017ed38",
      "placeholder": "​",
      "style": "IPY_MODEL_f9a2caba063b4a4f98ad258044d012fb",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "3c294ab0d9a648f39ea3f3fb7dd08c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430a9d1768614e0596960d2a3d15d69e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4914d10c0f354e178de66dc11449e26a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7998e50af804d66b6af0f26b5588255",
      "placeholder": "​",
      "style": "IPY_MODEL_4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "4cc5655f9bdb42bca5d80e2849e8cd2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f0a4e1b4929448a8b0a25b202271a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1d5a79d7ec4e42add7775fa925b187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa52eecbe8a4ba38ef969fd1cf48cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50859aa086814457bcab249b35d486a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "570b9a872e614e0eab6618f306be7306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34e574772e8b4f81bc7e02e8ebaeb258",
       "IPY_MODEL_1cf66f2a8c5f49ce98d59dae5186298d",
       "IPY_MODEL_71f100b04c964a1bbde06c537f483ed7"
      ],
      "layout": "IPY_MODEL_9e1caf8b23fb4eb1976f808269d1dd3e"
     }
    },
    "5a072e1f73624ea5aa35e7e18af17f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a0c04349bae44f4a7130463ded826d1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f11959bab964aad822250b6e6853cb8",
      "value": 466062
     }
    },
    "672e978f9b524c5784553abd8cc91507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17ae300ebf634778862bc211cb432eef",
       "IPY_MODEL_5a072e1f73624ea5aa35e7e18af17f50",
       "IPY_MODEL_1ec35f8bfadb40968f777ab7bbb55184"
      ],
      "layout": "IPY_MODEL_274875a4aa6047c9903ae3065a5d85c2"
     }
    },
    "69d90bdca5174dfb91f5cf124884095e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71d0c2b02f0c4a609477bc31aa880938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c12c857f159443f1b2a661fcd7afa002",
       "IPY_MODEL_989933f9c84a47d4b64d5b5441a1f492",
       "IPY_MODEL_2024092105904b418c984aae9f4118bf"
      ],
      "layout": "IPY_MODEL_4cc5655f9bdb42bca5d80e2849e8cd2b"
     }
    },
    "71f100b04c964a1bbde06c537f483ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34bbd1edf06c4a9194bd27eaeeee32b2",
      "placeholder": "​",
      "style": "IPY_MODEL_ea850e74cb6a4121a456578b29ce7955",
      "value": " 570/570 [00:00&lt;00:00, 5.04kB/s]"
     }
    },
    "8a0c04349bae44f4a7130463ded826d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "909ae03e117345f7a4b53f3045e090b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "989933f9c84a47d4b64d5b5441a1f492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9910be9c8b7b4188936721e958ca15c5",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50859aa086814457bcab249b35d486a8",
      "value": 28
     }
    },
    "9910be9c8b7b4188936721e958ca15c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0c918326174bc4b80585a52ac33e32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1caf8b23fb4eb1976f808269d1dd3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f11959bab964aad822250b6e6853cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a51f1ae4e3bd4563be3eb7c04dec7a60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac93c61a19c0474994803853194d2aa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae841edad05b4ef9b4308308d6683fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5516712d5304670a05ec871eb5896a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c12c857f159443f1b2a661fcd7afa002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd56d3ae17774e5496a7fdcbcb57b874",
      "placeholder": "​",
      "style": "IPY_MODEL_b5516712d5304670a05ec871eb5896a4",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "c7586ac9b41c4e75b02a6c076a458686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfe933364a3147368660f5463f1e5a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69dfd21bce04204b3220b71b4d4a968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4914d10c0f354e178de66dc11449e26a",
       "IPY_MODEL_f554ec9fe80a408680aa7b0a1c6837ac",
       "IPY_MODEL_f4ec333b7c654876a6caad010e88c203"
      ],
      "layout": "IPY_MODEL_cfe933364a3147368660f5463f1e5a29"
     }
    },
    "dfd44792f624499b87bd768836016e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e38ea829111b4065bad8ad4a4927bc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e89d668a4fb541ec8d75d171bf899869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e99b3d05437f4cdf9e1700e3cf466b34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea850e74cb6a4121a456578b29ce7955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee12049f5a9c4505b9769a4ff9c36477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18e134c7af5d45baa952ccf06f96f3d8",
       "IPY_MODEL_21bf2e03eac8419fa693628ab2cef02d",
       "IPY_MODEL_0f14c359d92748268810099e6cdd1fc3"
      ],
      "layout": "IPY_MODEL_e99b3d05437f4cdf9e1700e3cf466b34"
     }
    },
    "f4ec333b7c654876a6caad010e88c203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d90bdca5174dfb91f5cf124884095e",
      "placeholder": "​",
      "style": "IPY_MODEL_123641d1426541fba838576dff7f6082",
      "value": " 440M/440M [00:06&lt;00:00, 121MB/s]"
     }
    },
    "f554ec9fe80a408680aa7b0a1c6837ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31914a14cfa243388f43a02da4db24b6",
      "value": 440449768
     }
    },
    "f7998e50af804d66b6af0f26b5588255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a2caba063b4a4f98ad258044d012fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd56d3ae17774e5496a7fdcbcb57b874": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
